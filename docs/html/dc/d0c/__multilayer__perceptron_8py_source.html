<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Code Cloning Analysis: /home/jam/Research/IRES-2025/dev/src/llm-scripts/testing/hypothesis-testing/hyp-env/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py Source File</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../clipboard.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Code Cloning Analysis
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('dc/d0c/__multilayer__perceptron_8py_source.html','../../'); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">_multilayer_perceptron.py</div></div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno"><a class="line" href="../../d8/d15/namespacesklearn_1_1neural__network_1_1__multilayer__perceptron.html">    1</a></span><span class="stringliteral">&quot;&quot;&quot;Multi-layer Perceptron&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span> </div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment"># Authors: The scikit-learn developers</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment"># SPDX-License-Identifier: BSD-3-Clause</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span> </div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="keyword">import</span> warnings</div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="keyword">from</span> abc <span class="keyword">import</span> ABC, abstractmethod</div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="keyword">from</span> itertools <span class="keyword">import</span> chain, pairwise</div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="keyword">from</span> numbers <span class="keyword">import</span> Integral, Real</div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span> </div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="keyword">import</span> <a class="code hl_namespace" href="../../da/d87/namespacescipy_1_1optimize.html">scipy.optimize</a></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span> </div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="keyword">from</span> ..base <span class="keyword">import</span> (</div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span>    BaseEstimator,</div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span>    ClassifierMixin,</div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span>    RegressorMixin,</div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span>    _fit_context,</div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span>    is_classifier,</div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span>)</div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="keyword">from</span> ..exceptions <span class="keyword">import</span> ConvergenceWarning</div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="keyword">from</span> ..metrics <span class="keyword">import</span> accuracy_score, r2_score</div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="keyword">from</span> ..model_selection <span class="keyword">import</span> train_test_split</div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="keyword">from</span> ..preprocessing <span class="keyword">import</span> LabelBinarizer</div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span><span class="keyword">from</span> ..utils <span class="keyword">import</span> (</div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span>    _safe_indexing,</div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span>    check_random_state,</div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span>    column_or_1d,</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span>    gen_batches,</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span>    shuffle,</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span>)</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span><span class="keyword">from</span> ..utils._param_validation <span class="keyword">import</span> Interval, Options, StrOptions</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span><span class="keyword">from</span> ..utils.extmath <span class="keyword">import</span> safe_sparse_dot</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span><span class="keyword">from</span> ..utils.fixes <span class="keyword">import</span> _get_additional_lbfgs_options_dict</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span><span class="keyword">from</span> ..utils.metaestimators <span class="keyword">import</span> available_if</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span><span class="keyword">from</span> ..utils.multiclass <span class="keyword">import</span> (</div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span>    _check_partial_fit_first_call,</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span>    type_of_target,</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>    unique_labels,</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span>)</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span><span class="keyword">from</span> ..utils.optimize <span class="keyword">import</span> _check_optimize_result</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span><span class="keyword">from</span> ..utils.validation <span class="keyword">import</span> _check_sample_weight, check_is_fitted, validate_data</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span><span class="keyword">from</span> ._base <span class="keyword">import</span> ACTIVATIONS, DERIVATIVES, LOSS_FUNCTIONS</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span><span class="keyword">from</span> ._stochastic_optimizers <span class="keyword">import</span> AdamOptimizer, SGDOptimizer</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span> </div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>_STOCHASTIC_SOLVERS = [<span class="stringliteral">&quot;sgd&quot;</span>, <span class="stringliteral">&quot;adam&quot;</span>]</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span> </div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span> </div>
<div class="foldopen" id="foldopen00049" data-start="" data-end="">
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno"><a class="line" href="../../d8/d15/namespacesklearn_1_1neural__network_1_1__multilayer__perceptron.html#a1882a2fc5fa03f538467faae921802a5">   49</a></span><span class="keyword">def </span><a class="code hl_function" href="../../d8/d15/namespacesklearn_1_1neural__network_1_1__multilayer__perceptron.html#a1882a2fc5fa03f538467faae921802a5">_pack</a>(coefs_, intercepts_):</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>    <span class="stringliteral">&quot;&quot;&quot;Pack the parameters into a single vector.&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>    <span class="keywordflow">return</span> np.hstack([l.ravel() <span class="keywordflow">for</span> l <span class="keywordflow">in</span> coefs_ + intercepts_])</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span> </div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span> </div>
</div>
<div class="foldopen" id="foldopen00054" data-start="" data-end="">
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno"><a class="line" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html">   54</a></span><span class="keyword">class </span><a class="code hl_class" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html">BaseMultilayerPerceptron</a>(<a class="code hl_class" href="../../d3/d20/classsklearn_1_1base_1_1BaseEstimator.html">BaseEstimator</a>, <a class="code hl_class" href="../../dd/d9b/classABC.html">ABC</a>):</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span>    <span class="stringliteral">&quot;&quot;&quot;Base class for MLP classification and regression.</span></div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span><span class="stringliteral">    Warning: This class should not be used directly.</span></div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span><span class="stringliteral">    Use derived classes instead.</span></div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span><span class="stringliteral">    .. versionadded:: 0.18</span></div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span> </div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>    _parameter_constraints: dict = {</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>        <span class="stringliteral">&quot;hidden_layer_sizes&quot;</span>: [</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>            <span class="stringliteral">&quot;array-like&quot;</span>,</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>            <a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Integral, 1, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;left&quot;</span>),</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>        ],</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>        <span class="stringliteral">&quot;activation&quot;</span>: [<a class="code hl_class" href="../../d1/da1/classsklearn_1_1utils_1_1__param__validation_1_1StrOptions.html">StrOptions</a>({<span class="stringliteral">&quot;identity&quot;</span>, <span class="stringliteral">&quot;logistic&quot;</span>, <span class="stringliteral">&quot;tanh&quot;</span>, <span class="stringliteral">&quot;relu&quot;</span>})],</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>        <span class="stringliteral">&quot;solver&quot;</span>: [<a class="code hl_class" href="../../d1/da1/classsklearn_1_1utils_1_1__param__validation_1_1StrOptions.html">StrOptions</a>({<span class="stringliteral">&quot;lbfgs&quot;</span>, <span class="stringliteral">&quot;sgd&quot;</span>, <span class="stringliteral">&quot;adam&quot;</span>})],</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>        <span class="stringliteral">&quot;alpha&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Real, 0, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;left&quot;</span>)],</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>        <span class="stringliteral">&quot;batch_size&quot;</span>: [</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>            <a class="code hl_class" href="../../d1/da1/classsklearn_1_1utils_1_1__param__validation_1_1StrOptions.html">StrOptions</a>({<span class="stringliteral">&quot;auto&quot;</span>}),</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>            <a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Integral, 1, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;left&quot;</span>),</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>        ],</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>        <span class="stringliteral">&quot;learning_rate&quot;</span>: [<a class="code hl_class" href="../../d1/da1/classsklearn_1_1utils_1_1__param__validation_1_1StrOptions.html">StrOptions</a>({<span class="stringliteral">&quot;constant&quot;</span>, <span class="stringliteral">&quot;invscaling&quot;</span>, <span class="stringliteral">&quot;adaptive&quot;</span>})],</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>        <span class="stringliteral">&quot;learning_rate_init&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Real, 0, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;neither&quot;</span>)],</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>        <span class="stringliteral">&quot;power_t&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Real, 0, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;left&quot;</span>)],</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>        <span class="stringliteral">&quot;max_iter&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Integral, 1, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;left&quot;</span>)],</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>        <span class="stringliteral">&quot;shuffle&quot;</span>: [<span class="stringliteral">&quot;boolean&quot;</span>],</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>        <span class="stringliteral">&quot;random_state&quot;</span>: [<span class="stringliteral">&quot;random_state&quot;</span>],</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>        <span class="stringliteral">&quot;tol&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Real, 0, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;left&quot;</span>)],</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>        <span class="stringliteral">&quot;verbose&quot;</span>: [<span class="stringliteral">&quot;verbose&quot;</span>],</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>        <span class="stringliteral">&quot;warm_start&quot;</span>: [<span class="stringliteral">&quot;boolean&quot;</span>],</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>        <span class="stringliteral">&quot;momentum&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Real, 0, 1, closed=<span class="stringliteral">&quot;both&quot;</span>)],</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>        <span class="stringliteral">&quot;nesterovs_momentum&quot;</span>: [<span class="stringliteral">&quot;boolean&quot;</span>],</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>        <span class="stringliteral">&quot;early_stopping&quot;</span>: [<span class="stringliteral">&quot;boolean&quot;</span>],</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>        <span class="stringliteral">&quot;validation_fraction&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Real, 0, 1, closed=<span class="stringliteral">&quot;left&quot;</span>)],</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>        <span class="stringliteral">&quot;beta_1&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Real, 0, 1, closed=<span class="stringliteral">&quot;left&quot;</span>)],</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>        <span class="stringliteral">&quot;beta_2&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Real, 0, 1, closed=<span class="stringliteral">&quot;left&quot;</span>)],</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>        <span class="stringliteral">&quot;epsilon&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Real, 0, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;neither&quot;</span>)],</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>        <span class="stringliteral">&quot;n_iter_no_change&quot;</span>: [</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>            <a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Integral, 1, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;left&quot;</span>),</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>            <a class="code hl_class" href="../../d1/d66/classsklearn_1_1utils_1_1__param__validation_1_1Options.html">Options</a>(Real, {np.inf}),</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>        ],</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>        <span class="stringliteral">&quot;max_fun&quot;</span>: [<a class="code hl_class" href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">Interval</a>(Integral, 1, <span class="keywordtype">None</span>, closed=<span class="stringliteral">&quot;left&quot;</span>)],</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>    }</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span> </div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>    <span class="preprocessor">@abstractmethod</span></div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>    <span class="keyword">def </span>__init__(</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>        self,</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>        hidden_layer_sizes,</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>        activation,</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>        solver,</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>        alpha,</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>        batch_size,</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>        learning_rate,</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>        learning_rate_init,</div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>        power_t,</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>        max_iter,</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>        loss,</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>        shuffle,</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>        random_state,</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>        tol,</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>        verbose,</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>        warm_start,</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>        momentum,</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>        nesterovs_momentum,</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>        early_stopping,</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>        validation_fraction,</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>        beta_1,</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>        beta_2,</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>        epsilon,</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>        n_iter_no_change,</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>        max_fun,</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>    ):</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#afa5470b39ae914ecb63c854752afd667">activation</a> = activation</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aff5cec0cbb94c15f464c19ff02b738dc">solver</a> = solver</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a2b40afead813fd9060912fdc5c8c5585">alpha</a> = alpha</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a99d828d71d0571f169342d7b4dc54a57">batch_size</a> = batch_size</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0bd28615806017485087b01098172f8f">learning_rate</a> = learning_rate</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a7bb6a222df4472c2f8219ba605f490c3">learning_rate_init</a> = learning_rate_init</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#adb94c71df194fdc6d51b67e8e5bc93bc">power_t</a> = power_t</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a318bdf742f2e44c92f36b7a0c0912a83">max_iter</a> = max_iter</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0368ec6ff4ec3ab92c5ca109d4e80721">loss</a> = loss</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a7053e621a032a08513a2453f2367bd74">hidden_layer_sizes</a> = hidden_layer_sizes</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a3dc00b9cd7811c0f2a93016e9c31557a">shuffle</a> = shuffle</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5f9e6d09bc3196361c46192640196624">random_state</a> = random_state</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af3fc521b13aae045b9e10387f34b0ba1">tol</a> = tol</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#abb3113bc3c7d179d4a7e9443f2090036">verbose</a> = verbose</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a96c5a6ce572a9cfe24350c3f1b737116">warm_start</a> = warm_start</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad05c99ca6c9254da855b5d3fd2728f34">momentum</a> = momentum</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa19a4c76b460a193cd87c03cc5e30280">nesterovs_momentum</a> = nesterovs_momentum</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa019948ee2d7ac810cea9942dd3d5187">early_stopping</a> = early_stopping</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a85298d7736f4e7fe4b167fc8ff51aaa6">validation_fraction</a> = validation_fraction</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af338625696b13b08848be17ec42a3bcb">beta_1</a> = beta_1</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a4a0b9ab6cfff8afb6a02e09c65bfe064">beta_2</a> = beta_2</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0c95ef33cbc4840aa36c1cee559e1c9b">epsilon</a> = epsilon</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f052dea4e28c577fa309c8c104ea9f7">n_iter_no_change</a> = n_iter_no_change</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad0fedbabf4cba29b7e6800c566ed759e">max_fun</a> = max_fun</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span> </div>
<div class="foldopen" id="foldopen00151" data-start="" data-end="">
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno"><a class="line" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ab5407ee4ebf264a65951d66ac2dca857">  151</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ab5407ee4ebf264a65951d66ac2dca857">_unpack</a>(self, packed_parameters):</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>        <span class="stringliteral">&quot;&quot;&quot;Extract the coefficients and intercepts from packed_parameters.&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a> - 1):</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>            start, end, shape = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f8ac62cfaa9e175770b6e3acd1e7ac0">_coef_indptr</a>[i]</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>[i] = np.reshape(packed_parameters[start:end], shape)</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span> </div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>            start, end = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#afee67bc813d4cdc01e30d33c23b45f77">_intercept_indptr</a>[i]</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a>[i] = packed_parameters[start:end]</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span> </div>
</div>
<div class="foldopen" id="foldopen00160" data-start="" data-end="">
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno"><a class="line" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a446fb221b8ffb5dac45f7b0506729351">  160</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a446fb221b8ffb5dac45f7b0506729351">_forward_pass</a>(self, activations):</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>        <span class="stringliteral">&quot;&quot;&quot;Perform a forward pass on the network by computing the values</span></div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span><span class="stringliteral">        of the neurons in the hidden layers and the output layer.</span></div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span><span class="stringliteral">        activations : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span><span class="stringliteral">            The ith element of the list holds the values of the ith layer.</span></div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>        hidden_activation = ACTIVATIONS[self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#afa5470b39ae914ecb63c854752afd667">activation</a>]</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>        <span class="comment"># Iterate over the hidden layers</span></div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a> - 1):</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>            activations[i + 1] = safe_sparse_dot(activations[i], self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>[i])</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>            activations[i + 1] += self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a>[i]</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span> </div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>            <span class="comment"># For the hidden layers</span></div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>            <span class="keywordflow">if</span> (i + 1) != (self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a> - 1):</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>                hidden_activation(activations[i + 1])</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span> </div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>        <span class="comment"># For the last layer</span></div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>        output_activation = ACTIVATIONS[self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6ef171715977706490c0d6f09cefeb89">out_activation_</a>]</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>        output_activation(activations[i + 1])</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span> </div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>        <span class="keywordflow">return</span> activations</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span> </div>
</div>
<div class="foldopen" id="foldopen00185" data-start="" data-end="">
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno"><a class="line" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a65cb479141ebeb9fd5e77845b242979b">  185</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a65cb479141ebeb9fd5e77845b242979b">_forward_pass_fast</a>(self, X, check_input=True):</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>        <span class="stringliteral">&quot;&quot;&quot;Predict using the trained model</span></div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span><span class="stringliteral">        This is the same as _forward_pass but does not record the activations</span></div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span><span class="stringliteral">        of all layers and only returns the last layer&#39;s activation.</span></div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span><span class="stringliteral">        check_input : bool, default=True</span></div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span><span class="stringliteral">            Perform input data validation or not.</span></div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span><span class="stringliteral">        Returns</span></div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span><span class="stringliteral">        -------</span></div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span><span class="stringliteral">        y_pred : ndarray of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span><span class="stringliteral">            The decision function of the samples for each class in the model.</span></div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>        <span class="keywordflow">if</span> check_input:</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>            X = validate_data(self, X, accept_sparse=[<span class="stringliteral">&quot;csr&quot;</span>, <span class="stringliteral">&quot;csc&quot;</span>], reset=<span class="keyword">False</span>)</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span> </div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>        <span class="comment"># Initialize first layer</span></div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>        activation = X</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span> </div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>        <span class="comment"># Forward propagate</span></div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>        hidden_activation = ACTIVATIONS[self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#afa5470b39ae914ecb63c854752afd667">activation</a>]</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a> - 1):</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>            activation = safe_sparse_dot(activation, self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>[i])</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>            activation += self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a>[i]</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>            <span class="keywordflow">if</span> i != self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a> - 2:</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>                hidden_activation(activation)</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>        output_activation = ACTIVATIONS[self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6ef171715977706490c0d6f09cefeb89">out_activation_</a>]</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>        output_activation(activation)</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span> </div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>        <span class="keywordflow">return</span> activation</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span> </div>
</div>
<div class="foldopen" id="foldopen00222" data-start="" data-end="">
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno"><a class="line" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f969a1c0f205f30a10977d58a3f5837">  222</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f969a1c0f205f30a10977d58a3f5837">_compute_loss_grad</a>(</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>        self, layer, sw_sum, activations, deltas, coef_grads, intercept_grads</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>    ):</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>        <span class="stringliteral">&quot;&quot;&quot;Compute the gradient of loss with respect to coefs and intercept for</span></div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span><span class="stringliteral">        specified layer.</span></div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span><span class="stringliteral">        This function does backpropagation for the specified one layer.</span></div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>        coef_grads[layer] = safe_sparse_dot(activations[layer].T, deltas[layer])</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>        coef_grads[layer] += self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a2b40afead813fd9060912fdc5c8c5585">alpha</a> * self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>[layer]</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>        coef_grads[layer] /= sw_sum</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span> </div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>        intercept_grads[layer] = np.sum(deltas[layer], axis=0) / sw_sum</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span> </div>
</div>
<div class="foldopen" id="foldopen00236" data-start="" data-end="">
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno"><a class="line" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6f936f142295a4ed0e612fb834147f72">  236</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6f936f142295a4ed0e612fb834147f72">_loss_grad_lbfgs</a>(</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>        self,</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>        packed_coef_inter,</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>        X,</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>        y,</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>        sample_weight,</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>        activations,</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>        deltas,</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>        coef_grads,</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>        intercept_grads,</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>    ):</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>        <span class="stringliteral">&quot;&quot;&quot;Compute the MLP loss function and its corresponding derivatives</span></div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span><span class="stringliteral">        with respect to the different parameters given in the initialization.</span></div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span><span class="stringliteral">        Returned gradients are packed in a single vector so it can be used</span></div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span><span class="stringliteral">        in lbfgs</span></div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span><span class="stringliteral">        packed_coef_inter : ndarray</span></div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span><span class="stringliteral">            A vector comprising the flattened coefficients and intercepts.</span></div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span><span class="stringliteral">        y : ndarray of shape (n_samples,)</span></div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span><span class="stringliteral">            The target values.</span></div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span><span class="stringliteral">        sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span><span class="stringliteral">        activations : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span><span class="stringliteral">            The ith element of the list holds the values of the ith layer.</span></div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span><span class="stringliteral">        deltas : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span><span class="stringliteral">            The ith element of the list holds the difference between the</span></div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span><span class="stringliteral">            activations of the i + 1 layer and the backpropagated error.</span></div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span><span class="stringliteral">            More specifically, deltas are gradients of loss with respect to z</span></div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span><span class="stringliteral">            in each layer, where z = wx + b is the value of a particular layer</span></div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span><span class="stringliteral">            before passing through the activation function</span></div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span><span class="stringliteral">        coef_grads : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span><span class="stringliteral">            The ith element contains the amount of change used to update the</span></div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span><span class="stringliteral">            coefficient parameters of the ith layer in an iteration.</span></div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span><span class="stringliteral">        intercept_grads : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span><span class="stringliteral">            The ith element contains the amount of change used to update the</span></div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span><span class="stringliteral">            intercept parameters of the ith layer in an iteration.</span></div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span><span class="stringliteral">        Returns</span></div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span><span class="stringliteral">        -------</span></div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span><span class="stringliteral">        loss : float</span></div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span><span class="stringliteral">        grad : array-like, shape (number of nodes of all layers,)</span></div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>        self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ab5407ee4ebf264a65951d66ac2dca857">_unpack</a>(packed_coef_inter)</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>        loss, coef_grads, intercept_grads = self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a706a1c60c73f17d042b1ca83f395981b">_backprop</a>(</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>            X, y, sample_weight, activations, deltas, coef_grads, intercept_grads</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>        )</div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>        grad = <a class="code hl_function" href="../../d8/d15/namespacesklearn_1_1neural__network_1_1__multilayer__perceptron.html#a1882a2fc5fa03f538467faae921802a5">_pack</a>(coef_grads, intercept_grads)</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>        <span class="keywordflow">return</span> loss, grad</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span> </div>
</div>
<div class="foldopen" id="foldopen00297" data-start="" data-end="">
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno"><a class="line" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a706a1c60c73f17d042b1ca83f395981b">  297</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a706a1c60c73f17d042b1ca83f395981b">_backprop</a>(</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>        self, X, y, sample_weight, activations, deltas, coef_grads, intercept_grads</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>    ):</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>        <span class="stringliteral">&quot;&quot;&quot;Compute the MLP loss function and its corresponding derivatives</span></div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span><span class="stringliteral">        with respect to each parameter: weights and bias vectors.</span></div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span><span class="stringliteral">        y : ndarray of shape (n_samples,)</span></div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span><span class="stringliteral">            The target values.</span></div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span><span class="stringliteral">        sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span><span class="stringliteral">        activations : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span><span class="stringliteral">             The ith element of the list holds the values of the ith layer.</span></div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span><span class="stringliteral">        deltas : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span><span class="stringliteral">            The ith element of the list holds the difference between the</span></div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span><span class="stringliteral">            activations of the i + 1 layer and the backpropagated error.</span></div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span><span class="stringliteral">            More specifically, deltas are gradients of loss with respect to z</span></div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span><span class="stringliteral">            in each layer, where z = wx + b is the value of a particular layer</span></div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span><span class="stringliteral">            before passing through the activation function</span></div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span><span class="stringliteral">        coef_grads : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span><span class="stringliteral">            The ith element contains the amount of change used to update the</span></div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span><span class="stringliteral">            coefficient parameters of the ith layer in an iteration.</span></div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span><span class="stringliteral">        intercept_grads : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span><span class="stringliteral">            The ith element contains the amount of change used to update the</span></div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span><span class="stringliteral">            intercept parameters of the ith layer in an iteration.</span></div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span><span class="stringliteral">        Returns</span></div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span><span class="stringliteral">        -------</span></div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span><span class="stringliteral">        loss : float</span></div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span><span class="stringliteral">        coef_grads : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span><span class="stringliteral">        intercept_grads : list, length = n_layers - 1</span></div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>        n_samples = X.shape[0]</div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span> </div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span>        <span class="comment"># Forward propagate</span></div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>        activations = self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a446fb221b8ffb5dac45f7b0506729351">_forward_pass</a>(activations)</div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span> </div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>        <span class="comment"># Get loss</span></div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span>        loss_func_name = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0368ec6ff4ec3ab92c5ca109d4e80721">loss</a></div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span>        <span class="keywordflow">if</span> loss_func_name == <span class="stringliteral">&quot;log_loss&quot;</span> <span class="keywordflow">and</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6ef171715977706490c0d6f09cefeb89">out_activation_</a> == <span class="stringliteral">&quot;logistic&quot;</span>:</div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>            loss_func_name = <span class="stringliteral">&quot;binary_log_loss&quot;</span></div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>        loss = LOSS_FUNCTIONS[loss_func_name](y, activations[-1], sample_weight)</div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>        <span class="comment"># Add L2 regularization term to loss</span></div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>        values = 0</div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>        <span class="keywordflow">for</span> s <span class="keywordflow">in</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>:</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>            s = s.ravel()</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span>            values += np.dot(s, s)</div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>            sw_sum = n_samples</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>            sw_sum = sample_weight.sum()</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>        loss += (0.5 * self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a2b40afead813fd9060912fdc5c8c5585">alpha</a>) * values / sw_sum</div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span> </div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>        <span class="comment"># Backward propagate</span></div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>        last = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a> - 2</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span> </div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>        <span class="comment"># The calculation of delta[last] is as follows:</span></div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>        <span class="comment">#   delta[last] = d/dz loss(y, act(z)) = act(z) - y</span></div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span>        <span class="comment"># with z=x@w + b being the output of the last layer before passing through the</span></div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>        <span class="comment"># output activation, act(z) = activations[-1].</span></div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>        <span class="comment"># The simple formula for delta[last] here works with following (canonical</span></div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>        <span class="comment"># loss-link) combinations of output activation and loss function:</span></div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>        <span class="comment"># sigmoid and binary cross entropy, softmax and categorical cross</span></div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>        <span class="comment"># entropy, and identity with squared loss</span></div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>        deltas[last] = activations[-1] - y</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span>            deltas[last] *= sample_weight.reshape(-1, 1)</div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span> </div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>        <span class="comment"># Compute gradient for the last layer</span></div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>        self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f969a1c0f205f30a10977d58a3f5837">_compute_loss_grad</a>(</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>            last, sw_sum, activations, deltas, coef_grads, intercept_grads</div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>        )</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span> </div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>        inplace_derivative = DERIVATIVES[self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#afa5470b39ae914ecb63c854752afd667">activation</a>]</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>        <span class="comment"># Iterate over the hidden layers</span></div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(last, 0, -1):</div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>            deltas[i - 1] = safe_sparse_dot(deltas[i], self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>[i].T)</div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span>            inplace_derivative(activations[i], deltas[i - 1])</div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span> </div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span>            self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f969a1c0f205f30a10977d58a3f5837">_compute_loss_grad</a>(</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>                i - 1, sw_sum, activations, deltas, coef_grads, intercept_grads</div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span>            )</div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span> </div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>        <span class="keywordflow">return</span> loss, coef_grads, intercept_grads</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span> </div>
</div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>    <span class="keyword">def </span>_initialize(self, y, layer_units, dtype):</div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>        <span class="comment"># set all attributes, allocate weights etc. for first call</span></div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>        <span class="comment"># Initialize parameters</span></div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac4db5d73babe4976fac6b50ac73dccec">n_iter_</a> = 0</div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a1cdc4a9b4f8c1d00572be3ba7400d728">t_</a> = 0</div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac913f3e320e35d56add32462793c14e7">n_outputs_</a> = y.shape[1]</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span> </div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>        <span class="comment"># Compute the number of layers</span></div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a> = len(layer_units)</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span> </div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>        <span class="comment"># Output for regression</span></div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> is_classifier(self):</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span>            <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0368ec6ff4ec3ab92c5ca109d4e80721">loss</a> == <span class="stringliteral">&quot;poisson&quot;</span>:</div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6ef171715977706490c0d6f09cefeb89">out_activation_</a> = <span class="stringliteral">&quot;exp&quot;</span></div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span>                <span class="comment"># loss = &quot;squared_error&quot;</span></div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6ef171715977706490c0d6f09cefeb89">out_activation_</a> = <span class="stringliteral">&quot;identity&quot;</span></div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span>        <span class="comment"># Output for multi class</span></div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span>        <span class="keywordflow">elif</span> self._label_binarizer.y_type_ == <span class="stringliteral">&quot;multiclass&quot;</span>:</div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6ef171715977706490c0d6f09cefeb89">out_activation_</a> = <span class="stringliteral">&quot;softmax&quot;</span></div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span>        <span class="comment"># Output for binary class and multi-label</span></div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6ef171715977706490c0d6f09cefeb89">out_activation_</a> = <span class="stringliteral">&quot;logistic&quot;</span></div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span> </div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>        <span class="comment"># Initialize coefficient and intercept layers</span></div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a> = []</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a> = []</div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span> </div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a> - 1):</div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>            coef_init, intercept_init = self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a7e03c7f5817e706517ad8ca12110c99f">_init_coef</a>(</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>                layer_units[i], layer_units[i + 1], dtype</div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span>            )</div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>.append(coef_init)</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a>.append(intercept_init)</div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span> </div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a98812cf40a7067db51eba0c802f3d8f8">_best_coefs</a> = [c.copy() <span class="keywordflow">for</span> c <span class="keywordflow">in</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>]</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a09f3f5db1df292bba142574f372f80a7">_best_intercepts</a> = [i.copy() <span class="keywordflow">for</span> i <span class="keywordflow">in</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a>]</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span> </div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span>        <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aff5cec0cbb94c15f464c19ff02b738dc">solver</a> <span class="keywordflow">in</span> _STOCHASTIC_SOLVERS:</div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a24d8114c5f7a2c9fc35242135857f8ae">loss_curve_</a> = []</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a669612405aaf465d9489e5cbd6442a7a">_no_improvement_count</a> = 0</div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span>            <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa019948ee2d7ac810cea9942dd3d5187">early_stopping</a>:</div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0d765db3f3c8659b1d818a7b0bbbcd5e">validation_scores_</a> = []</div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af9772e422910c066bd1214dc5e01f984">best_validation_score_</a> = -np.inf</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a70a6072759ac7ac36b964c80d3620525">best_loss_</a> = <span class="keywordtype">None</span></div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a70a6072759ac7ac36b964c80d3620525">best_loss_</a> = np.inf</div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0d765db3f3c8659b1d818a7b0bbbcd5e">validation_scores_</a> = <span class="keywordtype">None</span></div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af9772e422910c066bd1214dc5e01f984">best_validation_score_</a> = <span class="keywordtype">None</span></div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span> </div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span>    <span class="keyword">def </span>_init_coef(self, fan_in, fan_out, dtype):</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>        <span class="comment"># Use the initialization method recommended by</span></div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>        <span class="comment"># Glorot et al.</span></div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>        factor = 6.0</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>        <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#afa5470b39ae914ecb63c854752afd667">activation</a> == <span class="stringliteral">&quot;logistic&quot;</span>:</div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>            factor = 2.0</div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>        init_bound = np.sqrt(factor / (fan_in + fan_out))</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span> </div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span>        <span class="comment"># Generate weights and bias:</span></div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span>        coef_init = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a215bc7c01b70f8525b1e8f1c0c035e4a">_random_state</a>.uniform(</div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>            -init_bound, init_bound, (fan_in, fan_out)</div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>        )</div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>        intercept_init = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a215bc7c01b70f8525b1e8f1c0c035e4a">_random_state</a>.uniform(-init_bound, init_bound, fan_out)</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>        coef_init = coef_init.astype(dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>        intercept_init = intercept_init.astype(dtype, copy=<span class="keyword">False</span>)</div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span>        <span class="keywordflow">return</span> coef_init, intercept_init</div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span> </div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>    <span class="keyword">def </span>_fit(self, X, y, sample_weight=None, incremental=False):</div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span>        <span class="comment"># Make sure self.hidden_layer_sizes is a list</span></div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>        hidden_layer_sizes = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a7053e621a032a08513a2453f2367bd74">hidden_layer_sizes</a></div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> hasattr(hidden_layer_sizes, <span class="stringliteral">&quot;__iter__&quot;</span>):</div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>            hidden_layer_sizes = [hidden_layer_sizes]</div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span>        hidden_layer_sizes = list(hidden_layer_sizes)</div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span> </div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span>        <span class="keywordflow">if</span> np.any(np.array(hidden_layer_sizes) &lt;= 0):</div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>            <span class="keywordflow">raise</span> <a class="code hl_class" href="../../de/d40/classValueError.html">ValueError</a>(</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>                <span class="stringliteral">&quot;hidden_layer_sizes must be &gt; 0, got %s.&quot;</span> % hidden_layer_sizes</div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span>            )</div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span>        first_pass = <span class="keywordflow">not</span> hasattr(self, <span class="stringliteral">&quot;coefs_&quot;</span>) <span class="keywordflow">or</span> (</div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>            <span class="keywordflow">not</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a96c5a6ce572a9cfe24350c3f1b737116">warm_start</a> <span class="keywordflow">and</span> <span class="keywordflow">not</span> incremental</div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span>        )</div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span> </div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span>        X, y = self._validate_input(X, y, incremental, reset=first_pass)</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>        n_samples, n_features = X.shape</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span>        <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>            sample_weight = _check_sample_weight(sample_weight, X)</div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span> </div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span>        <span class="comment"># Ensure y is 2D</span></div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>        <span class="keywordflow">if</span> y.ndim == 1:</div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>            y = y.reshape((-1, 1))</div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span> </div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac913f3e320e35d56add32462793c14e7">n_outputs_</a> = y.shape[1]</div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span> </div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span>        layer_units = [n_features] + hidden_layer_sizes + [self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac913f3e320e35d56add32462793c14e7">n_outputs_</a>]</div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span> </div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>        <span class="comment"># check random state</span></div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a215bc7c01b70f8525b1e8f1c0c035e4a">_random_state</a> = check_random_state(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5f9e6d09bc3196361c46192640196624">random_state</a>)</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span> </div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>        <span class="keywordflow">if</span> first_pass:</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>            <span class="comment"># First time training the model</span></div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>            self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa8cd7dbf0b493aab5c0f7e053575be1e">_initialize</a>(y, layer_units, X.dtype)</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span> </div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span>        <span class="comment"># Initialize lists</span></div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span>        activations = [X] + [<span class="keywordtype">None</span>] * (len(layer_units) - 1)</div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span>        deltas = [<span class="keywordtype">None</span>] * (len(activations) - 1)</div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span> </div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span>        coef_grads = [</div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>            np.empty((n_fan_in_, n_fan_out_), dtype=X.dtype)</div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>            <span class="keywordflow">for</span> n_fan_in_, n_fan_out_ <span class="keywordflow">in</span> pairwise(layer_units)</div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>        ]</div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span> </div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span>        intercept_grads = [</div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span>            np.empty(n_fan_out_, dtype=X.dtype) <span class="keywordflow">for</span> n_fan_out_ <span class="keywordflow">in</span> layer_units[1:]</div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>        ]</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span> </div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span>        <span class="comment"># Run the Stochastic optimization solver</span></div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>        <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aff5cec0cbb94c15f464c19ff02b738dc">solver</a> <span class="keywordflow">in</span> _STOCHASTIC_SOLVERS:</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>            self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ae70675d98fd81222592a806f5177eae5">_fit_stochastic</a>(</div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>                X,</div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span>                y,</div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span>                sample_weight,</div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>                activations,</div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>                deltas,</div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>                coef_grads,</div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>                intercept_grads,</div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>                layer_units,</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>                incremental,</div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span>            )</div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span> </div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span>        <span class="comment"># Run the LBFGS solver</span></div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span>        <span class="keywordflow">elif</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aff5cec0cbb94c15f464c19ff02b738dc">solver</a> == <span class="stringliteral">&quot;lbfgs&quot;</span>:</div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>            self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ae5604c756ba2c76a6ee244191ad5fb23">_fit_lbfgs</a>(</div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span>                X,</div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span>                y,</div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span>                sample_weight,</div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span>                activations,</div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span>                deltas,</div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span>                coef_grads,</div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span>                intercept_grads,</div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span>                layer_units,</div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span>            )</div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span> </div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span>        <span class="comment"># validate parameter weights</span></div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span>        weights = chain(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>, self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a>)</div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> all(np.isfinite(w).all() <span class="keywordflow">for</span> w <span class="keywordflow">in</span> weights):</div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span>            <span class="keywordflow">raise</span> <a class="code hl_class" href="../../de/d40/classValueError.html">ValueError</a>(</div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span>                <span class="stringliteral">&quot;Solver produced non-finite parameter weights. The input data may&quot;</span></div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span>                <span class="stringliteral">&quot; contain large values and need to be preprocessed.&quot;</span></div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span>            )</div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span> </div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span>        <span class="keywordflow">return</span> self</div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span> </div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span>    <span class="keyword">def </span>_fit_lbfgs(</div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span>        self,</div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span>        X,</div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span>        y,</div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span>        sample_weight,</div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span>        activations,</div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span>        deltas,</div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span>        coef_grads,</div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span>        intercept_grads,</div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span>        layer_units,</div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span>    ):</div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span>        <span class="comment"># Store meta information for the parameters</span></div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f8ac62cfaa9e175770b6e3acd1e7ac0">_coef_indptr</a> = []</div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#afee67bc813d4cdc01e30d33c23b45f77">_intercept_indptr</a> = []</div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span>        start = 0</div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span> </div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span>        <span class="comment"># Save sizes and indices of coefficients for faster unpacking</span></div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a> - 1):</div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span>            n_fan_in, n_fan_out = layer_units[i], layer_units[i + 1]</div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span> </div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span>            end = start + (n_fan_in * n_fan_out)</div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f8ac62cfaa9e175770b6e3acd1e7ac0">_coef_indptr</a>.append((start, end, (n_fan_in, n_fan_out)))</div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span>            start = end</div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span> </div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span>        <span class="comment"># Save sizes and indices of intercepts for faster unpacking</span></div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">n_layers_</a> - 1):</div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span>            end = start + layer_units[i + 1]</div>
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno">  570</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#afee67bc813d4cdc01e30d33c23b45f77">_intercept_indptr</a>.append((start, end))</div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span>            start = end</div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span> </div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span>        <span class="comment"># Run LBFGS</span></div>
<div class="line"><a id="l00574" name="l00574"></a><span class="lineno">  574</span>        packed_coef_inter = <a class="code hl_function" href="../../d8/d15/namespacesklearn_1_1neural__network_1_1__multilayer__perceptron.html#a1882a2fc5fa03f538467faae921802a5">_pack</a>(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>, self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a>)</div>
<div class="line"><a id="l00575" name="l00575"></a><span class="lineno">  575</span> </div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span>        <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#abb3113bc3c7d179d4a7e9443f2090036">verbose</a> <span class="keywordflow">is</span> <span class="keyword">True</span> <span class="keywordflow">or</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#abb3113bc3c7d179d4a7e9443f2090036">verbose</a> &gt;= 1:</div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span>            iprint = 1</div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno">  579</span>            iprint = -1</div>
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno">  580</span> </div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span>        opt_res = scipy.optimize.minimize(</div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span>            self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6f936f142295a4ed0e612fb834147f72">_loss_grad_lbfgs</a>,</div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span>            packed_coef_inter,</div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span>            method=<span class="stringliteral">&quot;L-BFGS-B&quot;</span>,</div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span>            jac=<span class="keyword">True</span>,</div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span>            options={</div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span>                <span class="stringliteral">&quot;maxfun&quot;</span>: self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad0fedbabf4cba29b7e6800c566ed759e">max_fun</a>,</div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span>                <span class="stringliteral">&quot;maxiter&quot;</span>: self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a318bdf742f2e44c92f36b7a0c0912a83">max_iter</a>,</div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span>                <span class="stringliteral">&quot;gtol&quot;</span>: self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af3fc521b13aae045b9e10387f34b0ba1">tol</a>,</div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span>                **_get_additional_lbfgs_options_dict(<span class="stringliteral">&quot;iprint&quot;</span>, iprint),</div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span>            },</div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span>            args=(</div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span>                X,</div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span>                y,</div>
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno">  595</span>                sample_weight,</div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno">  596</span>                activations,</div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span>                deltas,</div>
<div class="line"><a id="l00598" name="l00598"></a><span class="lineno">  598</span>                coef_grads,</div>
<div class="line"><a id="l00599" name="l00599"></a><span class="lineno">  599</span>                intercept_grads,</div>
<div class="line"><a id="l00600" name="l00600"></a><span class="lineno">  600</span>            ),</div>
<div class="line"><a id="l00601" name="l00601"></a><span class="lineno">  601</span>        )</div>
<div class="line"><a id="l00602" name="l00602"></a><span class="lineno">  602</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac4db5d73babe4976fac6b50ac73dccec">n_iter_</a> = _check_optimize_result(<span class="stringliteral">&quot;lbfgs&quot;</span>, opt_res, self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a318bdf742f2e44c92f36b7a0c0912a83">max_iter</a>)</div>
<div class="line"><a id="l00603" name="l00603"></a><span class="lineno">  603</span>        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a27576cf472db61b06d2951267d01df7a">loss_</a> = opt_res.fun</div>
<div class="line"><a id="l00604" name="l00604"></a><span class="lineno">  604</span>        self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ab5407ee4ebf264a65951d66ac2dca857">_unpack</a>(opt_res.x)</div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span> </div>
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno">  606</span>    <span class="keyword">def </span>_fit_stochastic(</div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno">  607</span>        self,</div>
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno">  608</span>        X,</div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno">  609</span>        y,</div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span>        sample_weight,</div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span>        activations,</div>
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno">  612</span>        deltas,</div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span>        coef_grads,</div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span>        intercept_grads,</div>
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno">  615</span>        layer_units,</div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span>        incremental,</div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno">  617</span>    ):</div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span>        params = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a> + self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a></div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno">  619</span>        <span class="keywordflow">if</span> <span class="keywordflow">not</span> incremental <span class="keywordflow">or</span> <span class="keywordflow">not</span> hasattr(self, <span class="stringliteral">&quot;_optimizer&quot;</span>):</div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span>            <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aff5cec0cbb94c15f464c19ff02b738dc">solver</a> == <span class="stringliteral">&quot;sgd&quot;</span>:</div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a9335dce7fccc3077842f4deccf52ac98">_optimizer</a> = <a class="code hl_class" href="../../de/d58/classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer.html">SGDOptimizer</a>(</div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno">  622</span>                    params,</div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno">  623</span>                    self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a7bb6a222df4472c2f8219ba605f490c3">learning_rate_init</a>,</div>
<div class="line"><a id="l00624" name="l00624"></a><span class="lineno">  624</span>                    self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0bd28615806017485087b01098172f8f">learning_rate</a>,</div>
<div class="line"><a id="l00625" name="l00625"></a><span class="lineno">  625</span>                    self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad05c99ca6c9254da855b5d3fd2728f34">momentum</a>,</div>
<div class="line"><a id="l00626" name="l00626"></a><span class="lineno">  626</span>                    self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa19a4c76b460a193cd87c03cc5e30280">nesterovs_momentum</a>,</div>
<div class="line"><a id="l00627" name="l00627"></a><span class="lineno">  627</span>                    self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#adb94c71df194fdc6d51b67e8e5bc93bc">power_t</a>,</div>
<div class="line"><a id="l00628" name="l00628"></a><span class="lineno">  628</span>                )</div>
<div class="line"><a id="l00629" name="l00629"></a><span class="lineno">  629</span>            <span class="keywordflow">elif</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aff5cec0cbb94c15f464c19ff02b738dc">solver</a> == <span class="stringliteral">&quot;adam&quot;</span>:</div>
<div class="line"><a id="l00630" name="l00630"></a><span class="lineno">  630</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a9335dce7fccc3077842f4deccf52ac98">_optimizer</a> = <a class="code hl_class" href="../../d1/d67/classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1AdamOptimizer.html">AdamOptimizer</a>(</div>
<div class="line"><a id="l00631" name="l00631"></a><span class="lineno">  631</span>                    params,</div>
<div class="line"><a id="l00632" name="l00632"></a><span class="lineno">  632</span>                    self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a7bb6a222df4472c2f8219ba605f490c3">learning_rate_init</a>,</div>
<div class="line"><a id="l00633" name="l00633"></a><span class="lineno">  633</span>                    self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af338625696b13b08848be17ec42a3bcb">beta_1</a>,</div>
<div class="line"><a id="l00634" name="l00634"></a><span class="lineno">  634</span>                    self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a4a0b9ab6cfff8afb6a02e09c65bfe064">beta_2</a>,</div>
<div class="line"><a id="l00635" name="l00635"></a><span class="lineno">  635</span>                    self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0c95ef33cbc4840aa36c1cee559e1c9b">epsilon</a>,</div>
<div class="line"><a id="l00636" name="l00636"></a><span class="lineno">  636</span>                )</div>
<div class="line"><a id="l00637" name="l00637"></a><span class="lineno">  637</span> </div>
<div class="line"><a id="l00638" name="l00638"></a><span class="lineno">  638</span>        <span class="comment"># early_stopping in partial_fit doesn&#39;t make sense</span></div>
<div class="line"><a id="l00639" name="l00639"></a><span class="lineno">  639</span>        <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa019948ee2d7ac810cea9942dd3d5187">early_stopping</a> <span class="keywordflow">and</span> incremental:</div>
<div class="line"><a id="l00640" name="l00640"></a><span class="lineno">  640</span>            <span class="keywordflow">raise</span> <a class="code hl_class" href="../../de/d40/classValueError.html">ValueError</a>(<span class="stringliteral">&quot;partial_fit does not support early_stopping=True&quot;</span>)</div>
<div class="line"><a id="l00641" name="l00641"></a><span class="lineno">  641</span>        early_stopping = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa019948ee2d7ac810cea9942dd3d5187">early_stopping</a></div>
<div class="line"><a id="l00642" name="l00642"></a><span class="lineno">  642</span>        <span class="keywordflow">if</span> early_stopping:</div>
<div class="line"><a id="l00643" name="l00643"></a><span class="lineno">  643</span>            <span class="comment"># don&#39;t stratify in multilabel classification</span></div>
<div class="line"><a id="l00644" name="l00644"></a><span class="lineno">  644</span>            should_stratify = is_classifier(self) <span class="keywordflow">and</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac913f3e320e35d56add32462793c14e7">n_outputs_</a> == 1</div>
<div class="line"><a id="l00645" name="l00645"></a><span class="lineno">  645</span>            stratify = y <span class="keywordflow">if</span> should_stratify <span class="keywordflow">else</span> <span class="keywordtype">None</span></div>
<div class="line"><a id="l00646" name="l00646"></a><span class="lineno">  646</span>            <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00647" name="l00647"></a><span class="lineno">  647</span>                X_train, X_val, y_train, y_val = train_test_split(</div>
<div class="line"><a id="l00648" name="l00648"></a><span class="lineno">  648</span>                    X,</div>
<div class="line"><a id="l00649" name="l00649"></a><span class="lineno">  649</span>                    y,</div>
<div class="line"><a id="l00650" name="l00650"></a><span class="lineno">  650</span>                    random_state=self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a215bc7c01b70f8525b1e8f1c0c035e4a">_random_state</a>,</div>
<div class="line"><a id="l00651" name="l00651"></a><span class="lineno">  651</span>                    test_size=self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a85298d7736f4e7fe4b167fc8ff51aaa6">validation_fraction</a>,</div>
<div class="line"><a id="l00652" name="l00652"></a><span class="lineno">  652</span>                    stratify=stratify,</div>
<div class="line"><a id="l00653" name="l00653"></a><span class="lineno">  653</span>                )</div>
<div class="line"><a id="l00654" name="l00654"></a><span class="lineno">  654</span>                sample_weight_train = sample_weight_val = <span class="keywordtype">None</span></div>
<div class="line"><a id="l00655" name="l00655"></a><span class="lineno">  655</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00656" name="l00656"></a><span class="lineno">  656</span>                <span class="comment"># TODO: incorporate sample_weight in sampling here.</span></div>
<div class="line"><a id="l00657" name="l00657"></a><span class="lineno">  657</span>                (</div>
<div class="line"><a id="l00658" name="l00658"></a><span class="lineno">  658</span>                    X_train,</div>
<div class="line"><a id="l00659" name="l00659"></a><span class="lineno">  659</span>                    X_val,</div>
<div class="line"><a id="l00660" name="l00660"></a><span class="lineno">  660</span>                    y_train,</div>
<div class="line"><a id="l00661" name="l00661"></a><span class="lineno">  661</span>                    y_val,</div>
<div class="line"><a id="l00662" name="l00662"></a><span class="lineno">  662</span>                    sample_weight_train,</div>
<div class="line"><a id="l00663" name="l00663"></a><span class="lineno">  663</span>                    sample_weight_val,</div>
<div class="line"><a id="l00664" name="l00664"></a><span class="lineno">  664</span>                ) = train_test_split(</div>
<div class="line"><a id="l00665" name="l00665"></a><span class="lineno">  665</span>                    X,</div>
<div class="line"><a id="l00666" name="l00666"></a><span class="lineno">  666</span>                    y,</div>
<div class="line"><a id="l00667" name="l00667"></a><span class="lineno">  667</span>                    sample_weight,</div>
<div class="line"><a id="l00668" name="l00668"></a><span class="lineno">  668</span>                    random_state=self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a215bc7c01b70f8525b1e8f1c0c035e4a">_random_state</a>,</div>
<div class="line"><a id="l00669" name="l00669"></a><span class="lineno">  669</span>                    test_size=self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a85298d7736f4e7fe4b167fc8ff51aaa6">validation_fraction</a>,</div>
<div class="line"><a id="l00670" name="l00670"></a><span class="lineno">  670</span>                    stratify=stratify,</div>
<div class="line"><a id="l00671" name="l00671"></a><span class="lineno">  671</span>                )</div>
<div class="line"><a id="l00672" name="l00672"></a><span class="lineno">  672</span>            <span class="keywordflow">if</span> X_val.shape[0] &lt; 2:</div>
<div class="line"><a id="l00673" name="l00673"></a><span class="lineno">  673</span>                <span class="keywordflow">raise</span> <a class="code hl_class" href="../../de/d40/classValueError.html">ValueError</a>(</div>
<div class="line"><a id="l00674" name="l00674"></a><span class="lineno">  674</span>                    <span class="stringliteral">&quot;The validation set is too small. Increase &#39;validation_fraction&#39; &quot;</span></div>
<div class="line"><a id="l00675" name="l00675"></a><span class="lineno">  675</span>                    <span class="stringliteral">&quot;or the size of your dataset.&quot;</span></div>
<div class="line"><a id="l00676" name="l00676"></a><span class="lineno">  676</span>                )</div>
<div class="line"><a id="l00677" name="l00677"></a><span class="lineno">  677</span> </div>
<div class="line"><a id="l00678" name="l00678"></a><span class="lineno">  678</span>            <span class="keywordflow">if</span> is_classifier(self):</div>
<div class="line"><a id="l00679" name="l00679"></a><span class="lineno">  679</span>                y_val = self._label_binarizer.inverse_transform(y_val)</div>
<div class="line"><a id="l00680" name="l00680"></a><span class="lineno">  680</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00681" name="l00681"></a><span class="lineno">  681</span>            X_train, y_train, sample_weight_train = X, y, sample_weight</div>
<div class="line"><a id="l00682" name="l00682"></a><span class="lineno">  682</span>            X_val = y_val = sample_weight_val = <span class="keywordtype">None</span></div>
<div class="line"><a id="l00683" name="l00683"></a><span class="lineno">  683</span> </div>
<div class="line"><a id="l00684" name="l00684"></a><span class="lineno">  684</span>        n_samples = X_train.shape[0]</div>
<div class="line"><a id="l00685" name="l00685"></a><span class="lineno">  685</span>        sample_idx = np.arange(n_samples, dtype=int)</div>
<div class="line"><a id="l00686" name="l00686"></a><span class="lineno">  686</span> </div>
<div class="line"><a id="l00687" name="l00687"></a><span class="lineno">  687</span>        <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a99d828d71d0571f169342d7b4dc54a57">batch_size</a> == <span class="stringliteral">&quot;auto&quot;</span>:</div>
<div class="line"><a id="l00688" name="l00688"></a><span class="lineno">  688</span>            batch_size = min(200, n_samples)</div>
<div class="line"><a id="l00689" name="l00689"></a><span class="lineno">  689</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00690" name="l00690"></a><span class="lineno">  690</span>            <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a99d828d71d0571f169342d7b4dc54a57">batch_size</a> &gt; n_samples:</div>
<div class="line"><a id="l00691" name="l00691"></a><span class="lineno">  691</span>                warnings.warn(</div>
<div class="line"><a id="l00692" name="l00692"></a><span class="lineno">  692</span>                    <span class="stringliteral">&quot;Got `batch_size` less than 1 or larger than &quot;</span></div>
<div class="line"><a id="l00693" name="l00693"></a><span class="lineno">  693</span>                    <span class="stringliteral">&quot;sample size. It is going to be clipped&quot;</span></div>
<div class="line"><a id="l00694" name="l00694"></a><span class="lineno">  694</span>                )</div>
<div class="line"><a id="l00695" name="l00695"></a><span class="lineno">  695</span>            batch_size = np.clip(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a99d828d71d0571f169342d7b4dc54a57">batch_size</a>, 1, n_samples)</div>
<div class="line"><a id="l00696" name="l00696"></a><span class="lineno">  696</span> </div>
<div class="line"><a id="l00697" name="l00697"></a><span class="lineno">  697</span>        <span class="keywordflow">try</span>:</div>
<div class="line"><a id="l00698" name="l00698"></a><span class="lineno">  698</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac4db5d73babe4976fac6b50ac73dccec">n_iter_</a> = 0</div>
<div class="line"><a id="l00699" name="l00699"></a><span class="lineno">  699</span>            <span class="keywordflow">for</span> it <span class="keywordflow">in</span> range(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a318bdf742f2e44c92f36b7a0c0912a83">max_iter</a>):</div>
<div class="line"><a id="l00700" name="l00700"></a><span class="lineno">  700</span>                <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a3dc00b9cd7811c0f2a93016e9c31557a">shuffle</a>:</div>
<div class="line"><a id="l00701" name="l00701"></a><span class="lineno">  701</span>                    <span class="comment"># Only shuffle the sample indices instead of X and y to</span></div>
<div class="line"><a id="l00702" name="l00702"></a><span class="lineno">  702</span>                    <span class="comment"># reduce the memory footprint. These indices will be used</span></div>
<div class="line"><a id="l00703" name="l00703"></a><span class="lineno">  703</span>                    <span class="comment"># to slice the X and y.</span></div>
<div class="line"><a id="l00704" name="l00704"></a><span class="lineno">  704</span>                    sample_idx = shuffle(sample_idx, random_state=self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a215bc7c01b70f8525b1e8f1c0c035e4a">_random_state</a>)</div>
<div class="line"><a id="l00705" name="l00705"></a><span class="lineno">  705</span> </div>
<div class="line"><a id="l00706" name="l00706"></a><span class="lineno">  706</span>                accumulated_loss = 0.0</div>
<div class="line"><a id="l00707" name="l00707"></a><span class="lineno">  707</span>                <span class="keywordflow">for</span> batch_slice <span class="keywordflow">in</span> gen_batches(n_samples, batch_size):</div>
<div class="line"><a id="l00708" name="l00708"></a><span class="lineno">  708</span>                    <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a3dc00b9cd7811c0f2a93016e9c31557a">shuffle</a>:</div>
<div class="line"><a id="l00709" name="l00709"></a><span class="lineno">  709</span>                        batch_idx = sample_idx[batch_slice]</div>
<div class="line"><a id="l00710" name="l00710"></a><span class="lineno">  710</span>                        X_batch = _safe_indexing(X_train, batch_idx)</div>
<div class="line"><a id="l00711" name="l00711"></a><span class="lineno">  711</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00712" name="l00712"></a><span class="lineno">  712</span>                        batch_idx = batch_slice</div>
<div class="line"><a id="l00713" name="l00713"></a><span class="lineno">  713</span>                        X_batch = X_train[batch_idx]</div>
<div class="line"><a id="l00714" name="l00714"></a><span class="lineno">  714</span>                    y_batch = y_train[batch_idx]</div>
<div class="line"><a id="l00715" name="l00715"></a><span class="lineno">  715</span>                    <span class="keywordflow">if</span> sample_weight <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00716" name="l00716"></a><span class="lineno">  716</span>                        sample_weight_batch = <span class="keywordtype">None</span></div>
<div class="line"><a id="l00717" name="l00717"></a><span class="lineno">  717</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00718" name="l00718"></a><span class="lineno">  718</span>                        sample_weight_batch = sample_weight_train[batch_idx]</div>
<div class="line"><a id="l00719" name="l00719"></a><span class="lineno">  719</span> </div>
<div class="line"><a id="l00720" name="l00720"></a><span class="lineno">  720</span>                    activations[0] = X_batch</div>
<div class="line"><a id="l00721" name="l00721"></a><span class="lineno">  721</span>                    batch_loss, coef_grads, intercept_grads = self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a706a1c60c73f17d042b1ca83f395981b">_backprop</a>(</div>
<div class="line"><a id="l00722" name="l00722"></a><span class="lineno">  722</span>                        X_batch,</div>
<div class="line"><a id="l00723" name="l00723"></a><span class="lineno">  723</span>                        y_batch,</div>
<div class="line"><a id="l00724" name="l00724"></a><span class="lineno">  724</span>                        sample_weight_batch,</div>
<div class="line"><a id="l00725" name="l00725"></a><span class="lineno">  725</span>                        activations,</div>
<div class="line"><a id="l00726" name="l00726"></a><span class="lineno">  726</span>                        deltas,</div>
<div class="line"><a id="l00727" name="l00727"></a><span class="lineno">  727</span>                        coef_grads,</div>
<div class="line"><a id="l00728" name="l00728"></a><span class="lineno">  728</span>                        intercept_grads,</div>
<div class="line"><a id="l00729" name="l00729"></a><span class="lineno">  729</span>                    )</div>
<div class="line"><a id="l00730" name="l00730"></a><span class="lineno">  730</span>                    accumulated_loss += batch_loss * (</div>
<div class="line"><a id="l00731" name="l00731"></a><span class="lineno">  731</span>                        batch_slice.stop - batch_slice.start</div>
<div class="line"><a id="l00732" name="l00732"></a><span class="lineno">  732</span>                    )</div>
<div class="line"><a id="l00733" name="l00733"></a><span class="lineno">  733</span> </div>
<div class="line"><a id="l00734" name="l00734"></a><span class="lineno">  734</span>                    <span class="comment"># update weights</span></div>
<div class="line"><a id="l00735" name="l00735"></a><span class="lineno">  735</span>                    grads = coef_grads + intercept_grads</div>
<div class="line"><a id="l00736" name="l00736"></a><span class="lineno">  736</span>                    self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a9335dce7fccc3077842f4deccf52ac98">_optimizer</a>.update_params(params, grads)</div>
<div class="line"><a id="l00737" name="l00737"></a><span class="lineno">  737</span> </div>
<div class="line"><a id="l00738" name="l00738"></a><span class="lineno">  738</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac4db5d73babe4976fac6b50ac73dccec">n_iter_</a> += 1</div>
<div class="line"><a id="l00739" name="l00739"></a><span class="lineno">  739</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a27576cf472db61b06d2951267d01df7a">loss_</a> = accumulated_loss / X_train.shape[0]</div>
<div class="line"><a id="l00740" name="l00740"></a><span class="lineno">  740</span> </div>
<div class="line"><a id="l00741" name="l00741"></a><span class="lineno">  741</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a1cdc4a9b4f8c1d00572be3ba7400d728">t_</a> += n_samples</div>
<div class="line"><a id="l00742" name="l00742"></a><span class="lineno">  742</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a24d8114c5f7a2c9fc35242135857f8ae">loss_curve_</a>.append(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a27576cf472db61b06d2951267d01df7a">loss_</a>)</div>
<div class="line"><a id="l00743" name="l00743"></a><span class="lineno">  743</span>                <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#abb3113bc3c7d179d4a7e9443f2090036">verbose</a>:</div>
<div class="line"><a id="l00744" name="l00744"></a><span class="lineno">  744</span>                    print(<span class="stringliteral">&quot;Iteration %d, loss = %.8f&quot;</span> % (self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac4db5d73babe4976fac6b50ac73dccec">n_iter_</a>, self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a27576cf472db61b06d2951267d01df7a">loss_</a>))</div>
<div class="line"><a id="l00745" name="l00745"></a><span class="lineno">  745</span> </div>
<div class="line"><a id="l00746" name="l00746"></a><span class="lineno">  746</span>                <span class="comment"># update no_improvement_count based on training loss or</span></div>
<div class="line"><a id="l00747" name="l00747"></a><span class="lineno">  747</span>                <span class="comment"># validation score according to early_stopping</span></div>
<div class="line"><a id="l00748" name="l00748"></a><span class="lineno">  748</span>                self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a51ff58bd42d10137a1ae0214d0840f5c">_update_no_improvement_count</a>(</div>
<div class="line"><a id="l00749" name="l00749"></a><span class="lineno">  749</span>                    early_stopping, X_val, y_val, sample_weight_val</div>
<div class="line"><a id="l00750" name="l00750"></a><span class="lineno">  750</span>                )</div>
<div class="line"><a id="l00751" name="l00751"></a><span class="lineno">  751</span> </div>
<div class="line"><a id="l00752" name="l00752"></a><span class="lineno">  752</span>                <span class="comment"># for learning rate that needs to be updated at iteration end</span></div>
<div class="line"><a id="l00753" name="l00753"></a><span class="lineno">  753</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a9335dce7fccc3077842f4deccf52ac98">_optimizer</a>.iteration_ends(self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a1cdc4a9b4f8c1d00572be3ba7400d728">t_</a>)</div>
<div class="line"><a id="l00754" name="l00754"></a><span class="lineno">  754</span> </div>
<div class="line"><a id="l00755" name="l00755"></a><span class="lineno">  755</span>                <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a669612405aaf465d9489e5cbd6442a7a">_no_improvement_count</a> &gt; self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f052dea4e28c577fa309c8c104ea9f7">n_iter_no_change</a>:</div>
<div class="line"><a id="l00756" name="l00756"></a><span class="lineno">  756</span>                    <span class="comment"># not better than last `n_iter_no_change` iterations by tol</span></div>
<div class="line"><a id="l00757" name="l00757"></a><span class="lineno">  757</span>                    <span class="comment"># stop or decrease learning rate</span></div>
<div class="line"><a id="l00758" name="l00758"></a><span class="lineno">  758</span>                    <span class="keywordflow">if</span> early_stopping:</div>
<div class="line"><a id="l00759" name="l00759"></a><span class="lineno">  759</span>                        msg = (</div>
<div class="line"><a id="l00760" name="l00760"></a><span class="lineno">  760</span>                            <span class="stringliteral">&quot;Validation score did not improve more than &quot;</span></div>
<div class="line"><a id="l00761" name="l00761"></a><span class="lineno">  761</span>                            <span class="stringliteral">&quot;tol=%f for %d consecutive epochs.&quot;</span></div>
<div class="line"><a id="l00762" name="l00762"></a><span class="lineno">  762</span>                            % (self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af3fc521b13aae045b9e10387f34b0ba1">tol</a>, self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f052dea4e28c577fa309c8c104ea9f7">n_iter_no_change</a>)</div>
<div class="line"><a id="l00763" name="l00763"></a><span class="lineno">  763</span>                        )</div>
<div class="line"><a id="l00764" name="l00764"></a><span class="lineno">  764</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00765" name="l00765"></a><span class="lineno">  765</span>                        msg = (</div>
<div class="line"><a id="l00766" name="l00766"></a><span class="lineno">  766</span>                            <span class="stringliteral">&quot;Training loss did not improve more than tol=%f&quot;</span></div>
<div class="line"><a id="l00767" name="l00767"></a><span class="lineno">  767</span>                            <span class="stringliteral">&quot; for %d consecutive epochs.&quot;</span></div>
<div class="line"><a id="l00768" name="l00768"></a><span class="lineno">  768</span>                            % (self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af3fc521b13aae045b9e10387f34b0ba1">tol</a>, self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f052dea4e28c577fa309c8c104ea9f7">n_iter_no_change</a>)</div>
<div class="line"><a id="l00769" name="l00769"></a><span class="lineno">  769</span>                        )</div>
<div class="line"><a id="l00770" name="l00770"></a><span class="lineno">  770</span> </div>
<div class="line"><a id="l00771" name="l00771"></a><span class="lineno">  771</span>                    is_stopping = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a9335dce7fccc3077842f4deccf52ac98">_optimizer</a>.trigger_stopping(msg, self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#abb3113bc3c7d179d4a7e9443f2090036">verbose</a>)</div>
<div class="line"><a id="l00772" name="l00772"></a><span class="lineno">  772</span>                    <span class="keywordflow">if</span> is_stopping:</div>
<div class="line"><a id="l00773" name="l00773"></a><span class="lineno">  773</span>                        <span class="keywordflow">break</span></div>
<div class="line"><a id="l00774" name="l00774"></a><span class="lineno">  774</span>                    <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00775" name="l00775"></a><span class="lineno">  775</span>                        self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a669612405aaf465d9489e5cbd6442a7a">_no_improvement_count</a> = 0</div>
<div class="line"><a id="l00776" name="l00776"></a><span class="lineno">  776</span> </div>
<div class="line"><a id="l00777" name="l00777"></a><span class="lineno">  777</span>                <span class="keywordflow">if</span> incremental:</div>
<div class="line"><a id="l00778" name="l00778"></a><span class="lineno">  778</span>                    <span class="keywordflow">break</span></div>
<div class="line"><a id="l00779" name="l00779"></a><span class="lineno">  779</span> </div>
<div class="line"><a id="l00780" name="l00780"></a><span class="lineno">  780</span>                <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac4db5d73babe4976fac6b50ac73dccec">n_iter_</a> == self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a318bdf742f2e44c92f36b7a0c0912a83">max_iter</a>:</div>
<div class="line"><a id="l00781" name="l00781"></a><span class="lineno">  781</span>                    warnings.warn(</div>
<div class="line"><a id="l00782" name="l00782"></a><span class="lineno">  782</span>                        <span class="stringliteral">&quot;Stochastic Optimizer: Maximum iterations (%d) &quot;</span></div>
<div class="line"><a id="l00783" name="l00783"></a><span class="lineno">  783</span>                        <span class="stringliteral">&quot;reached and the optimization hasn&#39;t converged yet.&quot;</span></div>
<div class="line"><a id="l00784" name="l00784"></a><span class="lineno">  784</span>                        % self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a318bdf742f2e44c92f36b7a0c0912a83">max_iter</a>,</div>
<div class="line"><a id="l00785" name="l00785"></a><span class="lineno">  785</span>                        ConvergenceWarning,</div>
<div class="line"><a id="l00786" name="l00786"></a><span class="lineno">  786</span>                    )</div>
<div class="line"><a id="l00787" name="l00787"></a><span class="lineno">  787</span>        <span class="keywordflow">except</span> KeyboardInterrupt:</div>
<div class="line"><a id="l00788" name="l00788"></a><span class="lineno">  788</span>            warnings.warn(<span class="stringliteral">&quot;Training interrupted by user.&quot;</span>)</div>
<div class="line"><a id="l00789" name="l00789"></a><span class="lineno">  789</span> </div>
<div class="line"><a id="l00790" name="l00790"></a><span class="lineno">  790</span>        <span class="keywordflow">if</span> early_stopping:</div>
<div class="line"><a id="l00791" name="l00791"></a><span class="lineno">  791</span>            <span class="comment"># restore best weights</span></div>
<div class="line"><a id="l00792" name="l00792"></a><span class="lineno">  792</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a> = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a98812cf40a7067db51eba0c802f3d8f8">_best_coefs</a></div>
<div class="line"><a id="l00793" name="l00793"></a><span class="lineno">  793</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a> = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a09f3f5db1df292bba142574f372f80a7">_best_intercepts</a></div>
<div class="line"><a id="l00794" name="l00794"></a><span class="lineno">  794</span> </div>
<div class="line"><a id="l00795" name="l00795"></a><span class="lineno">  795</span>    <span class="keyword">def </span>_update_no_improvement_count(self, early_stopping, X, y, sample_weight):</div>
<div class="line"><a id="l00796" name="l00796"></a><span class="lineno">  796</span>        <span class="keywordflow">if</span> early_stopping:</div>
<div class="line"><a id="l00797" name="l00797"></a><span class="lineno">  797</span>            <span class="comment"># compute validation score (can be NaN), use that for stopping</span></div>
<div class="line"><a id="l00798" name="l00798"></a><span class="lineno">  798</span>            val_score = self._score(X, y, sample_weight=sample_weight)</div>
<div class="line"><a id="l00799" name="l00799"></a><span class="lineno">  799</span> </div>
<div class="line"><a id="l00800" name="l00800"></a><span class="lineno">  800</span>            self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0d765db3f3c8659b1d818a7b0bbbcd5e">validation_scores_</a>.append(val_score)</div>
<div class="line"><a id="l00801" name="l00801"></a><span class="lineno">  801</span> </div>
<div class="line"><a id="l00802" name="l00802"></a><span class="lineno">  802</span>            <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#abb3113bc3c7d179d4a7e9443f2090036">verbose</a>:</div>
<div class="line"><a id="l00803" name="l00803"></a><span class="lineno">  803</span>                print(<span class="stringliteral">&quot;Validation score: %f&quot;</span> % self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0d765db3f3c8659b1d818a7b0bbbcd5e">validation_scores_</a>[-1])</div>
<div class="line"><a id="l00804" name="l00804"></a><span class="lineno">  804</span>            <span class="comment"># update best parameters</span></div>
<div class="line"><a id="l00805" name="l00805"></a><span class="lineno">  805</span>            <span class="comment"># use validation_scores_, not loss_curve_</span></div>
<div class="line"><a id="l00806" name="l00806"></a><span class="lineno">  806</span>            <span class="comment"># let&#39;s hope no-one overloads .score with mse</span></div>
<div class="line"><a id="l00807" name="l00807"></a><span class="lineno">  807</span>            last_valid_score = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0d765db3f3c8659b1d818a7b0bbbcd5e">validation_scores_</a>[-1]</div>
<div class="line"><a id="l00808" name="l00808"></a><span class="lineno">  808</span> </div>
<div class="line"><a id="l00809" name="l00809"></a><span class="lineno">  809</span>            <span class="keywordflow">if</span> last_valid_score &lt; (self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af9772e422910c066bd1214dc5e01f984">best_validation_score_</a> + self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af3fc521b13aae045b9e10387f34b0ba1">tol</a>):</div>
<div class="line"><a id="l00810" name="l00810"></a><span class="lineno">  810</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a669612405aaf465d9489e5cbd6442a7a">_no_improvement_count</a> += 1</div>
<div class="line"><a id="l00811" name="l00811"></a><span class="lineno">  811</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00812" name="l00812"></a><span class="lineno">  812</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a669612405aaf465d9489e5cbd6442a7a">_no_improvement_count</a> = 0</div>
<div class="line"><a id="l00813" name="l00813"></a><span class="lineno">  813</span> </div>
<div class="line"><a id="l00814" name="l00814"></a><span class="lineno">  814</span>            <span class="keywordflow">if</span> last_valid_score &gt; self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af9772e422910c066bd1214dc5e01f984">best_validation_score_</a>:</div>
<div class="line"><a id="l00815" name="l00815"></a><span class="lineno">  815</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af9772e422910c066bd1214dc5e01f984">best_validation_score_</a> = last_valid_score</div>
<div class="line"><a id="l00816" name="l00816"></a><span class="lineno">  816</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a98812cf40a7067db51eba0c802f3d8f8">_best_coefs</a> = [c.copy() <span class="keywordflow">for</span> c <span class="keywordflow">in</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">coefs_</a>]</div>
<div class="line"><a id="l00817" name="l00817"></a><span class="lineno">  817</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a09f3f5db1df292bba142574f372f80a7">_best_intercepts</a> = [i.copy() <span class="keywordflow">for</span> i <span class="keywordflow">in</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">intercepts_</a>]</div>
<div class="line"><a id="l00818" name="l00818"></a><span class="lineno">  818</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00819" name="l00819"></a><span class="lineno">  819</span>            <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a24d8114c5f7a2c9fc35242135857f8ae">loss_curve_</a>[-1] &gt; self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a70a6072759ac7ac36b964c80d3620525">best_loss_</a> - self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af3fc521b13aae045b9e10387f34b0ba1">tol</a>:</div>
<div class="line"><a id="l00820" name="l00820"></a><span class="lineno">  820</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a669612405aaf465d9489e5cbd6442a7a">_no_improvement_count</a> += 1</div>
<div class="line"><a id="l00821" name="l00821"></a><span class="lineno">  821</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00822" name="l00822"></a><span class="lineno">  822</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a669612405aaf465d9489e5cbd6442a7a">_no_improvement_count</a> = 0</div>
<div class="line"><a id="l00823" name="l00823"></a><span class="lineno">  823</span>            <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a24d8114c5f7a2c9fc35242135857f8ae">loss_curve_</a>[-1] &lt; self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a70a6072759ac7ac36b964c80d3620525">best_loss_</a>:</div>
<div class="line"><a id="l00824" name="l00824"></a><span class="lineno">  824</span>                self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a70a6072759ac7ac36b964c80d3620525">best_loss_</a> = self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a24d8114c5f7a2c9fc35242135857f8ae">loss_curve_</a>[-1]</div>
<div class="line"><a id="l00825" name="l00825"></a><span class="lineno">  825</span> </div>
<div class="line"><a id="l00826" name="l00826"></a><span class="lineno">  826</span>    <span class="preprocessor">@_fit_context(prefer_skip_nested_validation=True)</span></div>
<div class="foldopen" id="foldopen00827" data-start="" data-end="">
<div class="line"><a id="l00827" name="l00827"></a><span class="lineno"><a class="line" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa993801cc4d309b69244e4ea31d5a4a9">  827</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa993801cc4d309b69244e4ea31d5a4a9">fit</a>(self, X, y, sample_weight=None):</div>
<div class="line"><a id="l00828" name="l00828"></a><span class="lineno">  828</span>        <span class="stringliteral">&quot;&quot;&quot;Fit the model to data matrix X and target(s) y.</span></div>
<div class="line"><a id="l00829" name="l00829"></a><span class="lineno">  829</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00830" name="l00830"></a><span class="lineno">  830</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l00831" name="l00831"></a><span class="lineno">  831</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l00832" name="l00832"></a><span class="lineno">  832</span><span class="stringliteral">        X : ndarray or sparse matrix of shape (n_samples, n_features)</span></div>
<div class="line"><a id="l00833" name="l00833"></a><span class="lineno">  833</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><a id="l00834" name="l00834"></a><span class="lineno">  834</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00835" name="l00835"></a><span class="lineno">  835</span><span class="stringliteral">        y : ndarray of shape (n_samples,) or (n_samples, n_outputs)</span></div>
<div class="line"><a id="l00836" name="l00836"></a><span class="lineno">  836</span><span class="stringliteral">            The target values (class labels in classification, real numbers in</span></div>
<div class="line"><a id="l00837" name="l00837"></a><span class="lineno">  837</span><span class="stringliteral">            regression).</span></div>
<div class="line"><a id="l00838" name="l00838"></a><span class="lineno">  838</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00839" name="l00839"></a><span class="lineno">  839</span><span class="stringliteral">        sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><a id="l00840" name="l00840"></a><span class="lineno">  840</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><a id="l00841" name="l00841"></a><span class="lineno">  841</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00842" name="l00842"></a><span class="lineno">  842</span><span class="stringliteral">            .. versionadded:: 1.7</span></div>
<div class="line"><a id="l00843" name="l00843"></a><span class="lineno">  843</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00844" name="l00844"></a><span class="lineno">  844</span><span class="stringliteral">        Returns</span></div>
<div class="line"><a id="l00845" name="l00845"></a><span class="lineno">  845</span><span class="stringliteral">        -------</span></div>
<div class="line"><a id="l00846" name="l00846"></a><span class="lineno">  846</span><span class="stringliteral">        self : object</span></div>
<div class="line"><a id="l00847" name="l00847"></a><span class="lineno">  847</span><span class="stringliteral">            Returns a trained MLP model.</span></div>
<div class="line"><a id="l00848" name="l00848"></a><span class="lineno">  848</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00849" name="l00849"></a><span class="lineno">  849</span>        <span class="keywordflow">return</span> self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5ee59a9eb9aefd9dde989f3a32cac161">_fit</a>(X, y, sample_weight=sample_weight, incremental=<span class="keyword">False</span>)</div>
<div class="line"><a id="l00850" name="l00850"></a><span class="lineno">  850</span> </div>
</div>
<div class="line"><a id="l00851" name="l00851"></a><span class="lineno">  851</span>    <span class="keyword">def </span>_check_solver(self):</div>
<div class="line"><a id="l00852" name="l00852"></a><span class="lineno">  852</span>        <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aff5cec0cbb94c15f464c19ff02b738dc">solver</a> <span class="keywordflow">not</span> <span class="keywordflow">in</span> _STOCHASTIC_SOLVERS:</div>
<div class="line"><a id="l00853" name="l00853"></a><span class="lineno">  853</span>            <span class="keywordflow">raise</span> <a class="code hl_class" href="../../d7/d52/classAttributeError.html">AttributeError</a>(</div>
<div class="line"><a id="l00854" name="l00854"></a><span class="lineno">  854</span>                <span class="stringliteral">&quot;partial_fit is only available for stochastic&quot;</span></div>
<div class="line"><a id="l00855" name="l00855"></a><span class="lineno">  855</span>                <span class="stringliteral">&quot; optimizers. %s is not stochastic.&quot;</span> % self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aff5cec0cbb94c15f464c19ff02b738dc">solver</a></div>
<div class="line"><a id="l00856" name="l00856"></a><span class="lineno">  856</span>            )</div>
<div class="line"><a id="l00857" name="l00857"></a><span class="lineno">  857</span>        <span class="keywordflow">return</span> <span class="keyword">True</span></div>
<div class="line"><a id="l00858" name="l00858"></a><span class="lineno">  858</span> </div>
<div class="foldopen" id="foldopen00859" data-start="" data-end="">
<div class="line"><a id="l00859" name="l00859"></a><span class="lineno"><a class="line" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad19ee046e2bfe882adbddfb46980c0f6">  859</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad19ee046e2bfe882adbddfb46980c0f6">_score_with_function</a>(self, X, y, sample_weight, score_function):</div>
<div class="line"><a id="l00860" name="l00860"></a><span class="lineno">  860</span>        <span class="stringliteral">&quot;&quot;&quot;Private score method without input validation.&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00861" name="l00861"></a><span class="lineno">  861</span>        <span class="comment"># Input validation would remove feature names, so we disable it</span></div>
<div class="line"><a id="l00862" name="l00862"></a><span class="lineno">  862</span>        y_pred = self._predict(X, check_input=<span class="keyword">False</span>)</div>
<div class="line"><a id="l00863" name="l00863"></a><span class="lineno">  863</span> </div>
<div class="line"><a id="l00864" name="l00864"></a><span class="lineno">  864</span>        <span class="keywordflow">if</span> np.isnan(y_pred).any() <span class="keywordflow">or</span> np.isinf(y_pred).any():</div>
<div class="line"><a id="l00865" name="l00865"></a><span class="lineno">  865</span>            <span class="keywordflow">return</span> np.nan</div>
<div class="line"><a id="l00866" name="l00866"></a><span class="lineno">  866</span> </div>
<div class="line"><a id="l00867" name="l00867"></a><span class="lineno">  867</span>        <span class="keywordflow">return</span> score_function(y, y_pred, sample_weight=sample_weight)</div>
<div class="line"><a id="l00868" name="l00868"></a><span class="lineno">  868</span> </div>
</div>
<div class="line"><a id="l00869" name="l00869"></a><span class="lineno">  869</span>    <span class="keyword">def </span>__sklearn_tags__(self):</div>
<div class="line"><a id="l00870" name="l00870"></a><span class="lineno">  870</span>        tags = super().__sklearn_tags__()</div>
<div class="line"><a id="l00871" name="l00871"></a><span class="lineno">  871</span>        tags.input_tags.sparse = <span class="keyword">True</span></div>
<div class="line"><a id="l00872" name="l00872"></a><span class="lineno">  872</span>        <span class="keywordflow">return</span> tags</div>
<div class="line"><a id="l00873" name="l00873"></a><span class="lineno">  873</span> </div>
<div class="line"><a id="l00874" name="l00874"></a><span class="lineno">  874</span> </div>
</div>
<div class="foldopen" id="foldopen00875" data-start="" data-end="">
<div class="line"><a id="l00875" name="l00875"></a><span class="lineno"><a class="line" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html">  875</a></span><span class="keyword">class </span><a class="code hl_class" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html">MLPClassifier</a>(<a class="code hl_class" href="../../d2/d39/classsklearn_1_1base_1_1ClassifierMixin.html">ClassifierMixin</a>, <a class="code hl_class" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html">BaseMultilayerPerceptron</a>):</div>
<div class="line"><a id="l00876" name="l00876"></a><span class="lineno">  876</span>    <span class="stringliteral">&quot;&quot;&quot;Multi-layer Perceptron classifier.</span></div>
<div class="line"><a id="l00877" name="l00877"></a><span class="lineno">  877</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00878" name="l00878"></a><span class="lineno">  878</span><span class="stringliteral">    This model optimizes the log-loss function using LBFGS or stochastic</span></div>
<div class="line"><a id="l00879" name="l00879"></a><span class="lineno">  879</span><span class="stringliteral">    gradient descent.</span></div>
<div class="line"><a id="l00880" name="l00880"></a><span class="lineno">  880</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00881" name="l00881"></a><span class="lineno">  881</span><span class="stringliteral">    .. versionadded:: 0.18</span></div>
<div class="line"><a id="l00882" name="l00882"></a><span class="lineno">  882</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00883" name="l00883"></a><span class="lineno">  883</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><a id="l00884" name="l00884"></a><span class="lineno">  884</span><span class="stringliteral">    ----------</span></div>
<div class="line"><a id="l00885" name="l00885"></a><span class="lineno">  885</span><span class="stringliteral">    hidden_layer_sizes : array-like of shape(n_layers - 2,), default=(100,)</span></div>
<div class="line"><a id="l00886" name="l00886"></a><span class="lineno">  886</span><span class="stringliteral">        The ith element represents the number of neurons in the ith</span></div>
<div class="line"><a id="l00887" name="l00887"></a><span class="lineno">  887</span><span class="stringliteral">        hidden layer.</span></div>
<div class="line"><a id="l00888" name="l00888"></a><span class="lineno">  888</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00889" name="l00889"></a><span class="lineno">  889</span><span class="stringliteral">    activation : {&#39;identity&#39;, &#39;logistic&#39;, &#39;tanh&#39;, &#39;relu&#39;}, default=&#39;relu&#39;</span></div>
<div class="line"><a id="l00890" name="l00890"></a><span class="lineno">  890</span><span class="stringliteral">        Activation function for the hidden layer.</span></div>
<div class="line"><a id="l00891" name="l00891"></a><span class="lineno">  891</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00892" name="l00892"></a><span class="lineno">  892</span><span class="stringliteral">        - &#39;identity&#39;, no-op activation, useful to implement linear bottleneck,</span></div>
<div class="line"><a id="l00893" name="l00893"></a><span class="lineno">  893</span><span class="stringliteral">          returns f(x) = x</span></div>
<div class="line"><a id="l00894" name="l00894"></a><span class="lineno">  894</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00895" name="l00895"></a><span class="lineno">  895</span><span class="stringliteral">        - &#39;logistic&#39;, the logistic sigmoid function,</span></div>
<div class="line"><a id="l00896" name="l00896"></a><span class="lineno">  896</span><span class="stringliteral">          returns f(x) = 1 / (1 + exp(-x)).</span></div>
<div class="line"><a id="l00897" name="l00897"></a><span class="lineno">  897</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00898" name="l00898"></a><span class="lineno">  898</span><span class="stringliteral">        - &#39;tanh&#39;, the hyperbolic tan function,</span></div>
<div class="line"><a id="l00899" name="l00899"></a><span class="lineno">  899</span><span class="stringliteral">          returns f(x) = tanh(x).</span></div>
<div class="line"><a id="l00900" name="l00900"></a><span class="lineno">  900</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00901" name="l00901"></a><span class="lineno">  901</span><span class="stringliteral">        - &#39;relu&#39;, the rectified linear unit function,</span></div>
<div class="line"><a id="l00902" name="l00902"></a><span class="lineno">  902</span><span class="stringliteral">          returns f(x) = max(0, x)</span></div>
<div class="line"><a id="l00903" name="l00903"></a><span class="lineno">  903</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00904" name="l00904"></a><span class="lineno">  904</span><span class="stringliteral">    solver : {&#39;lbfgs&#39;, &#39;sgd&#39;, &#39;adam&#39;}, default=&#39;adam&#39;</span></div>
<div class="line"><a id="l00905" name="l00905"></a><span class="lineno">  905</span><span class="stringliteral">        The solver for weight optimization.</span></div>
<div class="line"><a id="l00906" name="l00906"></a><span class="lineno">  906</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00907" name="l00907"></a><span class="lineno">  907</span><span class="stringliteral">        - &#39;lbfgs&#39; is an optimizer in the family of quasi-Newton methods.</span></div>
<div class="line"><a id="l00908" name="l00908"></a><span class="lineno">  908</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00909" name="l00909"></a><span class="lineno">  909</span><span class="stringliteral">        - &#39;sgd&#39; refers to stochastic gradient descent.</span></div>
<div class="line"><a id="l00910" name="l00910"></a><span class="lineno">  910</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00911" name="l00911"></a><span class="lineno">  911</span><span class="stringliteral">        - &#39;adam&#39; refers to a stochastic gradient-based optimizer proposed</span></div>
<div class="line"><a id="l00912" name="l00912"></a><span class="lineno">  912</span><span class="stringliteral">          by Kingma, Diederik, and Jimmy Ba</span></div>
<div class="line"><a id="l00913" name="l00913"></a><span class="lineno">  913</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00914" name="l00914"></a><span class="lineno">  914</span><span class="stringliteral">        For a comparison between Adam optimizer and SGD, see</span></div>
<div class="line"><a id="l00915" name="l00915"></a><span class="lineno">  915</span><span class="stringliteral">        :ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_training_curves.py`.</span></div>
<div class="line"><a id="l00916" name="l00916"></a><span class="lineno">  916</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00917" name="l00917"></a><span class="lineno">  917</span><span class="stringliteral">        Note: The default solver &#39;adam&#39; works pretty well on relatively</span></div>
<div class="line"><a id="l00918" name="l00918"></a><span class="lineno">  918</span><span class="stringliteral">        large datasets (with thousands of training samples or more) in terms of</span></div>
<div class="line"><a id="l00919" name="l00919"></a><span class="lineno">  919</span><span class="stringliteral">        both training time and validation score.</span></div>
<div class="line"><a id="l00920" name="l00920"></a><span class="lineno">  920</span><span class="stringliteral">        For small datasets, however, &#39;lbfgs&#39; can converge faster and perform</span></div>
<div class="line"><a id="l00921" name="l00921"></a><span class="lineno">  921</span><span class="stringliteral">        better.</span></div>
<div class="line"><a id="l00922" name="l00922"></a><span class="lineno">  922</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00923" name="l00923"></a><span class="lineno">  923</span><span class="stringliteral">    alpha : float, default=0.0001</span></div>
<div class="line"><a id="l00924" name="l00924"></a><span class="lineno">  924</span><span class="stringliteral">        Strength of the L2 regularization term. The L2 regularization term</span></div>
<div class="line"><a id="l00925" name="l00925"></a><span class="lineno">  925</span><span class="stringliteral">        is divided by the sample size when added to the loss.</span></div>
<div class="line"><a id="l00926" name="l00926"></a><span class="lineno">  926</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00927" name="l00927"></a><span class="lineno">  927</span><span class="stringliteral">        For an example usage and visualization of varying regularization, see</span></div>
<div class="line"><a id="l00928" name="l00928"></a><span class="lineno">  928</span><span class="stringliteral">        :ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_alpha.py`.</span></div>
<div class="line"><a id="l00929" name="l00929"></a><span class="lineno">  929</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00930" name="l00930"></a><span class="lineno">  930</span><span class="stringliteral">    batch_size : int, default=&#39;auto&#39;</span></div>
<div class="line"><a id="l00931" name="l00931"></a><span class="lineno">  931</span><span class="stringliteral">        Size of minibatches for stochastic optimizers.</span></div>
<div class="line"><a id="l00932" name="l00932"></a><span class="lineno">  932</span><span class="stringliteral">        If the solver is &#39;lbfgs&#39;, the classifier will not use minibatch.</span></div>
<div class="line"><a id="l00933" name="l00933"></a><span class="lineno">  933</span><span class="stringliteral">        When set to &quot;auto&quot;, `batch_size=min(200, n_samples)`.</span></div>
<div class="line"><a id="l00934" name="l00934"></a><span class="lineno">  934</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00935" name="l00935"></a><span class="lineno">  935</span><span class="stringliteral">    learning_rate : {&#39;constant&#39;, &#39;invscaling&#39;, &#39;adaptive&#39;}, default=&#39;constant&#39;</span></div>
<div class="line"><a id="l00936" name="l00936"></a><span class="lineno">  936</span><span class="stringliteral">        Learning rate schedule for weight updates.</span></div>
<div class="line"><a id="l00937" name="l00937"></a><span class="lineno">  937</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00938" name="l00938"></a><span class="lineno">  938</span><span class="stringliteral">        - &#39;constant&#39; is a constant learning rate given by</span></div>
<div class="line"><a id="l00939" name="l00939"></a><span class="lineno">  939</span><span class="stringliteral">          &#39;learning_rate_init&#39;.</span></div>
<div class="line"><a id="l00940" name="l00940"></a><span class="lineno">  940</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00941" name="l00941"></a><span class="lineno">  941</span><span class="stringliteral">        - &#39;invscaling&#39; gradually decreases the learning rate at each</span></div>
<div class="line"><a id="l00942" name="l00942"></a><span class="lineno">  942</span><span class="stringliteral">          time step &#39;t&#39; using an inverse scaling exponent of &#39;power_t&#39;.</span></div>
<div class="line"><a id="l00943" name="l00943"></a><span class="lineno">  943</span><span class="stringliteral">          effective_learning_rate = learning_rate_init / pow(t, power_t)</span></div>
<div class="line"><a id="l00944" name="l00944"></a><span class="lineno">  944</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00945" name="l00945"></a><span class="lineno">  945</span><span class="stringliteral">        - &#39;adaptive&#39; keeps the learning rate constant to</span></div>
<div class="line"><a id="l00946" name="l00946"></a><span class="lineno">  946</span><span class="stringliteral">          &#39;learning_rate_init&#39; as long as training loss keeps decreasing.</span></div>
<div class="line"><a id="l00947" name="l00947"></a><span class="lineno">  947</span><span class="stringliteral">          Each time two consecutive epochs fail to decrease training loss by at</span></div>
<div class="line"><a id="l00948" name="l00948"></a><span class="lineno">  948</span><span class="stringliteral">          least tol, or fail to increase validation score by at least tol if</span></div>
<div class="line"><a id="l00949" name="l00949"></a><span class="lineno">  949</span><span class="stringliteral">          &#39;early_stopping&#39; is on, the current learning rate is divided by 5.</span></div>
<div class="line"><a id="l00950" name="l00950"></a><span class="lineno">  950</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00951" name="l00951"></a><span class="lineno">  951</span><span class="stringliteral">        Only used when ``solver=&#39;sgd&#39;``.</span></div>
<div class="line"><a id="l00952" name="l00952"></a><span class="lineno">  952</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00953" name="l00953"></a><span class="lineno">  953</span><span class="stringliteral">    learning_rate_init : float, default=0.001</span></div>
<div class="line"><a id="l00954" name="l00954"></a><span class="lineno">  954</span><span class="stringliteral">        The initial learning rate used. It controls the step-size</span></div>
<div class="line"><a id="l00955" name="l00955"></a><span class="lineno">  955</span><span class="stringliteral">        in updating the weights. Only used when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l00956" name="l00956"></a><span class="lineno">  956</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00957" name="l00957"></a><span class="lineno">  957</span><span class="stringliteral">    power_t : float, default=0.5</span></div>
<div class="line"><a id="l00958" name="l00958"></a><span class="lineno">  958</span><span class="stringliteral">        The exponent for inverse scaling learning rate.</span></div>
<div class="line"><a id="l00959" name="l00959"></a><span class="lineno">  959</span><span class="stringliteral">        It is used in updating effective learning rate when the learning_rate</span></div>
<div class="line"><a id="l00960" name="l00960"></a><span class="lineno">  960</span><span class="stringliteral">        is set to &#39;invscaling&#39;. Only used when solver=&#39;sgd&#39;.</span></div>
<div class="line"><a id="l00961" name="l00961"></a><span class="lineno">  961</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00962" name="l00962"></a><span class="lineno">  962</span><span class="stringliteral">    max_iter : int, default=200</span></div>
<div class="line"><a id="l00963" name="l00963"></a><span class="lineno">  963</span><span class="stringliteral">        Maximum number of iterations. The solver iterates until convergence</span></div>
<div class="line"><a id="l00964" name="l00964"></a><span class="lineno">  964</span><span class="stringliteral">        (determined by &#39;tol&#39;) or this number of iterations. For stochastic</span></div>
<div class="line"><a id="l00965" name="l00965"></a><span class="lineno">  965</span><span class="stringliteral">        solvers (&#39;sgd&#39;, &#39;adam&#39;), note that this determines the number of epochs</span></div>
<div class="line"><a id="l00966" name="l00966"></a><span class="lineno">  966</span><span class="stringliteral">        (how many times each data point will be used), not the number of</span></div>
<div class="line"><a id="l00967" name="l00967"></a><span class="lineno">  967</span><span class="stringliteral">        gradient steps.</span></div>
<div class="line"><a id="l00968" name="l00968"></a><span class="lineno">  968</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00969" name="l00969"></a><span class="lineno">  969</span><span class="stringliteral">    shuffle : bool, default=True</span></div>
<div class="line"><a id="l00970" name="l00970"></a><span class="lineno">  970</span><span class="stringliteral">        Whether to shuffle samples in each iteration. Only used when</span></div>
<div class="line"><a id="l00971" name="l00971"></a><span class="lineno">  971</span><span class="stringliteral">        solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l00972" name="l00972"></a><span class="lineno">  972</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00973" name="l00973"></a><span class="lineno">  973</span><span class="stringliteral">    random_state : int, RandomState instance, default=None</span></div>
<div class="line"><a id="l00974" name="l00974"></a><span class="lineno">  974</span><span class="stringliteral">        Determines random number generation for weights and bias</span></div>
<div class="line"><a id="l00975" name="l00975"></a><span class="lineno">  975</span><span class="stringliteral">        initialization, train-test split if early stopping is used, and batch</span></div>
<div class="line"><a id="l00976" name="l00976"></a><span class="lineno">  976</span><span class="stringliteral">        sampling when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l00977" name="l00977"></a><span class="lineno">  977</span><span class="stringliteral">        Pass an int for reproducible results across multiple function calls.</span></div>
<div class="line"><a id="l00978" name="l00978"></a><span class="lineno">  978</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><a id="l00979" name="l00979"></a><span class="lineno">  979</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00980" name="l00980"></a><span class="lineno">  980</span><span class="stringliteral">    tol : float, default=1e-4</span></div>
<div class="line"><a id="l00981" name="l00981"></a><span class="lineno">  981</span><span class="stringliteral">        Tolerance for the optimization. When the loss or score is not improving</span></div>
<div class="line"><a id="l00982" name="l00982"></a><span class="lineno">  982</span><span class="stringliteral">        by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,</span></div>
<div class="line"><a id="l00983" name="l00983"></a><span class="lineno">  983</span><span class="stringliteral">        unless ``learning_rate`` is set to &#39;adaptive&#39;, convergence is</span></div>
<div class="line"><a id="l00984" name="l00984"></a><span class="lineno">  984</span><span class="stringliteral">        considered to be reached and training stops.</span></div>
<div class="line"><a id="l00985" name="l00985"></a><span class="lineno">  985</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00986" name="l00986"></a><span class="lineno">  986</span><span class="stringliteral">    verbose : bool, default=False</span></div>
<div class="line"><a id="l00987" name="l00987"></a><span class="lineno">  987</span><span class="stringliteral">        Whether to print progress messages to stdout.</span></div>
<div class="line"><a id="l00988" name="l00988"></a><span class="lineno">  988</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00989" name="l00989"></a><span class="lineno">  989</span><span class="stringliteral">    warm_start : bool, default=False</span></div>
<div class="line"><a id="l00990" name="l00990"></a><span class="lineno">  990</span><span class="stringliteral">        When set to True, reuse the solution of the previous</span></div>
<div class="line"><a id="l00991" name="l00991"></a><span class="lineno">  991</span><span class="stringliteral">        call to fit as initialization, otherwise, just erase the</span></div>
<div class="line"><a id="l00992" name="l00992"></a><span class="lineno">  992</span><span class="stringliteral">        previous solution. See :term:`the Glossary &lt;warm_start&gt;`.</span></div>
<div class="line"><a id="l00993" name="l00993"></a><span class="lineno">  993</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00994" name="l00994"></a><span class="lineno">  994</span><span class="stringliteral">    momentum : float, default=0.9</span></div>
<div class="line"><a id="l00995" name="l00995"></a><span class="lineno">  995</span><span class="stringliteral">        Momentum for gradient descent update. Should be between 0 and 1. Only</span></div>
<div class="line"><a id="l00996" name="l00996"></a><span class="lineno">  996</span><span class="stringliteral">        used when solver=&#39;sgd&#39;.</span></div>
<div class="line"><a id="l00997" name="l00997"></a><span class="lineno">  997</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00998" name="l00998"></a><span class="lineno">  998</span><span class="stringliteral">    nesterovs_momentum : bool, default=True</span></div>
<div class="line"><a id="l00999" name="l00999"></a><span class="lineno">  999</span><span class="stringliteral">        Whether to use Nesterov&#39;s momentum. Only used when solver=&#39;sgd&#39; and</span></div>
<div class="line"><a id="l01000" name="l01000"></a><span class="lineno"> 1000</span><span class="stringliteral">        momentum &gt; 0.</span></div>
<div class="line"><a id="l01001" name="l01001"></a><span class="lineno"> 1001</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01002" name="l01002"></a><span class="lineno"> 1002</span><span class="stringliteral">    early_stopping : bool, default=False</span></div>
<div class="line"><a id="l01003" name="l01003"></a><span class="lineno"> 1003</span><span class="stringliteral">        Whether to use early stopping to terminate training when validation</span></div>
<div class="line"><a id="l01004" name="l01004"></a><span class="lineno"> 1004</span><span class="stringliteral">        score is not improving. If set to true, it will automatically set</span></div>
<div class="line"><a id="l01005" name="l01005"></a><span class="lineno"> 1005</span><span class="stringliteral">        aside 10% of training data as validation and terminate training when</span></div>
<div class="line"><a id="l01006" name="l01006"></a><span class="lineno"> 1006</span><span class="stringliteral">        validation score is not improving by at least ``tol`` for</span></div>
<div class="line"><a id="l01007" name="l01007"></a><span class="lineno"> 1007</span><span class="stringliteral">        ``n_iter_no_change`` consecutive epochs. The split is stratified,</span></div>
<div class="line"><a id="l01008" name="l01008"></a><span class="lineno"> 1008</span><span class="stringliteral">        except in a multilabel setting.</span></div>
<div class="line"><a id="l01009" name="l01009"></a><span class="lineno"> 1009</span><span class="stringliteral">        If early stopping is False, then the training stops when the training</span></div>
<div class="line"><a id="l01010" name="l01010"></a><span class="lineno"> 1010</span><span class="stringliteral">        loss does not improve by more than tol for n_iter_no_change consecutive</span></div>
<div class="line"><a id="l01011" name="l01011"></a><span class="lineno"> 1011</span><span class="stringliteral">        passes over the training set.</span></div>
<div class="line"><a id="l01012" name="l01012"></a><span class="lineno"> 1012</span><span class="stringliteral">        Only effective when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01013" name="l01013"></a><span class="lineno"> 1013</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01014" name="l01014"></a><span class="lineno"> 1014</span><span class="stringliteral">    validation_fraction : float, default=0.1</span></div>
<div class="line"><a id="l01015" name="l01015"></a><span class="lineno"> 1015</span><span class="stringliteral">        The proportion of training data to set aside as validation set for</span></div>
<div class="line"><a id="l01016" name="l01016"></a><span class="lineno"> 1016</span><span class="stringliteral">        early stopping. Must be between 0 and 1.</span></div>
<div class="line"><a id="l01017" name="l01017"></a><span class="lineno"> 1017</span><span class="stringliteral">        Only used if early_stopping is True.</span></div>
<div class="line"><a id="l01018" name="l01018"></a><span class="lineno"> 1018</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01019" name="l01019"></a><span class="lineno"> 1019</span><span class="stringliteral">    beta_1 : float, default=0.9</span></div>
<div class="line"><a id="l01020" name="l01020"></a><span class="lineno"> 1020</span><span class="stringliteral">        Exponential decay rate for estimates of first moment vector in adam,</span></div>
<div class="line"><a id="l01021" name="l01021"></a><span class="lineno"> 1021</span><span class="stringliteral">        should be in [0, 1). Only used when solver=&#39;adam&#39;.</span></div>
<div class="line"><a id="l01022" name="l01022"></a><span class="lineno"> 1022</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01023" name="l01023"></a><span class="lineno"> 1023</span><span class="stringliteral">    beta_2 : float, default=0.999</span></div>
<div class="line"><a id="l01024" name="l01024"></a><span class="lineno"> 1024</span><span class="stringliteral">        Exponential decay rate for estimates of second moment vector in adam,</span></div>
<div class="line"><a id="l01025" name="l01025"></a><span class="lineno"> 1025</span><span class="stringliteral">        should be in [0, 1). Only used when solver=&#39;adam&#39;.</span></div>
<div class="line"><a id="l01026" name="l01026"></a><span class="lineno"> 1026</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01027" name="l01027"></a><span class="lineno"> 1027</span><span class="stringliteral">    epsilon : float, default=1e-8</span></div>
<div class="line"><a id="l01028" name="l01028"></a><span class="lineno"> 1028</span><span class="stringliteral">        Value for numerical stability in adam. Only used when solver=&#39;adam&#39;.</span></div>
<div class="line"><a id="l01029" name="l01029"></a><span class="lineno"> 1029</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01030" name="l01030"></a><span class="lineno"> 1030</span><span class="stringliteral">    n_iter_no_change : int, default=10</span></div>
<div class="line"><a id="l01031" name="l01031"></a><span class="lineno"> 1031</span><span class="stringliteral">        Maximum number of epochs to not meet ``tol`` improvement.</span></div>
<div class="line"><a id="l01032" name="l01032"></a><span class="lineno"> 1032</span><span class="stringliteral">        Only effective when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01033" name="l01033"></a><span class="lineno"> 1033</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01034" name="l01034"></a><span class="lineno"> 1034</span><span class="stringliteral">        .. versionadded:: 0.20</span></div>
<div class="line"><a id="l01035" name="l01035"></a><span class="lineno"> 1035</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01036" name="l01036"></a><span class="lineno"> 1036</span><span class="stringliteral">    max_fun : int, default=15000</span></div>
<div class="line"><a id="l01037" name="l01037"></a><span class="lineno"> 1037</span><span class="stringliteral">        Only used when solver=&#39;lbfgs&#39;. Maximum number of loss function calls.</span></div>
<div class="line"><a id="l01038" name="l01038"></a><span class="lineno"> 1038</span><span class="stringliteral">        The solver iterates until convergence (determined by &#39;tol&#39;), number</span></div>
<div class="line"><a id="l01039" name="l01039"></a><span class="lineno"> 1039</span><span class="stringliteral">        of iterations reaches max_iter, or this number of loss function calls.</span></div>
<div class="line"><a id="l01040" name="l01040"></a><span class="lineno"> 1040</span><span class="stringliteral">        Note that number of loss function calls will be greater than or equal</span></div>
<div class="line"><a id="l01041" name="l01041"></a><span class="lineno"> 1041</span><span class="stringliteral">        to the number of iterations for the `MLPClassifier`.</span></div>
<div class="line"><a id="l01042" name="l01042"></a><span class="lineno"> 1042</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01043" name="l01043"></a><span class="lineno"> 1043</span><span class="stringliteral">        .. versionadded:: 0.22</span></div>
<div class="line"><a id="l01044" name="l01044"></a><span class="lineno"> 1044</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01045" name="l01045"></a><span class="lineno"> 1045</span><span class="stringliteral">    Attributes</span></div>
<div class="line"><a id="l01046" name="l01046"></a><span class="lineno"> 1046</span><span class="stringliteral">    ----------</span></div>
<div class="line"><a id="l01047" name="l01047"></a><span class="lineno"> 1047</span><span class="stringliteral">    classes_ : ndarray or list of ndarray of shape (n_classes,)</span></div>
<div class="line"><a id="l01048" name="l01048"></a><span class="lineno"> 1048</span><span class="stringliteral">        Class labels for each output.</span></div>
<div class="line"><a id="l01049" name="l01049"></a><span class="lineno"> 1049</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01050" name="l01050"></a><span class="lineno"> 1050</span><span class="stringliteral">    loss_ : float</span></div>
<div class="line"><a id="l01051" name="l01051"></a><span class="lineno"> 1051</span><span class="stringliteral">        The current loss computed with the loss function.</span></div>
<div class="line"><a id="l01052" name="l01052"></a><span class="lineno"> 1052</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01053" name="l01053"></a><span class="lineno"> 1053</span><span class="stringliteral">    best_loss_ : float or None</span></div>
<div class="line"><a id="l01054" name="l01054"></a><span class="lineno"> 1054</span><span class="stringliteral">        The minimum loss reached by the solver throughout fitting.</span></div>
<div class="line"><a id="l01055" name="l01055"></a><span class="lineno"> 1055</span><span class="stringliteral">        If `early_stopping=True`, this attribute is set to `None`. Refer to</span></div>
<div class="line"><a id="l01056" name="l01056"></a><span class="lineno"> 1056</span><span class="stringliteral">        the `best_validation_score_` fitted attribute instead.</span></div>
<div class="line"><a id="l01057" name="l01057"></a><span class="lineno"> 1057</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01058" name="l01058"></a><span class="lineno"> 1058</span><span class="stringliteral">    loss_curve_ : list of shape (`n_iter_`,)</span></div>
<div class="line"><a id="l01059" name="l01059"></a><span class="lineno"> 1059</span><span class="stringliteral">        The ith element in the list represents the loss at the ith iteration.</span></div>
<div class="line"><a id="l01060" name="l01060"></a><span class="lineno"> 1060</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01061" name="l01061"></a><span class="lineno"> 1061</span><span class="stringliteral">    validation_scores_ : list of shape (`n_iter_`,) or None</span></div>
<div class="line"><a id="l01062" name="l01062"></a><span class="lineno"> 1062</span><span class="stringliteral">        The score at each iteration on a held-out validation set. The score</span></div>
<div class="line"><a id="l01063" name="l01063"></a><span class="lineno"> 1063</span><span class="stringliteral">        reported is the accuracy score. Only available if `early_stopping=True`,</span></div>
<div class="line"><a id="l01064" name="l01064"></a><span class="lineno"> 1064</span><span class="stringliteral">        otherwise the attribute is set to `None`.</span></div>
<div class="line"><a id="l01065" name="l01065"></a><span class="lineno"> 1065</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01066" name="l01066"></a><span class="lineno"> 1066</span><span class="stringliteral">    best_validation_score_ : float or None</span></div>
<div class="line"><a id="l01067" name="l01067"></a><span class="lineno"> 1067</span><span class="stringliteral">        The best validation score (i.e. accuracy score) that triggered the</span></div>
<div class="line"><a id="l01068" name="l01068"></a><span class="lineno"> 1068</span><span class="stringliteral">        early stopping. Only available if `early_stopping=True`, otherwise the</span></div>
<div class="line"><a id="l01069" name="l01069"></a><span class="lineno"> 1069</span><span class="stringliteral">        attribute is set to `None`.</span></div>
<div class="line"><a id="l01070" name="l01070"></a><span class="lineno"> 1070</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01071" name="l01071"></a><span class="lineno"> 1071</span><span class="stringliteral">    t_ : int</span></div>
<div class="line"><a id="l01072" name="l01072"></a><span class="lineno"> 1072</span><span class="stringliteral">        The number of training samples seen by the solver during fitting.</span></div>
<div class="line"><a id="l01073" name="l01073"></a><span class="lineno"> 1073</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01074" name="l01074"></a><span class="lineno"> 1074</span><span class="stringliteral">    coefs_ : list of shape (n_layers - 1,)</span></div>
<div class="line"><a id="l01075" name="l01075"></a><span class="lineno"> 1075</span><span class="stringliteral">        The ith element in the list represents the weight matrix corresponding</span></div>
<div class="line"><a id="l01076" name="l01076"></a><span class="lineno"> 1076</span><span class="stringliteral">        to layer i.</span></div>
<div class="line"><a id="l01077" name="l01077"></a><span class="lineno"> 1077</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01078" name="l01078"></a><span class="lineno"> 1078</span><span class="stringliteral">    intercepts_ : list of shape (n_layers - 1,)</span></div>
<div class="line"><a id="l01079" name="l01079"></a><span class="lineno"> 1079</span><span class="stringliteral">        The ith element in the list represents the bias vector corresponding to</span></div>
<div class="line"><a id="l01080" name="l01080"></a><span class="lineno"> 1080</span><span class="stringliteral">        layer i + 1.</span></div>
<div class="line"><a id="l01081" name="l01081"></a><span class="lineno"> 1081</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01082" name="l01082"></a><span class="lineno"> 1082</span><span class="stringliteral">    n_features_in_ : int</span></div>
<div class="line"><a id="l01083" name="l01083"></a><span class="lineno"> 1083</span><span class="stringliteral">        Number of features seen during :term:`fit`.</span></div>
<div class="line"><a id="l01084" name="l01084"></a><span class="lineno"> 1084</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01085" name="l01085"></a><span class="lineno"> 1085</span><span class="stringliteral">        .. versionadded:: 0.24</span></div>
<div class="line"><a id="l01086" name="l01086"></a><span class="lineno"> 1086</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01087" name="l01087"></a><span class="lineno"> 1087</span><span class="stringliteral">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span></div>
<div class="line"><a id="l01088" name="l01088"></a><span class="lineno"> 1088</span><span class="stringliteral">        Names of features seen during :term:`fit`. Defined only when `X`</span></div>
<div class="line"><a id="l01089" name="l01089"></a><span class="lineno"> 1089</span><span class="stringliteral">        has feature names that are all strings.</span></div>
<div class="line"><a id="l01090" name="l01090"></a><span class="lineno"> 1090</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01091" name="l01091"></a><span class="lineno"> 1091</span><span class="stringliteral">        .. versionadded:: 1.0</span></div>
<div class="line"><a id="l01092" name="l01092"></a><span class="lineno"> 1092</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01093" name="l01093"></a><span class="lineno"> 1093</span><span class="stringliteral">    n_iter_ : int</span></div>
<div class="line"><a id="l01094" name="l01094"></a><span class="lineno"> 1094</span><span class="stringliteral">        The number of iterations the solver has run.</span></div>
<div class="line"><a id="l01095" name="l01095"></a><span class="lineno"> 1095</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01096" name="l01096"></a><span class="lineno"> 1096</span><span class="stringliteral">    n_layers_ : int</span></div>
<div class="line"><a id="l01097" name="l01097"></a><span class="lineno"> 1097</span><span class="stringliteral">        Number of layers.</span></div>
<div class="line"><a id="l01098" name="l01098"></a><span class="lineno"> 1098</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01099" name="l01099"></a><span class="lineno"> 1099</span><span class="stringliteral">    n_outputs_ : int</span></div>
<div class="line"><a id="l01100" name="l01100"></a><span class="lineno"> 1100</span><span class="stringliteral">        Number of outputs.</span></div>
<div class="line"><a id="l01101" name="l01101"></a><span class="lineno"> 1101</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01102" name="l01102"></a><span class="lineno"> 1102</span><span class="stringliteral">    out_activation_ : str</span></div>
<div class="line"><a id="l01103" name="l01103"></a><span class="lineno"> 1103</span><span class="stringliteral">        Name of the output activation function.</span></div>
<div class="line"><a id="l01104" name="l01104"></a><span class="lineno"> 1104</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01105" name="l01105"></a><span class="lineno"> 1105</span><span class="stringliteral">    See Also</span></div>
<div class="line"><a id="l01106" name="l01106"></a><span class="lineno"> 1106</span><span class="stringliteral">    --------</span></div>
<div class="line"><a id="l01107" name="l01107"></a><span class="lineno"> 1107</span><span class="stringliteral">    MLPRegressor : Multi-layer Perceptron regressor.</span></div>
<div class="line"><a id="l01108" name="l01108"></a><span class="lineno"> 1108</span><span class="stringliteral">    BernoulliRBM : Bernoulli Restricted Boltzmann Machine (RBM).</span></div>
<div class="line"><a id="l01109" name="l01109"></a><span class="lineno"> 1109</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01110" name="l01110"></a><span class="lineno"> 1110</span><span class="stringliteral">    Notes</span></div>
<div class="line"><a id="l01111" name="l01111"></a><span class="lineno"> 1111</span><span class="stringliteral">    -----</span></div>
<div class="line"><a id="l01112" name="l01112"></a><span class="lineno"> 1112</span><span class="stringliteral">    MLPClassifier trains iteratively since at each time step</span></div>
<div class="line"><a id="l01113" name="l01113"></a><span class="lineno"> 1113</span><span class="stringliteral">    the partial derivatives of the loss function with respect to the model</span></div>
<div class="line"><a id="l01114" name="l01114"></a><span class="lineno"> 1114</span><span class="stringliteral">    parameters are computed to update the parameters.</span></div>
<div class="line"><a id="l01115" name="l01115"></a><span class="lineno"> 1115</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01116" name="l01116"></a><span class="lineno"> 1116</span><span class="stringliteral">    It can also have a regularization term added to the loss function</span></div>
<div class="line"><a id="l01117" name="l01117"></a><span class="lineno"> 1117</span><span class="stringliteral">    that shrinks model parameters to prevent overfitting.</span></div>
<div class="line"><a id="l01118" name="l01118"></a><span class="lineno"> 1118</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01119" name="l01119"></a><span class="lineno"> 1119</span><span class="stringliteral">    This implementation works with data represented as dense numpy arrays or</span></div>
<div class="line"><a id="l01120" name="l01120"></a><span class="lineno"> 1120</span><span class="stringliteral">    sparse scipy arrays of floating point values.</span></div>
<div class="line"><a id="l01121" name="l01121"></a><span class="lineno"> 1121</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01122" name="l01122"></a><span class="lineno"> 1122</span><span class="stringliteral">    References</span></div>
<div class="line"><a id="l01123" name="l01123"></a><span class="lineno"> 1123</span><span class="stringliteral">    ----------</span></div>
<div class="line"><a id="l01124" name="l01124"></a><span class="lineno"> 1124</span><span class="stringliteral">    Hinton, Geoffrey E. &quot;Connectionist learning procedures.&quot;</span></div>
<div class="line"><a id="l01125" name="l01125"></a><span class="lineno"> 1125</span><span class="stringliteral">    Artificial intelligence 40.1 (1989): 185-234.</span></div>
<div class="line"><a id="l01126" name="l01126"></a><span class="lineno"> 1126</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01127" name="l01127"></a><span class="lineno"> 1127</span><span class="stringliteral">    Glorot, Xavier, and Yoshua Bengio.</span></div>
<div class="line"><a id="l01128" name="l01128"></a><span class="lineno"> 1128</span><span class="stringliteral">    &quot;Understanding the difficulty of training deep feedforward neural networks.&quot;</span></div>
<div class="line"><a id="l01129" name="l01129"></a><span class="lineno"> 1129</span><span class="stringliteral">    International Conference on Artificial Intelligence and Statistics. 2010.</span></div>
<div class="line"><a id="l01130" name="l01130"></a><span class="lineno"> 1130</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01131" name="l01131"></a><span class="lineno"> 1131</span><span class="stringliteral">    :arxiv:`He, Kaiming, et al (2015). &quot;Delving deep into rectifiers:</span></div>
<div class="line"><a id="l01132" name="l01132"></a><span class="lineno"> 1132</span><span class="stringliteral">    Surpassing human-level performance on imagenet classification.&quot; &lt;1502.01852&gt;`</span></div>
<div class="line"><a id="l01133" name="l01133"></a><span class="lineno"> 1133</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01134" name="l01134"></a><span class="lineno"> 1134</span><span class="stringliteral">    :arxiv:`Kingma, Diederik, and Jimmy Ba (2014)</span></div>
<div class="line"><a id="l01135" name="l01135"></a><span class="lineno"> 1135</span><span class="stringliteral">    &quot;Adam: A method for stochastic optimization.&quot; &lt;1412.6980&gt;`</span></div>
<div class="line"><a id="l01136" name="l01136"></a><span class="lineno"> 1136</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01137" name="l01137"></a><span class="lineno"> 1137</span><span class="stringliteral">    Examples</span></div>
<div class="line"><a id="l01138" name="l01138"></a><span class="lineno"> 1138</span><span class="stringliteral">    --------</span></div>
<div class="line"><a id="l01139" name="l01139"></a><span class="lineno"> 1139</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.neural_network import MLPClassifier</span></div>
<div class="line"><a id="l01140" name="l01140"></a><span class="lineno"> 1140</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.datasets import make_classification</span></div>
<div class="line"><a id="l01141" name="l01141"></a><span class="lineno"> 1141</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.model_selection import train_test_split</span></div>
<div class="line"><a id="l01142" name="l01142"></a><span class="lineno"> 1142</span><span class="stringliteral">    &gt;&gt;&gt; X, y = make_classification(n_samples=100, random_state=1)</span></div>
<div class="line"><a id="l01143" name="l01143"></a><span class="lineno"> 1143</span><span class="stringliteral">    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,</span></div>
<div class="line"><a id="l01144" name="l01144"></a><span class="lineno"> 1144</span><span class="stringliteral">    ...                                                     random_state=1)</span></div>
<div class="line"><a id="l01145" name="l01145"></a><span class="lineno"> 1145</span><span class="stringliteral">    &gt;&gt;&gt; clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)</span></div>
<div class="line"><a id="l01146" name="l01146"></a><span class="lineno"> 1146</span><span class="stringliteral">    &gt;&gt;&gt; clf.predict_proba(X_test[:1])</span></div>
<div class="line"><a id="l01147" name="l01147"></a><span class="lineno"> 1147</span><span class="stringliteral">    array([[0.0383, 0.961]])</span></div>
<div class="line"><a id="l01148" name="l01148"></a><span class="lineno"> 1148</span><span class="stringliteral">    &gt;&gt;&gt; clf.predict(X_test[:5, :])</span></div>
<div class="line"><a id="l01149" name="l01149"></a><span class="lineno"> 1149</span><span class="stringliteral">    array([1, 0, 1, 0, 1])</span></div>
<div class="line"><a id="l01150" name="l01150"></a><span class="lineno"> 1150</span><span class="stringliteral">    &gt;&gt;&gt; clf.score(X_test, y_test)</span></div>
<div class="line"><a id="l01151" name="l01151"></a><span class="lineno"> 1151</span><span class="stringliteral">    0.8...</span></div>
<div class="line"><a id="l01152" name="l01152"></a><span class="lineno"> 1152</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l01153" name="l01153"></a><span class="lineno"> 1153</span> </div>
<div class="line"><a id="l01154" name="l01154"></a><span class="lineno"> 1154</span>    <span class="keyword">def </span>__init__(</div>
<div class="line"><a id="l01155" name="l01155"></a><span class="lineno"> 1155</span>        self,</div>
<div class="line"><a id="l01156" name="l01156"></a><span class="lineno"> 1156</span>        hidden_layer_sizes=(100,),</div>
<div class="line"><a id="l01157" name="l01157"></a><span class="lineno"> 1157</span>        activation=<span class="stringliteral">&quot;relu&quot;</span>,</div>
<div class="line"><a id="l01158" name="l01158"></a><span class="lineno"> 1158</span>        *,</div>
<div class="line"><a id="l01159" name="l01159"></a><span class="lineno"> 1159</span>        solver=<span class="stringliteral">&quot;adam&quot;</span>,</div>
<div class="line"><a id="l01160" name="l01160"></a><span class="lineno"> 1160</span>        alpha=0.0001,</div>
<div class="line"><a id="l01161" name="l01161"></a><span class="lineno"> 1161</span>        batch_size=<span class="stringliteral">&quot;auto&quot;</span>,</div>
<div class="line"><a id="l01162" name="l01162"></a><span class="lineno"> 1162</span>        learning_rate=<span class="stringliteral">&quot;constant&quot;</span>,</div>
<div class="line"><a id="l01163" name="l01163"></a><span class="lineno"> 1163</span>        learning_rate_init=0.001,</div>
<div class="line"><a id="l01164" name="l01164"></a><span class="lineno"> 1164</span>        power_t=0.5,</div>
<div class="line"><a id="l01165" name="l01165"></a><span class="lineno"> 1165</span>        max_iter=200,</div>
<div class="line"><a id="l01166" name="l01166"></a><span class="lineno"> 1166</span>        shuffle=<span class="keyword">True</span>,</div>
<div class="line"><a id="l01167" name="l01167"></a><span class="lineno"> 1167</span>        random_state=<span class="keywordtype">None</span>,</div>
<div class="line"><a id="l01168" name="l01168"></a><span class="lineno"> 1168</span>        tol=1e-4,</div>
<div class="line"><a id="l01169" name="l01169"></a><span class="lineno"> 1169</span>        verbose=<span class="keyword">False</span>,</div>
<div class="line"><a id="l01170" name="l01170"></a><span class="lineno"> 1170</span>        warm_start=<span class="keyword">False</span>,</div>
<div class="line"><a id="l01171" name="l01171"></a><span class="lineno"> 1171</span>        momentum=0.9,</div>
<div class="line"><a id="l01172" name="l01172"></a><span class="lineno"> 1172</span>        nesterovs_momentum=<span class="keyword">True</span>,</div>
<div class="line"><a id="l01173" name="l01173"></a><span class="lineno"> 1173</span>        early_stopping=<span class="keyword">False</span>,</div>
<div class="line"><a id="l01174" name="l01174"></a><span class="lineno"> 1174</span>        validation_fraction=0.1,</div>
<div class="line"><a id="l01175" name="l01175"></a><span class="lineno"> 1175</span>        beta_1=0.9,</div>
<div class="line"><a id="l01176" name="l01176"></a><span class="lineno"> 1176</span>        beta_2=0.999,</div>
<div class="line"><a id="l01177" name="l01177"></a><span class="lineno"> 1177</span>        epsilon=1e-8,</div>
<div class="line"><a id="l01178" name="l01178"></a><span class="lineno"> 1178</span>        n_iter_no_change=10,</div>
<div class="line"><a id="l01179" name="l01179"></a><span class="lineno"> 1179</span>        max_fun=15000,</div>
<div class="line"><a id="l01180" name="l01180"></a><span class="lineno"> 1180</span>    ):</div>
<div class="line"><a id="l01181" name="l01181"></a><span class="lineno"> 1181</span>        super().__init__(</div>
<div class="line"><a id="l01182" name="l01182"></a><span class="lineno"> 1182</span>            hidden_layer_sizes=hidden_layer_sizes,</div>
<div class="line"><a id="l01183" name="l01183"></a><span class="lineno"> 1183</span>            activation=activation,</div>
<div class="line"><a id="l01184" name="l01184"></a><span class="lineno"> 1184</span>            solver=solver,</div>
<div class="line"><a id="l01185" name="l01185"></a><span class="lineno"> 1185</span>            alpha=alpha,</div>
<div class="line"><a id="l01186" name="l01186"></a><span class="lineno"> 1186</span>            batch_size=batch_size,</div>
<div class="line"><a id="l01187" name="l01187"></a><span class="lineno"> 1187</span>            learning_rate=learning_rate,</div>
<div class="line"><a id="l01188" name="l01188"></a><span class="lineno"> 1188</span>            learning_rate_init=learning_rate_init,</div>
<div class="line"><a id="l01189" name="l01189"></a><span class="lineno"> 1189</span>            power_t=power_t,</div>
<div class="line"><a id="l01190" name="l01190"></a><span class="lineno"> 1190</span>            max_iter=max_iter,</div>
<div class="line"><a id="l01191" name="l01191"></a><span class="lineno"> 1191</span>            loss=<span class="stringliteral">&quot;log_loss&quot;</span>,</div>
<div class="line"><a id="l01192" name="l01192"></a><span class="lineno"> 1192</span>            shuffle=shuffle,</div>
<div class="line"><a id="l01193" name="l01193"></a><span class="lineno"> 1193</span>            random_state=random_state,</div>
<div class="line"><a id="l01194" name="l01194"></a><span class="lineno"> 1194</span>            tol=tol,</div>
<div class="line"><a id="l01195" name="l01195"></a><span class="lineno"> 1195</span>            verbose=verbose,</div>
<div class="line"><a id="l01196" name="l01196"></a><span class="lineno"> 1196</span>            warm_start=warm_start,</div>
<div class="line"><a id="l01197" name="l01197"></a><span class="lineno"> 1197</span>            momentum=momentum,</div>
<div class="line"><a id="l01198" name="l01198"></a><span class="lineno"> 1198</span>            nesterovs_momentum=nesterovs_momentum,</div>
<div class="line"><a id="l01199" name="l01199"></a><span class="lineno"> 1199</span>            early_stopping=early_stopping,</div>
<div class="line"><a id="l01200" name="l01200"></a><span class="lineno"> 1200</span>            validation_fraction=validation_fraction,</div>
<div class="line"><a id="l01201" name="l01201"></a><span class="lineno"> 1201</span>            beta_1=beta_1,</div>
<div class="line"><a id="l01202" name="l01202"></a><span class="lineno"> 1202</span>            beta_2=beta_2,</div>
<div class="line"><a id="l01203" name="l01203"></a><span class="lineno"> 1203</span>            epsilon=epsilon,</div>
<div class="line"><a id="l01204" name="l01204"></a><span class="lineno"> 1204</span>            n_iter_no_change=n_iter_no_change,</div>
<div class="line"><a id="l01205" name="l01205"></a><span class="lineno"> 1205</span>            max_fun=max_fun,</div>
<div class="line"><a id="l01206" name="l01206"></a><span class="lineno"> 1206</span>        )</div>
<div class="line"><a id="l01207" name="l01207"></a><span class="lineno"> 1207</span> </div>
<div class="line"><a id="l01208" name="l01208"></a><span class="lineno"> 1208</span>    <span class="keyword">def </span>_validate_input(self, X, y, incremental, reset):</div>
<div class="line"><a id="l01209" name="l01209"></a><span class="lineno"> 1209</span>        X, y = validate_data(</div>
<div class="line"><a id="l01210" name="l01210"></a><span class="lineno"> 1210</span>            self,</div>
<div class="line"><a id="l01211" name="l01211"></a><span class="lineno"> 1211</span>            X,</div>
<div class="line"><a id="l01212" name="l01212"></a><span class="lineno"> 1212</span>            y,</div>
<div class="line"><a id="l01213" name="l01213"></a><span class="lineno"> 1213</span>            accept_sparse=[<span class="stringliteral">&quot;csr&quot;</span>, <span class="stringliteral">&quot;csc&quot;</span>],</div>
<div class="line"><a id="l01214" name="l01214"></a><span class="lineno"> 1214</span>            multi_output=<span class="keyword">True</span>,</div>
<div class="line"><a id="l01215" name="l01215"></a><span class="lineno"> 1215</span>            dtype=(np.float64, np.float32),</div>
<div class="line"><a id="l01216" name="l01216"></a><span class="lineno"> 1216</span>            reset=reset,</div>
<div class="line"><a id="l01217" name="l01217"></a><span class="lineno"> 1217</span>        )</div>
<div class="line"><a id="l01218" name="l01218"></a><span class="lineno"> 1218</span>        <span class="keywordflow">if</span> y.ndim == 2 <span class="keywordflow">and</span> y.shape[1] == 1:</div>
<div class="line"><a id="l01219" name="l01219"></a><span class="lineno"> 1219</span>            y = column_or_1d(y, warn=<span class="keyword">True</span>)</div>
<div class="line"><a id="l01220" name="l01220"></a><span class="lineno"> 1220</span> </div>
<div class="line"><a id="l01221" name="l01221"></a><span class="lineno"> 1221</span>        <span class="comment"># Matrix of actions to be taken under the possible combinations:</span></div>
<div class="line"><a id="l01222" name="l01222"></a><span class="lineno"> 1222</span>        <span class="comment"># The case that incremental == True and classes_ not defined is</span></div>
<div class="line"><a id="l01223" name="l01223"></a><span class="lineno"> 1223</span>        <span class="comment"># already checked by _check_partial_fit_first_call that is called</span></div>
<div class="line"><a id="l01224" name="l01224"></a><span class="lineno"> 1224</span>        <span class="comment"># in _partial_fit below.</span></div>
<div class="line"><a id="l01225" name="l01225"></a><span class="lineno"> 1225</span>        <span class="comment"># The cases are already grouped into the respective if blocks below.</span></div>
<div class="line"><a id="l01226" name="l01226"></a><span class="lineno"> 1226</span>        <span class="comment">#</span></div>
<div class="line"><a id="l01227" name="l01227"></a><span class="lineno"> 1227</span>        <span class="comment"># incremental warm_start classes_ def  action</span></div>
<div class="line"><a id="l01228" name="l01228"></a><span class="lineno"> 1228</span>        <span class="comment">#    0            0         0        define classes_</span></div>
<div class="line"><a id="l01229" name="l01229"></a><span class="lineno"> 1229</span>        <span class="comment">#    0            1         0        define classes_</span></div>
<div class="line"><a id="l01230" name="l01230"></a><span class="lineno"> 1230</span>        <span class="comment">#    0            0         1        redefine classes_</span></div>
<div class="line"><a id="l01231" name="l01231"></a><span class="lineno"> 1231</span>        <span class="comment">#</span></div>
<div class="line"><a id="l01232" name="l01232"></a><span class="lineno"> 1232</span>        <span class="comment">#    0            1         1        check compat warm_start</span></div>
<div class="line"><a id="l01233" name="l01233"></a><span class="lineno"> 1233</span>        <span class="comment">#    1            1         1        check compat warm_start</span></div>
<div class="line"><a id="l01234" name="l01234"></a><span class="lineno"> 1234</span>        <span class="comment">#</span></div>
<div class="line"><a id="l01235" name="l01235"></a><span class="lineno"> 1235</span>        <span class="comment">#    1            0         1        check compat last fit</span></div>
<div class="line"><a id="l01236" name="l01236"></a><span class="lineno"> 1236</span>        <span class="comment">#</span></div>
<div class="line"><a id="l01237" name="l01237"></a><span class="lineno"> 1237</span>        <span class="comment"># Note the reliance on short-circuiting here, so that the second</span></div>
<div class="line"><a id="l01238" name="l01238"></a><span class="lineno"> 1238</span>        <span class="comment"># or part implies that classes_ is defined.</span></div>
<div class="line"><a id="l01239" name="l01239"></a><span class="lineno"> 1239</span>        <span class="keywordflow">if</span> (<span class="keywordflow">not</span> hasattr(self, <span class="stringliteral">&quot;classes_&quot;</span>)) <span class="keywordflow">or</span> (<span class="keywordflow">not</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a96c5a6ce572a9cfe24350c3f1b737116">warm_start</a> <span class="keywordflow">and</span> <span class="keywordflow">not</span> incremental):</div>
<div class="line"><a id="l01240" name="l01240"></a><span class="lineno"> 1240</span>            self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#aa4a6e8fdf6566ab2228b0a33d956da60">_label_binarizer</a> = <a class="code hl_class" href="../../d9/d21/classsklearn_1_1preprocessing_1_1__label_1_1LabelBinarizer.html">LabelBinarizer</a>()</div>
<div class="line"><a id="l01241" name="l01241"></a><span class="lineno"> 1241</span>            self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#aa4a6e8fdf6566ab2228b0a33d956da60">_label_binarizer</a>.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa993801cc4d309b69244e4ea31d5a4a9">fit</a>(y)</div>
<div class="line"><a id="l01242" name="l01242"></a><span class="lineno"> 1242</span>            self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#adf5451f04bf39076f2d357a2ecba04e2">classes_</a> = self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#aa4a6e8fdf6566ab2228b0a33d956da60">_label_binarizer</a>.classes_</div>
<div class="line"><a id="l01243" name="l01243"></a><span class="lineno"> 1243</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l01244" name="l01244"></a><span class="lineno"> 1244</span>            classes = unique_labels(y)</div>
<div class="line"><a id="l01245" name="l01245"></a><span class="lineno"> 1245</span>            <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a96c5a6ce572a9cfe24350c3f1b737116">warm_start</a>:</div>
<div class="line"><a id="l01246" name="l01246"></a><span class="lineno"> 1246</span>                <span class="keywordflow">if</span> set(classes) != set(self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#adf5451f04bf39076f2d357a2ecba04e2">classes_</a>):</div>
<div class="line"><a id="l01247" name="l01247"></a><span class="lineno"> 1247</span>                    <span class="keywordflow">raise</span> <a class="code hl_class" href="../../de/d40/classValueError.html">ValueError</a>(</div>
<div class="line"><a id="l01248" name="l01248"></a><span class="lineno"> 1248</span>                        <span class="stringliteral">&quot;warm_start can only be used where `y` has the same &quot;</span></div>
<div class="line"><a id="l01249" name="l01249"></a><span class="lineno"> 1249</span>                        <span class="stringliteral">&quot;classes as in the previous call to fit. Previously &quot;</span></div>
<div class="line"><a id="l01250" name="l01250"></a><span class="lineno"> 1250</span>                        f<span class="stringliteral">&quot;got {self.classes_}, `y` has {classes}&quot;</span></div>
<div class="line"><a id="l01251" name="l01251"></a><span class="lineno"> 1251</span>                    )</div>
<div class="line"><a id="l01252" name="l01252"></a><span class="lineno"> 1252</span>            <span class="keywordflow">elif</span> len(np.setdiff1d(classes, self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#adf5451f04bf39076f2d357a2ecba04e2">classes_</a>, assume_unique=<span class="keyword">True</span>)):</div>
<div class="line"><a id="l01253" name="l01253"></a><span class="lineno"> 1253</span>                <span class="keywordflow">raise</span> <a class="code hl_class" href="../../de/d40/classValueError.html">ValueError</a>(</div>
<div class="line"><a id="l01254" name="l01254"></a><span class="lineno"> 1254</span>                    <span class="stringliteral">&quot;`y` has classes not in `self.classes_`. &quot;</span></div>
<div class="line"><a id="l01255" name="l01255"></a><span class="lineno"> 1255</span>                    f<span class="stringliteral">&quot;`self.classes_` has {self.classes_}. &#39;y&#39; has {classes}.&quot;</span></div>
<div class="line"><a id="l01256" name="l01256"></a><span class="lineno"> 1256</span>                )</div>
<div class="line"><a id="l01257" name="l01257"></a><span class="lineno"> 1257</span> </div>
<div class="line"><a id="l01258" name="l01258"></a><span class="lineno"> 1258</span>        <span class="comment"># This downcast to bool is to prevent upcasting when working with</span></div>
<div class="line"><a id="l01259" name="l01259"></a><span class="lineno"> 1259</span>        <span class="comment"># float32 data</span></div>
<div class="line"><a id="l01260" name="l01260"></a><span class="lineno"> 1260</span>        y = self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#aa4a6e8fdf6566ab2228b0a33d956da60">_label_binarizer</a>.transform(y).astype(bool)</div>
<div class="line"><a id="l01261" name="l01261"></a><span class="lineno"> 1261</span>        <span class="keywordflow">return</span> X, y</div>
<div class="line"><a id="l01262" name="l01262"></a><span class="lineno"> 1262</span> </div>
<div class="foldopen" id="foldopen01263" data-start="" data-end="">
<div class="line"><a id="l01263" name="l01263"></a><span class="lineno"><a class="line" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#a64069f3c9ec4c814c65fbe2aca94cf14"> 1263</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#a64069f3c9ec4c814c65fbe2aca94cf14">predict</a>(self, X):</div>
<div class="line"><a id="l01264" name="l01264"></a><span class="lineno"> 1264</span>        <span class="stringliteral">&quot;&quot;&quot;Predict using the multi-layer perceptron classifier.</span></div>
<div class="line"><a id="l01265" name="l01265"></a><span class="lineno"> 1265</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01266" name="l01266"></a><span class="lineno"> 1266</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l01267" name="l01267"></a><span class="lineno"> 1267</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l01268" name="l01268"></a><span class="lineno"> 1268</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><a id="l01269" name="l01269"></a><span class="lineno"> 1269</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><a id="l01270" name="l01270"></a><span class="lineno"> 1270</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01271" name="l01271"></a><span class="lineno"> 1271</span><span class="stringliteral">        Returns</span></div>
<div class="line"><a id="l01272" name="l01272"></a><span class="lineno"> 1272</span><span class="stringliteral">        -------</span></div>
<div class="line"><a id="l01273" name="l01273"></a><span class="lineno"> 1273</span><span class="stringliteral">        y : ndarray, shape (n_samples,) or (n_samples, n_classes)</span></div>
<div class="line"><a id="l01274" name="l01274"></a><span class="lineno"> 1274</span><span class="stringliteral">            The predicted classes.</span></div>
<div class="line"><a id="l01275" name="l01275"></a><span class="lineno"> 1275</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l01276" name="l01276"></a><span class="lineno"> 1276</span>        check_is_fitted(self)</div>
<div class="line"><a id="l01277" name="l01277"></a><span class="lineno"> 1277</span>        <span class="keywordflow">return</span> self.<a class="code hl_function" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#abc60cd9ab05a18e4a342e97a43034bac">_predict</a>(X)</div>
<div class="line"><a id="l01278" name="l01278"></a><span class="lineno"> 1278</span> </div>
</div>
<div class="foldopen" id="foldopen01279" data-start="" data-end="">
<div class="line"><a id="l01279" name="l01279"></a><span class="lineno"><a class="line" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#abc60cd9ab05a18e4a342e97a43034bac"> 1279</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#abc60cd9ab05a18e4a342e97a43034bac">_predict</a>(self, X, check_input=True):</div>
<div class="line"><a id="l01280" name="l01280"></a><span class="lineno"> 1280</span>        <span class="stringliteral">&quot;&quot;&quot;Private predict method with optional input validation&quot;&quot;&quot;</span></div>
<div class="line"><a id="l01281" name="l01281"></a><span class="lineno"> 1281</span>        y_pred = self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a65cb479141ebeb9fd5e77845b242979b">_forward_pass_fast</a>(X, check_input=check_input)</div>
<div class="line"><a id="l01282" name="l01282"></a><span class="lineno"> 1282</span> </div>
<div class="line"><a id="l01283" name="l01283"></a><span class="lineno"> 1283</span>        <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac913f3e320e35d56add32462793c14e7">n_outputs_</a> == 1:</div>
<div class="line"><a id="l01284" name="l01284"></a><span class="lineno"> 1284</span>            y_pred = y_pred.ravel()</div>
<div class="line"><a id="l01285" name="l01285"></a><span class="lineno"> 1285</span> </div>
<div class="line"><a id="l01286" name="l01286"></a><span class="lineno"> 1286</span>        <span class="keywordflow">return</span> self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#aa4a6e8fdf6566ab2228b0a33d956da60">_label_binarizer</a>.inverse_transform(y_pred)</div>
<div class="line"><a id="l01287" name="l01287"></a><span class="lineno"> 1287</span> </div>
</div>
<div class="line"><a id="l01288" name="l01288"></a><span class="lineno"> 1288</span>    <span class="keyword">def </span>_score(self, X, y, sample_weight=None):</div>
<div class="line"><a id="l01289" name="l01289"></a><span class="lineno"> 1289</span>        <span class="keywordflow">return</span> super().<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad19ee046e2bfe882adbddfb46980c0f6">_score_with_function</a>(</div>
<div class="line"><a id="l01290" name="l01290"></a><span class="lineno"> 1290</span>            X, y, sample_weight=sample_weight, score_function=accuracy_score</div>
<div class="line"><a id="l01291" name="l01291"></a><span class="lineno"> 1291</span>        )</div>
<div class="line"><a id="l01292" name="l01292"></a><span class="lineno"> 1292</span> </div>
<div class="line"><a id="l01293" name="l01293"></a><span class="lineno"> 1293</span>    <span class="preprocessor">@available_if(lambda est: est._check_solver()</span>)</div>
<div class="line"><a id="l01294" name="l01294"></a><span class="lineno"> 1294</span>    <span class="preprocessor">@_fit_context(prefer_skip_nested_validation=True)</span></div>
<div class="foldopen" id="foldopen01295" data-start="" data-end="">
<div class="line"><a id="l01295" name="l01295"></a><span class="lineno"><a class="line" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#a16623460fe2b65e46108871f5618a9fb"> 1295</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#a16623460fe2b65e46108871f5618a9fb">partial_fit</a>(self, X, y, sample_weight=None, classes=None):</div>
<div class="line"><a id="l01296" name="l01296"></a><span class="lineno"> 1296</span>        <span class="stringliteral">&quot;&quot;&quot;Update the model with a single iteration over the given data.</span></div>
<div class="line"><a id="l01297" name="l01297"></a><span class="lineno"> 1297</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01298" name="l01298"></a><span class="lineno"> 1298</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l01299" name="l01299"></a><span class="lineno"> 1299</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l01300" name="l01300"></a><span class="lineno"> 1300</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><a id="l01301" name="l01301"></a><span class="lineno"> 1301</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><a id="l01302" name="l01302"></a><span class="lineno"> 1302</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01303" name="l01303"></a><span class="lineno"> 1303</span><span class="stringliteral">        y : array-like of shape (n_samples,)</span></div>
<div class="line"><a id="l01304" name="l01304"></a><span class="lineno"> 1304</span><span class="stringliteral">            The target values.</span></div>
<div class="line"><a id="l01305" name="l01305"></a><span class="lineno"> 1305</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01306" name="l01306"></a><span class="lineno"> 1306</span><span class="stringliteral">        sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><a id="l01307" name="l01307"></a><span class="lineno"> 1307</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><a id="l01308" name="l01308"></a><span class="lineno"> 1308</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01309" name="l01309"></a><span class="lineno"> 1309</span><span class="stringliteral">            .. versionadded:: 1.7</span></div>
<div class="line"><a id="l01310" name="l01310"></a><span class="lineno"> 1310</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01311" name="l01311"></a><span class="lineno"> 1311</span><span class="stringliteral">        classes : array of shape (n_classes,), default=None</span></div>
<div class="line"><a id="l01312" name="l01312"></a><span class="lineno"> 1312</span><span class="stringliteral">            Classes across all calls to partial_fit.</span></div>
<div class="line"><a id="l01313" name="l01313"></a><span class="lineno"> 1313</span><span class="stringliteral">            Can be obtained via `np.unique(y_all)`, where y_all is the</span></div>
<div class="line"><a id="l01314" name="l01314"></a><span class="lineno"> 1314</span><span class="stringliteral">            target vector of the entire dataset.</span></div>
<div class="line"><a id="l01315" name="l01315"></a><span class="lineno"> 1315</span><span class="stringliteral">            This argument is required for the first call to partial_fit</span></div>
<div class="line"><a id="l01316" name="l01316"></a><span class="lineno"> 1316</span><span class="stringliteral">            and can be omitted in the subsequent calls.</span></div>
<div class="line"><a id="l01317" name="l01317"></a><span class="lineno"> 1317</span><span class="stringliteral">            Note that y doesn&#39;t need to contain all labels in `classes`.</span></div>
<div class="line"><a id="l01318" name="l01318"></a><span class="lineno"> 1318</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01319" name="l01319"></a><span class="lineno"> 1319</span><span class="stringliteral">        Returns</span></div>
<div class="line"><a id="l01320" name="l01320"></a><span class="lineno"> 1320</span><span class="stringliteral">        -------</span></div>
<div class="line"><a id="l01321" name="l01321"></a><span class="lineno"> 1321</span><span class="stringliteral">        self : object</span></div>
<div class="line"><a id="l01322" name="l01322"></a><span class="lineno"> 1322</span><span class="stringliteral">            Trained MLP model.</span></div>
<div class="line"><a id="l01323" name="l01323"></a><span class="lineno"> 1323</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l01324" name="l01324"></a><span class="lineno"> 1324</span>        <span class="keywordflow">if</span> _check_partial_fit_first_call(self, classes):</div>
<div class="line"><a id="l01325" name="l01325"></a><span class="lineno"> 1325</span>            self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#aa4a6e8fdf6566ab2228b0a33d956da60">_label_binarizer</a> = <a class="code hl_class" href="../../d9/d21/classsklearn_1_1preprocessing_1_1__label_1_1LabelBinarizer.html">LabelBinarizer</a>()</div>
<div class="line"><a id="l01326" name="l01326"></a><span class="lineno"> 1326</span>            <span class="keywordflow">if</span> type_of_target(y).startswith(<span class="stringliteral">&quot;multilabel&quot;</span>):</div>
<div class="line"><a id="l01327" name="l01327"></a><span class="lineno"> 1327</span>                self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#aa4a6e8fdf6566ab2228b0a33d956da60">_label_binarizer</a>.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa993801cc4d309b69244e4ea31d5a4a9">fit</a>(y)</div>
<div class="line"><a id="l01328" name="l01328"></a><span class="lineno"> 1328</span>            <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l01329" name="l01329"></a><span class="lineno"> 1329</span>                self.<a class="code hl_variable" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#aa4a6e8fdf6566ab2228b0a33d956da60">_label_binarizer</a>.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa993801cc4d309b69244e4ea31d5a4a9">fit</a>(classes)</div>
<div class="line"><a id="l01330" name="l01330"></a><span class="lineno"> 1330</span> </div>
<div class="line"><a id="l01331" name="l01331"></a><span class="lineno"> 1331</span>        <span class="keywordflow">return</span> self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5ee59a9eb9aefd9dde989f3a32cac161">_fit</a>(X, y, sample_weight=sample_weight, incremental=<span class="keyword">True</span>)</div>
<div class="line"><a id="l01332" name="l01332"></a><span class="lineno"> 1332</span> </div>
</div>
<div class="foldopen" id="foldopen01333" data-start="" data-end="">
<div class="line"><a id="l01333" name="l01333"></a><span class="lineno"><a class="line" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#a18543e8902910fb447a70a26df276d82"> 1333</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#a18543e8902910fb447a70a26df276d82">predict_log_proba</a>(self, X):</div>
<div class="line"><a id="l01334" name="l01334"></a><span class="lineno"> 1334</span>        <span class="stringliteral">&quot;&quot;&quot;Return the log of probability estimates.</span></div>
<div class="line"><a id="l01335" name="l01335"></a><span class="lineno"> 1335</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01336" name="l01336"></a><span class="lineno"> 1336</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l01337" name="l01337"></a><span class="lineno"> 1337</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l01338" name="l01338"></a><span class="lineno"> 1338</span><span class="stringliteral">        X : ndarray of shape (n_samples, n_features)</span></div>
<div class="line"><a id="l01339" name="l01339"></a><span class="lineno"> 1339</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><a id="l01340" name="l01340"></a><span class="lineno"> 1340</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01341" name="l01341"></a><span class="lineno"> 1341</span><span class="stringliteral">        Returns</span></div>
<div class="line"><a id="l01342" name="l01342"></a><span class="lineno"> 1342</span><span class="stringliteral">        -------</span></div>
<div class="line"><a id="l01343" name="l01343"></a><span class="lineno"> 1343</span><span class="stringliteral">        log_y_prob : ndarray of shape (n_samples, n_classes)</span></div>
<div class="line"><a id="l01344" name="l01344"></a><span class="lineno"> 1344</span><span class="stringliteral">            The predicted log-probability of the sample for each class</span></div>
<div class="line"><a id="l01345" name="l01345"></a><span class="lineno"> 1345</span><span class="stringliteral">            in the model, where classes are ordered as they are in</span></div>
<div class="line"><a id="l01346" name="l01346"></a><span class="lineno"> 1346</span><span class="stringliteral">            `self.classes_`. Equivalent to `log(predict_proba(X))`.</span></div>
<div class="line"><a id="l01347" name="l01347"></a><span class="lineno"> 1347</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l01348" name="l01348"></a><span class="lineno"> 1348</span>        y_prob = self.<a class="code hl_function" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#ab8223db06662e4b79f8cc97db664afe1">predict_proba</a>(X)</div>
<div class="line"><a id="l01349" name="l01349"></a><span class="lineno"> 1349</span>        <span class="keywordflow">return</span> np.log(y_prob, out=y_prob)</div>
<div class="line"><a id="l01350" name="l01350"></a><span class="lineno"> 1350</span> </div>
</div>
<div class="foldopen" id="foldopen01351" data-start="" data-end="">
<div class="line"><a id="l01351" name="l01351"></a><span class="lineno"><a class="line" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#ab8223db06662e4b79f8cc97db664afe1"> 1351</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#ab8223db06662e4b79f8cc97db664afe1">predict_proba</a>(self, X):</div>
<div class="line"><a id="l01352" name="l01352"></a><span class="lineno"> 1352</span>        <span class="stringliteral">&quot;&quot;&quot;Probability estimates.</span></div>
<div class="line"><a id="l01353" name="l01353"></a><span class="lineno"> 1353</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01354" name="l01354"></a><span class="lineno"> 1354</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l01355" name="l01355"></a><span class="lineno"> 1355</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l01356" name="l01356"></a><span class="lineno"> 1356</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><a id="l01357" name="l01357"></a><span class="lineno"> 1357</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><a id="l01358" name="l01358"></a><span class="lineno"> 1358</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01359" name="l01359"></a><span class="lineno"> 1359</span><span class="stringliteral">        Returns</span></div>
<div class="line"><a id="l01360" name="l01360"></a><span class="lineno"> 1360</span><span class="stringliteral">        -------</span></div>
<div class="line"><a id="l01361" name="l01361"></a><span class="lineno"> 1361</span><span class="stringliteral">        y_prob : ndarray of shape (n_samples, n_classes)</span></div>
<div class="line"><a id="l01362" name="l01362"></a><span class="lineno"> 1362</span><span class="stringliteral">            The predicted probability of the sample for each class in the</span></div>
<div class="line"><a id="l01363" name="l01363"></a><span class="lineno"> 1363</span><span class="stringliteral">            model, where classes are ordered as they are in `self.classes_`.</span></div>
<div class="line"><a id="l01364" name="l01364"></a><span class="lineno"> 1364</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l01365" name="l01365"></a><span class="lineno"> 1365</span>        check_is_fitted(self)</div>
<div class="line"><a id="l01366" name="l01366"></a><span class="lineno"> 1366</span>        y_pred = self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a65cb479141ebeb9fd5e77845b242979b">_forward_pass_fast</a>(X)</div>
<div class="line"><a id="l01367" name="l01367"></a><span class="lineno"> 1367</span> </div>
<div class="line"><a id="l01368" name="l01368"></a><span class="lineno"> 1368</span>        <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac913f3e320e35d56add32462793c14e7">n_outputs_</a> == 1:</div>
<div class="line"><a id="l01369" name="l01369"></a><span class="lineno"> 1369</span>            y_pred = y_pred.ravel()</div>
<div class="line"><a id="l01370" name="l01370"></a><span class="lineno"> 1370</span> </div>
<div class="line"><a id="l01371" name="l01371"></a><span class="lineno"> 1371</span>        <span class="keywordflow">if</span> y_pred.ndim == 1:</div>
<div class="line"><a id="l01372" name="l01372"></a><span class="lineno"> 1372</span>            <span class="keywordflow">return</span> np.vstack([1 - y_pred, y_pred]).T</div>
<div class="line"><a id="l01373" name="l01373"></a><span class="lineno"> 1373</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l01374" name="l01374"></a><span class="lineno"> 1374</span>            <span class="keywordflow">return</span> y_pred</div>
<div class="line"><a id="l01375" name="l01375"></a><span class="lineno"> 1375</span> </div>
</div>
<div class="line"><a id="l01376" name="l01376"></a><span class="lineno"> 1376</span>    <span class="keyword">def </span>__sklearn_tags__(self):</div>
<div class="line"><a id="l01377" name="l01377"></a><span class="lineno"> 1377</span>        tags = super().__sklearn_tags__()</div>
<div class="line"><a id="l01378" name="l01378"></a><span class="lineno"> 1378</span>        tags.classifier_tags.multi_label = <span class="keyword">True</span></div>
<div class="line"><a id="l01379" name="l01379"></a><span class="lineno"> 1379</span>        <span class="keywordflow">return</span> tags</div>
<div class="line"><a id="l01380" name="l01380"></a><span class="lineno"> 1380</span> </div>
<div class="line"><a id="l01381" name="l01381"></a><span class="lineno"> 1381</span> </div>
</div>
<div class="foldopen" id="foldopen01382" data-start="" data-end="">
<div class="line"><a id="l01382" name="l01382"></a><span class="lineno"><a class="line" href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html"> 1382</a></span><span class="keyword">class </span><a class="code hl_class" href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html">MLPRegressor</a>(<a class="code hl_class" href="../../df/d64/classsklearn_1_1base_1_1RegressorMixin.html">RegressorMixin</a>, <a class="code hl_class" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html">BaseMultilayerPerceptron</a>):</div>
<div class="line"><a id="l01383" name="l01383"></a><span class="lineno"> 1383</span>    <span class="stringliteral">&quot;&quot;&quot;Multi-layer Perceptron regressor.</span></div>
<div class="line"><a id="l01384" name="l01384"></a><span class="lineno"> 1384</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01385" name="l01385"></a><span class="lineno"> 1385</span><span class="stringliteral">    This model optimizes the squared error using LBFGS or stochastic gradient</span></div>
<div class="line"><a id="l01386" name="l01386"></a><span class="lineno"> 1386</span><span class="stringliteral">    descent.</span></div>
<div class="line"><a id="l01387" name="l01387"></a><span class="lineno"> 1387</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01388" name="l01388"></a><span class="lineno"> 1388</span><span class="stringliteral">    .. versionadded:: 0.18</span></div>
<div class="line"><a id="l01389" name="l01389"></a><span class="lineno"> 1389</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01390" name="l01390"></a><span class="lineno"> 1390</span><span class="stringliteral">    Parameters</span></div>
<div class="line"><a id="l01391" name="l01391"></a><span class="lineno"> 1391</span><span class="stringliteral">    ----------</span></div>
<div class="line"><a id="l01392" name="l01392"></a><span class="lineno"> 1392</span><span class="stringliteral">    loss : {&#39;squared_error&#39;, &#39;poisson&#39;}, default=&#39;squared_error&#39;</span></div>
<div class="line"><a id="l01393" name="l01393"></a><span class="lineno"> 1393</span><span class="stringliteral">        The loss function to use when training the weights. Note that the</span></div>
<div class="line"><a id="l01394" name="l01394"></a><span class="lineno"> 1394</span><span class="stringliteral">        &quot;squared error&quot; and &quot;poisson&quot; losses actually implement</span></div>
<div class="line"><a id="l01395" name="l01395"></a><span class="lineno"> 1395</span><span class="stringliteral">        &quot;half squares error&quot; and &quot;half poisson deviance&quot; to simplify the</span></div>
<div class="line"><a id="l01396" name="l01396"></a><span class="lineno"> 1396</span><span class="stringliteral">        computation of the gradient. Furthermore, the &quot;poisson&quot; loss internally uses</span></div>
<div class="line"><a id="l01397" name="l01397"></a><span class="lineno"> 1397</span><span class="stringliteral">        a log-link (exponential as the output activation function) and requires</span></div>
<div class="line"><a id="l01398" name="l01398"></a><span class="lineno"> 1398</span><span class="stringliteral">        ``y &gt;= 0``.</span></div>
<div class="line"><a id="l01399" name="l01399"></a><span class="lineno"> 1399</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01400" name="l01400"></a><span class="lineno"> 1400</span><span class="stringliteral">        .. versionchanged:: 1.7</span></div>
<div class="line"><a id="l01401" name="l01401"></a><span class="lineno"> 1401</span><span class="stringliteral">           Added parameter `loss` and option &#39;poisson&#39;.</span></div>
<div class="line"><a id="l01402" name="l01402"></a><span class="lineno"> 1402</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01403" name="l01403"></a><span class="lineno"> 1403</span><span class="stringliteral">    hidden_layer_sizes : array-like of shape(n_layers - 2,), default=(100,)</span></div>
<div class="line"><a id="l01404" name="l01404"></a><span class="lineno"> 1404</span><span class="stringliteral">        The ith element represents the number of neurons in the ith</span></div>
<div class="line"><a id="l01405" name="l01405"></a><span class="lineno"> 1405</span><span class="stringliteral">        hidden layer.</span></div>
<div class="line"><a id="l01406" name="l01406"></a><span class="lineno"> 1406</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01407" name="l01407"></a><span class="lineno"> 1407</span><span class="stringliteral">    activation : {&#39;identity&#39;, &#39;logistic&#39;, &#39;tanh&#39;, &#39;relu&#39;}, default=&#39;relu&#39;</span></div>
<div class="line"><a id="l01408" name="l01408"></a><span class="lineno"> 1408</span><span class="stringliteral">        Activation function for the hidden layer.</span></div>
<div class="line"><a id="l01409" name="l01409"></a><span class="lineno"> 1409</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01410" name="l01410"></a><span class="lineno"> 1410</span><span class="stringliteral">        - &#39;identity&#39;, no-op activation, useful to implement linear bottleneck,</span></div>
<div class="line"><a id="l01411" name="l01411"></a><span class="lineno"> 1411</span><span class="stringliteral">          returns f(x) = x</span></div>
<div class="line"><a id="l01412" name="l01412"></a><span class="lineno"> 1412</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01413" name="l01413"></a><span class="lineno"> 1413</span><span class="stringliteral">        - &#39;logistic&#39;, the logistic sigmoid function,</span></div>
<div class="line"><a id="l01414" name="l01414"></a><span class="lineno"> 1414</span><span class="stringliteral">          returns f(x) = 1 / (1 + exp(-x)).</span></div>
<div class="line"><a id="l01415" name="l01415"></a><span class="lineno"> 1415</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01416" name="l01416"></a><span class="lineno"> 1416</span><span class="stringliteral">        - &#39;tanh&#39;, the hyperbolic tan function,</span></div>
<div class="line"><a id="l01417" name="l01417"></a><span class="lineno"> 1417</span><span class="stringliteral">          returns f(x) = tanh(x).</span></div>
<div class="line"><a id="l01418" name="l01418"></a><span class="lineno"> 1418</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01419" name="l01419"></a><span class="lineno"> 1419</span><span class="stringliteral">        - &#39;relu&#39;, the rectified linear unit function,</span></div>
<div class="line"><a id="l01420" name="l01420"></a><span class="lineno"> 1420</span><span class="stringliteral">          returns f(x) = max(0, x)</span></div>
<div class="line"><a id="l01421" name="l01421"></a><span class="lineno"> 1421</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01422" name="l01422"></a><span class="lineno"> 1422</span><span class="stringliteral">    solver : {&#39;lbfgs&#39;, &#39;sgd&#39;, &#39;adam&#39;}, default=&#39;adam&#39;</span></div>
<div class="line"><a id="l01423" name="l01423"></a><span class="lineno"> 1423</span><span class="stringliteral">        The solver for weight optimization.</span></div>
<div class="line"><a id="l01424" name="l01424"></a><span class="lineno"> 1424</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01425" name="l01425"></a><span class="lineno"> 1425</span><span class="stringliteral">        - &#39;lbfgs&#39; is an optimizer in the family of quasi-Newton methods.</span></div>
<div class="line"><a id="l01426" name="l01426"></a><span class="lineno"> 1426</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01427" name="l01427"></a><span class="lineno"> 1427</span><span class="stringliteral">        - &#39;sgd&#39; refers to stochastic gradient descent.</span></div>
<div class="line"><a id="l01428" name="l01428"></a><span class="lineno"> 1428</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01429" name="l01429"></a><span class="lineno"> 1429</span><span class="stringliteral">        - &#39;adam&#39; refers to a stochastic gradient-based optimizer proposed by</span></div>
<div class="line"><a id="l01430" name="l01430"></a><span class="lineno"> 1430</span><span class="stringliteral">          Kingma, Diederik, and Jimmy Ba</span></div>
<div class="line"><a id="l01431" name="l01431"></a><span class="lineno"> 1431</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01432" name="l01432"></a><span class="lineno"> 1432</span><span class="stringliteral">        For a comparison between Adam optimizer and SGD, see</span></div>
<div class="line"><a id="l01433" name="l01433"></a><span class="lineno"> 1433</span><span class="stringliteral">        :ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_training_curves.py`.</span></div>
<div class="line"><a id="l01434" name="l01434"></a><span class="lineno"> 1434</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01435" name="l01435"></a><span class="lineno"> 1435</span><span class="stringliteral">        Note: The default solver &#39;adam&#39; works pretty well on relatively</span></div>
<div class="line"><a id="l01436" name="l01436"></a><span class="lineno"> 1436</span><span class="stringliteral">        large datasets (with thousands of training samples or more) in terms of</span></div>
<div class="line"><a id="l01437" name="l01437"></a><span class="lineno"> 1437</span><span class="stringliteral">        both training time and validation score.</span></div>
<div class="line"><a id="l01438" name="l01438"></a><span class="lineno"> 1438</span><span class="stringliteral">        For small datasets, however, &#39;lbfgs&#39; can converge faster and perform</span></div>
<div class="line"><a id="l01439" name="l01439"></a><span class="lineno"> 1439</span><span class="stringliteral">        better.</span></div>
<div class="line"><a id="l01440" name="l01440"></a><span class="lineno"> 1440</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01441" name="l01441"></a><span class="lineno"> 1441</span><span class="stringliteral">    alpha : float, default=0.0001</span></div>
<div class="line"><a id="l01442" name="l01442"></a><span class="lineno"> 1442</span><span class="stringliteral">        Strength of the L2 regularization term. The L2 regularization term</span></div>
<div class="line"><a id="l01443" name="l01443"></a><span class="lineno"> 1443</span><span class="stringliteral">        is divided by the sample size when added to the loss.</span></div>
<div class="line"><a id="l01444" name="l01444"></a><span class="lineno"> 1444</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01445" name="l01445"></a><span class="lineno"> 1445</span><span class="stringliteral">    batch_size : int, default=&#39;auto&#39;</span></div>
<div class="line"><a id="l01446" name="l01446"></a><span class="lineno"> 1446</span><span class="stringliteral">        Size of minibatches for stochastic optimizers.</span></div>
<div class="line"><a id="l01447" name="l01447"></a><span class="lineno"> 1447</span><span class="stringliteral">        If the solver is &#39;lbfgs&#39;, the regressor will not use minibatch.</span></div>
<div class="line"><a id="l01448" name="l01448"></a><span class="lineno"> 1448</span><span class="stringliteral">        When set to &quot;auto&quot;, `batch_size=min(200, n_samples)`.</span></div>
<div class="line"><a id="l01449" name="l01449"></a><span class="lineno"> 1449</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01450" name="l01450"></a><span class="lineno"> 1450</span><span class="stringliteral">    learning_rate : {&#39;constant&#39;, &#39;invscaling&#39;, &#39;adaptive&#39;}, default=&#39;constant&#39;</span></div>
<div class="line"><a id="l01451" name="l01451"></a><span class="lineno"> 1451</span><span class="stringliteral">        Learning rate schedule for weight updates.</span></div>
<div class="line"><a id="l01452" name="l01452"></a><span class="lineno"> 1452</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01453" name="l01453"></a><span class="lineno"> 1453</span><span class="stringliteral">        - &#39;constant&#39; is a constant learning rate given by</span></div>
<div class="line"><a id="l01454" name="l01454"></a><span class="lineno"> 1454</span><span class="stringliteral">          &#39;learning_rate_init&#39;.</span></div>
<div class="line"><a id="l01455" name="l01455"></a><span class="lineno"> 1455</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01456" name="l01456"></a><span class="lineno"> 1456</span><span class="stringliteral">        - &#39;invscaling&#39; gradually decreases the learning rate ``learning_rate_``</span></div>
<div class="line"><a id="l01457" name="l01457"></a><span class="lineno"> 1457</span><span class="stringliteral">          at each time step &#39;t&#39; using an inverse scaling exponent of &#39;power_t&#39;.</span></div>
<div class="line"><a id="l01458" name="l01458"></a><span class="lineno"> 1458</span><span class="stringliteral">          effective_learning_rate = learning_rate_init / pow(t, power_t)</span></div>
<div class="line"><a id="l01459" name="l01459"></a><span class="lineno"> 1459</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01460" name="l01460"></a><span class="lineno"> 1460</span><span class="stringliteral">        - &#39;adaptive&#39; keeps the learning rate constant to</span></div>
<div class="line"><a id="l01461" name="l01461"></a><span class="lineno"> 1461</span><span class="stringliteral">          &#39;learning_rate_init&#39; as long as training loss keeps decreasing.</span></div>
<div class="line"><a id="l01462" name="l01462"></a><span class="lineno"> 1462</span><span class="stringliteral">          Each time two consecutive epochs fail to decrease training loss by at</span></div>
<div class="line"><a id="l01463" name="l01463"></a><span class="lineno"> 1463</span><span class="stringliteral">          least tol, or fail to increase validation score by at least tol if</span></div>
<div class="line"><a id="l01464" name="l01464"></a><span class="lineno"> 1464</span><span class="stringliteral">          &#39;early_stopping&#39; is on, the current learning rate is divided by 5.</span></div>
<div class="line"><a id="l01465" name="l01465"></a><span class="lineno"> 1465</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01466" name="l01466"></a><span class="lineno"> 1466</span><span class="stringliteral">        Only used when solver=&#39;sgd&#39;.</span></div>
<div class="line"><a id="l01467" name="l01467"></a><span class="lineno"> 1467</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01468" name="l01468"></a><span class="lineno"> 1468</span><span class="stringliteral">    learning_rate_init : float, default=0.001</span></div>
<div class="line"><a id="l01469" name="l01469"></a><span class="lineno"> 1469</span><span class="stringliteral">        The initial learning rate used. It controls the step-size</span></div>
<div class="line"><a id="l01470" name="l01470"></a><span class="lineno"> 1470</span><span class="stringliteral">        in updating the weights. Only used when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01471" name="l01471"></a><span class="lineno"> 1471</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01472" name="l01472"></a><span class="lineno"> 1472</span><span class="stringliteral">    power_t : float, default=0.5</span></div>
<div class="line"><a id="l01473" name="l01473"></a><span class="lineno"> 1473</span><span class="stringliteral">        The exponent for inverse scaling learning rate.</span></div>
<div class="line"><a id="l01474" name="l01474"></a><span class="lineno"> 1474</span><span class="stringliteral">        It is used in updating effective learning rate when the learning_rate</span></div>
<div class="line"><a id="l01475" name="l01475"></a><span class="lineno"> 1475</span><span class="stringliteral">        is set to &#39;invscaling&#39;. Only used when solver=&#39;sgd&#39;.</span></div>
<div class="line"><a id="l01476" name="l01476"></a><span class="lineno"> 1476</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01477" name="l01477"></a><span class="lineno"> 1477</span><span class="stringliteral">    max_iter : int, default=200</span></div>
<div class="line"><a id="l01478" name="l01478"></a><span class="lineno"> 1478</span><span class="stringliteral">        Maximum number of iterations. The solver iterates until convergence</span></div>
<div class="line"><a id="l01479" name="l01479"></a><span class="lineno"> 1479</span><span class="stringliteral">        (determined by &#39;tol&#39;) or this number of iterations. For stochastic</span></div>
<div class="line"><a id="l01480" name="l01480"></a><span class="lineno"> 1480</span><span class="stringliteral">        solvers (&#39;sgd&#39;, &#39;adam&#39;), note that this determines the number of epochs</span></div>
<div class="line"><a id="l01481" name="l01481"></a><span class="lineno"> 1481</span><span class="stringliteral">        (how many times each data point will be used), not the number of</span></div>
<div class="line"><a id="l01482" name="l01482"></a><span class="lineno"> 1482</span><span class="stringliteral">        gradient steps.</span></div>
<div class="line"><a id="l01483" name="l01483"></a><span class="lineno"> 1483</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01484" name="l01484"></a><span class="lineno"> 1484</span><span class="stringliteral">    shuffle : bool, default=True</span></div>
<div class="line"><a id="l01485" name="l01485"></a><span class="lineno"> 1485</span><span class="stringliteral">        Whether to shuffle samples in each iteration. Only used when</span></div>
<div class="line"><a id="l01486" name="l01486"></a><span class="lineno"> 1486</span><span class="stringliteral">        solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01487" name="l01487"></a><span class="lineno"> 1487</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01488" name="l01488"></a><span class="lineno"> 1488</span><span class="stringliteral">    random_state : int, RandomState instance, default=None</span></div>
<div class="line"><a id="l01489" name="l01489"></a><span class="lineno"> 1489</span><span class="stringliteral">        Determines random number generation for weights and bias</span></div>
<div class="line"><a id="l01490" name="l01490"></a><span class="lineno"> 1490</span><span class="stringliteral">        initialization, train-test split if early stopping is used, and batch</span></div>
<div class="line"><a id="l01491" name="l01491"></a><span class="lineno"> 1491</span><span class="stringliteral">        sampling when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01492" name="l01492"></a><span class="lineno"> 1492</span><span class="stringliteral">        Pass an int for reproducible results across multiple function calls.</span></div>
<div class="line"><a id="l01493" name="l01493"></a><span class="lineno"> 1493</span><span class="stringliteral">        See :term:`Glossary &lt;random_state&gt;`.</span></div>
<div class="line"><a id="l01494" name="l01494"></a><span class="lineno"> 1494</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01495" name="l01495"></a><span class="lineno"> 1495</span><span class="stringliteral">    tol : float, default=1e-4</span></div>
<div class="line"><a id="l01496" name="l01496"></a><span class="lineno"> 1496</span><span class="stringliteral">        Tolerance for the optimization. When the loss or score is not improving</span></div>
<div class="line"><a id="l01497" name="l01497"></a><span class="lineno"> 1497</span><span class="stringliteral">        by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,</span></div>
<div class="line"><a id="l01498" name="l01498"></a><span class="lineno"> 1498</span><span class="stringliteral">        unless ``learning_rate`` is set to &#39;adaptive&#39;, convergence is</span></div>
<div class="line"><a id="l01499" name="l01499"></a><span class="lineno"> 1499</span><span class="stringliteral">        considered to be reached and training stops.</span></div>
<div class="line"><a id="l01500" name="l01500"></a><span class="lineno"> 1500</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01501" name="l01501"></a><span class="lineno"> 1501</span><span class="stringliteral">    verbose : bool, default=False</span></div>
<div class="line"><a id="l01502" name="l01502"></a><span class="lineno"> 1502</span><span class="stringliteral">        Whether to print progress messages to stdout.</span></div>
<div class="line"><a id="l01503" name="l01503"></a><span class="lineno"> 1503</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01504" name="l01504"></a><span class="lineno"> 1504</span><span class="stringliteral">    warm_start : bool, default=False</span></div>
<div class="line"><a id="l01505" name="l01505"></a><span class="lineno"> 1505</span><span class="stringliteral">        When set to True, reuse the solution of the previous</span></div>
<div class="line"><a id="l01506" name="l01506"></a><span class="lineno"> 1506</span><span class="stringliteral">        call to fit as initialization, otherwise, just erase the</span></div>
<div class="line"><a id="l01507" name="l01507"></a><span class="lineno"> 1507</span><span class="stringliteral">        previous solution. See :term:`the Glossary &lt;warm_start&gt;`.</span></div>
<div class="line"><a id="l01508" name="l01508"></a><span class="lineno"> 1508</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01509" name="l01509"></a><span class="lineno"> 1509</span><span class="stringliteral">    momentum : float, default=0.9</span></div>
<div class="line"><a id="l01510" name="l01510"></a><span class="lineno"> 1510</span><span class="stringliteral">        Momentum for gradient descent update. Should be between 0 and 1. Only</span></div>
<div class="line"><a id="l01511" name="l01511"></a><span class="lineno"> 1511</span><span class="stringliteral">        used when solver=&#39;sgd&#39;.</span></div>
<div class="line"><a id="l01512" name="l01512"></a><span class="lineno"> 1512</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01513" name="l01513"></a><span class="lineno"> 1513</span><span class="stringliteral">    nesterovs_momentum : bool, default=True</span></div>
<div class="line"><a id="l01514" name="l01514"></a><span class="lineno"> 1514</span><span class="stringliteral">        Whether to use Nesterov&#39;s momentum. Only used when solver=&#39;sgd&#39; and</span></div>
<div class="line"><a id="l01515" name="l01515"></a><span class="lineno"> 1515</span><span class="stringliteral">        momentum &gt; 0.</span></div>
<div class="line"><a id="l01516" name="l01516"></a><span class="lineno"> 1516</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01517" name="l01517"></a><span class="lineno"> 1517</span><span class="stringliteral">    early_stopping : bool, default=False</span></div>
<div class="line"><a id="l01518" name="l01518"></a><span class="lineno"> 1518</span><span class="stringliteral">        Whether to use early stopping to terminate training when validation</span></div>
<div class="line"><a id="l01519" name="l01519"></a><span class="lineno"> 1519</span><span class="stringliteral">        score is not improving. If set to True, it will automatically set</span></div>
<div class="line"><a id="l01520" name="l01520"></a><span class="lineno"> 1520</span><span class="stringliteral">        aside ``validation_fraction`` of training data as validation and</span></div>
<div class="line"><a id="l01521" name="l01521"></a><span class="lineno"> 1521</span><span class="stringliteral">        terminate training when validation score is not improving by at</span></div>
<div class="line"><a id="l01522" name="l01522"></a><span class="lineno"> 1522</span><span class="stringliteral">        least ``tol`` for ``n_iter_no_change`` consecutive epochs.</span></div>
<div class="line"><a id="l01523" name="l01523"></a><span class="lineno"> 1523</span><span class="stringliteral">        Only effective when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01524" name="l01524"></a><span class="lineno"> 1524</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01525" name="l01525"></a><span class="lineno"> 1525</span><span class="stringliteral">    validation_fraction : float, default=0.1</span></div>
<div class="line"><a id="l01526" name="l01526"></a><span class="lineno"> 1526</span><span class="stringliteral">        The proportion of training data to set aside as validation set for</span></div>
<div class="line"><a id="l01527" name="l01527"></a><span class="lineno"> 1527</span><span class="stringliteral">        early stopping. Must be between 0 and 1.</span></div>
<div class="line"><a id="l01528" name="l01528"></a><span class="lineno"> 1528</span><span class="stringliteral">        Only used if early_stopping is True.</span></div>
<div class="line"><a id="l01529" name="l01529"></a><span class="lineno"> 1529</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01530" name="l01530"></a><span class="lineno"> 1530</span><span class="stringliteral">    beta_1 : float, default=0.9</span></div>
<div class="line"><a id="l01531" name="l01531"></a><span class="lineno"> 1531</span><span class="stringliteral">        Exponential decay rate for estimates of first moment vector in adam,</span></div>
<div class="line"><a id="l01532" name="l01532"></a><span class="lineno"> 1532</span><span class="stringliteral">        should be in [0, 1). Only used when solver=&#39;adam&#39;.</span></div>
<div class="line"><a id="l01533" name="l01533"></a><span class="lineno"> 1533</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01534" name="l01534"></a><span class="lineno"> 1534</span><span class="stringliteral">    beta_2 : float, default=0.999</span></div>
<div class="line"><a id="l01535" name="l01535"></a><span class="lineno"> 1535</span><span class="stringliteral">        Exponential decay rate for estimates of second moment vector in adam,</span></div>
<div class="line"><a id="l01536" name="l01536"></a><span class="lineno"> 1536</span><span class="stringliteral">        should be in [0, 1). Only used when solver=&#39;adam&#39;.</span></div>
<div class="line"><a id="l01537" name="l01537"></a><span class="lineno"> 1537</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01538" name="l01538"></a><span class="lineno"> 1538</span><span class="stringliteral">    epsilon : float, default=1e-8</span></div>
<div class="line"><a id="l01539" name="l01539"></a><span class="lineno"> 1539</span><span class="stringliteral">        Value for numerical stability in adam. Only used when solver=&#39;adam&#39;.</span></div>
<div class="line"><a id="l01540" name="l01540"></a><span class="lineno"> 1540</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01541" name="l01541"></a><span class="lineno"> 1541</span><span class="stringliteral">    n_iter_no_change : int, default=10</span></div>
<div class="line"><a id="l01542" name="l01542"></a><span class="lineno"> 1542</span><span class="stringliteral">        Maximum number of epochs to not meet ``tol`` improvement.</span></div>
<div class="line"><a id="l01543" name="l01543"></a><span class="lineno"> 1543</span><span class="stringliteral">        Only effective when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01544" name="l01544"></a><span class="lineno"> 1544</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01545" name="l01545"></a><span class="lineno"> 1545</span><span class="stringliteral">        .. versionadded:: 0.20</span></div>
<div class="line"><a id="l01546" name="l01546"></a><span class="lineno"> 1546</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01547" name="l01547"></a><span class="lineno"> 1547</span><span class="stringliteral">    max_fun : int, default=15000</span></div>
<div class="line"><a id="l01548" name="l01548"></a><span class="lineno"> 1548</span><span class="stringliteral">        Only used when solver=&#39;lbfgs&#39;. Maximum number of function calls.</span></div>
<div class="line"><a id="l01549" name="l01549"></a><span class="lineno"> 1549</span><span class="stringliteral">        The solver iterates until convergence (determined by ``tol``), number</span></div>
<div class="line"><a id="l01550" name="l01550"></a><span class="lineno"> 1550</span><span class="stringliteral">        of iterations reaches max_iter, or this number of function calls.</span></div>
<div class="line"><a id="l01551" name="l01551"></a><span class="lineno"> 1551</span><span class="stringliteral">        Note that number of function calls will be greater than or equal to</span></div>
<div class="line"><a id="l01552" name="l01552"></a><span class="lineno"> 1552</span><span class="stringliteral">        the number of iterations for the MLPRegressor.</span></div>
<div class="line"><a id="l01553" name="l01553"></a><span class="lineno"> 1553</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01554" name="l01554"></a><span class="lineno"> 1554</span><span class="stringliteral">        .. versionadded:: 0.22</span></div>
<div class="line"><a id="l01555" name="l01555"></a><span class="lineno"> 1555</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01556" name="l01556"></a><span class="lineno"> 1556</span><span class="stringliteral">    Attributes</span></div>
<div class="line"><a id="l01557" name="l01557"></a><span class="lineno"> 1557</span><span class="stringliteral">    ----------</span></div>
<div class="line"><a id="l01558" name="l01558"></a><span class="lineno"> 1558</span><span class="stringliteral">    loss_ : float</span></div>
<div class="line"><a id="l01559" name="l01559"></a><span class="lineno"> 1559</span><span class="stringliteral">        The current loss computed with the loss function.</span></div>
<div class="line"><a id="l01560" name="l01560"></a><span class="lineno"> 1560</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01561" name="l01561"></a><span class="lineno"> 1561</span><span class="stringliteral">    best_loss_ : float</span></div>
<div class="line"><a id="l01562" name="l01562"></a><span class="lineno"> 1562</span><span class="stringliteral">        The minimum loss reached by the solver throughout fitting.</span></div>
<div class="line"><a id="l01563" name="l01563"></a><span class="lineno"> 1563</span><span class="stringliteral">        If `early_stopping=True`, this attribute is set to `None`. Refer to</span></div>
<div class="line"><a id="l01564" name="l01564"></a><span class="lineno"> 1564</span><span class="stringliteral">        the `best_validation_score_` fitted attribute instead.</span></div>
<div class="line"><a id="l01565" name="l01565"></a><span class="lineno"> 1565</span><span class="stringliteral">        Only accessible when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01566" name="l01566"></a><span class="lineno"> 1566</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01567" name="l01567"></a><span class="lineno"> 1567</span><span class="stringliteral">    loss_curve_ : list of shape (`n_iter_`,)</span></div>
<div class="line"><a id="l01568" name="l01568"></a><span class="lineno"> 1568</span><span class="stringliteral">        Loss value evaluated at the end of each training step.</span></div>
<div class="line"><a id="l01569" name="l01569"></a><span class="lineno"> 1569</span><span class="stringliteral">        The ith element in the list represents the loss at the ith iteration.</span></div>
<div class="line"><a id="l01570" name="l01570"></a><span class="lineno"> 1570</span><span class="stringliteral">        Only accessible when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01571" name="l01571"></a><span class="lineno"> 1571</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01572" name="l01572"></a><span class="lineno"> 1572</span><span class="stringliteral">    validation_scores_ : list of shape (`n_iter_`,) or None</span></div>
<div class="line"><a id="l01573" name="l01573"></a><span class="lineno"> 1573</span><span class="stringliteral">        The score at each iteration on a held-out validation set. The score</span></div>
<div class="line"><a id="l01574" name="l01574"></a><span class="lineno"> 1574</span><span class="stringliteral">        reported is the R2 score. Only available if `early_stopping=True`,</span></div>
<div class="line"><a id="l01575" name="l01575"></a><span class="lineno"> 1575</span><span class="stringliteral">        otherwise the attribute is set to `None`.</span></div>
<div class="line"><a id="l01576" name="l01576"></a><span class="lineno"> 1576</span><span class="stringliteral">        Only accessible when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01577" name="l01577"></a><span class="lineno"> 1577</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01578" name="l01578"></a><span class="lineno"> 1578</span><span class="stringliteral">    best_validation_score_ : float or None</span></div>
<div class="line"><a id="l01579" name="l01579"></a><span class="lineno"> 1579</span><span class="stringliteral">        The best validation score (i.e. R2 score) that triggered the</span></div>
<div class="line"><a id="l01580" name="l01580"></a><span class="lineno"> 1580</span><span class="stringliteral">        early stopping. Only available if `early_stopping=True`, otherwise the</span></div>
<div class="line"><a id="l01581" name="l01581"></a><span class="lineno"> 1581</span><span class="stringliteral">        attribute is set to `None`.</span></div>
<div class="line"><a id="l01582" name="l01582"></a><span class="lineno"> 1582</span><span class="stringliteral">        Only accessible when solver=&#39;sgd&#39; or &#39;adam&#39;.</span></div>
<div class="line"><a id="l01583" name="l01583"></a><span class="lineno"> 1583</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01584" name="l01584"></a><span class="lineno"> 1584</span><span class="stringliteral">    t_ : int</span></div>
<div class="line"><a id="l01585" name="l01585"></a><span class="lineno"> 1585</span><span class="stringliteral">        The number of training samples seen by the solver during fitting.</span></div>
<div class="line"><a id="l01586" name="l01586"></a><span class="lineno"> 1586</span><span class="stringliteral">        Mathematically equals `n_iters * X.shape[0]`, it means</span></div>
<div class="line"><a id="l01587" name="l01587"></a><span class="lineno"> 1587</span><span class="stringliteral">        `time_step` and it is used by optimizer&#39;s learning rate scheduler.</span></div>
<div class="line"><a id="l01588" name="l01588"></a><span class="lineno"> 1588</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01589" name="l01589"></a><span class="lineno"> 1589</span><span class="stringliteral">    coefs_ : list of shape (n_layers - 1,)</span></div>
<div class="line"><a id="l01590" name="l01590"></a><span class="lineno"> 1590</span><span class="stringliteral">        The ith element in the list represents the weight matrix corresponding</span></div>
<div class="line"><a id="l01591" name="l01591"></a><span class="lineno"> 1591</span><span class="stringliteral">        to layer i.</span></div>
<div class="line"><a id="l01592" name="l01592"></a><span class="lineno"> 1592</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01593" name="l01593"></a><span class="lineno"> 1593</span><span class="stringliteral">    intercepts_ : list of shape (n_layers - 1,)</span></div>
<div class="line"><a id="l01594" name="l01594"></a><span class="lineno"> 1594</span><span class="stringliteral">        The ith element in the list represents the bias vector corresponding to</span></div>
<div class="line"><a id="l01595" name="l01595"></a><span class="lineno"> 1595</span><span class="stringliteral">        layer i + 1.</span></div>
<div class="line"><a id="l01596" name="l01596"></a><span class="lineno"> 1596</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01597" name="l01597"></a><span class="lineno"> 1597</span><span class="stringliteral">    n_features_in_ : int</span></div>
<div class="line"><a id="l01598" name="l01598"></a><span class="lineno"> 1598</span><span class="stringliteral">        Number of features seen during :term:`fit`.</span></div>
<div class="line"><a id="l01599" name="l01599"></a><span class="lineno"> 1599</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01600" name="l01600"></a><span class="lineno"> 1600</span><span class="stringliteral">        .. versionadded:: 0.24</span></div>
<div class="line"><a id="l01601" name="l01601"></a><span class="lineno"> 1601</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01602" name="l01602"></a><span class="lineno"> 1602</span><span class="stringliteral">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span></div>
<div class="line"><a id="l01603" name="l01603"></a><span class="lineno"> 1603</span><span class="stringliteral">        Names of features seen during :term:`fit`. Defined only when `X`</span></div>
<div class="line"><a id="l01604" name="l01604"></a><span class="lineno"> 1604</span><span class="stringliteral">        has feature names that are all strings.</span></div>
<div class="line"><a id="l01605" name="l01605"></a><span class="lineno"> 1605</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01606" name="l01606"></a><span class="lineno"> 1606</span><span class="stringliteral">        .. versionadded:: 1.0</span></div>
<div class="line"><a id="l01607" name="l01607"></a><span class="lineno"> 1607</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01608" name="l01608"></a><span class="lineno"> 1608</span><span class="stringliteral">    n_iter_ : int</span></div>
<div class="line"><a id="l01609" name="l01609"></a><span class="lineno"> 1609</span><span class="stringliteral">        The number of iterations the solver has run.</span></div>
<div class="line"><a id="l01610" name="l01610"></a><span class="lineno"> 1610</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01611" name="l01611"></a><span class="lineno"> 1611</span><span class="stringliteral">    n_layers_ : int</span></div>
<div class="line"><a id="l01612" name="l01612"></a><span class="lineno"> 1612</span><span class="stringliteral">        Number of layers.</span></div>
<div class="line"><a id="l01613" name="l01613"></a><span class="lineno"> 1613</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01614" name="l01614"></a><span class="lineno"> 1614</span><span class="stringliteral">    n_outputs_ : int</span></div>
<div class="line"><a id="l01615" name="l01615"></a><span class="lineno"> 1615</span><span class="stringliteral">        Number of outputs.</span></div>
<div class="line"><a id="l01616" name="l01616"></a><span class="lineno"> 1616</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01617" name="l01617"></a><span class="lineno"> 1617</span><span class="stringliteral">    out_activation_ : str</span></div>
<div class="line"><a id="l01618" name="l01618"></a><span class="lineno"> 1618</span><span class="stringliteral">        Name of the output activation function.</span></div>
<div class="line"><a id="l01619" name="l01619"></a><span class="lineno"> 1619</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01620" name="l01620"></a><span class="lineno"> 1620</span><span class="stringliteral">    See Also</span></div>
<div class="line"><a id="l01621" name="l01621"></a><span class="lineno"> 1621</span><span class="stringliteral">    --------</span></div>
<div class="line"><a id="l01622" name="l01622"></a><span class="lineno"> 1622</span><span class="stringliteral">    BernoulliRBM : Bernoulli Restricted Boltzmann Machine (RBM).</span></div>
<div class="line"><a id="l01623" name="l01623"></a><span class="lineno"> 1623</span><span class="stringliteral">    MLPClassifier : Multi-layer Perceptron classifier.</span></div>
<div class="line"><a id="l01624" name="l01624"></a><span class="lineno"> 1624</span><span class="stringliteral">    sklearn.linear_model.SGDRegressor : Linear model fitted by minimizing</span></div>
<div class="line"><a id="l01625" name="l01625"></a><span class="lineno"> 1625</span><span class="stringliteral">        a regularized empirical loss with SGD.</span></div>
<div class="line"><a id="l01626" name="l01626"></a><span class="lineno"> 1626</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01627" name="l01627"></a><span class="lineno"> 1627</span><span class="stringliteral">    Notes</span></div>
<div class="line"><a id="l01628" name="l01628"></a><span class="lineno"> 1628</span><span class="stringliteral">    -----</span></div>
<div class="line"><a id="l01629" name="l01629"></a><span class="lineno"> 1629</span><span class="stringliteral">    MLPRegressor trains iteratively since at each time step</span></div>
<div class="line"><a id="l01630" name="l01630"></a><span class="lineno"> 1630</span><span class="stringliteral">    the partial derivatives of the loss function with respect to the model</span></div>
<div class="line"><a id="l01631" name="l01631"></a><span class="lineno"> 1631</span><span class="stringliteral">    parameters are computed to update the parameters.</span></div>
<div class="line"><a id="l01632" name="l01632"></a><span class="lineno"> 1632</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01633" name="l01633"></a><span class="lineno"> 1633</span><span class="stringliteral">    It can also have a regularization term added to the loss function</span></div>
<div class="line"><a id="l01634" name="l01634"></a><span class="lineno"> 1634</span><span class="stringliteral">    that shrinks model parameters to prevent overfitting.</span></div>
<div class="line"><a id="l01635" name="l01635"></a><span class="lineno"> 1635</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01636" name="l01636"></a><span class="lineno"> 1636</span><span class="stringliteral">    This implementation works with data represented as dense and sparse numpy</span></div>
<div class="line"><a id="l01637" name="l01637"></a><span class="lineno"> 1637</span><span class="stringliteral">    arrays of floating point values.</span></div>
<div class="line"><a id="l01638" name="l01638"></a><span class="lineno"> 1638</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01639" name="l01639"></a><span class="lineno"> 1639</span><span class="stringliteral">    References</span></div>
<div class="line"><a id="l01640" name="l01640"></a><span class="lineno"> 1640</span><span class="stringliteral">    ----------</span></div>
<div class="line"><a id="l01641" name="l01641"></a><span class="lineno"> 1641</span><span class="stringliteral">    Hinton, Geoffrey E. &quot;Connectionist learning procedures.&quot;</span></div>
<div class="line"><a id="l01642" name="l01642"></a><span class="lineno"> 1642</span><span class="stringliteral">    Artificial intelligence 40.1 (1989): 185-234.</span></div>
<div class="line"><a id="l01643" name="l01643"></a><span class="lineno"> 1643</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01644" name="l01644"></a><span class="lineno"> 1644</span><span class="stringliteral">    Glorot, Xavier, and Yoshua Bengio.</span></div>
<div class="line"><a id="l01645" name="l01645"></a><span class="lineno"> 1645</span><span class="stringliteral">    &quot;Understanding the difficulty of training deep feedforward neural networks.&quot;</span></div>
<div class="line"><a id="l01646" name="l01646"></a><span class="lineno"> 1646</span><span class="stringliteral">    International Conference on Artificial Intelligence and Statistics. 2010.</span></div>
<div class="line"><a id="l01647" name="l01647"></a><span class="lineno"> 1647</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01648" name="l01648"></a><span class="lineno"> 1648</span><span class="stringliteral">    :arxiv:`He, Kaiming, et al (2015). &quot;Delving deep into rectifiers:</span></div>
<div class="line"><a id="l01649" name="l01649"></a><span class="lineno"> 1649</span><span class="stringliteral">    Surpassing human-level performance on imagenet classification.&quot; &lt;1502.01852&gt;`</span></div>
<div class="line"><a id="l01650" name="l01650"></a><span class="lineno"> 1650</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01651" name="l01651"></a><span class="lineno"> 1651</span><span class="stringliteral">    :arxiv:`Kingma, Diederik, and Jimmy Ba (2014)</span></div>
<div class="line"><a id="l01652" name="l01652"></a><span class="lineno"> 1652</span><span class="stringliteral">    &quot;Adam: A method for stochastic optimization.&quot; &lt;1412.6980&gt;`</span></div>
<div class="line"><a id="l01653" name="l01653"></a><span class="lineno"> 1653</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01654" name="l01654"></a><span class="lineno"> 1654</span><span class="stringliteral">    Examples</span></div>
<div class="line"><a id="l01655" name="l01655"></a><span class="lineno"> 1655</span><span class="stringliteral">    --------</span></div>
<div class="line"><a id="l01656" name="l01656"></a><span class="lineno"> 1656</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.neural_network import MLPRegressor</span></div>
<div class="line"><a id="l01657" name="l01657"></a><span class="lineno"> 1657</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.datasets import make_regression</span></div>
<div class="line"><a id="l01658" name="l01658"></a><span class="lineno"> 1658</span><span class="stringliteral">    &gt;&gt;&gt; from sklearn.model_selection import train_test_split</span></div>
<div class="line"><a id="l01659" name="l01659"></a><span class="lineno"> 1659</span><span class="stringliteral">    &gt;&gt;&gt; X, y = make_regression(n_samples=200, n_features=20, random_state=1)</span></div>
<div class="line"><a id="l01660" name="l01660"></a><span class="lineno"> 1660</span><span class="stringliteral">    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X, y,</span></div>
<div class="line"><a id="l01661" name="l01661"></a><span class="lineno"> 1661</span><span class="stringliteral">    ...                                                     random_state=1)</span></div>
<div class="line"><a id="l01662" name="l01662"></a><span class="lineno"> 1662</span><span class="stringliteral">    &gt;&gt;&gt; regr = MLPRegressor(random_state=1, max_iter=2000, tol=0.1)</span></div>
<div class="line"><a id="l01663" name="l01663"></a><span class="lineno"> 1663</span><span class="stringliteral">    &gt;&gt;&gt; regr.fit(X_train, y_train)</span></div>
<div class="line"><a id="l01664" name="l01664"></a><span class="lineno"> 1664</span><span class="stringliteral">    MLPRegressor(max_iter=2000, random_state=1, tol=0.1)</span></div>
<div class="line"><a id="l01665" name="l01665"></a><span class="lineno"> 1665</span><span class="stringliteral">    &gt;&gt;&gt; regr.predict(X_test[:2])</span></div>
<div class="line"><a id="l01666" name="l01666"></a><span class="lineno"> 1666</span><span class="stringliteral">    array([  28.98, -291])</span></div>
<div class="line"><a id="l01667" name="l01667"></a><span class="lineno"> 1667</span><span class="stringliteral">    &gt;&gt;&gt; regr.score(X_test, y_test)</span></div>
<div class="line"><a id="l01668" name="l01668"></a><span class="lineno"> 1668</span><span class="stringliteral">    0.98</span></div>
<div class="line"><a id="l01669" name="l01669"></a><span class="lineno"> 1669</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l01670" name="l01670"></a><span class="lineno"> 1670</span> </div>
<div class="line"><a id="l01671" name="l01671"></a><span class="lineno"> 1671</span>    _parameter_constraints: dict = {</div>
<div class="line"><a id="l01672" name="l01672"></a><span class="lineno"> 1672</span>        **BaseMultilayerPerceptron._parameter_constraints,</div>
<div class="line"><a id="l01673" name="l01673"></a><span class="lineno"> 1673</span>        <span class="stringliteral">&quot;loss&quot;</span>: [<a class="code hl_class" href="../../d1/da1/classsklearn_1_1utils_1_1__param__validation_1_1StrOptions.html">StrOptions</a>({<span class="stringliteral">&quot;squared_error&quot;</span>, <span class="stringliteral">&quot;poisson&quot;</span>})],</div>
<div class="line"><a id="l01674" name="l01674"></a><span class="lineno"> 1674</span>    }</div>
<div class="line"><a id="l01675" name="l01675"></a><span class="lineno"> 1675</span> </div>
<div class="line"><a id="l01676" name="l01676"></a><span class="lineno"> 1676</span>    <span class="keyword">def </span>__init__(</div>
<div class="line"><a id="l01677" name="l01677"></a><span class="lineno"> 1677</span>        self,</div>
<div class="line"><a id="l01678" name="l01678"></a><span class="lineno"> 1678</span>        loss=&quot;squared_error&quot;,</div>
<div class="line"><a id="l01679" name="l01679"></a><span class="lineno"> 1679</span>        hidden_layer_sizes=(100,),</div>
<div class="line"><a id="l01680" name="l01680"></a><span class="lineno"> 1680</span>        activation=<span class="stringliteral">&quot;relu&quot;</span>,</div>
<div class="line"><a id="l01681" name="l01681"></a><span class="lineno"> 1681</span>        *,</div>
<div class="line"><a id="l01682" name="l01682"></a><span class="lineno"> 1682</span>        solver=<span class="stringliteral">&quot;adam&quot;</span>,</div>
<div class="line"><a id="l01683" name="l01683"></a><span class="lineno"> 1683</span>        alpha=0.0001,</div>
<div class="line"><a id="l01684" name="l01684"></a><span class="lineno"> 1684</span>        batch_size=<span class="stringliteral">&quot;auto&quot;</span>,</div>
<div class="line"><a id="l01685" name="l01685"></a><span class="lineno"> 1685</span>        learning_rate=<span class="stringliteral">&quot;constant&quot;</span>,</div>
<div class="line"><a id="l01686" name="l01686"></a><span class="lineno"> 1686</span>        learning_rate_init=0.001,</div>
<div class="line"><a id="l01687" name="l01687"></a><span class="lineno"> 1687</span>        power_t=0.5,</div>
<div class="line"><a id="l01688" name="l01688"></a><span class="lineno"> 1688</span>        max_iter=200,</div>
<div class="line"><a id="l01689" name="l01689"></a><span class="lineno"> 1689</span>        shuffle=<span class="keyword">True</span>,</div>
<div class="line"><a id="l01690" name="l01690"></a><span class="lineno"> 1690</span>        random_state=<span class="keywordtype">None</span>,</div>
<div class="line"><a id="l01691" name="l01691"></a><span class="lineno"> 1691</span>        tol=1e-4,</div>
<div class="line"><a id="l01692" name="l01692"></a><span class="lineno"> 1692</span>        verbose=<span class="keyword">False</span>,</div>
<div class="line"><a id="l01693" name="l01693"></a><span class="lineno"> 1693</span>        warm_start=<span class="keyword">False</span>,</div>
<div class="line"><a id="l01694" name="l01694"></a><span class="lineno"> 1694</span>        momentum=0.9,</div>
<div class="line"><a id="l01695" name="l01695"></a><span class="lineno"> 1695</span>        nesterovs_momentum=<span class="keyword">True</span>,</div>
<div class="line"><a id="l01696" name="l01696"></a><span class="lineno"> 1696</span>        early_stopping=<span class="keyword">False</span>,</div>
<div class="line"><a id="l01697" name="l01697"></a><span class="lineno"> 1697</span>        validation_fraction=0.1,</div>
<div class="line"><a id="l01698" name="l01698"></a><span class="lineno"> 1698</span>        beta_1=0.9,</div>
<div class="line"><a id="l01699" name="l01699"></a><span class="lineno"> 1699</span>        beta_2=0.999,</div>
<div class="line"><a id="l01700" name="l01700"></a><span class="lineno"> 1700</span>        epsilon=1e-8,</div>
<div class="line"><a id="l01701" name="l01701"></a><span class="lineno"> 1701</span>        n_iter_no_change=10,</div>
<div class="line"><a id="l01702" name="l01702"></a><span class="lineno"> 1702</span>        max_fun=15000,</div>
<div class="line"><a id="l01703" name="l01703"></a><span class="lineno"> 1703</span>    ):</div>
<div class="line"><a id="l01704" name="l01704"></a><span class="lineno"> 1704</span>        super().__init__(</div>
<div class="line"><a id="l01705" name="l01705"></a><span class="lineno"> 1705</span>            hidden_layer_sizes=hidden_layer_sizes,</div>
<div class="line"><a id="l01706" name="l01706"></a><span class="lineno"> 1706</span>            activation=activation,</div>
<div class="line"><a id="l01707" name="l01707"></a><span class="lineno"> 1707</span>            solver=solver,</div>
<div class="line"><a id="l01708" name="l01708"></a><span class="lineno"> 1708</span>            alpha=alpha,</div>
<div class="line"><a id="l01709" name="l01709"></a><span class="lineno"> 1709</span>            batch_size=batch_size,</div>
<div class="line"><a id="l01710" name="l01710"></a><span class="lineno"> 1710</span>            learning_rate=learning_rate,</div>
<div class="line"><a id="l01711" name="l01711"></a><span class="lineno"> 1711</span>            learning_rate_init=learning_rate_init,</div>
<div class="line"><a id="l01712" name="l01712"></a><span class="lineno"> 1712</span>            power_t=power_t,</div>
<div class="line"><a id="l01713" name="l01713"></a><span class="lineno"> 1713</span>            max_iter=max_iter,</div>
<div class="line"><a id="l01714" name="l01714"></a><span class="lineno"> 1714</span>            loss=loss,</div>
<div class="line"><a id="l01715" name="l01715"></a><span class="lineno"> 1715</span>            shuffle=shuffle,</div>
<div class="line"><a id="l01716" name="l01716"></a><span class="lineno"> 1716</span>            random_state=random_state,</div>
<div class="line"><a id="l01717" name="l01717"></a><span class="lineno"> 1717</span>            tol=tol,</div>
<div class="line"><a id="l01718" name="l01718"></a><span class="lineno"> 1718</span>            verbose=verbose,</div>
<div class="line"><a id="l01719" name="l01719"></a><span class="lineno"> 1719</span>            warm_start=warm_start,</div>
<div class="line"><a id="l01720" name="l01720"></a><span class="lineno"> 1720</span>            momentum=momentum,</div>
<div class="line"><a id="l01721" name="l01721"></a><span class="lineno"> 1721</span>            nesterovs_momentum=nesterovs_momentum,</div>
<div class="line"><a id="l01722" name="l01722"></a><span class="lineno"> 1722</span>            early_stopping=early_stopping,</div>
<div class="line"><a id="l01723" name="l01723"></a><span class="lineno"> 1723</span>            validation_fraction=validation_fraction,</div>
<div class="line"><a id="l01724" name="l01724"></a><span class="lineno"> 1724</span>            beta_1=beta_1,</div>
<div class="line"><a id="l01725" name="l01725"></a><span class="lineno"> 1725</span>            beta_2=beta_2,</div>
<div class="line"><a id="l01726" name="l01726"></a><span class="lineno"> 1726</span>            epsilon=epsilon,</div>
<div class="line"><a id="l01727" name="l01727"></a><span class="lineno"> 1727</span>            n_iter_no_change=n_iter_no_change,</div>
<div class="line"><a id="l01728" name="l01728"></a><span class="lineno"> 1728</span>            max_fun=max_fun,</div>
<div class="line"><a id="l01729" name="l01729"></a><span class="lineno"> 1729</span>        )</div>
<div class="line"><a id="l01730" name="l01730"></a><span class="lineno"> 1730</span> </div>
<div class="foldopen" id="foldopen01731" data-start="" data-end="">
<div class="line"><a id="l01731" name="l01731"></a><span class="lineno"><a class="line" href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html#a9ea14b09750b499e00adcf4c6505b5b9"> 1731</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html#a9ea14b09750b499e00adcf4c6505b5b9">predict</a>(self, X):</div>
<div class="line"><a id="l01732" name="l01732"></a><span class="lineno"> 1732</span>        <span class="stringliteral">&quot;&quot;&quot;Predict using the multi-layer perceptron model.</span></div>
<div class="line"><a id="l01733" name="l01733"></a><span class="lineno"> 1733</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01734" name="l01734"></a><span class="lineno"> 1734</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l01735" name="l01735"></a><span class="lineno"> 1735</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l01736" name="l01736"></a><span class="lineno"> 1736</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><a id="l01737" name="l01737"></a><span class="lineno"> 1737</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><a id="l01738" name="l01738"></a><span class="lineno"> 1738</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01739" name="l01739"></a><span class="lineno"> 1739</span><span class="stringliteral">        Returns</span></div>
<div class="line"><a id="l01740" name="l01740"></a><span class="lineno"> 1740</span><span class="stringliteral">        -------</span></div>
<div class="line"><a id="l01741" name="l01741"></a><span class="lineno"> 1741</span><span class="stringliteral">        y : ndarray of shape (n_samples, n_outputs)</span></div>
<div class="line"><a id="l01742" name="l01742"></a><span class="lineno"> 1742</span><span class="stringliteral">            The predicted values.</span></div>
<div class="line"><a id="l01743" name="l01743"></a><span class="lineno"> 1743</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l01744" name="l01744"></a><span class="lineno"> 1744</span>        check_is_fitted(self)</div>
<div class="line"><a id="l01745" name="l01745"></a><span class="lineno"> 1745</span>        <span class="keywordflow">return</span> self.<a class="code hl_function" href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html#a26053a11dc28091476e8082c3a11bb90">_predict</a>(X)</div>
<div class="line"><a id="l01746" name="l01746"></a><span class="lineno"> 1746</span> </div>
</div>
<div class="foldopen" id="foldopen01747" data-start="" data-end="">
<div class="line"><a id="l01747" name="l01747"></a><span class="lineno"><a class="line" href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html#a26053a11dc28091476e8082c3a11bb90"> 1747</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html#a26053a11dc28091476e8082c3a11bb90">_predict</a>(self, X, check_input=True):</div>
<div class="line"><a id="l01748" name="l01748"></a><span class="lineno"> 1748</span>        <span class="stringliteral">&quot;&quot;&quot;Private predict method with optional input validation&quot;&quot;&quot;</span></div>
<div class="line"><a id="l01749" name="l01749"></a><span class="lineno"> 1749</span>        y_pred = self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a65cb479141ebeb9fd5e77845b242979b">_forward_pass_fast</a>(X, check_input=check_input)</div>
<div class="line"><a id="l01750" name="l01750"></a><span class="lineno"> 1750</span>        <span class="keywordflow">if</span> y_pred.shape[1] == 1:</div>
<div class="line"><a id="l01751" name="l01751"></a><span class="lineno"> 1751</span>            <span class="keywordflow">return</span> y_pred.ravel()</div>
<div class="line"><a id="l01752" name="l01752"></a><span class="lineno"> 1752</span>        <span class="keywordflow">return</span> y_pred</div>
<div class="line"><a id="l01753" name="l01753"></a><span class="lineno"> 1753</span> </div>
</div>
<div class="line"><a id="l01754" name="l01754"></a><span class="lineno"> 1754</span>    <span class="keyword">def </span>_score(self, X, y, sample_weight=None):</div>
<div class="line"><a id="l01755" name="l01755"></a><span class="lineno"> 1755</span>        <span class="keywordflow">return</span> super().<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad19ee046e2bfe882adbddfb46980c0f6">_score_with_function</a>(</div>
<div class="line"><a id="l01756" name="l01756"></a><span class="lineno"> 1756</span>            X, y, sample_weight=sample_weight, score_function=r2_score</div>
<div class="line"><a id="l01757" name="l01757"></a><span class="lineno"> 1757</span>        )</div>
<div class="line"><a id="l01758" name="l01758"></a><span class="lineno"> 1758</span> </div>
<div class="line"><a id="l01759" name="l01759"></a><span class="lineno"> 1759</span>    <span class="keyword">def </span>_validate_input(self, X, y, incremental, reset):</div>
<div class="line"><a id="l01760" name="l01760"></a><span class="lineno"> 1760</span>        X, y = validate_data(</div>
<div class="line"><a id="l01761" name="l01761"></a><span class="lineno"> 1761</span>            self,</div>
<div class="line"><a id="l01762" name="l01762"></a><span class="lineno"> 1762</span>            X,</div>
<div class="line"><a id="l01763" name="l01763"></a><span class="lineno"> 1763</span>            y,</div>
<div class="line"><a id="l01764" name="l01764"></a><span class="lineno"> 1764</span>            accept_sparse=[<span class="stringliteral">&quot;csr&quot;</span>, <span class="stringliteral">&quot;csc&quot;</span>],</div>
<div class="line"><a id="l01765" name="l01765"></a><span class="lineno"> 1765</span>            multi_output=<span class="keyword">True</span>,</div>
<div class="line"><a id="l01766" name="l01766"></a><span class="lineno"> 1766</span>            y_numeric=<span class="keyword">True</span>,</div>
<div class="line"><a id="l01767" name="l01767"></a><span class="lineno"> 1767</span>            dtype=(np.float64, np.float32),</div>
<div class="line"><a id="l01768" name="l01768"></a><span class="lineno"> 1768</span>            reset=reset,</div>
<div class="line"><a id="l01769" name="l01769"></a><span class="lineno"> 1769</span>        )</div>
<div class="line"><a id="l01770" name="l01770"></a><span class="lineno"> 1770</span>        <span class="keywordflow">if</span> y.ndim == 2 <span class="keywordflow">and</span> y.shape[1] == 1:</div>
<div class="line"><a id="l01771" name="l01771"></a><span class="lineno"> 1771</span>            y = column_or_1d(y, warn=<span class="keyword">True</span>)</div>
<div class="line"><a id="l01772" name="l01772"></a><span class="lineno"> 1772</span>        <span class="keywordflow">return</span> X, y</div>
<div class="line"><a id="l01773" name="l01773"></a><span class="lineno"> 1773</span> </div>
<div class="line"><a id="l01774" name="l01774"></a><span class="lineno"> 1774</span>    <span class="preprocessor">@available_if(lambda est: est._check_solver)</span></div>
<div class="line"><a id="l01775" name="l01775"></a><span class="lineno"> 1775</span>    <span class="preprocessor">@_fit_context(prefer_skip_nested_validation=True)</span></div>
<div class="foldopen" id="foldopen01776" data-start="" data-end="">
<div class="line"><a id="l01776" name="l01776"></a><span class="lineno"><a class="line" href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html#a2163fbbe2d120e75a23e675fb3704607"> 1776</a></span>    <span class="keyword">def </span><a class="code hl_function" href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html#a2163fbbe2d120e75a23e675fb3704607">partial_fit</a>(self, X, y, sample_weight=None):</div>
<div class="line"><a id="l01777" name="l01777"></a><span class="lineno"> 1777</span>        <span class="stringliteral">&quot;&quot;&quot;Update the model with a single iteration over the given data.</span></div>
<div class="line"><a id="l01778" name="l01778"></a><span class="lineno"> 1778</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01779" name="l01779"></a><span class="lineno"> 1779</span><span class="stringliteral">        Parameters</span></div>
<div class="line"><a id="l01780" name="l01780"></a><span class="lineno"> 1780</span><span class="stringliteral">        ----------</span></div>
<div class="line"><a id="l01781" name="l01781"></a><span class="lineno"> 1781</span><span class="stringliteral">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span></div>
<div class="line"><a id="l01782" name="l01782"></a><span class="lineno"> 1782</span><span class="stringliteral">            The input data.</span></div>
<div class="line"><a id="l01783" name="l01783"></a><span class="lineno"> 1783</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01784" name="l01784"></a><span class="lineno"> 1784</span><span class="stringliteral">        y : ndarray of shape (n_samples,)</span></div>
<div class="line"><a id="l01785" name="l01785"></a><span class="lineno"> 1785</span><span class="stringliteral">            The target values.</span></div>
<div class="line"><a id="l01786" name="l01786"></a><span class="lineno"> 1786</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01787" name="l01787"></a><span class="lineno"> 1787</span><span class="stringliteral">        sample_weight : array-like of shape (n_samples,), default=None</span></div>
<div class="line"><a id="l01788" name="l01788"></a><span class="lineno"> 1788</span><span class="stringliteral">            Sample weights.</span></div>
<div class="line"><a id="l01789" name="l01789"></a><span class="lineno"> 1789</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01790" name="l01790"></a><span class="lineno"> 1790</span><span class="stringliteral">            .. versionadded:: 1.6</span></div>
<div class="line"><a id="l01791" name="l01791"></a><span class="lineno"> 1791</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01792" name="l01792"></a><span class="lineno"> 1792</span><span class="stringliteral">        Returns</span></div>
<div class="line"><a id="l01793" name="l01793"></a><span class="lineno"> 1793</span><span class="stringliteral">        -------</span></div>
<div class="line"><a id="l01794" name="l01794"></a><span class="lineno"> 1794</span><span class="stringliteral">        self : object</span></div>
<div class="line"><a id="l01795" name="l01795"></a><span class="lineno"> 1795</span><span class="stringliteral">            Trained MLP model.</span></div>
<div class="line"><a id="l01796" name="l01796"></a><span class="lineno"> 1796</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l01797" name="l01797"></a><span class="lineno"> 1797</span>        <span class="keywordflow">return</span> self.<a class="code hl_function" href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5ee59a9eb9aefd9dde989f3a32cac161">_fit</a>(X, y, sample_weight=sample_weight, incremental=<span class="keyword">True</span>)</div>
</div>
</div>
<div class="ttc" id="aclassABC_html"><div class="ttname"><a href="../../dd/d9b/classABC.html">ABC</a></div></div>
<div class="ttc" id="aclassAttributeError_html"><div class="ttname"><a href="../../d7/d52/classAttributeError.html">AttributeError</a></div></div>
<div class="ttc" id="aclassValueError_html"><div class="ttname"><a href="../../de/d40/classValueError.html">ValueError</a></div></div>
<div class="ttc" id="aclasssklearn_1_1base_1_1BaseEstimator_html"><div class="ttname"><a href="../../d3/d20/classsklearn_1_1base_1_1BaseEstimator.html">sklearn.base.BaseEstimator</a></div><div class="ttdef"><b>Definition</b> <a href="../../d7/d3d/sklearn_2base_8py_source.html#l00156">base.py:156</a></div></div>
<div class="ttc" id="aclasssklearn_1_1base_1_1ClassifierMixin_html"><div class="ttname"><a href="../../d2/d39/classsklearn_1_1base_1_1ClassifierMixin.html">sklearn.base.ClassifierMixin</a></div><div class="ttdef"><b>Definition</b> <a href="../../d7/d3d/sklearn_2base_8py_source.html#l00478">base.py:478</a></div></div>
<div class="ttc" id="aclasssklearn_1_1base_1_1RegressorMixin_html"><div class="ttname"><a href="../../df/d64/classsklearn_1_1base_1_1RegressorMixin.html">sklearn.base.RegressorMixin</a></div><div class="ttdef"><b>Definition</b> <a href="../../d7/d3d/sklearn_2base_8py_source.html#l00551">base.py:551</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron</a></div><div class="ttdef"><b>Definition</b> <a href="#l00054">_multilayer_perceptron.py:54</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a0368ec6ff4ec3ab92c5ca109d4e80721"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0368ec6ff4ec3ab92c5ca109d4e80721">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.loss</a></div><div class="ttdeci">str loss</div><div class="ttdef"><b>Definition</b> <a href="#l00134">_multilayer_perceptron.py:134</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a09f3f5db1df292bba142574f372f80a7"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a09f3f5db1df292bba142574f372f80a7">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._best_intercepts</a></div><div class="ttdeci">list _best_intercepts</div><div class="ttdef"><b>Definition</b> <a href="#l00427">_multilayer_perceptron.py:427</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a0bd28615806017485087b01098172f8f"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0bd28615806017485087b01098172f8f">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.learning_rate</a></div><div class="ttdeci">learning_rate</div><div class="ttdef"><b>Definition</b> <a href="#l00130">_multilayer_perceptron.py:130</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a0c95ef33cbc4840aa36c1cee559e1c9b"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0c95ef33cbc4840aa36c1cee559e1c9b">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.epsilon</a></div><div class="ttdeci">epsilon</div><div class="ttdef"><b>Definition</b> <a href="#l00147">_multilayer_perceptron.py:147</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a0d765db3f3c8659b1d818a7b0bbbcd5e"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0d765db3f3c8659b1d818a7b0bbbcd5e">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.validation_scores_</a></div><div class="ttdeci">list validation_scores_</div><div class="ttdef"><b>Definition</b> <a href="#l00433">_multilayer_perceptron.py:433</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a0f052dea4e28c577fa309c8c104ea9f7"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f052dea4e28c577fa309c8c104ea9f7">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.n_iter_no_change</a></div><div class="ttdeci">n_iter_no_change</div><div class="ttdef"><b>Definition</b> <a href="#l00148">_multilayer_perceptron.py:148</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a0f8ac62cfaa9e175770b6e3acd1e7ac0"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f8ac62cfaa9e175770b6e3acd1e7ac0">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._coef_indptr</a></div><div class="ttdeci">list _coef_indptr</div><div class="ttdef"><b>Definition</b> <a href="#l00555">_multilayer_perceptron.py:555</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a0f969a1c0f205f30a10977d58a3f5837"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a0f969a1c0f205f30a10977d58a3f5837">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._compute_loss_grad</a></div><div class="ttdeci">_compute_loss_grad(self, layer, sw_sum, activations, deltas, coef_grads, intercept_grads)</div><div class="ttdef"><b>Definition</b> <a href="#l00222">_multilayer_perceptron.py:224</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a1cdc4a9b4f8c1d00572be3ba7400d728"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a1cdc4a9b4f8c1d00572be3ba7400d728">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.t_</a></div><div class="ttdeci">int t_</div><div class="ttdef"><b>Definition</b> <a href="#l00395">_multilayer_perceptron.py:395</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a215bc7c01b70f8525b1e8f1c0c035e4a"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a215bc7c01b70f8525b1e8f1c0c035e4a">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._random_state</a></div><div class="ttdeci">_random_state</div><div class="ttdef"><b>Definition</b> <a href="#l00487">_multilayer_perceptron.py:487</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a24d8114c5f7a2c9fc35242135857f8ae"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a24d8114c5f7a2c9fc35242135857f8ae">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.loss_curve_</a></div><div class="ttdeci">list loss_curve_</div><div class="ttdef"><b>Definition</b> <a href="#l00430">_multilayer_perceptron.py:430</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a27576cf472db61b06d2951267d01df7a"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a27576cf472db61b06d2951267d01df7a">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.loss_</a></div><div class="ttdeci">loss_</div><div class="ttdef"><b>Definition</b> <a href="#l00603">_multilayer_perceptron.py:603</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a2b40afead813fd9060912fdc5c8c5585"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a2b40afead813fd9060912fdc5c8c5585">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.alpha</a></div><div class="ttdeci">alpha</div><div class="ttdef"><b>Definition</b> <a href="#l00128">_multilayer_perceptron.py:128</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a318bdf742f2e44c92f36b7a0c0912a83"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a318bdf742f2e44c92f36b7a0c0912a83">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.max_iter</a></div><div class="ttdeci">max_iter</div><div class="ttdef"><b>Definition</b> <a href="#l00133">_multilayer_perceptron.py:133</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a3dc00b9cd7811c0f2a93016e9c31557a"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a3dc00b9cd7811c0f2a93016e9c31557a">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.shuffle</a></div><div class="ttdeci">shuffle</div><div class="ttdef"><b>Definition</b> <a href="#l00136">_multilayer_perceptron.py:136</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a446fb221b8ffb5dac45f7b0506729351"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a446fb221b8ffb5dac45f7b0506729351">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._forward_pass</a></div><div class="ttdeci">_forward_pass(self, activations)</div><div class="ttdef"><b>Definition</b> <a href="#l00160">_multilayer_perceptron.py:160</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a4a0b9ab6cfff8afb6a02e09c65bfe064"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a4a0b9ab6cfff8afb6a02e09c65bfe064">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.beta_2</a></div><div class="ttdeci">beta_2</div><div class="ttdef"><b>Definition</b> <a href="#l00146">_multilayer_perceptron.py:146</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a51ff58bd42d10137a1ae0214d0840f5c"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a51ff58bd42d10137a1ae0214d0840f5c">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._update_no_improvement_count</a></div><div class="ttdeci">_update_no_improvement_count(self, early_stopping, X, y, sample_weight)</div><div class="ttdef"><b>Definition</b> <a href="#l00795">_multilayer_perceptron.py:795</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a5cda8eac7691d634a8687ec9b7c40ba3"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5cda8eac7691d634a8687ec9b7c40ba3">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.n_layers_</a></div><div class="ttdeci">n_layers_</div><div class="ttdef"><b>Definition</b> <a href="#l00399">_multilayer_perceptron.py:399</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a5ee59a9eb9aefd9dde989f3a32cac161"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5ee59a9eb9aefd9dde989f3a32cac161">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._fit</a></div><div class="ttdeci">_fit(self, X, y, sample_weight=None, incremental=False)</div><div class="ttdef"><b>Definition</b> <a href="#l00458">_multilayer_perceptron.py:458</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a5f9e6d09bc3196361c46192640196624"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a5f9e6d09bc3196361c46192640196624">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.random_state</a></div><div class="ttdeci">random_state</div><div class="ttdef"><b>Definition</b> <a href="#l00137">_multilayer_perceptron.py:137</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a65cb479141ebeb9fd5e77845b242979b"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a65cb479141ebeb9fd5e77845b242979b">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._forward_pass_fast</a></div><div class="ttdeci">_forward_pass_fast(self, X, check_input=True)</div><div class="ttdef"><b>Definition</b> <a href="#l00185">_multilayer_perceptron.py:185</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a669612405aaf465d9489e5cbd6442a7a"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a669612405aaf465d9489e5cbd6442a7a">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._no_improvement_count</a></div><div class="ttdeci">int _no_improvement_count</div><div class="ttdef"><b>Definition</b> <a href="#l00431">_multilayer_perceptron.py:431</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a6ef171715977706490c0d6f09cefeb89"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6ef171715977706490c0d6f09cefeb89">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.out_activation_</a></div><div class="ttdeci">str out_activation_</div><div class="ttdef"><b>Definition</b> <a href="#l00404">_multilayer_perceptron.py:404</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a6f936f142295a4ed0e612fb834147f72"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a6f936f142295a4ed0e612fb834147f72">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._loss_grad_lbfgs</a></div><div class="ttdeci">_loss_grad_lbfgs(self, packed_coef_inter, X, y, sample_weight, activations, deltas, coef_grads, intercept_grads)</div><div class="ttdef"><b>Definition</b> <a href="#l00236">_multilayer_perceptron.py:246</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a7053e621a032a08513a2453f2367bd74"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a7053e621a032a08513a2453f2367bd74">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.hidden_layer_sizes</a></div><div class="ttdeci">hidden_layer_sizes</div><div class="ttdef"><b>Definition</b> <a href="#l00135">_multilayer_perceptron.py:135</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a706a1c60c73f17d042b1ca83f395981b"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a706a1c60c73f17d042b1ca83f395981b">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._backprop</a></div><div class="ttdeci">_backprop(self, X, y, sample_weight, activations, deltas, coef_grads, intercept_grads)</div><div class="ttdef"><b>Definition</b> <a href="#l00297">_multilayer_perceptron.py:299</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a70a6072759ac7ac36b964c80d3620525"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a70a6072759ac7ac36b964c80d3620525">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.best_loss_</a></div><div class="ttdeci">list best_loss_</div><div class="ttdef"><b>Definition</b> <a href="#l00435">_multilayer_perceptron.py:435</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a7bb6a222df4472c2f8219ba605f490c3"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a7bb6a222df4472c2f8219ba605f490c3">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.learning_rate_init</a></div><div class="ttdeci">learning_rate_init</div><div class="ttdef"><b>Definition</b> <a href="#l00131">_multilayer_perceptron.py:131</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a7e03c7f5817e706517ad8ca12110c99f"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a7e03c7f5817e706517ad8ca12110c99f">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._init_coef</a></div><div class="ttdeci">_init_coef(self, fan_in, fan_out, dtype)</div><div class="ttdef"><b>Definition</b> <a href="#l00441">_multilayer_perceptron.py:441</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a85298d7736f4e7fe4b167fc8ff51aaa6"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a85298d7736f4e7fe4b167fc8ff51aaa6">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.validation_fraction</a></div><div class="ttdeci">validation_fraction</div><div class="ttdef"><b>Definition</b> <a href="#l00144">_multilayer_perceptron.py:144</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a8e8860831f3364befbe42eae4224be95"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a8e8860831f3364befbe42eae4224be95">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.coefs_</a></div><div class="ttdeci">list coefs_</div><div class="ttdef"><b>Definition</b> <a href="#l00350">_multilayer_perceptron.py:350</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a9335dce7fccc3077842f4deccf52ac98"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a9335dce7fccc3077842f4deccf52ac98">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._optimizer</a></div><div class="ttdeci">_optimizer</div><div class="ttdef"><b>Definition</b> <a href="#l00621">_multilayer_perceptron.py:621</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a96c5a6ce572a9cfe24350c3f1b737116"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a96c5a6ce572a9cfe24350c3f1b737116">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.warm_start</a></div><div class="ttdeci">warm_start</div><div class="ttdef"><b>Definition</b> <a href="#l00140">_multilayer_perceptron.py:140</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a98812cf40a7067db51eba0c802f3d8f8"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a98812cf40a7067db51eba0c802f3d8f8">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._best_coefs</a></div><div class="ttdeci">list _best_coefs</div><div class="ttdef"><b>Definition</b> <a href="#l00426">_multilayer_perceptron.py:426</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_a99d828d71d0571f169342d7b4dc54a57"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#a99d828d71d0571f169342d7b4dc54a57">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.batch_size</a></div><div class="ttdeci">str batch_size</div><div class="ttdef"><b>Definition</b> <a href="#l00129">_multilayer_perceptron.py:129</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_aa019948ee2d7ac810cea9942dd3d5187"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa019948ee2d7ac810cea9942dd3d5187">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.early_stopping</a></div><div class="ttdeci">early_stopping</div><div class="ttdef"><b>Definition</b> <a href="#l00143">_multilayer_perceptron.py:143</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_aa19a4c76b460a193cd87c03cc5e30280"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa19a4c76b460a193cd87c03cc5e30280">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.nesterovs_momentum</a></div><div class="ttdeci">nesterovs_momentum</div><div class="ttdef"><b>Definition</b> <a href="#l00142">_multilayer_perceptron.py:142</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_aa8cd7dbf0b493aab5c0f7e053575be1e"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa8cd7dbf0b493aab5c0f7e053575be1e">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._initialize</a></div><div class="ttdeci">_initialize(self, y, layer_units, dtype)</div><div class="ttdef"><b>Definition</b> <a href="#l00391">_multilayer_perceptron.py:391</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_aa993801cc4d309b69244e4ea31d5a4a9"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aa993801cc4d309b69244e4ea31d5a4a9">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.fit</a></div><div class="ttdeci">fit(self, X, y, sample_weight=None)</div><div class="ttdef"><b>Definition</b> <a href="#l00827">_multilayer_perceptron.py:827</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_ab5407ee4ebf264a65951d66ac2dca857"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ab5407ee4ebf264a65951d66ac2dca857">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._unpack</a></div><div class="ttdeci">_unpack(self, packed_parameters)</div><div class="ttdef"><b>Definition</b> <a href="#l00151">_multilayer_perceptron.py:151</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_abb3113bc3c7d179d4a7e9443f2090036"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#abb3113bc3c7d179d4a7e9443f2090036">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.verbose</a></div><div class="ttdeci">verbose</div><div class="ttdef"><b>Definition</b> <a href="#l00139">_multilayer_perceptron.py:139</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_ac4db5d73babe4976fac6b50ac73dccec"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac4db5d73babe4976fac6b50ac73dccec">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.n_iter_</a></div><div class="ttdeci">int n_iter_</div><div class="ttdef"><b>Definition</b> <a href="#l00394">_multilayer_perceptron.py:394</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_ac913f3e320e35d56add32462793c14e7"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ac913f3e320e35d56add32462793c14e7">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.n_outputs_</a></div><div class="ttdeci">n_outputs_</div><div class="ttdef"><b>Definition</b> <a href="#l00396">_multilayer_perceptron.py:396</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_ad05c99ca6c9254da855b5d3fd2728f34"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad05c99ca6c9254da855b5d3fd2728f34">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.momentum</a></div><div class="ttdeci">momentum</div><div class="ttdef"><b>Definition</b> <a href="#l00141">_multilayer_perceptron.py:141</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_ad0fedbabf4cba29b7e6800c566ed759e"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad0fedbabf4cba29b7e6800c566ed759e">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.max_fun</a></div><div class="ttdeci">max_fun</div><div class="ttdef"><b>Definition</b> <a href="#l00149">_multilayer_perceptron.py:149</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_ad19ee046e2bfe882adbddfb46980c0f6"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ad19ee046e2bfe882adbddfb46980c0f6">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._score_with_function</a></div><div class="ttdeci">_score_with_function(self, X, y, sample_weight, score_function)</div><div class="ttdef"><b>Definition</b> <a href="#l00859">_multilayer_perceptron.py:859</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_adb94c71df194fdc6d51b67e8e5bc93bc"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#adb94c71df194fdc6d51b67e8e5bc93bc">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.power_t</a></div><div class="ttdeci">power_t</div><div class="ttdef"><b>Definition</b> <a href="#l00132">_multilayer_perceptron.py:132</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_ae5604c756ba2c76a6ee244191ad5fb23"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ae5604c756ba2c76a6ee244191ad5fb23">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._fit_lbfgs</a></div><div class="ttdeci">_fit_lbfgs(self, X, y, sample_weight, activations, deltas, coef_grads, intercept_grads, layer_units)</div><div class="ttdef"><b>Definition</b> <a href="#l00543">_multilayer_perceptron.py:553</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_ae70675d98fd81222592a806f5177eae5"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#ae70675d98fd81222592a806f5177eae5">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._fit_stochastic</a></div><div class="ttdeci">_fit_stochastic(self, X, y, sample_weight, activations, deltas, coef_grads, intercept_grads, layer_units, incremental)</div><div class="ttdef"><b>Definition</b> <a href="#l00606">_multilayer_perceptron.py:617</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_aeb74743a17844cbe20a4da921e4f3a0f"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aeb74743a17844cbe20a4da921e4f3a0f">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.intercepts_</a></div><div class="ttdeci">list intercepts_</div><div class="ttdef"><b>Definition</b> <a href="#l00417">_multilayer_perceptron.py:417</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_af338625696b13b08848be17ec42a3bcb"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af338625696b13b08848be17ec42a3bcb">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.beta_1</a></div><div class="ttdeci">beta_1</div><div class="ttdef"><b>Definition</b> <a href="#l00145">_multilayer_perceptron.py:145</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_af3fc521b13aae045b9e10387f34b0ba1"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af3fc521b13aae045b9e10387f34b0ba1">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.tol</a></div><div class="ttdeci">tol</div><div class="ttdef"><b>Definition</b> <a href="#l00138">_multilayer_perceptron.py:138</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_af9772e422910c066bd1214dc5e01f984"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#af9772e422910c066bd1214dc5e01f984">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.best_validation_score_</a></div><div class="ttdeci">best_validation_score_</div><div class="ttdef"><b>Definition</b> <a href="#l00434">_multilayer_perceptron.py:434</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_afa5470b39ae914ecb63c854752afd667"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#afa5470b39ae914ecb63c854752afd667">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.activation</a></div><div class="ttdeci">str activation</div><div class="ttdef"><b>Definition</b> <a href="#l00126">_multilayer_perceptron.py:126</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_afee67bc813d4cdc01e30d33c23b45f77"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#afee67bc813d4cdc01e30d33c23b45f77">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron._intercept_indptr</a></div><div class="ttdeci">list _intercept_indptr</div><div class="ttdef"><b>Definition</b> <a href="#l00556">_multilayer_perceptron.py:556</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron_html_aff5cec0cbb94c15f464c19ff02b738dc"><div class="ttname"><a href="../../dc/d8a/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1BaseMultilayerPerceptron.html#aff5cec0cbb94c15f464c19ff02b738dc">sklearn.neural_network._multilayer_perceptron.BaseMultilayerPerceptron.solver</a></div><div class="ttdeci">str solver</div><div class="ttdef"><b>Definition</b> <a href="#l00127">_multilayer_perceptron.py:127</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier_html"><div class="ttname"><a href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html">sklearn.neural_network._multilayer_perceptron.MLPClassifier</a></div><div class="ttdef"><b>Definition</b> <a href="#l00875">_multilayer_perceptron.py:875</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier_html_a16623460fe2b65e46108871f5618a9fb"><div class="ttname"><a href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#a16623460fe2b65e46108871f5618a9fb">sklearn.neural_network._multilayer_perceptron.MLPClassifier.partial_fit</a></div><div class="ttdeci">partial_fit(self, X, y, sample_weight=None, classes=None)</div><div class="ttdef"><b>Definition</b> <a href="#l01295">_multilayer_perceptron.py:1295</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier_html_a18543e8902910fb447a70a26df276d82"><div class="ttname"><a href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#a18543e8902910fb447a70a26df276d82">sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict_log_proba</a></div><div class="ttdeci">predict_log_proba(self, X)</div><div class="ttdef"><b>Definition</b> <a href="#l01333">_multilayer_perceptron.py:1333</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier_html_a64069f3c9ec4c814c65fbe2aca94cf14"><div class="ttname"><a href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#a64069f3c9ec4c814c65fbe2aca94cf14">sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict</a></div><div class="ttdeci">predict(self, X)</div><div class="ttdef"><b>Definition</b> <a href="#l01263">_multilayer_perceptron.py:1263</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier_html_aa4a6e8fdf6566ab2228b0a33d956da60"><div class="ttname"><a href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#aa4a6e8fdf6566ab2228b0a33d956da60">sklearn.neural_network._multilayer_perceptron.MLPClassifier._label_binarizer</a></div><div class="ttdeci">_label_binarizer</div><div class="ttdef"><b>Definition</b> <a href="#l01240">_multilayer_perceptron.py:1240</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier_html_ab8223db06662e4b79f8cc97db664afe1"><div class="ttname"><a href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#ab8223db06662e4b79f8cc97db664afe1">sklearn.neural_network._multilayer_perceptron.MLPClassifier.predict_proba</a></div><div class="ttdeci">predict_proba(self, X)</div><div class="ttdef"><b>Definition</b> <a href="#l01351">_multilayer_perceptron.py:1351</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier_html_abc60cd9ab05a18e4a342e97a43034bac"><div class="ttname"><a href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#abc60cd9ab05a18e4a342e97a43034bac">sklearn.neural_network._multilayer_perceptron.MLPClassifier._predict</a></div><div class="ttdeci">_predict(self, X, check_input=True)</div><div class="ttdef"><b>Definition</b> <a href="#l01279">_multilayer_perceptron.py:1279</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier_html_adf5451f04bf39076f2d357a2ecba04e2"><div class="ttname"><a href="../../d7/d60/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier.html#adf5451f04bf39076f2d357a2ecba04e2">sklearn.neural_network._multilayer_perceptron.MLPClassifier.classes_</a></div><div class="ttdeci">classes_</div><div class="ttdef"><b>Definition</b> <a href="#l01242">_multilayer_perceptron.py:1242</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor_html"><div class="ttname"><a href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html">sklearn.neural_network._multilayer_perceptron.MLPRegressor</a></div><div class="ttdef"><b>Definition</b> <a href="#l01382">_multilayer_perceptron.py:1382</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor_html_a2163fbbe2d120e75a23e675fb3704607"><div class="ttname"><a href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html#a2163fbbe2d120e75a23e675fb3704607">sklearn.neural_network._multilayer_perceptron.MLPRegressor.partial_fit</a></div><div class="ttdeci">partial_fit(self, X, y, sample_weight=None)</div><div class="ttdef"><b>Definition</b> <a href="#l01776">_multilayer_perceptron.py:1776</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor_html_a26053a11dc28091476e8082c3a11bb90"><div class="ttname"><a href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html#a26053a11dc28091476e8082c3a11bb90">sklearn.neural_network._multilayer_perceptron.MLPRegressor._predict</a></div><div class="ttdeci">_predict(self, X, check_input=True)</div><div class="ttdef"><b>Definition</b> <a href="#l01747">_multilayer_perceptron.py:1747</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor_html_a9ea14b09750b499e00adcf4c6505b5b9"><div class="ttname"><a href="../../d6/dc9/classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor.html#a9ea14b09750b499e00adcf4c6505b5b9">sklearn.neural_network._multilayer_perceptron.MLPRegressor.predict</a></div><div class="ttdeci">predict(self, X)</div><div class="ttdef"><b>Definition</b> <a href="#l01731">_multilayer_perceptron.py:1731</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__stochastic__optimizers_1_1AdamOptimizer_html"><div class="ttname"><a href="../../d1/d67/classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1AdamOptimizer.html">sklearn.neural_network._stochastic_optimizers.AdamOptimizer</a></div><div class="ttdef"><b>Definition</b> <a href="../../d0/dbc/__stochastic__optimizers_8py_source.html#l00197">_stochastic_optimizers.py:197</a></div></div>
<div class="ttc" id="aclasssklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_html"><div class="ttname"><a href="../../de/d58/classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer.html">sklearn.neural_network._stochastic_optimizers.SGDOptimizer</a></div><div class="ttdef"><b>Definition</b> <a href="../../d0/dbc/__stochastic__optimizers_8py_source.html#l00072">_stochastic_optimizers.py:72</a></div></div>
<div class="ttc" id="aclasssklearn_1_1preprocessing_1_1__label_1_1LabelBinarizer_html"><div class="ttname"><a href="../../d9/d21/classsklearn_1_1preprocessing_1_1__label_1_1LabelBinarizer.html">sklearn.preprocessing._label.LabelBinarizer</a></div><div class="ttdef"><b>Definition</b> <a href="../../da/df5/__label_8py_source.html#l00174">_label.py:174</a></div></div>
<div class="ttc" id="aclasssklearn_1_1utils_1_1__param__validation_1_1Interval_html"><div class="ttname"><a href="../../dc/dae/classsklearn_1_1utils_1_1__param__validation_1_1Interval.html">sklearn.utils._param_validation.Interval</a></div><div class="ttdef"><b>Definition</b> <a href="../../d2/d2e/__param__validation_8py_source.html#l00402">_param_validation.py:402</a></div></div>
<div class="ttc" id="aclasssklearn_1_1utils_1_1__param__validation_1_1Options_html"><div class="ttname"><a href="../../d1/d66/classsklearn_1_1utils_1_1__param__validation_1_1Options.html">sklearn.utils._param_validation.Options</a></div><div class="ttdef"><b>Definition</b> <a href="../../d2/d2e/__param__validation_8py_source.html#l00344">_param_validation.py:344</a></div></div>
<div class="ttc" id="aclasssklearn_1_1utils_1_1__param__validation_1_1StrOptions_html"><div class="ttname"><a href="../../d1/da1/classsklearn_1_1utils_1_1__param__validation_1_1StrOptions.html">sklearn.utils._param_validation.StrOptions</a></div><div class="ttdef"><b>Definition</b> <a href="../../d2/d2e/__param__validation_8py_source.html#l00385">_param_validation.py:385</a></div></div>
<div class="ttc" id="anamespacescipy_1_1optimize_html"><div class="ttname"><a href="../../da/d87/namespacescipy_1_1optimize.html">scipy.optimize</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/d41/scipy_2optimize_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1neural__network_1_1__multilayer__perceptron_html_a1882a2fc5fa03f538467faae921802a5"><div class="ttname"><a href="../../d8/d15/namespacesklearn_1_1neural__network_1_1__multilayer__perceptron.html#a1882a2fc5fa03f538467faae921802a5">sklearn.neural_network._multilayer_perceptron._pack</a></div><div class="ttdeci">_pack(coefs_, intercepts_)</div><div class="ttdef"><b>Definition</b> <a href="#l00049">_multilayer_perceptron.py:49</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="../../dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="../../dir_f6da99e2877b0632a7e4a834e7483fed.html">llm-scripts</a></li><li class="navelem"><a class="el" href="../../dir_70c99b0173b62e0b00f95d6bf5d77b0f.html">testing</a></li><li class="navelem"><a class="el" href="../../dir_c90555aa24febdaeb0b43db3ed65d5d9.html">hypothesis-testing</a></li><li class="navelem"><a class="el" href="../../dir_5d121c57859a2187a176663451f456b7.html">hyp-env</a></li><li class="navelem"><a class="el" href="../../dir_bd811e5d8688c3c2df683649a5255528.html">lib</a></li><li class="navelem"><a class="el" href="../../dir_ed8133538883844379882c9fac17a38e.html">python3.12</a></li><li class="navelem"><a class="el" href="../../dir_ec5d4580713abd487320f8eae4ae4e88.html">site-packages</a></li><li class="navelem"><a class="el" href="../../dir_95412a8f6746b9685e089ed9447bfec4.html">sklearn</a></li><li class="navelem"><a class="el" href="../../dir_86f16965b563241dacc4d3d18028b86f.html">neural_network</a></li><li class="navelem"><b>_multilayer_perceptron.py</b></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
