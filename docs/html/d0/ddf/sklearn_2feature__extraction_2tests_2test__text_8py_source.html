<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Code Cloning Analysis: /home/jam/Research/IRES-2025/dev/src/llm-scripts/testing/hypothesis-testing/hyp-env/lib/python3.12/site-packages/sklearn/feature_extraction/tests/test_text.py Source File</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../clipboard.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Code Cloning Analysis
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('d0/ddf/sklearn_2feature__extraction_2tests_2test__text_8py_source.html','../../'); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">test_text.py</div></div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno"><a class="line" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html">    1</a></span><span class="keyword">import</span> pickle</div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="keyword">import</span> re</div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="keyword">import</span> uuid</div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="keyword">import</span> warnings</div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="keyword">from</span> <a class="code hl_namespace" href="../../d3/d39/namespacecollections_1_1abc.html">collections.abc</a> <span class="keyword">import</span> Mapping</div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="keyword">from</span> functools <span class="keyword">import</span> partial</div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="keyword">from</span> itertools <span class="keyword">import</span> product</div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span> </div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="keyword">import</span> pytest</div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="keyword">from</span> <a class="code hl_namespace" href="../../df/d7e/namespacenumpy_1_1testing.html">numpy.testing</a> <span class="keyword">import</span> assert_array_almost_equal, assert_array_equal</div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span> </div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="keyword">from</span> <a class="code hl_namespace" href="../../d6/da3/namespacesklearn_1_1base.html">sklearn.base</a> <span class="keyword">import</span> clone</div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="keyword">from</span> <a class="code hl_namespace" href="../../da/d65/namespacesklearn_1_1feature__extraction_1_1text.html">sklearn.feature_extraction.text</a> <span class="keyword">import</span> (</div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span>    ENGLISH_STOP_WORDS,</div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span>    CountVectorizer,</div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span>    HashingVectorizer,</div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span>    TfidfTransformer,</div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span>    TfidfVectorizer,</div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span>    strip_accents_ascii,</div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span>    strip_accents_unicode,</div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span>    strip_tags,</div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span>)</div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span><span class="keyword">from</span> <a class="code hl_namespace" href="../../d0/d54/namespacesklearn_1_1model__selection.html">sklearn.model_selection</a> <span class="keyword">import</span> GridSearchCV, cross_val_score, train_test_split</div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="keyword">from</span> <a class="code hl_namespace" href="../../dc/d8e/namespacesklearn_1_1pipeline.html">sklearn.pipeline</a> <span class="keyword">import</span> Pipeline</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span><span class="keyword">from</span> <a class="code hl_namespace" href="../../d9/d80/namespacesklearn_1_1svm.html">sklearn.svm</a> <span class="keyword">import</span> LinearSVC</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="keyword">from</span> <a class="code hl_namespace" href="../../d8/d2d/namespacesklearn_1_1utils_1_1__testing.html">sklearn.utils._testing</a> <span class="keyword">import</span> (</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span>    assert_allclose_dense_sparse,</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span>    assert_almost_equal,</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span>    skip_if_32bit,</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span>)</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span><span class="keyword">from</span> <a class="code hl_namespace" href="../../d1/d3f/namespacesklearn_1_1utils_1_1fixes.html">sklearn.utils.fixes</a> <span class="keyword">import</span> _IS_WASM, CSC_CONTAINERS, CSR_CONTAINERS</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span> </div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span>JUNK_FOOD_DOCS = (</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span>    <span class="stringliteral">&quot;the pizza pizza beer copyright&quot;</span>,</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>    <span class="stringliteral">&quot;the pizza burger beer copyright&quot;</span>,</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span>    <span class="stringliteral">&quot;the the pizza beer beer copyright&quot;</span>,</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>    <span class="stringliteral">&quot;the burger beer beer copyright&quot;</span>,</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span>    <span class="stringliteral">&quot;the coke burger coke copyright&quot;</span>,</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span>    <span class="stringliteral">&quot;the coke burger burger&quot;</span>,</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>)</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span> </div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>NOTJUNK_FOOD_DOCS = (</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span>    <span class="stringliteral">&quot;the salad celeri copyright&quot;</span>,</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>    <span class="stringliteral">&quot;the salad salad sparkling water copyright&quot;</span>,</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>    <span class="stringliteral">&quot;the the celeri celeri copyright&quot;</span>,</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>    <span class="stringliteral">&quot;the tomato tomato salad water&quot;</span>,</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>    <span class="stringliteral">&quot;the tomato salad water copyright&quot;</span>,</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>)</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span> </div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>ALL_FOOD_DOCS = JUNK_FOOD_DOCS + NOTJUNK_FOOD_DOCS</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span> </div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span> </div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span><span class="keyword">def </span>uppercase(s):</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>    <span class="keywordflow">return</span> strip_accents_unicode(s).upper()</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span> </div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span> </div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span><span class="keyword">def </span>strip_eacute(s):</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>    <span class="keywordflow">return</span> s.replace(<span class="stringliteral">&quot;é&quot;</span>, <span class="stringliteral">&quot;e&quot;</span>)</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span> </div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span> </div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span><span class="keyword">def </span>split_tokenize(s):</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>    <span class="keywordflow">return</span> s.split()</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span> </div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span> </div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span><span class="keyword">def </span>lazy_analyze(s):</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>    <span class="keywordflow">return</span> [<span class="stringliteral">&quot;the_ultimate_feature&quot;</span>]</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span> </div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span> </div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span><span class="keyword">def </span>test_strip_accents():</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>    <span class="comment"># check some classical latin accentuated symbols</span></div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>    a = <span class="stringliteral">&quot;àáâãäåçèéêë&quot;</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>    expected = <span class="stringliteral">&quot;aaaaaaceeee&quot;</span></div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span> </div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>    a = <span class="stringliteral">&quot;ìíîïñòóôõöùúûüý&quot;</span></div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>    expected = <span class="stringliteral">&quot;iiiinooooouuuuy&quot;</span></div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span> </div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>    <span class="comment"># check some arabic</span></div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>    a = <span class="stringliteral">&quot;\u0625&quot;</span>  <span class="comment"># alef with a hamza below: إ</span></div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>    expected = <span class="stringliteral">&quot;\u0627&quot;</span>  <span class="comment"># simple alef: ا</span></div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span> </div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>    <span class="comment"># mix letters accentuated and not</span></div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>    a = <span class="stringliteral">&quot;this is à test&quot;</span></div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>    expected = <span class="stringliteral">&quot;this is a test&quot;</span></div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span> </div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>    <span class="comment"># strings that are already decomposed</span></div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>    a = <span class="stringliteral">&quot;o\u0308&quot;</span>  <span class="comment"># o with diaeresis</span></div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>    expected = <span class="stringliteral">&quot;o&quot;</span></div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span> </div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>    <span class="comment"># combining marks by themselves</span></div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>    a = <span class="stringliteral">&quot;\u0300\u0301\u0302\u0303&quot;</span></div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>    expected = <span class="stringliteral">&quot;&quot;</span></div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span> </div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>    <span class="comment"># Multiple combining marks on one character</span></div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>    a = <span class="stringliteral">&quot;o\u0308\u0304&quot;</span></div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>    expected = <span class="stringliteral">&quot;o&quot;</span></div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>    <span class="keyword">assert</span> strip_accents_unicode(a) == expected</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span> </div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span> </div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span><span class="keyword">def </span>test_to_ascii():</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>    <span class="comment"># check some classical latin accentuated symbols</span></div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>    a = <span class="stringliteral">&quot;àáâãäåçèéêë&quot;</span></div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>    expected = <span class="stringliteral">&quot;aaaaaaceeee&quot;</span></div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>    <span class="keyword">assert</span> strip_accents_ascii(a) == expected</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span> </div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>    a = <span class="stringliteral">&quot;ìíîïñòóôõöùúûüý&quot;</span></div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>    expected = <span class="stringliteral">&quot;iiiinooooouuuuy&quot;</span></div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>    <span class="keyword">assert</span> strip_accents_ascii(a) == expected</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span> </div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>    <span class="comment"># check some arabic</span></div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>    a = <span class="stringliteral">&quot;\u0625&quot;</span>  <span class="comment"># halef with a hamza below</span></div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>    expected = <span class="stringliteral">&quot;&quot;</span>  <span class="comment"># halef has no direct ascii match</span></div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>    <span class="keyword">assert</span> strip_accents_ascii(a) == expected</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span> </div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>    <span class="comment"># mix letters accentuated and not</span></div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>    a = <span class="stringliteral">&quot;this is à test&quot;</span></div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>    expected = <span class="stringliteral">&quot;this is a test&quot;</span></div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>    <span class="keyword">assert</span> strip_accents_ascii(a) == expected</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span> </div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span> </div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span><span class="preprocessor">@pytest.mark.parametrize(&quot;Vectorizer&quot;, (CountVectorizer, HashingVectorizer)</span>)</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span><span class="keyword">def </span>test_word_analyzer_unigrams(Vectorizer):</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>    wa = Vectorizer(strip_accents=<span class="stringliteral">&quot;ascii&quot;</span>).build_analyzer()</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>    text = <span class="stringliteral">&quot;J&#39;ai mangé du kangourou  ce midi, c&#39;était pas très bon.&quot;</span></div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>    expected = [</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>        <span class="stringliteral">&quot;ai&quot;</span>,</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>        <span class="stringliteral">&quot;mange&quot;</span>,</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>        <span class="stringliteral">&quot;du&quot;</span>,</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>        <span class="stringliteral">&quot;kangourou&quot;</span>,</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>        <span class="stringliteral">&quot;ce&quot;</span>,</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>        <span class="stringliteral">&quot;midi&quot;</span>,</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>        <span class="stringliteral">&quot;etait&quot;</span>,</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>        <span class="stringliteral">&quot;pas&quot;</span>,</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>        <span class="stringliteral">&quot;tres&quot;</span>,</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>        <span class="stringliteral">&quot;bon&quot;</span>,</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>    ]</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span> </div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>    text = <span class="stringliteral">&quot;This is a test, really.\n\n I met Harry yesterday.&quot;</span></div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>    expected = [<span class="stringliteral">&quot;this&quot;</span>, <span class="stringliteral">&quot;is&quot;</span>, <span class="stringliteral">&quot;test&quot;</span>, <span class="stringliteral">&quot;really&quot;</span>, <span class="stringliteral">&quot;met&quot;</span>, <span class="stringliteral">&quot;harry&quot;</span>, <span class="stringliteral">&quot;yesterday&quot;</span>]</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span> </div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>    wa = Vectorizer(input=<span class="stringliteral">&quot;file&quot;</span>).build_analyzer()</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>    text = <a class="code hl_class" href="../../d1/d8d/classStringIO.html">StringIO</a>(<span class="stringliteral">&quot;This is a test with a file-like object!&quot;</span>)</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>    expected = [<span class="stringliteral">&quot;this&quot;</span>, <span class="stringliteral">&quot;is&quot;</span>, <span class="stringliteral">&quot;test&quot;</span>, <span class="stringliteral">&quot;with&quot;</span>, <span class="stringliteral">&quot;file&quot;</span>, <span class="stringliteral">&quot;like&quot;</span>, <span class="stringliteral">&quot;object&quot;</span>]</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span> </div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>    <span class="comment"># with custom preprocessor</span></div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>    wa = Vectorizer(preprocessor=uppercase).build_analyzer()</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>    text = <span class="stringliteral">&quot;J&#39;ai mangé du kangourou  ce midi,  c&#39;était pas très bon.&quot;</span></div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>    expected = [</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>        <span class="stringliteral">&quot;AI&quot;</span>,</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>        <span class="stringliteral">&quot;MANGE&quot;</span>,</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>        <span class="stringliteral">&quot;DU&quot;</span>,</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>        <span class="stringliteral">&quot;KANGOUROU&quot;</span>,</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>        <span class="stringliteral">&quot;CE&quot;</span>,</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>        <span class="stringliteral">&quot;MIDI&quot;</span>,</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>        <span class="stringliteral">&quot;ETAIT&quot;</span>,</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>        <span class="stringliteral">&quot;PAS&quot;</span>,</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>        <span class="stringliteral">&quot;TRES&quot;</span>,</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>        <span class="stringliteral">&quot;BON&quot;</span>,</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>    ]</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span> </div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>    <span class="comment"># with custom tokenizer</span></div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>    wa = Vectorizer(tokenizer=split_tokenize, strip_accents=<span class="stringliteral">&quot;ascii&quot;</span>).build_analyzer()</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>    text = <span class="stringliteral">&quot;J&#39;ai mangé du kangourou  ce midi, c&#39;était pas très bon.&quot;</span></div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>    expected = [</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>        <span class="stringliteral">&quot;j&#39;ai&quot;</span>,</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>        <span class="stringliteral">&quot;mange&quot;</span>,</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>        <span class="stringliteral">&quot;du&quot;</span>,</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>        <span class="stringliteral">&quot;kangourou&quot;</span>,</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>        <span class="stringliteral">&quot;ce&quot;</span>,</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>        <span class="stringliteral">&quot;midi,&quot;</span>,</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>        <span class="stringliteral">&quot;c&#39;etait&quot;</span>,</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>        <span class="stringliteral">&quot;pas&quot;</span>,</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>        <span class="stringliteral">&quot;tres&quot;</span>,</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>        <span class="stringliteral">&quot;bon.&quot;</span>,</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>    ]</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span> </div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span> </div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span><span class="keyword">def </span>test_word_analyzer_unigrams_and_bigrams():</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>    wa = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>        analyzer=<span class="stringliteral">&quot;word&quot;</span>, strip_accents=<span class="stringliteral">&quot;unicode&quot;</span>, ngram_range=(1, 2)</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>    ).build_analyzer()</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span> </div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>    text = <span class="stringliteral">&quot;J&#39;ai mangé du kangourou  ce midi, c&#39;était pas très bon.&quot;</span></div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>    expected = [</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>        <span class="stringliteral">&quot;ai&quot;</span>,</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>        <span class="stringliteral">&quot;mange&quot;</span>,</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>        <span class="stringliteral">&quot;du&quot;</span>,</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>        <span class="stringliteral">&quot;kangourou&quot;</span>,</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>        <span class="stringliteral">&quot;ce&quot;</span>,</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>        <span class="stringliteral">&quot;midi&quot;</span>,</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>        <span class="stringliteral">&quot;etait&quot;</span>,</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>        <span class="stringliteral">&quot;pas&quot;</span>,</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>        <span class="stringliteral">&quot;tres&quot;</span>,</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>        <span class="stringliteral">&quot;bon&quot;</span>,</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>        <span class="stringliteral">&quot;ai mange&quot;</span>,</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>        <span class="stringliteral">&quot;mange du&quot;</span>,</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>        <span class="stringliteral">&quot;du kangourou&quot;</span>,</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>        <span class="stringliteral">&quot;kangourou ce&quot;</span>,</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>        <span class="stringliteral">&quot;ce midi&quot;</span>,</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>        <span class="stringliteral">&quot;midi etait&quot;</span>,</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>        <span class="stringliteral">&quot;etait pas&quot;</span>,</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>        <span class="stringliteral">&quot;pas tres&quot;</span>,</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>        <span class="stringliteral">&quot;tres bon&quot;</span>,</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>    ]</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>    <span class="keyword">assert</span> wa(text) == expected</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span> </div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span> </div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span><span class="keyword">def </span>test_unicode_decode_error():</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>    <span class="comment"># decode_error default to strict, so this should fail</span></div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>    <span class="comment"># First, encode (as bytes) a unicode string.</span></div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>    text = <span class="stringliteral">&quot;J&#39;ai mangé du kangourou  ce midi, c&#39;était pas très bon.&quot;</span></div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>    text_bytes = text.encode(<span class="stringliteral">&quot;utf-8&quot;</span>)</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span> </div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>    <span class="comment"># Then let the Analyzer try to decode it as ascii. It should fail,</span></div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>    <span class="comment"># because we have given it an incorrect encoding.</span></div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>    wa = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(ngram_range=(1, 2), encoding=<span class="stringliteral">&quot;ascii&quot;</span>).build_analyzer()</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>    <span class="keyword">with</span> pytest.raises(UnicodeDecodeError):</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>        wa(text_bytes)</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span> </div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>    ca = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>        analyzer=<span class="stringliteral">&quot;char&quot;</span>, ngram_range=(3, 6), encoding=<span class="stringliteral">&quot;ascii&quot;</span></div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>    ).build_analyzer()</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>    <span class="keyword">with</span> pytest.raises(UnicodeDecodeError):</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>        ca(text_bytes)</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span> </div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span> </div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span><span class="keyword">def </span>test_char_ngram_analyzer():</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>    cnga = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>        analyzer=<span class="stringliteral">&quot;char&quot;</span>, strip_accents=<span class="stringliteral">&quot;unicode&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>    ).build_analyzer()</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span> </div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>    text = <span class="stringliteral">&quot;J&#39;ai mangé du kangourou  ce midi, c&#39;était pas très bon&quot;</span></div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>    expected = [<span class="stringliteral">&quot;j&#39;a&quot;</span>, <span class="stringliteral">&quot;&#39;ai&quot;</span>, <span class="stringliteral">&quot;ai &quot;</span>, <span class="stringliteral">&quot;i m&quot;</span>, <span class="stringliteral">&quot; ma&quot;</span>]</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>    <span class="keyword">assert</span> cnga(text)[:5] == expected</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>    expected = [<span class="stringliteral">&quot;s tres&quot;</span>, <span class="stringliteral">&quot; tres &quot;</span>, <span class="stringliteral">&quot;tres b&quot;</span>, <span class="stringliteral">&quot;res bo&quot;</span>, <span class="stringliteral">&quot;es bon&quot;</span>]</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>    <span class="keyword">assert</span> cnga(text)[-5:] == expected</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span> </div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>    text = <span class="stringliteral">&quot;This \n\tis a test, really.\n\n I met Harry yesterday&quot;</span></div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>    expected = [<span class="stringliteral">&quot;thi&quot;</span>, <span class="stringliteral">&quot;his&quot;</span>, <span class="stringliteral">&quot;is &quot;</span>, <span class="stringliteral">&quot;s i&quot;</span>, <span class="stringliteral">&quot; is&quot;</span>]</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>    <span class="keyword">assert</span> cnga(text)[:5] == expected</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span> </div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>    expected = [<span class="stringliteral">&quot; yeste&quot;</span>, <span class="stringliteral">&quot;yester&quot;</span>, <span class="stringliteral">&quot;esterd&quot;</span>, <span class="stringliteral">&quot;sterda&quot;</span>, <span class="stringliteral">&quot;terday&quot;</span>]</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>    <span class="keyword">assert</span> cnga(text)[-5:] == expected</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span> </div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>    cnga = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>        input=<span class="stringliteral">&quot;file&quot;</span>, analyzer=<span class="stringliteral">&quot;char&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>    ).build_analyzer()</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>    text = <a class="code hl_class" href="../../d1/d8d/classStringIO.html">StringIO</a>(<span class="stringliteral">&quot;This is a test with a file-like object!&quot;</span>)</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>    expected = [<span class="stringliteral">&quot;thi&quot;</span>, <span class="stringliteral">&quot;his&quot;</span>, <span class="stringliteral">&quot;is &quot;</span>, <span class="stringliteral">&quot;s i&quot;</span>, <span class="stringliteral">&quot; is&quot;</span>]</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>    <span class="keyword">assert</span> cnga(text)[:5] == expected</div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span> </div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span> </div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span><span class="keyword">def </span>test_char_wb_ngram_analyzer():</div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>    cnga = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>        analyzer=<span class="stringliteral">&quot;char_wb&quot;</span>, strip_accents=<span class="stringliteral">&quot;unicode&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>    ).build_analyzer()</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span> </div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>    text = <span class="stringliteral">&quot;This \n\tis a test, really.\n\n I met Harry yesterday&quot;</span></div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>    expected = [<span class="stringliteral">&quot; th&quot;</span>, <span class="stringliteral">&quot;thi&quot;</span>, <span class="stringliteral">&quot;his&quot;</span>, <span class="stringliteral">&quot;is &quot;</span>, <span class="stringliteral">&quot; thi&quot;</span>]</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>    <span class="keyword">assert</span> cnga(text)[:5] == expected</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span> </div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>    expected = [<span class="stringliteral">&quot;yester&quot;</span>, <span class="stringliteral">&quot;esterd&quot;</span>, <span class="stringliteral">&quot;sterda&quot;</span>, <span class="stringliteral">&quot;terday&quot;</span>, <span class="stringliteral">&quot;erday &quot;</span>]</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>    <span class="keyword">assert</span> cnga(text)[-5:] == expected</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span> </div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>    cnga = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span>        input=<span class="stringliteral">&quot;file&quot;</span>, analyzer=<span class="stringliteral">&quot;char_wb&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>    ).build_analyzer()</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>    text = <a class="code hl_class" href="../../d1/d8d/classStringIO.html">StringIO</a>(<span class="stringliteral">&quot;A test with a file-like object!&quot;</span>)</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>    expected = [<span class="stringliteral">&quot; a &quot;</span>, <span class="stringliteral">&quot; te&quot;</span>, <span class="stringliteral">&quot;tes&quot;</span>, <span class="stringliteral">&quot;est&quot;</span>, <span class="stringliteral">&quot;st &quot;</span>, <span class="stringliteral">&quot; tes&quot;</span>]</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>    <span class="keyword">assert</span> cnga(text)[:6] == expected</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span> </div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span> </div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span><span class="keyword">def </span>test_word_ngram_analyzer():</div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>    cnga = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>        analyzer=<span class="stringliteral">&quot;word&quot;</span>, strip_accents=<span class="stringliteral">&quot;unicode&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>    ).build_analyzer()</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span> </div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>    text = <span class="stringliteral">&quot;This \n\tis a test, really.\n\n I met Harry yesterday&quot;</span></div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>    expected = [<span class="stringliteral">&quot;this is test&quot;</span>, <span class="stringliteral">&quot;is test really&quot;</span>, <span class="stringliteral">&quot;test really met&quot;</span>]</div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>    <span class="keyword">assert</span> cnga(text)[:3] == expected</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span> </div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>    expected = [</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>        <span class="stringliteral">&quot;test really met harry yesterday&quot;</span>,</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>        <span class="stringliteral">&quot;this is test really met harry&quot;</span>,</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>        <span class="stringliteral">&quot;is test really met harry yesterday&quot;</span>,</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>    ]</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>    <span class="keyword">assert</span> cnga(text)[-3:] == expected</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span> </div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>    cnga_file = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>        input=<span class="stringliteral">&quot;file&quot;</span>, analyzer=<span class="stringliteral">&quot;word&quot;</span>, ngram_range=(3, 6)</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>    ).build_analyzer()</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>    file = <a class="code hl_class" href="../../d1/d8d/classStringIO.html">StringIO</a>(text)</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>    <span class="keyword">assert</span> cnga_file(file) == cnga(text)</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span> </div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span> </div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span><span class="keyword">def </span>test_countvectorizer_custom_vocabulary():</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>    vocab = {<span class="stringliteral">&quot;pizza&quot;</span>: 0, <span class="stringliteral">&quot;beer&quot;</span>: 1}</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>    terms = set(vocab.keys())</div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span> </div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>    <span class="comment"># Try a few of the supported types.</span></div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span>    <span class="keywordflow">for</span> typ <span class="keywordflow">in</span> [dict, list, iter, partial(defaultdict, int)]:</div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span>        v = typ(vocab)</div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>        vect = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(vocabulary=v)</div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>        vect.fit(JUNK_FOOD_DOCS)</div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>        <span class="keywordflow">if</span> isinstance(v, Mapping):</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>            <span class="keyword">assert</span> vect.vocabulary_ == vocab</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>            <span class="keyword">assert</span> set(vect.vocabulary_) == terms</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>        X = vect.transform(JUNK_FOOD_DOCS)</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>        <span class="keyword">assert</span> X.shape[1] == len(terms)</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>        v = typ(vocab)</div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>        vect = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(vocabulary=v)</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span>        inv = vect.inverse_transform(X)</div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>        <span class="keyword">assert</span> len(inv) == X.shape[0]</div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span> </div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span> </div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span><span class="keyword">def </span>test_countvectorizer_custom_vocabulary_pipeline():</div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span>    what_we_like = [<span class="stringliteral">&quot;pizza&quot;</span>, <span class="stringliteral">&quot;beer&quot;</span>]</div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span>    pipe = <a class="code hl_class" href="../../dc/dbb/classsklearn_1_1pipeline_1_1Pipeline.html">Pipeline</a>(</div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span>        [</div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span>            (<span class="stringliteral">&quot;count&quot;</span>, <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(vocabulary=what_we_like)),</div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span>            (<span class="stringliteral">&quot;tfidf&quot;</span>, <a class="code hl_class" href="../../d4/d08/classsklearn_1_1feature__extraction_1_1text_1_1TfidfTransformer.html">TfidfTransformer</a>()),</div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span>        ]</div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>    )</div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span>    X = pipe.fit_transform(ALL_FOOD_DOCS)</div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span>    <span class="keyword">assert</span> set(pipe.named_steps[<span class="stringliteral">&quot;count&quot;</span>].vocabulary_) == set(what_we_like)</div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>    <span class="keyword">assert</span> X.shape[1] == len(what_we_like)</div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span> </div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span> </div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span><span class="keyword">def </span>test_countvectorizer_custom_vocabulary_repeated_indices():</div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span>    vocab = {<span class="stringliteral">&quot;pizza&quot;</span>: 0, <span class="stringliteral">&quot;beer&quot;</span>: 0}</div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>    msg = <span class="stringliteral">&quot;Vocabulary contains repeated indices&quot;</span></div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=msg):</div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>        vect = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(vocabulary=vocab)</div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>        vect.fit([<span class="stringliteral">&quot;pasta_siziliana&quot;</span>])</div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span> </div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span> </div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span><span class="keyword">def </span>test_countvectorizer_custom_vocabulary_gap_index():</div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>    vocab = {<span class="stringliteral">&quot;pizza&quot;</span>: 1, <span class="stringliteral">&quot;beer&quot;</span>: 2}</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;doesn&#39;t contain index&quot;</span>):</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>        vect = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(vocabulary=vocab)</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>        vect.fit([<span class="stringliteral">&quot;pasta_verdura&quot;</span>])</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span> </div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span> </div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span><span class="keyword">def </span>test_countvectorizer_stop_words():</div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>    cv = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>()</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span>    cv.set_params(stop_words=<span class="stringliteral">&quot;english&quot;</span>)</div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>    <span class="keyword">assert</span> cv.get_stop_words() == ENGLISH_STOP_WORDS</div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>    cv.set_params(stop_words=<span class="stringliteral">&quot;_bad_str_stop_&quot;</span>)</div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>        cv.get_stop_words()</div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>    cv.set_params(stop_words=<span class="stringliteral">&quot;_bad_unicode_stop_&quot;</span>)</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>    <span class="keyword">with</span> pytest.raises(ValueError):</div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>        cv.get_stop_words()</div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>    stoplist = [<span class="stringliteral">&quot;some&quot;</span>, <span class="stringliteral">&quot;other&quot;</span>, <span class="stringliteral">&quot;words&quot;</span>]</div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>    cv.set_params(stop_words=stoplist)</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>    <span class="keyword">assert</span> cv.get_stop_words() == set(stoplist)</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span> </div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span> </div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span><span class="keyword">def </span>test_countvectorizer_empty_vocabulary():</div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;empty vocabulary&quot;</span>):</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>        vect = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(vocabulary=[])</div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>        vect.fit([<span class="stringliteral">&quot;foo&quot;</span>])</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span> </div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=<span class="stringliteral">&quot;empty vocabulary&quot;</span>):</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>        v = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(max_df=1.0, stop_words=<span class="stringliteral">&quot;english&quot;</span>)</div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span>        <span class="comment"># fit on stopwords only</span></div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>        v.fit([<span class="stringliteral">&quot;to be or not to be&quot;</span>, <span class="stringliteral">&quot;and me too&quot;</span>, <span class="stringliteral">&quot;and so do you&quot;</span>])</div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span> </div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span> </div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span><span class="keyword">def </span>test_fit_countvectorizer_twice():</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>    cv = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>()</div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span>    X1 = cv.fit_transform(ALL_FOOD_DOCS[:5])</div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>    X2 = cv.fit_transform(ALL_FOOD_DOCS[5:])</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>    <span class="keyword">assert</span> X1.shape[1] != X2.shape[1]</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span> </div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span> </div>
<div class="foldopen" id="foldopen00392" data-start="" data-end="">
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno"><a class="line" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ac54253d945d359f90e71b1e619433cfc">  392</a></span><span class="keyword">def </span><a class="code hl_function" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ac54253d945d359f90e71b1e619433cfc">test_countvectorizer_custom_token_pattern</a>():</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>    <span class="stringliteral">&quot;&quot;&quot;Check `get_feature_names_out()` when a custom token pattern is passed.</span></div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span><span class="stringliteral">    Non-regression test for:</span></div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span><span class="stringliteral">    https://github.com/scikit-learn/scikit-learn/issues/12971</span></div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>    corpus = [</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>        <span class="stringliteral">&quot;This is the 1st document in my corpus.&quot;</span>,</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>        <span class="stringliteral">&quot;This document is the 2nd sample.&quot;</span>,</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>        <span class="stringliteral">&quot;And this is the 3rd one.&quot;</span>,</div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>        <span class="stringliteral">&quot;Is this the 4th document?&quot;</span>,</div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>    ]</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span>    token_pattern = <span class="stringliteral">r&quot;[0-9]{1,3}(?:st|nd|rd|th)\s\b(\w{2,})\b&quot;</span></div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span>    vectorizer = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(token_pattern=token_pattern)</div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span>    vectorizer.fit_transform(corpus)</div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span>    expected = [<span class="stringliteral">&quot;document&quot;</span>, <span class="stringliteral">&quot;one&quot;</span>, <span class="stringliteral">&quot;sample&quot;</span>]</div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span>    feature_names_out = vectorizer.get_feature_names_out()</div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span>    assert_array_equal(feature_names_out, expected)</div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span> </div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span> </div>
</div>
<div class="foldopen" id="foldopen00411" data-start="" data-end="">
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno"><a class="line" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a77e574bb766b18279d1a9a7d62b69825">  411</a></span><span class="keyword">def </span><a class="code hl_function" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a77e574bb766b18279d1a9a7d62b69825">test_countvectorizer_custom_token_pattern_with_several_group</a>():</div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>    <span class="stringliteral">&quot;&quot;&quot;Check that we raise an error if token pattern capture several groups.</span></div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span><span class="stringliteral">    Non-regression test for:</span></div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span><span class="stringliteral">    https://github.com/scikit-learn/scikit-learn/issues/12971</span></div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>    corpus = [</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>        <span class="stringliteral">&quot;This is the 1st document in my corpus.&quot;</span>,</div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span>        <span class="stringliteral">&quot;This document is the 2nd sample.&quot;</span>,</div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>        <span class="stringliteral">&quot;And this is the 3rd one.&quot;</span>,</div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>        <span class="stringliteral">&quot;Is this the 4th document?&quot;</span>,</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>    ]</div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span> </div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>    token_pattern = <span class="stringliteral">r&quot;([0-9]{1,3}(?:st|nd|rd|th))\s\b(\w{2,})\b&quot;</span></div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>    err_msg = <span class="stringliteral">&quot;More than 1 capturing group in token pattern&quot;</span></div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>    vectorizer = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(token_pattern=token_pattern)</div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>    <span class="keyword">with</span> pytest.raises(ValueError, match=err_msg):</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>        vectorizer.fit(corpus)</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span> </div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span> </div>
</div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span><span class="keyword">def </span>test_countvectorizer_uppercase_in_vocab():</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>    <span class="comment"># Check that the check for uppercase in the provided vocabulary is only done at fit</span></div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span>    <span class="comment"># time and not at transform time (#21251)</span></div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>    vocabulary = [<span class="stringliteral">&quot;Sample&quot;</span>, <span class="stringliteral">&quot;Upper&quot;</span>, <span class="stringliteral">&quot;Case&quot;</span>, <span class="stringliteral">&quot;Vocabulary&quot;</span>]</div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>    message = (</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>        <span class="stringliteral">&quot;Upper case characters found in&quot;</span></div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>        <span class="stringliteral">&quot; vocabulary while &#39;lowercase&#39;&quot;</span></div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span>        <span class="stringliteral">&quot; is True. These entries will not&quot;</span></div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>        <span class="stringliteral">&quot; be matched with any documents&quot;</span></div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>    )</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span> </div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span>    vectorizer = <a class="code hl_class" href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">CountVectorizer</a>(lowercase=<span class="keyword">True</span>, vocabulary=vocabulary)</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span> </div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>    <span class="keyword">with</span> pytest.warns(UserWarning, match=message):</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>        vectorizer.fit(vocabulary)</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span> </div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>    <span class="keyword">with</span> warnings.catch_warnings():</div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>        warnings.simplefilter(<span class="stringliteral">&quot;error&quot;</span>, UserWarning)</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span>        vectorizer.transform(vocabulary)</div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span> </div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span> </div>
<div class="foldopen" id="foldopen00451" data-start="" data-end="">
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno"><a class="line" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a557512858124fb8cd8ac2369d112b4c1">  451</a></span><span class="keyword">def </span><a class="code hl_function" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a557512858124fb8cd8ac2369d112b4c1">test_tf_transformer_feature_names_out</a>():</div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>    <span class="stringliteral">&quot;&quot;&quot;Check get_feature_names_out for TfidfTransformer&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span><span class="stringliteral">    X = [[1, 1, 1], [1, 1, 0], [1, 0, 0]]</span></div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span><span class="stringliteral">    tr = TfidfTransformer(smooth_idf=True, norm=&quot;l2&quot;).fit(X)</span></div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span><span class="stringliteral">    feature_names_in = [&quot;a&quot;, &quot;c&quot;, &quot;b&quot;]</span></div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span><span class="stringliteral">    feature_names_out = tr.get_feature_names_out(feature_names_in)</span></div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span><span class="stringliteral">    assert_array_equal(feature_names_in, feature_names_out)</span></div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span><span class="stringliteral"></span> </div>
</div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span><span class="stringliteral">def test_tf_idf_smoothing():</span></div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span><span class="stringliteral">    X = [[1, 1, 1], [1, 1, 0], [1, 0, 0]]</span></div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span><span class="stringliteral">    tr = TfidfTransformer(smooth_idf=True, norm=&quot;l2&quot;)</span></div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span><span class="stringliteral">    tfidf = tr.fit_transform(X).toarray()</span></div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span><span class="stringliteral">    assert (tfidf &gt;= 0).all()</span></div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span><span class="stringliteral">    # check normalization</span></div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span><span class="stringliteral">    assert_array_almost_equal((tfidf**2).sum(axis=1), [1.0, 1.0, 1.0])</span></div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span><span class="stringliteral">    # this is robust to features with only zeros</span></div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span><span class="stringliteral">    X = [[1, 1, 0], [1, 1, 0], [1, 0, 0]]</span></div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span><span class="stringliteral">    tr = TfidfTransformer(smooth_idf=True, norm=&quot;l2&quot;)</span></div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span><span class="stringliteral">    tfidf = tr.fit_transform(X).toarray()</span></div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span><span class="stringliteral">    assert (tfidf &gt;= 0).all()</span></div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span><span class="stringliteral">@pytest.mark.xfail(</span></div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span><span class="stringliteral">    _IS_WASM,</span></div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span><span class="stringliteral">    reason=(</span></div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span><span class="stringliteral">        &quot;no floating point exceptions, see&quot;</span></div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span><span class="stringliteral">        &quot; https://github.com/numpy/numpy/pull/21895#issuecomment-1311525881&quot;</span></div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span><span class="stringliteral">    ),</span></div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span><span class="stringliteral">)</span></div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span><span class="stringliteral">def test_tfidf_no_smoothing():</span></div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span><span class="stringliteral">    X = [[1, 1, 1], [1, 1, 0], [1, 0, 0]]</span></div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span><span class="stringliteral">    tr = TfidfTransformer(smooth_idf=False, norm=&quot;l2&quot;)</span></div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span><span class="stringliteral">    tfidf = tr.fit_transform(X).toarray()</span></div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span><span class="stringliteral">    assert (tfidf &gt;= 0).all()</span></div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span><span class="stringliteral">    # check normalization</span></div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span><span class="stringliteral">    assert_array_almost_equal((tfidf**2).sum(axis=1), [1.0, 1.0, 1.0])</span></div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span><span class="stringliteral">    # the lack of smoothing make IDF fragile in the presence of feature with</span></div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span><span class="stringliteral">    # only zeros</span></div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span><span class="stringliteral">    X = [[1, 1, 0], [1, 1, 0], [1, 0, 0]]</span></div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span><span class="stringliteral">    tr = TfidfTransformer(smooth_idf=False, norm=&quot;l2&quot;)</span></div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span><span class="stringliteral">    in_warning_message = &quot;divide by zero&quot;</span></div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span><span class="stringliteral">    with pytest.warns(RuntimeWarning, match=in_warning_message):</span></div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span><span class="stringliteral">        tr.fit_transform(X).toarray()</span></div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span><span class="stringliteral">def test_sublinear_tf():</span></div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span><span class="stringliteral">    X = [[1], [2], [3]]</span></div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span><span class="stringliteral">    tr = TfidfTransformer(sublinear_tf=True, use_idf=False, norm=None)</span></div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span><span class="stringliteral">    tfidf = tr.fit_transform(X).toarray()</span></div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span><span class="stringliteral">    assert tfidf[0] == 1</span></div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span><span class="stringliteral">    assert tfidf[1] &gt; tfidf[0]</span></div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span><span class="stringliteral">    assert tfidf[2] &gt; tfidf[1]</span></div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span><span class="stringliteral">    assert tfidf[1] &lt; 2</span></div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span><span class="stringliteral">    assert tfidf[2] &lt; 3</span></div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span><span class="stringliteral">def test_vectorizer():</span></div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span><span class="stringliteral">    # raw documents as an iterator</span></div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span><span class="stringliteral">    train_data = iter(ALL_FOOD_DOCS[:-1])</span></div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span><span class="stringliteral">    test_data = [ALL_FOOD_DOCS[-1]]</span></div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span><span class="stringliteral">    n_train = len(ALL_FOOD_DOCS) - 1</span></div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span><span class="stringliteral">    # test without vocabulary</span></div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span><span class="stringliteral">    v1 = CountVectorizer(max_df=0.5)</span></div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span><span class="stringliteral">    counts_train = v1.fit_transform(train_data)</span></div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span><span class="stringliteral">    if hasattr(counts_train, &quot;tocsr&quot;):</span></div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span><span class="stringliteral">        counts_train = counts_train.tocsr()</span></div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span><span class="stringliteral">    assert counts_train[0, v1.vocabulary_[&quot;pizza&quot;]] == 2</span></div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span><span class="stringliteral">    # build a vectorizer v1 with the same vocabulary as the one fitted by v1</span></div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span><span class="stringliteral">    v2 = CountVectorizer(vocabulary=v1.vocabulary_)</span></div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span><span class="stringliteral">    # compare that the two vectorizer give the same output on the test sample</span></div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span><span class="stringliteral">    for v in (v1, v2):</span></div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span><span class="stringliteral">        counts_test = v.transform(test_data)</span></div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span><span class="stringliteral">        if hasattr(counts_test, &quot;tocsr&quot;):</span></div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span><span class="stringliteral">            counts_test = counts_test.tocsr()</span></div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span><span class="stringliteral">        vocabulary = v.vocabulary_</span></div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span><span class="stringliteral">        assert counts_test[0, vocabulary[&quot;salad&quot;]] == 1</span></div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span><span class="stringliteral">        assert counts_test[0, vocabulary[&quot;tomato&quot;]] == 1</span></div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span><span class="stringliteral">        assert counts_test[0, vocabulary[&quot;water&quot;]] == 1</span></div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span><span class="stringliteral">        # stop word from the fixed list</span></div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span><span class="stringliteral">        assert &quot;the&quot; not in vocabulary</span></div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span><span class="stringliteral">        # stop word found automatically by the vectorizer DF thresholding</span></div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span><span class="stringliteral">        # words that are high frequent across the complete corpus are likely</span></div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span><span class="stringliteral">        # to be not informative (either real stop words of extraction</span></div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span><span class="stringliteral">        # artifacts)</span></div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span><span class="stringliteral">        assert &quot;copyright&quot; not in vocabulary</span></div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span><span class="stringliteral">        # not present in the sample</span></div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span><span class="stringliteral">        assert counts_test[0, vocabulary[&quot;coke&quot;]] == 0</span></div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span><span class="stringliteral">        assert counts_test[0, vocabulary[&quot;burger&quot;]] == 0</span></div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span><span class="stringliteral">        assert counts_test[0, vocabulary[&quot;beer&quot;]] == 0</span></div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span><span class="stringliteral">        assert counts_test[0, vocabulary[&quot;pizza&quot;]] == 0</span></div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span><span class="stringliteral">    # test tf-idf</span></div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span><span class="stringliteral">    t1 = TfidfTransformer(norm=&quot;l1&quot;)</span></div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span><span class="stringliteral">    tfidf = t1.fit(counts_train).transform(counts_train).toarray()</span></div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span><span class="stringliteral">    assert len(t1.idf_) == len(v1.vocabulary_)</span></div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span><span class="stringliteral">    assert tfidf.shape == (n_train, len(v1.vocabulary_))</span></div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span><span class="stringliteral">    # test tf-idf with new data</span></div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span><span class="stringliteral">    tfidf_test = t1.transform(counts_test).toarray()</span></div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span><span class="stringliteral">    assert tfidf_test.shape == (len(test_data), len(v1.vocabulary_))</span></div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span><span class="stringliteral">    # test tf alone</span></div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span><span class="stringliteral">    t2 = TfidfTransformer(norm=&quot;l1&quot;, use_idf=False)</span></div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span><span class="stringliteral">    tf = t2.fit(counts_train).transform(counts_train).toarray()</span></div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span><span class="stringliteral">    assert not hasattr(t2, &quot;idf_&quot;)</span></div>
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno">  570</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span><span class="stringliteral">    # test idf transform with unlearned idf vector</span></div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span><span class="stringliteral">    t3 = TfidfTransformer(use_idf=True)</span></div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span><span class="stringliteral">    with pytest.raises(ValueError):</span></div>
<div class="line"><a id="l00574" name="l00574"></a><span class="lineno">  574</span><span class="stringliteral">        t3.transform(counts_train)</span></div>
<div class="line"><a id="l00575" name="l00575"></a><span class="lineno">  575</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span><span class="stringliteral">    # L1-normalized term frequencies sum to one</span></div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span><span class="stringliteral">    assert_array_almost_equal(np.sum(tf, axis=1), [1.0] * n_train)</span></div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno">  579</span><span class="stringliteral">    # test the direct tfidf vectorizer</span></div>
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno">  580</span><span class="stringliteral">    # (equivalent to term count vectorizer + tfidf transformer)</span></div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span><span class="stringliteral">    train_data = iter(ALL_FOOD_DOCS[:-1])</span></div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span><span class="stringliteral">    tv = TfidfVectorizer(norm=&quot;l1&quot;)</span></div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span><span class="stringliteral">    tv.max_df = v1.max_df</span></div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span><span class="stringliteral">    tfidf2 = tv.fit_transform(train_data).toarray()</span></div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span><span class="stringliteral">    assert not tv.fixed_vocabulary_</span></div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span><span class="stringliteral">    assert_array_almost_equal(tfidf, tfidf2)</span></div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span><span class="stringliteral">    # test the direct tfidf vectorizer with new data</span></div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span><span class="stringliteral">    tfidf_test2 = tv.transform(test_data).toarray()</span></div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span><span class="stringliteral">    assert_array_almost_equal(tfidf_test, tfidf_test2)</span></div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span><span class="stringliteral">    # test transform on unfitted vectorizer with empty vocabulary</span></div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span><span class="stringliteral">    v3 = CountVectorizer(vocabulary=None)</span></div>
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno">  595</span><span class="stringliteral">    with pytest.raises(ValueError):</span></div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno">  596</span><span class="stringliteral">        v3.transform(train_data)</span></div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00598" name="l00598"></a><span class="lineno">  598</span><span class="stringliteral">    # ascii preprocessor?</span></div>
<div class="line"><a id="l00599" name="l00599"></a><span class="lineno">  599</span><span class="stringliteral">    v3.set_params(strip_accents=&quot;ascii&quot;, lowercase=False)</span></div>
<div class="line"><a id="l00600" name="l00600"></a><span class="lineno">  600</span><span class="stringliteral">    processor = v3.build_preprocessor()</span></div>
<div class="line"><a id="l00601" name="l00601"></a><span class="lineno">  601</span><span class="stringliteral">    text = &quot;J&#39;ai mangé du kangourou  ce midi, c&#39;était pas très bon.&quot;</span></div>
<div class="line"><a id="l00602" name="l00602"></a><span class="lineno">  602</span><span class="stringliteral">    expected = strip_accents_ascii(text)</span></div>
<div class="line"><a id="l00603" name="l00603"></a><span class="lineno">  603</span><span class="stringliteral">    result = processor(text)</span></div>
<div class="line"><a id="l00604" name="l00604"></a><span class="lineno">  604</span><span class="stringliteral">    assert expected == result</span></div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno">  606</span><span class="stringliteral">    # error on bad strip_accents param</span></div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno">  607</span><span class="stringliteral">    v3.set_params(strip_accents=&quot;_gabbledegook_&quot;, preprocessor=None)</span></div>
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno">  608</span><span class="stringliteral">    with pytest.raises(ValueError):</span></div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno">  609</span><span class="stringliteral">        v3.build_preprocessor()</span></div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span><span class="stringliteral">    # error with bad analyzer type</span></div>
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno">  612</span><span class="stringliteral">    v3.set_params = &quot;_invalid_analyzer_type_&quot;</span></div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span><span class="stringliteral">    with pytest.raises(ValueError):</span></div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span><span class="stringliteral">        v3.build_analyzer()</span></div>
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno">  615</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno">  617</span><span class="stringliteral">def test_tfidf_vectorizer_setters():</span></div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span><span class="stringliteral">    norm, use_idf, smooth_idf, sublinear_tf = &quot;l2&quot;, False, False, False</span></div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno">  619</span><span class="stringliteral">    tv = TfidfVectorizer(</span></div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span><span class="stringliteral">        norm=norm, use_idf=use_idf, smooth_idf=smooth_idf, sublinear_tf=sublinear_tf</span></div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span><span class="stringliteral">    )</span></div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno">  622</span><span class="stringliteral">    tv.fit(JUNK_FOOD_DOCS)</span></div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno">  623</span><span class="stringliteral">    assert tv._tfidf.norm == norm</span></div>
<div class="line"><a id="l00624" name="l00624"></a><span class="lineno">  624</span><span class="stringliteral">    assert tv._tfidf.use_idf == use_idf</span></div>
<div class="line"><a id="l00625" name="l00625"></a><span class="lineno">  625</span><span class="stringliteral">    assert tv._tfidf.smooth_idf == smooth_idf</span></div>
<div class="line"><a id="l00626" name="l00626"></a><span class="lineno">  626</span><span class="stringliteral">    assert tv._tfidf.sublinear_tf == sublinear_tf</span></div>
<div class="line"><a id="l00627" name="l00627"></a><span class="lineno">  627</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00628" name="l00628"></a><span class="lineno">  628</span><span class="stringliteral">    # assigning value to `TfidfTransformer` should not have any effect until</span></div>
<div class="line"><a id="l00629" name="l00629"></a><span class="lineno">  629</span><span class="stringliteral">    # fitting</span></div>
<div class="line"><a id="l00630" name="l00630"></a><span class="lineno">  630</span><span class="stringliteral">    tv.norm = &quot;l1&quot;</span></div>
<div class="line"><a id="l00631" name="l00631"></a><span class="lineno">  631</span><span class="stringliteral">    tv.use_idf = True</span></div>
<div class="line"><a id="l00632" name="l00632"></a><span class="lineno">  632</span><span class="stringliteral">    tv.smooth_idf = True</span></div>
<div class="line"><a id="l00633" name="l00633"></a><span class="lineno">  633</span><span class="stringliteral">    tv.sublinear_tf = True</span></div>
<div class="line"><a id="l00634" name="l00634"></a><span class="lineno">  634</span><span class="stringliteral">    assert tv._tfidf.norm == norm</span></div>
<div class="line"><a id="l00635" name="l00635"></a><span class="lineno">  635</span><span class="stringliteral">    assert tv._tfidf.use_idf == use_idf</span></div>
<div class="line"><a id="l00636" name="l00636"></a><span class="lineno">  636</span><span class="stringliteral">    assert tv._tfidf.smooth_idf == smooth_idf</span></div>
<div class="line"><a id="l00637" name="l00637"></a><span class="lineno">  637</span><span class="stringliteral">    assert tv._tfidf.sublinear_tf == sublinear_tf</span></div>
<div class="line"><a id="l00638" name="l00638"></a><span class="lineno">  638</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00639" name="l00639"></a><span class="lineno">  639</span><span class="stringliteral">    tv.fit(JUNK_FOOD_DOCS)</span></div>
<div class="line"><a id="l00640" name="l00640"></a><span class="lineno">  640</span><span class="stringliteral">    assert tv._tfidf.norm == tv.norm</span></div>
<div class="line"><a id="l00641" name="l00641"></a><span class="lineno">  641</span><span class="stringliteral">    assert tv._tfidf.use_idf == tv.use_idf</span></div>
<div class="line"><a id="l00642" name="l00642"></a><span class="lineno">  642</span><span class="stringliteral">    assert tv._tfidf.smooth_idf == tv.smooth_idf</span></div>
<div class="line"><a id="l00643" name="l00643"></a><span class="lineno">  643</span><span class="stringliteral">    assert tv._tfidf.sublinear_tf == tv.sublinear_tf</span></div>
<div class="line"><a id="l00644" name="l00644"></a><span class="lineno">  644</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00645" name="l00645"></a><span class="lineno">  645</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00646" name="l00646"></a><span class="lineno">  646</span><span class="stringliteral">def test_hashing_vectorizer():</span></div>
<div class="line"><a id="l00647" name="l00647"></a><span class="lineno">  647</span><span class="stringliteral">    v = HashingVectorizer()</span></div>
<div class="line"><a id="l00648" name="l00648"></a><span class="lineno">  648</span><span class="stringliteral">    X = v.transform(ALL_FOOD_DOCS)</span></div>
<div class="line"><a id="l00649" name="l00649"></a><span class="lineno">  649</span><span class="stringliteral">    token_nnz = X.nnz</span></div>
<div class="line"><a id="l00650" name="l00650"></a><span class="lineno">  650</span><span class="stringliteral">    assert X.shape == (len(ALL_FOOD_DOCS), v.n_features)</span></div>
<div class="line"><a id="l00651" name="l00651"></a><span class="lineno">  651</span><span class="stringliteral">    assert X.dtype == v.dtype</span></div>
<div class="line"><a id="l00652" name="l00652"></a><span class="lineno">  652</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00653" name="l00653"></a><span class="lineno">  653</span><span class="stringliteral">    # By default the hashed values receive a random sign and l2 normalization</span></div>
<div class="line"><a id="l00654" name="l00654"></a><span class="lineno">  654</span><span class="stringliteral">    # makes the feature values bounded</span></div>
<div class="line"><a id="l00655" name="l00655"></a><span class="lineno">  655</span><span class="stringliteral">    assert np.min(X.data) &gt; -1</span></div>
<div class="line"><a id="l00656" name="l00656"></a><span class="lineno">  656</span><span class="stringliteral">    assert np.min(X.data) &lt; 0</span></div>
<div class="line"><a id="l00657" name="l00657"></a><span class="lineno">  657</span><span class="stringliteral">    assert np.max(X.data) &gt; 0</span></div>
<div class="line"><a id="l00658" name="l00658"></a><span class="lineno">  658</span><span class="stringliteral">    assert np.max(X.data) &lt; 1</span></div>
<div class="line"><a id="l00659" name="l00659"></a><span class="lineno">  659</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00660" name="l00660"></a><span class="lineno">  660</span><span class="stringliteral">    # Check that the rows are normalized</span></div>
<div class="line"><a id="l00661" name="l00661"></a><span class="lineno">  661</span><span class="stringliteral">    for i in range(X.shape[0]):</span></div>
<div class="line"><a id="l00662" name="l00662"></a><span class="lineno">  662</span><span class="stringliteral">        assert_almost_equal(np.linalg.norm(X[0].data, 2), 1.0)</span></div>
<div class="line"><a id="l00663" name="l00663"></a><span class="lineno">  663</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00664" name="l00664"></a><span class="lineno">  664</span><span class="stringliteral">    # Check vectorization with some non-default parameters</span></div>
<div class="line"><a id="l00665" name="l00665"></a><span class="lineno">  665</span><span class="stringliteral">    v = HashingVectorizer(ngram_range=(1, 2), norm=&quot;l1&quot;)</span></div>
<div class="line"><a id="l00666" name="l00666"></a><span class="lineno">  666</span><span class="stringliteral">    X = v.transform(ALL_FOOD_DOCS)</span></div>
<div class="line"><a id="l00667" name="l00667"></a><span class="lineno">  667</span><span class="stringliteral">    assert X.shape == (len(ALL_FOOD_DOCS), v.n_features)</span></div>
<div class="line"><a id="l00668" name="l00668"></a><span class="lineno">  668</span><span class="stringliteral">    assert X.dtype == v.dtype</span></div>
<div class="line"><a id="l00669" name="l00669"></a><span class="lineno">  669</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00670" name="l00670"></a><span class="lineno">  670</span><span class="stringliteral">    # ngrams generate more non zeros</span></div>
<div class="line"><a id="l00671" name="l00671"></a><span class="lineno">  671</span><span class="stringliteral">    ngrams_nnz = X.nnz</span></div>
<div class="line"><a id="l00672" name="l00672"></a><span class="lineno">  672</span><span class="stringliteral">    assert ngrams_nnz &gt; token_nnz</span></div>
<div class="line"><a id="l00673" name="l00673"></a><span class="lineno">  673</span><span class="stringliteral">    assert ngrams_nnz &lt; 2 * token_nnz</span></div>
<div class="line"><a id="l00674" name="l00674"></a><span class="lineno">  674</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00675" name="l00675"></a><span class="lineno">  675</span><span class="stringliteral">    # makes the feature values bounded</span></div>
<div class="line"><a id="l00676" name="l00676"></a><span class="lineno">  676</span><span class="stringliteral">    assert np.min(X.data) &gt; -1</span></div>
<div class="line"><a id="l00677" name="l00677"></a><span class="lineno">  677</span><span class="stringliteral">    assert np.max(X.data) &lt; 1</span></div>
<div class="line"><a id="l00678" name="l00678"></a><span class="lineno">  678</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00679" name="l00679"></a><span class="lineno">  679</span><span class="stringliteral">    # Check that the rows are normalized</span></div>
<div class="line"><a id="l00680" name="l00680"></a><span class="lineno">  680</span><span class="stringliteral">    for i in range(X.shape[0]):</span></div>
<div class="line"><a id="l00681" name="l00681"></a><span class="lineno">  681</span><span class="stringliteral">        assert_almost_equal(np.linalg.norm(X[0].data, 1), 1.0)</span></div>
<div class="line"><a id="l00682" name="l00682"></a><span class="lineno">  682</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00683" name="l00683"></a><span class="lineno">  683</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00684" name="l00684"></a><span class="lineno">  684</span><span class="stringliteral">def test_feature_names():</span></div>
<div class="line"><a id="l00685" name="l00685"></a><span class="lineno">  685</span><span class="stringliteral">    cv = CountVectorizer(max_df=0.5)</span></div>
<div class="line"><a id="l00686" name="l00686"></a><span class="lineno">  686</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00687" name="l00687"></a><span class="lineno">  687</span><span class="stringliteral">    # test for Value error on unfitted/empty vocabulary</span></div>
<div class="line"><a id="l00688" name="l00688"></a><span class="lineno">  688</span><span class="stringliteral">    with pytest.raises(ValueError):</span></div>
<div class="line"><a id="l00689" name="l00689"></a><span class="lineno">  689</span><span class="stringliteral">        cv.get_feature_names_out()</span></div>
<div class="line"><a id="l00690" name="l00690"></a><span class="lineno">  690</span><span class="stringliteral">    assert not cv.fixed_vocabulary_</span></div>
<div class="line"><a id="l00691" name="l00691"></a><span class="lineno">  691</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00692" name="l00692"></a><span class="lineno">  692</span><span class="stringliteral">    # test for vocabulary learned from data</span></div>
<div class="line"><a id="l00693" name="l00693"></a><span class="lineno">  693</span><span class="stringliteral">    X = cv.fit_transform(ALL_FOOD_DOCS)</span></div>
<div class="line"><a id="l00694" name="l00694"></a><span class="lineno">  694</span><span class="stringliteral">    n_samples, n_features = X.shape</span></div>
<div class="line"><a id="l00695" name="l00695"></a><span class="lineno">  695</span><span class="stringliteral">    assert len(cv.vocabulary_) == n_features</span></div>
<div class="line"><a id="l00696" name="l00696"></a><span class="lineno">  696</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00697" name="l00697"></a><span class="lineno">  697</span><span class="stringliteral">    feature_names = cv.get_feature_names_out()</span></div>
<div class="line"><a id="l00698" name="l00698"></a><span class="lineno">  698</span><span class="stringliteral">    assert isinstance(feature_names, np.ndarray)</span></div>
<div class="line"><a id="l00699" name="l00699"></a><span class="lineno">  699</span><span class="stringliteral">    assert feature_names.dtype == object</span></div>
<div class="line"><a id="l00700" name="l00700"></a><span class="lineno">  700</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00701" name="l00701"></a><span class="lineno">  701</span><span class="stringliteral">    assert len(feature_names) == n_features</span></div>
<div class="line"><a id="l00702" name="l00702"></a><span class="lineno">  702</span><span class="stringliteral">    assert_array_equal(</span></div>
<div class="line"><a id="l00703" name="l00703"></a><span class="lineno">  703</span><span class="stringliteral">        [</span></div>
<div class="line"><a id="l00704" name="l00704"></a><span class="lineno">  704</span><span class="stringliteral">            &quot;beer&quot;,</span></div>
<div class="line"><a id="l00705" name="l00705"></a><span class="lineno">  705</span><span class="stringliteral">            &quot;burger&quot;,</span></div>
<div class="line"><a id="l00706" name="l00706"></a><span class="lineno">  706</span><span class="stringliteral">            &quot;celeri&quot;,</span></div>
<div class="line"><a id="l00707" name="l00707"></a><span class="lineno">  707</span><span class="stringliteral">            &quot;coke&quot;,</span></div>
<div class="line"><a id="l00708" name="l00708"></a><span class="lineno">  708</span><span class="stringliteral">            &quot;pizza&quot;,</span></div>
<div class="line"><a id="l00709" name="l00709"></a><span class="lineno">  709</span><span class="stringliteral">            &quot;salad&quot;,</span></div>
<div class="line"><a id="l00710" name="l00710"></a><span class="lineno">  710</span><span class="stringliteral">            &quot;sparkling&quot;,</span></div>
<div class="line"><a id="l00711" name="l00711"></a><span class="lineno">  711</span><span class="stringliteral">            &quot;tomato&quot;,</span></div>
<div class="line"><a id="l00712" name="l00712"></a><span class="lineno">  712</span><span class="stringliteral">            &quot;water&quot;,</span></div>
<div class="line"><a id="l00713" name="l00713"></a><span class="lineno">  713</span><span class="stringliteral">        ],</span></div>
<div class="line"><a id="l00714" name="l00714"></a><span class="lineno">  714</span><span class="stringliteral">        feature_names,</span></div>
<div class="line"><a id="l00715" name="l00715"></a><span class="lineno">  715</span><span class="stringliteral">    )</span></div>
<div class="line"><a id="l00716" name="l00716"></a><span class="lineno">  716</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00717" name="l00717"></a><span class="lineno">  717</span><span class="stringliteral">    for idx, name in enumerate(feature_names):</span></div>
<div class="line"><a id="l00718" name="l00718"></a><span class="lineno">  718</span><span class="stringliteral">        assert idx == cv.vocabulary_.get(name)</span></div>
<div class="line"><a id="l00719" name="l00719"></a><span class="lineno">  719</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00720" name="l00720"></a><span class="lineno">  720</span><span class="stringliteral">    # test for custom vocabulary</span></div>
<div class="line"><a id="l00721" name="l00721"></a><span class="lineno">  721</span><span class="stringliteral">    vocab = [</span></div>
<div class="line"><a id="l00722" name="l00722"></a><span class="lineno">  722</span><span class="stringliteral">        &quot;beer&quot;,</span></div>
<div class="line"><a id="l00723" name="l00723"></a><span class="lineno">  723</span><span class="stringliteral">        &quot;burger&quot;,</span></div>
<div class="line"><a id="l00724" name="l00724"></a><span class="lineno">  724</span><span class="stringliteral">        &quot;celeri&quot;,</span></div>
<div class="line"><a id="l00725" name="l00725"></a><span class="lineno">  725</span><span class="stringliteral">        &quot;coke&quot;,</span></div>
<div class="line"><a id="l00726" name="l00726"></a><span class="lineno">  726</span><span class="stringliteral">        &quot;pizza&quot;,</span></div>
<div class="line"><a id="l00727" name="l00727"></a><span class="lineno">  727</span><span class="stringliteral">        &quot;salad&quot;,</span></div>
<div class="line"><a id="l00728" name="l00728"></a><span class="lineno">  728</span><span class="stringliteral">        &quot;sparkling&quot;,</span></div>
<div class="line"><a id="l00729" name="l00729"></a><span class="lineno">  729</span><span class="stringliteral">        &quot;tomato&quot;,</span></div>
<div class="line"><a id="l00730" name="l00730"></a><span class="lineno">  730</span><span class="stringliteral">        &quot;water&quot;,</span></div>
<div class="line"><a id="l00731" name="l00731"></a><span class="lineno">  731</span><span class="stringliteral">    ]</span></div>
<div class="line"><a id="l00732" name="l00732"></a><span class="lineno">  732</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00733" name="l00733"></a><span class="lineno">  733</span><span class="stringliteral">    cv = CountVectorizer(vocabulary=vocab)</span></div>
<div class="line"><a id="l00734" name="l00734"></a><span class="lineno">  734</span><span class="stringliteral">    feature_names = cv.get_feature_names_out()</span></div>
<div class="line"><a id="l00735" name="l00735"></a><span class="lineno">  735</span><span class="stringliteral">    assert_array_equal(</span></div>
<div class="line"><a id="l00736" name="l00736"></a><span class="lineno">  736</span><span class="stringliteral">        [</span></div>
<div class="line"><a id="l00737" name="l00737"></a><span class="lineno">  737</span><span class="stringliteral">            &quot;beer&quot;,</span></div>
<div class="line"><a id="l00738" name="l00738"></a><span class="lineno">  738</span><span class="stringliteral">            &quot;burger&quot;,</span></div>
<div class="line"><a id="l00739" name="l00739"></a><span class="lineno">  739</span><span class="stringliteral">            &quot;celeri&quot;,</span></div>
<div class="line"><a id="l00740" name="l00740"></a><span class="lineno">  740</span><span class="stringliteral">            &quot;coke&quot;,</span></div>
<div class="line"><a id="l00741" name="l00741"></a><span class="lineno">  741</span><span class="stringliteral">            &quot;pizza&quot;,</span></div>
<div class="line"><a id="l00742" name="l00742"></a><span class="lineno">  742</span><span class="stringliteral">            &quot;salad&quot;,</span></div>
<div class="line"><a id="l00743" name="l00743"></a><span class="lineno">  743</span><span class="stringliteral">            &quot;sparkling&quot;,</span></div>
<div class="line"><a id="l00744" name="l00744"></a><span class="lineno">  744</span><span class="stringliteral">            &quot;tomato&quot;,</span></div>
<div class="line"><a id="l00745" name="l00745"></a><span class="lineno">  745</span><span class="stringliteral">            &quot;water&quot;,</span></div>
<div class="line"><a id="l00746" name="l00746"></a><span class="lineno">  746</span><span class="stringliteral">        ],</span></div>
<div class="line"><a id="l00747" name="l00747"></a><span class="lineno">  747</span><span class="stringliteral">        feature_names,</span></div>
<div class="line"><a id="l00748" name="l00748"></a><span class="lineno">  748</span><span class="stringliteral">    )</span></div>
<div class="line"><a id="l00749" name="l00749"></a><span class="lineno">  749</span><span class="stringliteral">    assert cv.fixed_vocabulary_</span></div>
<div class="line"><a id="l00750" name="l00750"></a><span class="lineno">  750</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00751" name="l00751"></a><span class="lineno">  751</span><span class="stringliteral">    for idx, name in enumerate(feature_names):</span></div>
<div class="line"><a id="l00752" name="l00752"></a><span class="lineno">  752</span><span class="stringliteral">        assert idx == cv.vocabulary_.get(name)</span></div>
<div class="line"><a id="l00753" name="l00753"></a><span class="lineno">  753</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00754" name="l00754"></a><span class="lineno">  754</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00755" name="l00755"></a><span class="lineno">  755</span><span class="stringliteral">@pytest.mark.parametrize(&quot;Vectorizer&quot;, (CountVectorizer, TfidfVectorizer))</span></div>
<div class="line"><a id="l00756" name="l00756"></a><span class="lineno">  756</span><span class="stringliteral">def test_vectorizer_max_features(Vectorizer):</span></div>
<div class="line"><a id="l00757" name="l00757"></a><span class="lineno">  757</span><span class="stringliteral">    expected_vocabulary = {&quot;burger&quot;, &quot;beer&quot;, &quot;salad&quot;, &quot;pizza&quot;}</span></div>
<div class="line"><a id="l00758" name="l00758"></a><span class="lineno">  758</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00759" name="l00759"></a><span class="lineno">  759</span><span class="stringliteral">    # test bounded number of extracted features</span></div>
<div class="line"><a id="l00760" name="l00760"></a><span class="lineno">  760</span><span class="stringliteral">    vectorizer = Vectorizer(max_df=0.6, max_features=4)</span></div>
<div class="line"><a id="l00761" name="l00761"></a><span class="lineno">  761</span><span class="stringliteral">    vectorizer.fit(ALL_FOOD_DOCS)</span></div>
<div class="line"><a id="l00762" name="l00762"></a><span class="lineno">  762</span><span class="stringliteral">    assert set(vectorizer.vocabulary_) == expected_vocabulary</span></div>
<div class="line"><a id="l00763" name="l00763"></a><span class="lineno">  763</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00764" name="l00764"></a><span class="lineno">  764</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00765" name="l00765"></a><span class="lineno">  765</span><span class="stringliteral">def test_count_vectorizer_max_features():</span></div>
<div class="line"><a id="l00766" name="l00766"></a><span class="lineno">  766</span><span class="stringliteral">    # Regression test: max_features didn&#39;t work correctly in 0.14.</span></div>
<div class="line"><a id="l00767" name="l00767"></a><span class="lineno">  767</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00768" name="l00768"></a><span class="lineno">  768</span><span class="stringliteral">    cv_1 = CountVectorizer(max_features=1)</span></div>
<div class="line"><a id="l00769" name="l00769"></a><span class="lineno">  769</span><span class="stringliteral">    cv_3 = CountVectorizer(max_features=3)</span></div>
<div class="line"><a id="l00770" name="l00770"></a><span class="lineno">  770</span><span class="stringliteral">    cv_None = CountVectorizer(max_features=None)</span></div>
<div class="line"><a id="l00771" name="l00771"></a><span class="lineno">  771</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00772" name="l00772"></a><span class="lineno">  772</span><span class="stringliteral">    counts_1 = cv_1.fit_transform(JUNK_FOOD_DOCS).sum(axis=0)</span></div>
<div class="line"><a id="l00773" name="l00773"></a><span class="lineno">  773</span><span class="stringliteral">    counts_3 = cv_3.fit_transform(JUNK_FOOD_DOCS).sum(axis=0)</span></div>
<div class="line"><a id="l00774" name="l00774"></a><span class="lineno">  774</span><span class="stringliteral">    counts_None = cv_None.fit_transform(JUNK_FOOD_DOCS).sum(axis=0)</span></div>
<div class="line"><a id="l00775" name="l00775"></a><span class="lineno">  775</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00776" name="l00776"></a><span class="lineno">  776</span><span class="stringliteral">    features_1 = cv_1.get_feature_names_out()</span></div>
<div class="line"><a id="l00777" name="l00777"></a><span class="lineno">  777</span><span class="stringliteral">    features_3 = cv_3.get_feature_names_out()</span></div>
<div class="line"><a id="l00778" name="l00778"></a><span class="lineno">  778</span><span class="stringliteral">    features_None = cv_None.get_feature_names_out()</span></div>
<div class="line"><a id="l00779" name="l00779"></a><span class="lineno">  779</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00780" name="l00780"></a><span class="lineno">  780</span><span class="stringliteral">    # The most common feature is &quot;the&quot;, with frequency 7.</span></div>
<div class="line"><a id="l00781" name="l00781"></a><span class="lineno">  781</span><span class="stringliteral">    assert 7 == counts_1.max()</span></div>
<div class="line"><a id="l00782" name="l00782"></a><span class="lineno">  782</span><span class="stringliteral">    assert 7 == counts_3.max()</span></div>
<div class="line"><a id="l00783" name="l00783"></a><span class="lineno">  783</span><span class="stringliteral">    assert 7 == counts_None.max()</span></div>
<div class="line"><a id="l00784" name="l00784"></a><span class="lineno">  784</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00785" name="l00785"></a><span class="lineno">  785</span><span class="stringliteral">    # The most common feature should be the same</span></div>
<div class="line"><a id="l00786" name="l00786"></a><span class="lineno">  786</span><span class="stringliteral">    assert &quot;the&quot; == features_1[np.argmax(counts_1)]</span></div>
<div class="line"><a id="l00787" name="l00787"></a><span class="lineno">  787</span><span class="stringliteral">    assert &quot;the&quot; == features_3[np.argmax(counts_3)]</span></div>
<div class="line"><a id="l00788" name="l00788"></a><span class="lineno">  788</span><span class="stringliteral">    assert &quot;the&quot; == features_None[np.argmax(counts_None)]</span></div>
<div class="line"><a id="l00789" name="l00789"></a><span class="lineno">  789</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00790" name="l00790"></a><span class="lineno">  790</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00791" name="l00791"></a><span class="lineno">  791</span><span class="stringliteral">def test_vectorizer_max_df():</span></div>
<div class="line"><a id="l00792" name="l00792"></a><span class="lineno">  792</span><span class="stringliteral">    test_data = [&quot;abc&quot;, &quot;dea&quot;, &quot;eat&quot;]</span></div>
<div class="line"><a id="l00793" name="l00793"></a><span class="lineno">  793</span><span class="stringliteral">    vect = CountVectorizer(analyzer=&quot;char&quot;, max_df=1.0)</span></div>
<div class="line"><a id="l00794" name="l00794"></a><span class="lineno">  794</span><span class="stringliteral">    vect.fit(test_data)</span></div>
<div class="line"><a id="l00795" name="l00795"></a><span class="lineno">  795</span><span class="stringliteral">    assert &quot;a&quot; in vect.vocabulary_.keys()</span></div>
<div class="line"><a id="l00796" name="l00796"></a><span class="lineno">  796</span><span class="stringliteral">    assert len(vect.vocabulary_.keys()) == 6</span></div>
<div class="line"><a id="l00797" name="l00797"></a><span class="lineno">  797</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00798" name="l00798"></a><span class="lineno">  798</span><span class="stringliteral">    vect.max_df = 0.5  # 0.5 * 3 documents -&gt; max_doc_count == 1.5</span></div>
<div class="line"><a id="l00799" name="l00799"></a><span class="lineno">  799</span><span class="stringliteral">    vect.fit(test_data)</span></div>
<div class="line"><a id="l00800" name="l00800"></a><span class="lineno">  800</span><span class="stringliteral">    assert &quot;a&quot; not in vect.vocabulary_.keys()  # {ae} ignored</span></div>
<div class="line"><a id="l00801" name="l00801"></a><span class="lineno">  801</span><span class="stringliteral">    assert len(vect.vocabulary_.keys()) == 4  # {bcdt} remain</span></div>
<div class="line"><a id="l00802" name="l00802"></a><span class="lineno">  802</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00803" name="l00803"></a><span class="lineno">  803</span><span class="stringliteral">    vect.max_df = 1</span></div>
<div class="line"><a id="l00804" name="l00804"></a><span class="lineno">  804</span><span class="stringliteral">    vect.fit(test_data)</span></div>
<div class="line"><a id="l00805" name="l00805"></a><span class="lineno">  805</span><span class="stringliteral">    assert &quot;a&quot; not in vect.vocabulary_.keys()  # {ae} ignored</span></div>
<div class="line"><a id="l00806" name="l00806"></a><span class="lineno">  806</span><span class="stringliteral">    assert len(vect.vocabulary_.keys()) == 4  # {bcdt} remain</span></div>
<div class="line"><a id="l00807" name="l00807"></a><span class="lineno">  807</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00808" name="l00808"></a><span class="lineno">  808</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00809" name="l00809"></a><span class="lineno">  809</span><span class="stringliteral">def test_vectorizer_min_df():</span></div>
<div class="line"><a id="l00810" name="l00810"></a><span class="lineno">  810</span><span class="stringliteral">    test_data = [&quot;abc&quot;, &quot;dea&quot;, &quot;eat&quot;]</span></div>
<div class="line"><a id="l00811" name="l00811"></a><span class="lineno">  811</span><span class="stringliteral">    vect = CountVectorizer(analyzer=&quot;char&quot;, min_df=1)</span></div>
<div class="line"><a id="l00812" name="l00812"></a><span class="lineno">  812</span><span class="stringliteral">    vect.fit(test_data)</span></div>
<div class="line"><a id="l00813" name="l00813"></a><span class="lineno">  813</span><span class="stringliteral">    assert &quot;a&quot; in vect.vocabulary_.keys()</span></div>
<div class="line"><a id="l00814" name="l00814"></a><span class="lineno">  814</span><span class="stringliteral">    assert len(vect.vocabulary_.keys()) == 6</span></div>
<div class="line"><a id="l00815" name="l00815"></a><span class="lineno">  815</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00816" name="l00816"></a><span class="lineno">  816</span><span class="stringliteral">    vect.min_df = 2</span></div>
<div class="line"><a id="l00817" name="l00817"></a><span class="lineno">  817</span><span class="stringliteral">    vect.fit(test_data)</span></div>
<div class="line"><a id="l00818" name="l00818"></a><span class="lineno">  818</span><span class="stringliteral">    assert &quot;c&quot; not in vect.vocabulary_.keys()  # {bcdt} ignored</span></div>
<div class="line"><a id="l00819" name="l00819"></a><span class="lineno">  819</span><span class="stringliteral">    assert len(vect.vocabulary_.keys()) == 2  # {ae} remain</span></div>
<div class="line"><a id="l00820" name="l00820"></a><span class="lineno">  820</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00821" name="l00821"></a><span class="lineno">  821</span><span class="stringliteral">    vect.min_df = 0.8  # 0.8 * 3 documents -&gt; min_doc_count == 2.4</span></div>
<div class="line"><a id="l00822" name="l00822"></a><span class="lineno">  822</span><span class="stringliteral">    vect.fit(test_data)</span></div>
<div class="line"><a id="l00823" name="l00823"></a><span class="lineno">  823</span><span class="stringliteral">    assert &quot;c&quot; not in vect.vocabulary_.keys()  # {bcdet} ignored</span></div>
<div class="line"><a id="l00824" name="l00824"></a><span class="lineno">  824</span><span class="stringliteral">    assert len(vect.vocabulary_.keys()) == 1  # {a} remains</span></div>
<div class="line"><a id="l00825" name="l00825"></a><span class="lineno">  825</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00826" name="l00826"></a><span class="lineno">  826</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00827" name="l00827"></a><span class="lineno">  827</span><span class="stringliteral">def test_count_binary_occurrences():</span></div>
<div class="line"><a id="l00828" name="l00828"></a><span class="lineno">  828</span><span class="stringliteral">    # by default multiple occurrences are counted as longs</span></div>
<div class="line"><a id="l00829" name="l00829"></a><span class="lineno">  829</span><span class="stringliteral">    test_data = [&quot;aaabc&quot;, &quot;abbde&quot;]</span></div>
<div class="line"><a id="l00830" name="l00830"></a><span class="lineno">  830</span><span class="stringliteral">    vect = CountVectorizer(analyzer=&quot;char&quot;, max_df=1.0)</span></div>
<div class="line"><a id="l00831" name="l00831"></a><span class="lineno">  831</span><span class="stringliteral">    X = vect.fit_transform(test_data).toarray()</span></div>
<div class="line"><a id="l00832" name="l00832"></a><span class="lineno">  832</span><span class="stringliteral">    assert_array_equal([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;], vect.get_feature_names_out())</span></div>
<div class="line"><a id="l00833" name="l00833"></a><span class="lineno">  833</span><span class="stringliteral">    assert_array_equal([[3, 1, 1, 0, 0], [1, 2, 0, 1, 1]], X)</span></div>
<div class="line"><a id="l00834" name="l00834"></a><span class="lineno">  834</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00835" name="l00835"></a><span class="lineno">  835</span><span class="stringliteral">    # using boolean features, we can fetch the binary occurrence info</span></div>
<div class="line"><a id="l00836" name="l00836"></a><span class="lineno">  836</span><span class="stringliteral">    # instead.</span></div>
<div class="line"><a id="l00837" name="l00837"></a><span class="lineno">  837</span><span class="stringliteral">    vect = CountVectorizer(analyzer=&quot;char&quot;, max_df=1.0, binary=True)</span></div>
<div class="line"><a id="l00838" name="l00838"></a><span class="lineno">  838</span><span class="stringliteral">    X = vect.fit_transform(test_data).toarray()</span></div>
<div class="line"><a id="l00839" name="l00839"></a><span class="lineno">  839</span><span class="stringliteral">    assert_array_equal([[1, 1, 1, 0, 0], [1, 1, 0, 1, 1]], X)</span></div>
<div class="line"><a id="l00840" name="l00840"></a><span class="lineno">  840</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00841" name="l00841"></a><span class="lineno">  841</span><span class="stringliteral">    # check the ability to change the dtype</span></div>
<div class="line"><a id="l00842" name="l00842"></a><span class="lineno">  842</span><span class="stringliteral">    vect = CountVectorizer(analyzer=&quot;char&quot;, max_df=1.0, binary=True, dtype=np.float32)</span></div>
<div class="line"><a id="l00843" name="l00843"></a><span class="lineno">  843</span><span class="stringliteral">    X_sparse = vect.fit_transform(test_data)</span></div>
<div class="line"><a id="l00844" name="l00844"></a><span class="lineno">  844</span><span class="stringliteral">    assert X_sparse.dtype == np.float32</span></div>
<div class="line"><a id="l00845" name="l00845"></a><span class="lineno">  845</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00846" name="l00846"></a><span class="lineno">  846</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00847" name="l00847"></a><span class="lineno">  847</span><span class="stringliteral">def test_hashed_binary_occurrences():</span></div>
<div class="line"><a id="l00848" name="l00848"></a><span class="lineno">  848</span><span class="stringliteral">    # by default multiple occurrences are counted as longs</span></div>
<div class="line"><a id="l00849" name="l00849"></a><span class="lineno">  849</span><span class="stringliteral">    test_data = [&quot;aaabc&quot;, &quot;abbde&quot;]</span></div>
<div class="line"><a id="l00850" name="l00850"></a><span class="lineno">  850</span><span class="stringliteral">    vect = HashingVectorizer(alternate_sign=False, analyzer=&quot;char&quot;, norm=None)</span></div>
<div class="line"><a id="l00851" name="l00851"></a><span class="lineno">  851</span><span class="stringliteral">    X = vect.transform(test_data)</span></div>
<div class="line"><a id="l00852" name="l00852"></a><span class="lineno">  852</span><span class="stringliteral">    assert np.max(X[0:1].data) == 3</span></div>
<div class="line"><a id="l00853" name="l00853"></a><span class="lineno">  853</span><span class="stringliteral">    assert np.max(X[1:2].data) == 2</span></div>
<div class="line"><a id="l00854" name="l00854"></a><span class="lineno">  854</span><span class="stringliteral">    assert X.dtype == np.float64</span></div>
<div class="line"><a id="l00855" name="l00855"></a><span class="lineno">  855</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00856" name="l00856"></a><span class="lineno">  856</span><span class="stringliteral">    # using boolean features, we can fetch the binary occurrence info</span></div>
<div class="line"><a id="l00857" name="l00857"></a><span class="lineno">  857</span><span class="stringliteral">    # instead.</span></div>
<div class="line"><a id="l00858" name="l00858"></a><span class="lineno">  858</span><span class="stringliteral">    vect = HashingVectorizer(</span></div>
<div class="line"><a id="l00859" name="l00859"></a><span class="lineno">  859</span><span class="stringliteral">        analyzer=&quot;char&quot;, alternate_sign=False, binary=True, norm=None</span></div>
<div class="line"><a id="l00860" name="l00860"></a><span class="lineno">  860</span><span class="stringliteral">    )</span></div>
<div class="line"><a id="l00861" name="l00861"></a><span class="lineno">  861</span><span class="stringliteral">    X = vect.transform(test_data)</span></div>
<div class="line"><a id="l00862" name="l00862"></a><span class="lineno">  862</span><span class="stringliteral">    assert np.max(X.data) == 1</span></div>
<div class="line"><a id="l00863" name="l00863"></a><span class="lineno">  863</span><span class="stringliteral">    assert X.dtype == np.float64</span></div>
<div class="line"><a id="l00864" name="l00864"></a><span class="lineno">  864</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00865" name="l00865"></a><span class="lineno">  865</span><span class="stringliteral">    # check the ability to change the dtype</span></div>
<div class="line"><a id="l00866" name="l00866"></a><span class="lineno">  866</span><span class="stringliteral">    vect = HashingVectorizer(</span></div>
<div class="line"><a id="l00867" name="l00867"></a><span class="lineno">  867</span><span class="stringliteral">        analyzer=&quot;char&quot;, alternate_sign=False, binary=True, norm=None, dtype=np.float64</span></div>
<div class="line"><a id="l00868" name="l00868"></a><span class="lineno">  868</span><span class="stringliteral">    )</span></div>
<div class="line"><a id="l00869" name="l00869"></a><span class="lineno">  869</span><span class="stringliteral">    X = vect.transform(test_data)</span></div>
<div class="line"><a id="l00870" name="l00870"></a><span class="lineno">  870</span><span class="stringliteral">    assert X.dtype == np.float64</span></div>
<div class="line"><a id="l00871" name="l00871"></a><span class="lineno">  871</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00872" name="l00872"></a><span class="lineno">  872</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00873" name="l00873"></a><span class="lineno">  873</span><span class="stringliteral">@pytest.mark.parametrize(&quot;Vectorizer&quot;, (CountVectorizer, TfidfVectorizer))</span></div>
<div class="line"><a id="l00874" name="l00874"></a><span class="lineno">  874</span><span class="stringliteral">def test_vectorizer_inverse_transform(Vectorizer):</span></div>
<div class="line"><a id="l00875" name="l00875"></a><span class="lineno">  875</span><span class="stringliteral">    # raw documents</span></div>
<div class="line"><a id="l00876" name="l00876"></a><span class="lineno">  876</span><span class="stringliteral">    data = ALL_FOOD_DOCS</span></div>
<div class="line"><a id="l00877" name="l00877"></a><span class="lineno">  877</span><span class="stringliteral">    vectorizer = Vectorizer()</span></div>
<div class="line"><a id="l00878" name="l00878"></a><span class="lineno">  878</span><span class="stringliteral">    transformed_data = vectorizer.fit_transform(data)</span></div>
<div class="line"><a id="l00879" name="l00879"></a><span class="lineno">  879</span><span class="stringliteral">    inversed_data = vectorizer.inverse_transform(transformed_data)</span></div>
<div class="line"><a id="l00880" name="l00880"></a><span class="lineno">  880</span><span class="stringliteral">    assert isinstance(inversed_data, list)</span></div>
<div class="line"><a id="l00881" name="l00881"></a><span class="lineno">  881</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00882" name="l00882"></a><span class="lineno">  882</span><span class="stringliteral">    analyze = vectorizer.build_analyzer()</span></div>
<div class="line"><a id="l00883" name="l00883"></a><span class="lineno">  883</span><span class="stringliteral">    for doc, inversed_terms in zip(data, inversed_data):</span></div>
<div class="line"><a id="l00884" name="l00884"></a><span class="lineno">  884</span><span class="stringliteral">        terms = np.sort(np.unique(analyze(doc)))</span></div>
<div class="line"><a id="l00885" name="l00885"></a><span class="lineno">  885</span><span class="stringliteral">        inversed_terms = np.sort(np.unique(inversed_terms))</span></div>
<div class="line"><a id="l00886" name="l00886"></a><span class="lineno">  886</span><span class="stringliteral">        assert_array_equal(terms, inversed_terms)</span></div>
<div class="line"><a id="l00887" name="l00887"></a><span class="lineno">  887</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00888" name="l00888"></a><span class="lineno">  888</span><span class="stringliteral">    assert sparse.issparse(transformed_data)</span></div>
<div class="line"><a id="l00889" name="l00889"></a><span class="lineno">  889</span><span class="stringliteral">    assert transformed_data.format == &quot;csr&quot;</span></div>
<div class="line"><a id="l00890" name="l00890"></a><span class="lineno">  890</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00891" name="l00891"></a><span class="lineno">  891</span><span class="stringliteral">    # Test that inverse_transform also works with numpy arrays and</span></div>
<div class="line"><a id="l00892" name="l00892"></a><span class="lineno">  892</span><span class="stringliteral">    # scipy</span></div>
<div class="line"><a id="l00893" name="l00893"></a><span class="lineno">  893</span><span class="stringliteral">    transformed_data2 = transformed_data.toarray()</span></div>
<div class="line"><a id="l00894" name="l00894"></a><span class="lineno">  894</span><span class="stringliteral">    inversed_data2 = vectorizer.inverse_transform(transformed_data2)</span></div>
<div class="line"><a id="l00895" name="l00895"></a><span class="lineno">  895</span><span class="stringliteral">    for terms, terms2 in zip(inversed_data, inversed_data2):</span></div>
<div class="line"><a id="l00896" name="l00896"></a><span class="lineno">  896</span><span class="stringliteral">        assert_array_equal(np.sort(terms), np.sort(terms2))</span></div>
<div class="line"><a id="l00897" name="l00897"></a><span class="lineno">  897</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00898" name="l00898"></a><span class="lineno">  898</span><span class="stringliteral">    # Check that inverse_transform also works on non CSR sparse data:</span></div>
<div class="line"><a id="l00899" name="l00899"></a><span class="lineno">  899</span><span class="stringliteral">    transformed_data3 = transformed_data.tocsc()</span></div>
<div class="line"><a id="l00900" name="l00900"></a><span class="lineno">  900</span><span class="stringliteral">    inversed_data3 = vectorizer.inverse_transform(transformed_data3)</span></div>
<div class="line"><a id="l00901" name="l00901"></a><span class="lineno">  901</span><span class="stringliteral">    for terms, terms3 in zip(inversed_data, inversed_data3):</span></div>
<div class="line"><a id="l00902" name="l00902"></a><span class="lineno">  902</span><span class="stringliteral">        assert_array_equal(np.sort(terms), np.sort(terms3))</span></div>
<div class="line"><a id="l00903" name="l00903"></a><span class="lineno">  903</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00904" name="l00904"></a><span class="lineno">  904</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00905" name="l00905"></a><span class="lineno">  905</span><span class="stringliteral">def test_count_vectorizer_pipeline_grid_selection():</span></div>
<div class="line"><a id="l00906" name="l00906"></a><span class="lineno">  906</span><span class="stringliteral">    # raw documents</span></div>
<div class="line"><a id="l00907" name="l00907"></a><span class="lineno">  907</span><span class="stringliteral">    data = JUNK_FOOD_DOCS + NOTJUNK_FOOD_DOCS</span></div>
<div class="line"><a id="l00908" name="l00908"></a><span class="lineno">  908</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00909" name="l00909"></a><span class="lineno">  909</span><span class="stringliteral">    # label junk food as -1, the others as +1</span></div>
<div class="line"><a id="l00910" name="l00910"></a><span class="lineno">  910</span><span class="stringliteral">    target = [-1] * len(JUNK_FOOD_DOCS) + [1] * len(NOTJUNK_FOOD_DOCS)</span></div>
<div class="line"><a id="l00911" name="l00911"></a><span class="lineno">  911</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00912" name="l00912"></a><span class="lineno">  912</span><span class="stringliteral">    # split the dataset for model development and final evaluation</span></div>
<div class="line"><a id="l00913" name="l00913"></a><span class="lineno">  913</span><span class="stringliteral">    train_data, test_data, target_train, target_test = train_test_split(</span></div>
<div class="line"><a id="l00914" name="l00914"></a><span class="lineno">  914</span><span class="stringliteral">        data, target, test_size=0.2, random_state=0</span></div>
<div class="line"><a id="l00915" name="l00915"></a><span class="lineno">  915</span><span class="stringliteral">    )</span></div>
<div class="line"><a id="l00916" name="l00916"></a><span class="lineno">  916</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00917" name="l00917"></a><span class="lineno">  917</span><span class="stringliteral">    pipeline = Pipeline([(&quot;vect&quot;, CountVectorizer()), (&quot;svc&quot;, LinearSVC())])</span></div>
<div class="line"><a id="l00918" name="l00918"></a><span class="lineno">  918</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00919" name="l00919"></a><span class="lineno">  919</span><span class="stringliteral">    parameters = {</span></div>
<div class="line"><a id="l00920" name="l00920"></a><span class="lineno">  920</span><span class="stringliteral">        &quot;vect__ngram_range&quot;: [(1, 1), (1, 2)],</span></div>
<div class="line"><a id="l00921" name="l00921"></a><span class="lineno">  921</span><span class="stringliteral">        &quot;svc__loss&quot;: (&quot;hinge&quot;, &quot;squared_hinge&quot;),</span></div>
<div class="line"><a id="l00922" name="l00922"></a><span class="lineno">  922</span><span class="stringliteral">    }</span></div>
<div class="line"><a id="l00923" name="l00923"></a><span class="lineno">  923</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00924" name="l00924"></a><span class="lineno">  924</span><span class="stringliteral">    # find the best parameters for both the feature extraction and the</span></div>
<div class="line"><a id="l00925" name="l00925"></a><span class="lineno">  925</span><span class="stringliteral">    # classifier</span></div>
<div class="line"><a id="l00926" name="l00926"></a><span class="lineno">  926</span><span class="stringliteral">    grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, cv=3)</span></div>
<div class="line"><a id="l00927" name="l00927"></a><span class="lineno">  927</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00928" name="l00928"></a><span class="lineno">  928</span><span class="stringliteral">    # Check that the best model found by grid search is 100% correct on the</span></div>
<div class="line"><a id="l00929" name="l00929"></a><span class="lineno">  929</span><span class="stringliteral">    # held out evaluation set.</span></div>
<div class="line"><a id="l00930" name="l00930"></a><span class="lineno">  930</span><span class="stringliteral">    pred = grid_search.fit(train_data, target_train).predict(test_data)</span></div>
<div class="line"><a id="l00931" name="l00931"></a><span class="lineno">  931</span><span class="stringliteral">    assert_array_equal(pred, target_test)</span></div>
<div class="line"><a id="l00932" name="l00932"></a><span class="lineno">  932</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00933" name="l00933"></a><span class="lineno">  933</span><span class="stringliteral">    # on this toy dataset bigram representation which is used in the last of</span></div>
<div class="line"><a id="l00934" name="l00934"></a><span class="lineno">  934</span><span class="stringliteral">    # the grid_search is considered the best estimator since they all converge</span></div>
<div class="line"><a id="l00935" name="l00935"></a><span class="lineno">  935</span><span class="stringliteral">    # to 100% accuracy models</span></div>
<div class="line"><a id="l00936" name="l00936"></a><span class="lineno">  936</span><span class="stringliteral">    assert grid_search.best_score_ == 1.0</span></div>
<div class="line"><a id="l00937" name="l00937"></a><span class="lineno">  937</span><span class="stringliteral">    best_vectorizer = grid_search.best_estimator_.named_steps[&quot;vect&quot;]</span></div>
<div class="line"><a id="l00938" name="l00938"></a><span class="lineno">  938</span><span class="stringliteral">    assert best_vectorizer.ngram_range == (1, 1)</span></div>
<div class="line"><a id="l00939" name="l00939"></a><span class="lineno">  939</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00940" name="l00940"></a><span class="lineno">  940</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00941" name="l00941"></a><span class="lineno">  941</span><span class="stringliteral">def test_vectorizer_pipeline_grid_selection():</span></div>
<div class="line"><a id="l00942" name="l00942"></a><span class="lineno">  942</span><span class="stringliteral">    # raw documents</span></div>
<div class="line"><a id="l00943" name="l00943"></a><span class="lineno">  943</span><span class="stringliteral">    data = JUNK_FOOD_DOCS + NOTJUNK_FOOD_DOCS</span></div>
<div class="line"><a id="l00944" name="l00944"></a><span class="lineno">  944</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00945" name="l00945"></a><span class="lineno">  945</span><span class="stringliteral">    # label junk food as -1, the others as +1</span></div>
<div class="line"><a id="l00946" name="l00946"></a><span class="lineno">  946</span><span class="stringliteral">    target = [-1] * len(JUNK_FOOD_DOCS) + [1] * len(NOTJUNK_FOOD_DOCS)</span></div>
<div class="line"><a id="l00947" name="l00947"></a><span class="lineno">  947</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00948" name="l00948"></a><span class="lineno">  948</span><span class="stringliteral">    # split the dataset for model development and final evaluation</span></div>
<div class="line"><a id="l00949" name="l00949"></a><span class="lineno">  949</span><span class="stringliteral">    train_data, test_data, target_train, target_test = train_test_split(</span></div>
<div class="line"><a id="l00950" name="l00950"></a><span class="lineno">  950</span><span class="stringliteral">        data, target, test_size=0.1, random_state=0</span></div>
<div class="line"><a id="l00951" name="l00951"></a><span class="lineno">  951</span><span class="stringliteral">    )</span></div>
<div class="line"><a id="l00952" name="l00952"></a><span class="lineno">  952</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00953" name="l00953"></a><span class="lineno">  953</span><span class="stringliteral">    pipeline = Pipeline([(&quot;vect&quot;, TfidfVectorizer()), (&quot;svc&quot;, LinearSVC())])</span></div>
<div class="line"><a id="l00954" name="l00954"></a><span class="lineno">  954</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00955" name="l00955"></a><span class="lineno">  955</span><span class="stringliteral">    parameters = {</span></div>
<div class="line"><a id="l00956" name="l00956"></a><span class="lineno">  956</span><span class="stringliteral">        &quot;vect__ngram_range&quot;: [(1, 1), (1, 2)],</span></div>
<div class="line"><a id="l00957" name="l00957"></a><span class="lineno">  957</span><span class="stringliteral">        &quot;vect__norm&quot;: (&quot;l1&quot;, &quot;l2&quot;),</span></div>
<div class="line"><a id="l00958" name="l00958"></a><span class="lineno">  958</span><span class="stringliteral">        &quot;svc__loss&quot;: (&quot;hinge&quot;, &quot;squared_hinge&quot;),</span></div>
<div class="line"><a id="l00959" name="l00959"></a><span class="lineno">  959</span><span class="stringliteral">    }</span></div>
<div class="line"><a id="l00960" name="l00960"></a><span class="lineno">  960</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00961" name="l00961"></a><span class="lineno">  961</span><span class="stringliteral">    # find the best parameters for both the feature extraction and the</span></div>
<div class="line"><a id="l00962" name="l00962"></a><span class="lineno">  962</span><span class="stringliteral">    # classifier</span></div>
<div class="line"><a id="l00963" name="l00963"></a><span class="lineno">  963</span><span class="stringliteral">    grid_search = GridSearchCV(pipeline, parameters, n_jobs=1)</span></div>
<div class="line"><a id="l00964" name="l00964"></a><span class="lineno">  964</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00965" name="l00965"></a><span class="lineno">  965</span><span class="stringliteral">    # Check that the best model found by grid search is 100% correct on the</span></div>
<div class="line"><a id="l00966" name="l00966"></a><span class="lineno">  966</span><span class="stringliteral">    # held out evaluation set.</span></div>
<div class="line"><a id="l00967" name="l00967"></a><span class="lineno">  967</span><span class="stringliteral">    pred = grid_search.fit(train_data, target_train).predict(test_data)</span></div>
<div class="line"><a id="l00968" name="l00968"></a><span class="lineno">  968</span><span class="stringliteral">    assert_array_equal(pred, target_test)</span></div>
<div class="line"><a id="l00969" name="l00969"></a><span class="lineno">  969</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00970" name="l00970"></a><span class="lineno">  970</span><span class="stringliteral">    # on this toy dataset bigram representation which is used in the last of</span></div>
<div class="line"><a id="l00971" name="l00971"></a><span class="lineno">  971</span><span class="stringliteral">    # the grid_search is considered the best estimator since they all converge</span></div>
<div class="line"><a id="l00972" name="l00972"></a><span class="lineno">  972</span><span class="stringliteral">    # to 100% accuracy models</span></div>
<div class="line"><a id="l00973" name="l00973"></a><span class="lineno">  973</span><span class="stringliteral">    assert grid_search.best_score_ == 1.0</span></div>
<div class="line"><a id="l00974" name="l00974"></a><span class="lineno">  974</span><span class="stringliteral">    best_vectorizer = grid_search.best_estimator_.named_steps[&quot;vect&quot;]</span></div>
<div class="line"><a id="l00975" name="l00975"></a><span class="lineno">  975</span><span class="stringliteral">    assert best_vectorizer.ngram_range == (1, 1)</span></div>
<div class="line"><a id="l00976" name="l00976"></a><span class="lineno">  976</span><span class="stringliteral">    assert best_vectorizer.norm == &quot;l2&quot;</span></div>
<div class="line"><a id="l00977" name="l00977"></a><span class="lineno">  977</span><span class="stringliteral">    assert not best_vectorizer.fixed_vocabulary_</span></div>
<div class="line"><a id="l00978" name="l00978"></a><span class="lineno">  978</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00979" name="l00979"></a><span class="lineno">  979</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00980" name="l00980"></a><span class="lineno">  980</span><span class="stringliteral">def test_vectorizer_pipeline_cross_validation():</span></div>
<div class="line"><a id="l00981" name="l00981"></a><span class="lineno">  981</span><span class="stringliteral">    # raw documents</span></div>
<div class="line"><a id="l00982" name="l00982"></a><span class="lineno">  982</span><span class="stringliteral">    data = JUNK_FOOD_DOCS + NOTJUNK_FOOD_DOCS</span></div>
<div class="line"><a id="l00983" name="l00983"></a><span class="lineno">  983</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00984" name="l00984"></a><span class="lineno">  984</span><span class="stringliteral">    # label junk food as -1, the others as +1</span></div>
<div class="line"><a id="l00985" name="l00985"></a><span class="lineno">  985</span><span class="stringliteral">    target = [-1] * len(JUNK_FOOD_DOCS) + [1] * len(NOTJUNK_FOOD_DOCS)</span></div>
<div class="line"><a id="l00986" name="l00986"></a><span class="lineno">  986</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00987" name="l00987"></a><span class="lineno">  987</span><span class="stringliteral">    pipeline = Pipeline([(&quot;vect&quot;, TfidfVectorizer()), (&quot;svc&quot;, LinearSVC())])</span></div>
<div class="line"><a id="l00988" name="l00988"></a><span class="lineno">  988</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00989" name="l00989"></a><span class="lineno">  989</span><span class="stringliteral">    cv_scores = cross_val_score(pipeline, data, target, cv=3)</span></div>
<div class="line"><a id="l00990" name="l00990"></a><span class="lineno">  990</span><span class="stringliteral">    assert_array_equal(cv_scores, [1.0, 1.0, 1.0])</span></div>
<div class="line"><a id="l00991" name="l00991"></a><span class="lineno">  991</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00992" name="l00992"></a><span class="lineno">  992</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00993" name="l00993"></a><span class="lineno">  993</span><span class="stringliteral">def test_vectorizer_unicode():</span></div>
<div class="line"><a id="l00994" name="l00994"></a><span class="lineno">  994</span><span class="stringliteral">    # tests that the count vectorizer works with cyrillic.</span></div>
<div class="line"><a id="l00995" name="l00995"></a><span class="lineno">  995</span><span class="stringliteral">    document = (</span></div>
<div class="line"><a id="l00996" name="l00996"></a><span class="lineno">  996</span><span class="stringliteral">        &quot;Машинное обучение — обширный подраздел искусственного &quot;</span></div>
<div class="line"><a id="l00997" name="l00997"></a><span class="lineno">  997</span><span class="stringliteral">        &quot;интеллекта, изучающий методы построения алгоритмов, &quot;</span></div>
<div class="line"><a id="l00998" name="l00998"></a><span class="lineno">  998</span><span class="stringliteral">        &quot;способных обучаться.&quot;</span></div>
<div class="line"><a id="l00999" name="l00999"></a><span class="lineno">  999</span><span class="stringliteral">    )</span></div>
<div class="line"><a id="l01000" name="l01000"></a><span class="lineno"> 1000</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01001" name="l01001"></a><span class="lineno"> 1001</span><span class="stringliteral">    vect = CountVectorizer()</span></div>
<div class="line"><a id="l01002" name="l01002"></a><span class="lineno"> 1002</span><span class="stringliteral">    X_counted = vect.fit_transform([document])</span></div>
<div class="line"><a id="l01003" name="l01003"></a><span class="lineno"> 1003</span><span class="stringliteral">    assert X_counted.shape == (1, 12)</span></div>
<div class="line"><a id="l01004" name="l01004"></a><span class="lineno"> 1004</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01005" name="l01005"></a><span class="lineno"> 1005</span><span class="stringliteral">    vect = HashingVectorizer(norm=None, alternate_sign=False)</span></div>
<div class="line"><a id="l01006" name="l01006"></a><span class="lineno"> 1006</span><span class="stringliteral">    X_hashed = vect.transform([document])</span></div>
<div class="line"><a id="l01007" name="l01007"></a><span class="lineno"> 1007</span><span class="stringliteral">    assert X_hashed.shape == (1, 2**20)</span></div>
<div class="line"><a id="l01008" name="l01008"></a><span class="lineno"> 1008</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01009" name="l01009"></a><span class="lineno"> 1009</span><span class="stringliteral">    # No collisions on such a small dataset</span></div>
<div class="line"><a id="l01010" name="l01010"></a><span class="lineno"> 1010</span><span class="stringliteral">    assert X_counted.nnz == X_hashed.nnz</span></div>
<div class="line"><a id="l01011" name="l01011"></a><span class="lineno"> 1011</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01012" name="l01012"></a><span class="lineno"> 1012</span><span class="stringliteral">    # When norm is None and not alternate_sign, the tokens are counted up to</span></div>
<div class="line"><a id="l01013" name="l01013"></a><span class="lineno"> 1013</span><span class="stringliteral">    # collisions</span></div>
<div class="line"><a id="l01014" name="l01014"></a><span class="lineno"> 1014</span><span class="stringliteral">    assert_array_equal(np.sort(X_counted.data), np.sort(X_hashed.data))</span></div>
<div class="line"><a id="l01015" name="l01015"></a><span class="lineno"> 1015</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01016" name="l01016"></a><span class="lineno"> 1016</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01017" name="l01017"></a><span class="lineno"> 1017</span><span class="stringliteral">def test_tfidf_vectorizer_with_fixed_vocabulary():</span></div>
<div class="line"><a id="l01018" name="l01018"></a><span class="lineno"> 1018</span><span class="stringliteral">    # non regression smoke test for inheritance issues</span></div>
<div class="line"><a id="l01019" name="l01019"></a><span class="lineno"> 1019</span><span class="stringliteral">    vocabulary = [&quot;pizza&quot;, &quot;celeri&quot;]</span></div>
<div class="line"><a id="l01020" name="l01020"></a><span class="lineno"> 1020</span><span class="stringliteral">    vect = TfidfVectorizer(vocabulary=vocabulary)</span></div>
<div class="line"><a id="l01021" name="l01021"></a><span class="lineno"> 1021</span><span class="stringliteral">    X_1 = vect.fit_transform(ALL_FOOD_DOCS)</span></div>
<div class="line"><a id="l01022" name="l01022"></a><span class="lineno"> 1022</span><span class="stringliteral">    X_2 = vect.transform(ALL_FOOD_DOCS)</span></div>
<div class="line"><a id="l01023" name="l01023"></a><span class="lineno"> 1023</span><span class="stringliteral">    assert_array_almost_equal(X_1.toarray(), X_2.toarray())</span></div>
<div class="line"><a id="l01024" name="l01024"></a><span class="lineno"> 1024</span><span class="stringliteral">    assert vect.fixed_vocabulary_</span></div>
<div class="line"><a id="l01025" name="l01025"></a><span class="lineno"> 1025</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01026" name="l01026"></a><span class="lineno"> 1026</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01027" name="l01027"></a><span class="lineno"> 1027</span><span class="stringliteral">def test_pickling_vectorizer():</span></div>
<div class="line"><a id="l01028" name="l01028"></a><span class="lineno"> 1028</span><span class="stringliteral">    instances = [</span></div>
<div class="line"><a id="l01029" name="l01029"></a><span class="lineno"> 1029</span><span class="stringliteral">        HashingVectorizer(),</span></div>
<div class="line"><a id="l01030" name="l01030"></a><span class="lineno"> 1030</span><span class="stringliteral">        HashingVectorizer(norm=&quot;l1&quot;),</span></div>
<div class="line"><a id="l01031" name="l01031"></a><span class="lineno"> 1031</span><span class="stringliteral">        HashingVectorizer(binary=True),</span></div>
<div class="line"><a id="l01032" name="l01032"></a><span class="lineno"> 1032</span><span class="stringliteral">        HashingVectorizer(ngram_range=(1, 2)),</span></div>
<div class="line"><a id="l01033" name="l01033"></a><span class="lineno"> 1033</span><span class="stringliteral">        CountVectorizer(),</span></div>
<div class="line"><a id="l01034" name="l01034"></a><span class="lineno"> 1034</span><span class="stringliteral">        CountVectorizer(preprocessor=strip_tags),</span></div>
<div class="line"><a id="l01035" name="l01035"></a><span class="lineno"> 1035</span><span class="stringliteral">        CountVectorizer(analyzer=lazy_analyze),</span></div>
<div class="line"><a id="l01036" name="l01036"></a><span class="lineno"> 1036</span><span class="stringliteral">        CountVectorizer(preprocessor=strip_tags).fit(JUNK_FOOD_DOCS),</span></div>
<div class="line"><a id="l01037" name="l01037"></a><span class="lineno"> 1037</span><span class="stringliteral">        CountVectorizer(strip_accents=strip_eacute).fit(JUNK_FOOD_DOCS),</span></div>
<div class="line"><a id="l01038" name="l01038"></a><span class="lineno"> 1038</span><span class="stringliteral">        TfidfVectorizer(),</span></div>
<div class="line"><a id="l01039" name="l01039"></a><span class="lineno"> 1039</span><span class="stringliteral">        TfidfVectorizer(analyzer=lazy_analyze),</span></div>
<div class="line"><a id="l01040" name="l01040"></a><span class="lineno"> 1040</span><span class="stringliteral">        TfidfVectorizer().fit(JUNK_FOOD_DOCS),</span></div>
<div class="line"><a id="l01041" name="l01041"></a><span class="lineno"> 1041</span><span class="stringliteral">    ]</span></div>
<div class="line"><a id="l01042" name="l01042"></a><span class="lineno"> 1042</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01043" name="l01043"></a><span class="lineno"> 1043</span><span class="stringliteral">    for orig in instances:</span></div>
<div class="line"><a id="l01044" name="l01044"></a><span class="lineno"> 1044</span><span class="stringliteral">        s = pickle.dumps(orig)</span></div>
<div class="line"><a id="l01045" name="l01045"></a><span class="lineno"> 1045</span><span class="stringliteral">        copy = pickle.loads(s)</span></div>
<div class="line"><a id="l01046" name="l01046"></a><span class="lineno"> 1046</span><span class="stringliteral">        assert type(copy) == orig.__class__</span></div>
<div class="line"><a id="l01047" name="l01047"></a><span class="lineno"> 1047</span><span class="stringliteral">        assert copy.get_params() == orig.get_params()</span></div>
<div class="line"><a id="l01048" name="l01048"></a><span class="lineno"> 1048</span><span class="stringliteral">        assert_allclose_dense_sparse(</span></div>
<div class="line"><a id="l01049" name="l01049"></a><span class="lineno"> 1049</span><span class="stringliteral">            copy.fit_transform(JUNK_FOOD_DOCS),</span></div>
<div class="line"><a id="l01050" name="l01050"></a><span class="lineno"> 1050</span><span class="stringliteral">            orig.fit_transform(JUNK_FOOD_DOCS),</span></div>
<div class="line"><a id="l01051" name="l01051"></a><span class="lineno"> 1051</span><span class="stringliteral">        )</span></div>
<div class="line"><a id="l01052" name="l01052"></a><span class="lineno"> 1052</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01053" name="l01053"></a><span class="lineno"> 1053</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l01054" name="l01054"></a><span class="lineno"> 1054</span><span class="stringliteral">@pytest.mark.parametrize(</span></div>
<div class="line"><a id="l01055" name="l01055"></a><span class="lineno"> 1055</span><span class="stringliteral">    &quot;factory&quot;,</span></div>
<div class="line"><a id="l01056" name="l01056"></a><span class="lineno"> 1056</span><span class="stringliteral">    [</span></div>
<div class="line"><a id="l01057" name="l01057"></a><span class="lineno"> 1057</span><span class="stringliteral">        CountVectorizer.build_analyzer,</span></div>
<div class="line"><a id="l01058" name="l01058"></a><span class="lineno"> 1058</span><span class="stringliteral">        CountVectorizer.build_preprocessor,</span></div>
<div class="line"><a id="l01059" name="l01059"></a><span class="lineno"> 1059</span><span class="stringliteral">        CountVectorizer.build_tokenizer,</span></div>
<div class="line"><a id="l01060" name="l01060"></a><span class="lineno"> 1060</span><span class="stringliteral">    ],</span></div>
<div class="line"><a id="l01061" name="l01061"></a><span class="lineno"> 1061</span><span class="stringliteral">)</span></div>
<div class="foldopen" id="foldopen01062" data-start="" data-end="">
<div class="line"><a id="l01062" name="l01062"></a><span class="lineno"><a class="line" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ae36066f25159e8b99ceb1e4b71911346"> 1062</a></span><span class="stringliteral">def test_pickling_built_processors(factory):</span></div>
<div class="line"><a id="l01063" name="l01063"></a><span class="lineno"> 1063</span><span class="stringliteral">    &quot;&quot;&quot;</span>Tokenizers cannot be pickled</div>
<div class="line"><a id="l01064" name="l01064"></a><span class="lineno"> 1064</span>    https://github.com/scikit-learn/scikit-learn/issues/12833</div>
<div class="line"><a id="l01065" name="l01065"></a><span class="lineno"> 1065</span>    &quot;&quot;&quot;</div>
<div class="line"><a id="l01066" name="l01066"></a><span class="lineno"> 1066</span>    vec = CountVectorizer()</div>
<div class="line"><a id="l01067" name="l01067"></a><span class="lineno"> 1067</span>    function = factory(vec)</div>
<div class="line"><a id="l01068" name="l01068"></a><span class="lineno"> 1068</span>    text = &quot;J&#39;ai mangé du kangourou  ce midi, c&#39;était pas très bon.&quot;</div>
<div class="line"><a id="l01069" name="l01069"></a><span class="lineno"> 1069</span>    roundtripped_function = pickle.loads(pickle.dumps(function))</div>
<div class="line"><a id="l01070" name="l01070"></a><span class="lineno"> 1070</span>    expected = function(text)</div>
<div class="line"><a id="l01071" name="l01071"></a><span class="lineno"> 1071</span>    result = roundtripped_function(text)</div>
<div class="line"><a id="l01072" name="l01072"></a><span class="lineno"> 1072</span>    assert result == expected</div>
<div class="line"><a id="l01073" name="l01073"></a><span class="lineno"> 1073</span> </div>
<div class="line"><a id="l01074" name="l01074"></a><span class="lineno"> 1074</span> </div>
</div>
<div class="line"><a id="l01075" name="l01075"></a><span class="lineno"> 1075</span>def test_countvectorizer_vocab_sets_when_pickling():</div>
<div class="line"><a id="l01076" name="l01076"></a><span class="lineno"> 1076</span>    # ensure that vocabulary of type set is coerced to a list to</div>
<div class="line"><a id="l01077" name="l01077"></a><span class="lineno"> 1077</span>    # preserve iteration ordering after deserialization</div>
<div class="line"><a id="l01078" name="l01078"></a><span class="lineno"> 1078</span>    rng = np.random.RandomState(0)</div>
<div class="line"><a id="l01079" name="l01079"></a><span class="lineno"> 1079</span>    vocab_words = np.array(</div>
<div class="line"><a id="l01080" name="l01080"></a><span class="lineno"> 1080</span>        [</div>
<div class="line"><a id="l01081" name="l01081"></a><span class="lineno"> 1081</span>            &quot;beer&quot;,</div>
<div class="line"><a id="l01082" name="l01082"></a><span class="lineno"> 1082</span>            &quot;burger&quot;,</div>
<div class="line"><a id="l01083" name="l01083"></a><span class="lineno"> 1083</span>            &quot;celeri&quot;,</div>
<div class="line"><a id="l01084" name="l01084"></a><span class="lineno"> 1084</span>            &quot;coke&quot;,</div>
<div class="line"><a id="l01085" name="l01085"></a><span class="lineno"> 1085</span>            &quot;pizza&quot;,</div>
<div class="line"><a id="l01086" name="l01086"></a><span class="lineno"> 1086</span>            &quot;salad&quot;,</div>
<div class="line"><a id="l01087" name="l01087"></a><span class="lineno"> 1087</span>            &quot;sparkling&quot;,</div>
<div class="line"><a id="l01088" name="l01088"></a><span class="lineno"> 1088</span>            &quot;tomato&quot;,</div>
<div class="line"><a id="l01089" name="l01089"></a><span class="lineno"> 1089</span>            &quot;water&quot;,</div>
<div class="line"><a id="l01090" name="l01090"></a><span class="lineno"> 1090</span>        ]</div>
<div class="line"><a id="l01091" name="l01091"></a><span class="lineno"> 1091</span>    )</div>
<div class="line"><a id="l01092" name="l01092"></a><span class="lineno"> 1092</span>    for x in range(0, 100):</div>
<div class="line"><a id="l01093" name="l01093"></a><span class="lineno"> 1093</span>        vocab_set = set(rng.choice(vocab_words, size=5, replace=False))</div>
<div class="line"><a id="l01094" name="l01094"></a><span class="lineno"> 1094</span>        cv = CountVectorizer(vocabulary=vocab_set)</div>
<div class="line"><a id="l01095" name="l01095"></a><span class="lineno"> 1095</span>        unpickled_cv = pickle.loads(pickle.dumps(cv))</div>
<div class="line"><a id="l01096" name="l01096"></a><span class="lineno"> 1096</span>        cv.fit(ALL_FOOD_DOCS)</div>
<div class="line"><a id="l01097" name="l01097"></a><span class="lineno"> 1097</span>        unpickled_cv.fit(ALL_FOOD_DOCS)</div>
<div class="line"><a id="l01098" name="l01098"></a><span class="lineno"> 1098</span>        assert_array_equal(</div>
<div class="line"><a id="l01099" name="l01099"></a><span class="lineno"> 1099</span>            cv.get_feature_names_out(), unpickled_cv.get_feature_names_out()</div>
<div class="line"><a id="l01100" name="l01100"></a><span class="lineno"> 1100</span>        )</div>
<div class="line"><a id="l01101" name="l01101"></a><span class="lineno"> 1101</span> </div>
<div class="line"><a id="l01102" name="l01102"></a><span class="lineno"> 1102</span> </div>
<div class="line"><a id="l01103" name="l01103"></a><span class="lineno"> 1103</span>def test_countvectorizer_vocab_dicts_when_pickling():</div>
<div class="line"><a id="l01104" name="l01104"></a><span class="lineno"> 1104</span>    rng = np.random.RandomState(0)</div>
<div class="line"><a id="l01105" name="l01105"></a><span class="lineno"> 1105</span>    vocab_words = np.array(</div>
<div class="line"><a id="l01106" name="l01106"></a><span class="lineno"> 1106</span>        [</div>
<div class="line"><a id="l01107" name="l01107"></a><span class="lineno"> 1107</span>            &quot;beer&quot;,</div>
<div class="line"><a id="l01108" name="l01108"></a><span class="lineno"> 1108</span>            &quot;burger&quot;,</div>
<div class="line"><a id="l01109" name="l01109"></a><span class="lineno"> 1109</span>            &quot;celeri&quot;,</div>
<div class="line"><a id="l01110" name="l01110"></a><span class="lineno"> 1110</span>            &quot;coke&quot;,</div>
<div class="line"><a id="l01111" name="l01111"></a><span class="lineno"> 1111</span>            &quot;pizza&quot;,</div>
<div class="line"><a id="l01112" name="l01112"></a><span class="lineno"> 1112</span>            &quot;salad&quot;,</div>
<div class="line"><a id="l01113" name="l01113"></a><span class="lineno"> 1113</span>            &quot;sparkling&quot;,</div>
<div class="line"><a id="l01114" name="l01114"></a><span class="lineno"> 1114</span>            &quot;tomato&quot;,</div>
<div class="line"><a id="l01115" name="l01115"></a><span class="lineno"> 1115</span>            &quot;water&quot;,</div>
<div class="line"><a id="l01116" name="l01116"></a><span class="lineno"> 1116</span>        ]</div>
<div class="line"><a id="l01117" name="l01117"></a><span class="lineno"> 1117</span>    )</div>
<div class="line"><a id="l01118" name="l01118"></a><span class="lineno"> 1118</span>    for x in range(0, 100):</div>
<div class="line"><a id="l01119" name="l01119"></a><span class="lineno"> 1119</span>        vocab_dict = dict()</div>
<div class="line"><a id="l01120" name="l01120"></a><span class="lineno"> 1120</span>        words = rng.choice(vocab_words, size=5, replace=False)</div>
<div class="line"><a id="l01121" name="l01121"></a><span class="lineno"> 1121</span>        for y in range(0, 5):</div>
<div class="line"><a id="l01122" name="l01122"></a><span class="lineno"> 1122</span>            vocab_dict[words[y]] = y</div>
<div class="line"><a id="l01123" name="l01123"></a><span class="lineno"> 1123</span>        cv = CountVectorizer(vocabulary=vocab_dict)</div>
<div class="line"><a id="l01124" name="l01124"></a><span class="lineno"> 1124</span>        unpickled_cv = pickle.loads(pickle.dumps(cv))</div>
<div class="line"><a id="l01125" name="l01125"></a><span class="lineno"> 1125</span>        cv.fit(ALL_FOOD_DOCS)</div>
<div class="line"><a id="l01126" name="l01126"></a><span class="lineno"> 1126</span>        unpickled_cv.fit(ALL_FOOD_DOCS)</div>
<div class="line"><a id="l01127" name="l01127"></a><span class="lineno"> 1127</span>        assert_array_equal(</div>
<div class="line"><a id="l01128" name="l01128"></a><span class="lineno"> 1128</span>            cv.get_feature_names_out(), unpickled_cv.get_feature_names_out()</div>
<div class="line"><a id="l01129" name="l01129"></a><span class="lineno"> 1129</span>        )</div>
<div class="line"><a id="l01130" name="l01130"></a><span class="lineno"> 1130</span> </div>
<div class="line"><a id="l01131" name="l01131"></a><span class="lineno"> 1131</span> </div>
<div class="line"><a id="l01132" name="l01132"></a><span class="lineno"> 1132</span>def test_pickling_transformer():</div>
<div class="line"><a id="l01133" name="l01133"></a><span class="lineno"> 1133</span>    X = CountVectorizer().fit_transform(JUNK_FOOD_DOCS)</div>
<div class="line"><a id="l01134" name="l01134"></a><span class="lineno"> 1134</span>    orig = TfidfTransformer().fit(X)</div>
<div class="line"><a id="l01135" name="l01135"></a><span class="lineno"> 1135</span>    s = pickle.dumps(orig)</div>
<div class="line"><a id="l01136" name="l01136"></a><span class="lineno"> 1136</span>    copy = pickle.loads(s)</div>
<div class="line"><a id="l01137" name="l01137"></a><span class="lineno"> 1137</span>    assert type(copy) == orig.__class__</div>
<div class="line"><a id="l01138" name="l01138"></a><span class="lineno"> 1138</span>    assert_array_equal(copy.fit_transform(X).toarray(), orig.fit_transform(X).toarray())</div>
<div class="line"><a id="l01139" name="l01139"></a><span class="lineno"> 1139</span> </div>
<div class="line"><a id="l01140" name="l01140"></a><span class="lineno"> 1140</span> </div>
<div class="line"><a id="l01141" name="l01141"></a><span class="lineno"> 1141</span>def test_transformer_idf_setter():</div>
<div class="line"><a id="l01142" name="l01142"></a><span class="lineno"> 1142</span>    X = CountVectorizer().fit_transform(JUNK_FOOD_DOCS)</div>
<div class="line"><a id="l01143" name="l01143"></a><span class="lineno"> 1143</span>    orig = TfidfTransformer().fit(X)</div>
<div class="line"><a id="l01144" name="l01144"></a><span class="lineno"> 1144</span>    copy = TfidfTransformer()</div>
<div class="line"><a id="l01145" name="l01145"></a><span class="lineno"> 1145</span>    copy.idf_ = orig.idf_</div>
<div class="line"><a id="l01146" name="l01146"></a><span class="lineno"> 1146</span>    assert_array_equal(copy.transform(X).toarray(), orig.transform(X).toarray())</div>
<div class="line"><a id="l01147" name="l01147"></a><span class="lineno"> 1147</span> </div>
<div class="line"><a id="l01148" name="l01148"></a><span class="lineno"> 1148</span> </div>
<div class="line"><a id="l01149" name="l01149"></a><span class="lineno"> 1149</span>def test_tfidf_vectorizer_setter():</div>
<div class="line"><a id="l01150" name="l01150"></a><span class="lineno"> 1150</span>    orig = TfidfVectorizer(use_idf=True)</div>
<div class="line"><a id="l01151" name="l01151"></a><span class="lineno"> 1151</span>    orig.fit(JUNK_FOOD_DOCS)</div>
<div class="line"><a id="l01152" name="l01152"></a><span class="lineno"> 1152</span>    copy = TfidfVectorizer(vocabulary=orig.vocabulary_, use_idf=True)</div>
<div class="line"><a id="l01153" name="l01153"></a><span class="lineno"> 1153</span>    copy.idf_ = orig.idf_</div>
<div class="line"><a id="l01154" name="l01154"></a><span class="lineno"> 1154</span>    assert_array_equal(</div>
<div class="line"><a id="l01155" name="l01155"></a><span class="lineno"> 1155</span>        copy.transform(JUNK_FOOD_DOCS).toarray(),</div>
<div class="line"><a id="l01156" name="l01156"></a><span class="lineno"> 1156</span>        orig.transform(JUNK_FOOD_DOCS).toarray(),</div>
<div class="line"><a id="l01157" name="l01157"></a><span class="lineno"> 1157</span>    )</div>
<div class="line"><a id="l01158" name="l01158"></a><span class="lineno"> 1158</span>    # `idf_` cannot be set with `use_idf=False`</div>
<div class="line"><a id="l01159" name="l01159"></a><span class="lineno"> 1159</span>    copy = TfidfVectorizer(vocabulary=orig.vocabulary_, use_idf=False)</div>
<div class="line"><a id="l01160" name="l01160"></a><span class="lineno"> 1160</span>    err_msg = &quot;`idf_` cannot be set when `user_idf=False`.&quot;</div>
<div class="line"><a id="l01161" name="l01161"></a><span class="lineno"> 1161</span>    with pytest.raises(ValueError, match=err_msg):</div>
<div class="line"><a id="l01162" name="l01162"></a><span class="lineno"> 1162</span>        copy.idf_ = orig.idf_</div>
<div class="line"><a id="l01163" name="l01163"></a><span class="lineno"> 1163</span> </div>
<div class="line"><a id="l01164" name="l01164"></a><span class="lineno"> 1164</span> </div>
<div class="line"><a id="l01165" name="l01165"></a><span class="lineno"> 1165</span>def test_tfidfvectorizer_invalid_idf_attr():</div>
<div class="line"><a id="l01166" name="l01166"></a><span class="lineno"> 1166</span>    vect = TfidfVectorizer(use_idf=True)</div>
<div class="line"><a id="l01167" name="l01167"></a><span class="lineno"> 1167</span>    vect.fit(JUNK_FOOD_DOCS)</div>
<div class="line"><a id="l01168" name="l01168"></a><span class="lineno"> 1168</span>    copy = TfidfVectorizer(vocabulary=vect.vocabulary_, use_idf=True)</div>
<div class="line"><a id="l01169" name="l01169"></a><span class="lineno"> 1169</span>    expected_idf_len = len(vect.idf_)</div>
<div class="line"><a id="l01170" name="l01170"></a><span class="lineno"> 1170</span>    invalid_idf = [1.0] * (expected_idf_len + 1)</div>
<div class="line"><a id="l01171" name="l01171"></a><span class="lineno"> 1171</span>    with pytest.raises(ValueError):</div>
<div class="line"><a id="l01172" name="l01172"></a><span class="lineno"> 1172</span>        setattr(copy, &quot;idf_&quot;, invalid_idf)</div>
<div class="line"><a id="l01173" name="l01173"></a><span class="lineno"> 1173</span> </div>
<div class="line"><a id="l01174" name="l01174"></a><span class="lineno"> 1174</span> </div>
<div class="line"><a id="l01175" name="l01175"></a><span class="lineno"> 1175</span>def test_non_unique_vocab():</div>
<div class="line"><a id="l01176" name="l01176"></a><span class="lineno"> 1176</span>    vocab = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;a&quot;]</div>
<div class="line"><a id="l01177" name="l01177"></a><span class="lineno"> 1177</span>    vect = CountVectorizer(vocabulary=vocab)</div>
<div class="line"><a id="l01178" name="l01178"></a><span class="lineno"> 1178</span>    with pytest.raises(ValueError):</div>
<div class="line"><a id="l01179" name="l01179"></a><span class="lineno"> 1179</span>        vect.fit([])</div>
<div class="line"><a id="l01180" name="l01180"></a><span class="lineno"> 1180</span> </div>
<div class="line"><a id="l01181" name="l01181"></a><span class="lineno"> 1181</span> </div>
<div class="line"><a id="l01182" name="l01182"></a><span class="lineno"> 1182</span>def test_hashingvectorizer_nan_in_docs():</div>
<div class="line"><a id="l01183" name="l01183"></a><span class="lineno"> 1183</span>    # np.nan can appear when using pandas to load text fields from a csv file</div>
<div class="line"><a id="l01184" name="l01184"></a><span class="lineno"> 1184</span>    # with missing values.</div>
<div class="line"><a id="l01185" name="l01185"></a><span class="lineno"> 1185</span>    message = &quot;np.nan is an invalid document, expected byte or unicode string.&quot;</div>
<div class="line"><a id="l01186" name="l01186"></a><span class="lineno"> 1186</span>    exception = ValueError</div>
<div class="line"><a id="l01187" name="l01187"></a><span class="lineno"> 1187</span> </div>
<div class="line"><a id="l01188" name="l01188"></a><span class="lineno"> 1188</span>    def func():</div>
<div class="line"><a id="l01189" name="l01189"></a><span class="lineno"> 1189</span>        hv = HashingVectorizer()</div>
<div class="line"><a id="l01190" name="l01190"></a><span class="lineno"> 1190</span>        hv.fit_transform([&quot;hello world&quot;, np.nan, &quot;hello hello&quot;])</div>
<div class="line"><a id="l01191" name="l01191"></a><span class="lineno"> 1191</span> </div>
<div class="line"><a id="l01192" name="l01192"></a><span class="lineno"> 1192</span>    with pytest.raises(exception, match=message):</div>
<div class="line"><a id="l01193" name="l01193"></a><span class="lineno"> 1193</span>        func()</div>
<div class="line"><a id="l01194" name="l01194"></a><span class="lineno"> 1194</span> </div>
<div class="line"><a id="l01195" name="l01195"></a><span class="lineno"> 1195</span> </div>
<div class="line"><a id="l01196" name="l01196"></a><span class="lineno"> 1196</span>def test_tfidfvectorizer_binary():</div>
<div class="line"><a id="l01197" name="l01197"></a><span class="lineno"> 1197</span>    # Non-regression test: TfidfVectorizer used to ignore its &quot;binary&quot; param.</div>
<div class="line"><a id="l01198" name="l01198"></a><span class="lineno"> 1198</span>    v = TfidfVectorizer(binary=True, use_idf=False, norm=None)</div>
<div class="line"><a id="l01199" name="l01199"></a><span class="lineno"> 1199</span>    assert v.binary</div>
<div class="line"><a id="l01200" name="l01200"></a><span class="lineno"> 1200</span> </div>
<div class="line"><a id="l01201" name="l01201"></a><span class="lineno"> 1201</span>    X = v.fit_transform([&quot;hello world&quot;, &quot;hello hello&quot;]).toarray()</div>
<div class="line"><a id="l01202" name="l01202"></a><span class="lineno"> 1202</span>    assert_array_equal(X.ravel(), [1, 1, 1, 0])</div>
<div class="line"><a id="l01203" name="l01203"></a><span class="lineno"> 1203</span>    X2 = v.transform([&quot;hello world&quot;, &quot;hello hello&quot;]).toarray()</div>
<div class="line"><a id="l01204" name="l01204"></a><span class="lineno"> 1204</span>    assert_array_equal(X2.ravel(), [1, 1, 1, 0])</div>
<div class="line"><a id="l01205" name="l01205"></a><span class="lineno"> 1205</span> </div>
<div class="line"><a id="l01206" name="l01206"></a><span class="lineno"> 1206</span> </div>
<div class="line"><a id="l01207" name="l01207"></a><span class="lineno"> 1207</span>def test_tfidfvectorizer_export_idf():</div>
<div class="line"><a id="l01208" name="l01208"></a><span class="lineno"> 1208</span>    vect = TfidfVectorizer(use_idf=True)</div>
<div class="line"><a id="l01209" name="l01209"></a><span class="lineno"> 1209</span>    vect.fit(JUNK_FOOD_DOCS)</div>
<div class="line"><a id="l01210" name="l01210"></a><span class="lineno"> 1210</span>    assert_array_almost_equal(vect.idf_, vect._tfidf.idf_)</div>
<div class="line"><a id="l01211" name="l01211"></a><span class="lineno"> 1211</span> </div>
<div class="line"><a id="l01212" name="l01212"></a><span class="lineno"> 1212</span> </div>
<div class="line"><a id="l01213" name="l01213"></a><span class="lineno"> 1213</span>def test_vectorizer_vocab_clone():</div>
<div class="line"><a id="l01214" name="l01214"></a><span class="lineno"> 1214</span>    vect_vocab = TfidfVectorizer(vocabulary=[&quot;the&quot;])</div>
<div class="line"><a id="l01215" name="l01215"></a><span class="lineno"> 1215</span>    vect_vocab_clone = clone(vect_vocab)</div>
<div class="line"><a id="l01216" name="l01216"></a><span class="lineno"> 1216</span>    vect_vocab.fit(ALL_FOOD_DOCS)</div>
<div class="line"><a id="l01217" name="l01217"></a><span class="lineno"> 1217</span>    vect_vocab_clone.fit(ALL_FOOD_DOCS)</div>
<div class="line"><a id="l01218" name="l01218"></a><span class="lineno"> 1218</span>    assert vect_vocab_clone.vocabulary_ == vect_vocab.vocabulary_</div>
<div class="line"><a id="l01219" name="l01219"></a><span class="lineno"> 1219</span> </div>
<div class="line"><a id="l01220" name="l01220"></a><span class="lineno"> 1220</span> </div>
<div class="line"><a id="l01221" name="l01221"></a><span class="lineno"> 1221</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01222" name="l01222"></a><span class="lineno"> 1222</span>    &quot;Vectorizer&quot;, (CountVectorizer, TfidfVectorizer, HashingVectorizer)</div>
<div class="line"><a id="l01223" name="l01223"></a><span class="lineno"> 1223</span>)</div>
<div class="line"><a id="l01224" name="l01224"></a><span class="lineno"> 1224</span>def test_vectorizer_string_object_as_input(Vectorizer):</div>
<div class="line"><a id="l01225" name="l01225"></a><span class="lineno"> 1225</span>    message = &quot;Iterable over raw text documents expected, string object received.&quot;</div>
<div class="line"><a id="l01226" name="l01226"></a><span class="lineno"> 1226</span>    vec = Vectorizer()</div>
<div class="line"><a id="l01227" name="l01227"></a><span class="lineno"> 1227</span> </div>
<div class="line"><a id="l01228" name="l01228"></a><span class="lineno"> 1228</span>    with pytest.raises(ValueError, match=message):</div>
<div class="line"><a id="l01229" name="l01229"></a><span class="lineno"> 1229</span>        vec.fit_transform(&quot;hello world!&quot;)</div>
<div class="line"><a id="l01230" name="l01230"></a><span class="lineno"> 1230</span> </div>
<div class="line"><a id="l01231" name="l01231"></a><span class="lineno"> 1231</span>    with pytest.raises(ValueError, match=message):</div>
<div class="line"><a id="l01232" name="l01232"></a><span class="lineno"> 1232</span>        vec.fit(&quot;hello world!&quot;)</div>
<div class="line"><a id="l01233" name="l01233"></a><span class="lineno"> 1233</span>    vec.fit([&quot;some text&quot;, &quot;some other text&quot;])</div>
<div class="line"><a id="l01234" name="l01234"></a><span class="lineno"> 1234</span> </div>
<div class="line"><a id="l01235" name="l01235"></a><span class="lineno"> 1235</span>    with pytest.raises(ValueError, match=message):</div>
<div class="line"><a id="l01236" name="l01236"></a><span class="lineno"> 1236</span>        vec.transform(&quot;hello world!&quot;)</div>
<div class="line"><a id="l01237" name="l01237"></a><span class="lineno"> 1237</span> </div>
<div class="line"><a id="l01238" name="l01238"></a><span class="lineno"> 1238</span> </div>
<div class="line"><a id="l01239" name="l01239"></a><span class="lineno"> 1239</span>@pytest.mark.parametrize(&quot;X_dtype&quot;, [np.float32, np.float64])</div>
<div class="line"><a id="l01240" name="l01240"></a><span class="lineno"> 1240</span>def test_tfidf_transformer_type(X_dtype):</div>
<div class="line"><a id="l01241" name="l01241"></a><span class="lineno"> 1241</span>    X = sparse.rand(10, 20000, dtype=X_dtype, random_state=42)</div>
<div class="line"><a id="l01242" name="l01242"></a><span class="lineno"> 1242</span>    X_trans = TfidfTransformer().fit_transform(X)</div>
<div class="line"><a id="l01243" name="l01243"></a><span class="lineno"> 1243</span>    assert X_trans.dtype == X.dtype</div>
<div class="line"><a id="l01244" name="l01244"></a><span class="lineno"> 1244</span> </div>
<div class="line"><a id="l01245" name="l01245"></a><span class="lineno"> 1245</span> </div>
<div class="line"><a id="l01246" name="l01246"></a><span class="lineno"> 1246</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01247" name="l01247"></a><span class="lineno"> 1247</span>    &quot;csc_container, csr_container&quot;, product(CSC_CONTAINERS, CSR_CONTAINERS)</div>
<div class="line"><a id="l01248" name="l01248"></a><span class="lineno"> 1248</span>)</div>
<div class="line"><a id="l01249" name="l01249"></a><span class="lineno"> 1249</span>def test_tfidf_transformer_sparse(csc_container, csr_container):</div>
<div class="line"><a id="l01250" name="l01250"></a><span class="lineno"> 1250</span>    X = sparse.rand(10, 20000, dtype=np.float64, random_state=42)</div>
<div class="line"><a id="l01251" name="l01251"></a><span class="lineno"> 1251</span>    X_csc = csc_container(X)</div>
<div class="line"><a id="l01252" name="l01252"></a><span class="lineno"> 1252</span>    X_csr = csr_container(X)</div>
<div class="line"><a id="l01253" name="l01253"></a><span class="lineno"> 1253</span> </div>
<div class="line"><a id="l01254" name="l01254"></a><span class="lineno"> 1254</span>    X_trans_csc = TfidfTransformer().fit_transform(X_csc)</div>
<div class="line"><a id="l01255" name="l01255"></a><span class="lineno"> 1255</span>    X_trans_csr = TfidfTransformer().fit_transform(X_csr)</div>
<div class="line"><a id="l01256" name="l01256"></a><span class="lineno"> 1256</span>    assert_allclose_dense_sparse(X_trans_csc, X_trans_csr)</div>
<div class="line"><a id="l01257" name="l01257"></a><span class="lineno"> 1257</span>    assert X_trans_csc.format == X_trans_csr.format</div>
<div class="line"><a id="l01258" name="l01258"></a><span class="lineno"> 1258</span> </div>
<div class="line"><a id="l01259" name="l01259"></a><span class="lineno"> 1259</span> </div>
<div class="line"><a id="l01260" name="l01260"></a><span class="lineno"> 1260</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01261" name="l01261"></a><span class="lineno"> 1261</span>    &quot;vectorizer_dtype, output_dtype, warning_expected&quot;,</div>
<div class="line"><a id="l01262" name="l01262"></a><span class="lineno"> 1262</span>    [</div>
<div class="line"><a id="l01263" name="l01263"></a><span class="lineno"> 1263</span>        (np.int32, np.float64, True),</div>
<div class="line"><a id="l01264" name="l01264"></a><span class="lineno"> 1264</span>        (np.int64, np.float64, True),</div>
<div class="line"><a id="l01265" name="l01265"></a><span class="lineno"> 1265</span>        (np.float32, np.float32, False),</div>
<div class="line"><a id="l01266" name="l01266"></a><span class="lineno"> 1266</span>        (np.float64, np.float64, False),</div>
<div class="line"><a id="l01267" name="l01267"></a><span class="lineno"> 1267</span>    ],</div>
<div class="line"><a id="l01268" name="l01268"></a><span class="lineno"> 1268</span>)</div>
<div class="line"><a id="l01269" name="l01269"></a><span class="lineno"> 1269</span>def test_tfidf_vectorizer_type(vectorizer_dtype, output_dtype, warning_expected):</div>
<div class="line"><a id="l01270" name="l01270"></a><span class="lineno"> 1270</span>    X = np.array([&quot;numpy&quot;, &quot;scipy&quot;, &quot;sklearn&quot;])</div>
<div class="line"><a id="l01271" name="l01271"></a><span class="lineno"> 1271</span>    vectorizer = TfidfVectorizer(dtype=vectorizer_dtype)</div>
<div class="line"><a id="l01272" name="l01272"></a><span class="lineno"> 1272</span> </div>
<div class="line"><a id="l01273" name="l01273"></a><span class="lineno"> 1273</span>    warning_msg_match = &quot;&#39;dtype&#39; should be used.&quot;</div>
<div class="line"><a id="l01274" name="l01274"></a><span class="lineno"> 1274</span>    if warning_expected:</div>
<div class="line"><a id="l01275" name="l01275"></a><span class="lineno"> 1275</span>        with pytest.warns(UserWarning, match=warning_msg_match):</div>
<div class="line"><a id="l01276" name="l01276"></a><span class="lineno"> 1276</span>            X_idf = vectorizer.fit_transform(X)</div>
<div class="line"><a id="l01277" name="l01277"></a><span class="lineno"> 1277</span>    else:</div>
<div class="line"><a id="l01278" name="l01278"></a><span class="lineno"> 1278</span>        with warnings.catch_warnings():</div>
<div class="line"><a id="l01279" name="l01279"></a><span class="lineno"> 1279</span>            warnings.simplefilter(&quot;error&quot;, UserWarning)</div>
<div class="line"><a id="l01280" name="l01280"></a><span class="lineno"> 1280</span>            X_idf = vectorizer.fit_transform(X)</div>
<div class="line"><a id="l01281" name="l01281"></a><span class="lineno"> 1281</span>    assert X_idf.dtype == output_dtype</div>
<div class="line"><a id="l01282" name="l01282"></a><span class="lineno"> 1282</span> </div>
<div class="line"><a id="l01283" name="l01283"></a><span class="lineno"> 1283</span> </div>
<div class="line"><a id="l01284" name="l01284"></a><span class="lineno"> 1284</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01285" name="l01285"></a><span class="lineno"> 1285</span>    &quot;vec&quot;,</div>
<div class="line"><a id="l01286" name="l01286"></a><span class="lineno"> 1286</span>    [</div>
<div class="line"><a id="l01287" name="l01287"></a><span class="lineno"> 1287</span>        HashingVectorizer(ngram_range=(2, 1)),</div>
<div class="line"><a id="l01288" name="l01288"></a><span class="lineno"> 1288</span>        CountVectorizer(ngram_range=(2, 1)),</div>
<div class="line"><a id="l01289" name="l01289"></a><span class="lineno"> 1289</span>        TfidfVectorizer(ngram_range=(2, 1)),</div>
<div class="line"><a id="l01290" name="l01290"></a><span class="lineno"> 1290</span>    ],</div>
<div class="line"><a id="l01291" name="l01291"></a><span class="lineno"> 1291</span>)</div>
<div class="line"><a id="l01292" name="l01292"></a><span class="lineno"> 1292</span>def test_vectorizers_invalid_ngram_range(vec):</div>
<div class="line"><a id="l01293" name="l01293"></a><span class="lineno"> 1293</span>    # vectorizers could be initialized with invalid ngram range</div>
<div class="line"><a id="l01294" name="l01294"></a><span class="lineno"> 1294</span>    # test for raising error message</div>
<div class="line"><a id="l01295" name="l01295"></a><span class="lineno"> 1295</span>    invalid_range = vec.ngram_range</div>
<div class="line"><a id="l01296" name="l01296"></a><span class="lineno"> 1296</span>    message = re.escape(</div>
<div class="line"><a id="l01297" name="l01297"></a><span class="lineno"> 1297</span>        f&quot;Invalid value for ngram_range={invalid_range} &quot;</div>
<div class="line"><a id="l01298" name="l01298"></a><span class="lineno"> 1298</span>        &quot;lower boundary larger than the upper boundary.&quot;</div>
<div class="line"><a id="l01299" name="l01299"></a><span class="lineno"> 1299</span>    )</div>
<div class="line"><a id="l01300" name="l01300"></a><span class="lineno"> 1300</span> </div>
<div class="line"><a id="l01301" name="l01301"></a><span class="lineno"> 1301</span>    with pytest.raises(ValueError, match=message):</div>
<div class="line"><a id="l01302" name="l01302"></a><span class="lineno"> 1302</span>        vec.fit([&quot;good news everyone&quot;])</div>
<div class="line"><a id="l01303" name="l01303"></a><span class="lineno"> 1303</span> </div>
<div class="line"><a id="l01304" name="l01304"></a><span class="lineno"> 1304</span>    with pytest.raises(ValueError, match=message):</div>
<div class="line"><a id="l01305" name="l01305"></a><span class="lineno"> 1305</span>        vec.fit_transform([&quot;good news everyone&quot;])</div>
<div class="line"><a id="l01306" name="l01306"></a><span class="lineno"> 1306</span> </div>
<div class="line"><a id="l01307" name="l01307"></a><span class="lineno"> 1307</span>    if isinstance(vec, HashingVectorizer):</div>
<div class="line"><a id="l01308" name="l01308"></a><span class="lineno"> 1308</span>        with pytest.raises(ValueError, match=message):</div>
<div class="line"><a id="l01309" name="l01309"></a><span class="lineno"> 1309</span>            vec.transform([&quot;good news everyone&quot;])</div>
<div class="line"><a id="l01310" name="l01310"></a><span class="lineno"> 1310</span> </div>
<div class="line"><a id="l01311" name="l01311"></a><span class="lineno"> 1311</span> </div>
<div class="line"><a id="l01312" name="l01312"></a><span class="lineno"> 1312</span>def _check_stop_words_consistency(estimator):</div>
<div class="line"><a id="l01313" name="l01313"></a><span class="lineno"> 1313</span>    stop_words = estimator.get_stop_words()</div>
<div class="line"><a id="l01314" name="l01314"></a><span class="lineno"> 1314</span>    tokenize = estimator.build_tokenizer()</div>
<div class="line"><a id="l01315" name="l01315"></a><span class="lineno"> 1315</span>    preprocess = estimator.build_preprocessor()</div>
<div class="line"><a id="l01316" name="l01316"></a><span class="lineno"> 1316</span>    return estimator._check_stop_words_consistency(stop_words, preprocess, tokenize)</div>
<div class="line"><a id="l01317" name="l01317"></a><span class="lineno"> 1317</span> </div>
<div class="line"><a id="l01318" name="l01318"></a><span class="lineno"> 1318</span> </div>
<div class="line"><a id="l01319" name="l01319"></a><span class="lineno"> 1319</span>def test_vectorizer_stop_words_inconsistent():</div>
<div class="line"><a id="l01320" name="l01320"></a><span class="lineno"> 1320</span>    lstr = r&quot;\[&#39;and&#39;, &#39;ll&#39;, &#39;ve&#39;\]&quot;</div>
<div class="line"><a id="l01321" name="l01321"></a><span class="lineno"> 1321</span>    message = (</div>
<div class="line"><a id="l01322" name="l01322"></a><span class="lineno"> 1322</span>        &quot;Your stop_words may be inconsistent with your &quot;</div>
<div class="line"><a id="l01323" name="l01323"></a><span class="lineno"> 1323</span>        &quot;preprocessing. Tokenizing the stop words generated &quot;</div>
<div class="line"><a id="l01324" name="l01324"></a><span class="lineno"> 1324</span>        &quot;tokens %s not in stop_words.&quot; % lstr</div>
<div class="line"><a id="l01325" name="l01325"></a><span class="lineno"> 1325</span>    )</div>
<div class="line"><a id="l01326" name="l01326"></a><span class="lineno"> 1326</span>    for vec in [CountVectorizer(), TfidfVectorizer(), HashingVectorizer()]:</div>
<div class="line"><a id="l01327" name="l01327"></a><span class="lineno"> 1327</span>        vec.set_params(stop_words=[&quot;you&#39;ve&quot;, &quot;you&quot;, &quot;you&#39;ll&quot;, &quot;AND&quot;])</div>
<div class="line"><a id="l01328" name="l01328"></a><span class="lineno"> 1328</span>        with pytest.warns(UserWarning, match=message):</div>
<div class="line"><a id="l01329" name="l01329"></a><span class="lineno"> 1329</span>            vec.fit_transform([&quot;hello world&quot;])</div>
<div class="line"><a id="l01330" name="l01330"></a><span class="lineno"> 1330</span>        # reset stop word validation</div>
<div class="line"><a id="l01331" name="l01331"></a><span class="lineno"> 1331</span>        del vec._stop_words_id</div>
<div class="line"><a id="l01332" name="l01332"></a><span class="lineno"> 1332</span>        assert _check_stop_words_consistency(vec) is False</div>
<div class="line"><a id="l01333" name="l01333"></a><span class="lineno"> 1333</span> </div>
<div class="line"><a id="l01334" name="l01334"></a><span class="lineno"> 1334</span>    # Only one warning per stop list</div>
<div class="line"><a id="l01335" name="l01335"></a><span class="lineno"> 1335</span>    with warnings.catch_warnings():</div>
<div class="line"><a id="l01336" name="l01336"></a><span class="lineno"> 1336</span>        warnings.simplefilter(&quot;error&quot;, UserWarning)</div>
<div class="line"><a id="l01337" name="l01337"></a><span class="lineno"> 1337</span>        vec.fit_transform([&quot;hello world&quot;])</div>
<div class="line"><a id="l01338" name="l01338"></a><span class="lineno"> 1338</span>    assert _check_stop_words_consistency(vec) is None</div>
<div class="line"><a id="l01339" name="l01339"></a><span class="lineno"> 1339</span> </div>
<div class="line"><a id="l01340" name="l01340"></a><span class="lineno"> 1340</span>    # Test caching of inconsistency assessment</div>
<div class="line"><a id="l01341" name="l01341"></a><span class="lineno"> 1341</span>    vec.set_params(stop_words=[&quot;you&#39;ve&quot;, &quot;you&quot;, &quot;you&#39;ll&quot;, &quot;blah&quot;, &quot;AND&quot;])</div>
<div class="line"><a id="l01342" name="l01342"></a><span class="lineno"> 1342</span>    with pytest.warns(UserWarning, match=message):</div>
<div class="line"><a id="l01343" name="l01343"></a><span class="lineno"> 1343</span>        vec.fit_transform([&quot;hello world&quot;])</div>
<div class="line"><a id="l01344" name="l01344"></a><span class="lineno"> 1344</span> </div>
<div class="line"><a id="l01345" name="l01345"></a><span class="lineno"> 1345</span> </div>
<div class="line"><a id="l01346" name="l01346"></a><span class="lineno"> 1346</span>@skip_if_32bit</div>
<div class="line"><a id="l01347" name="l01347"></a><span class="lineno"> 1347</span>@pytest.mark.parametrize(&quot;csr_container&quot;, CSR_CONTAINERS)</div>
<div class="foldopen" id="foldopen01348" data-start="" data-end="">
<div class="line"><a id="l01348" name="l01348"></a><span class="lineno"><a class="line" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a7cfdc4de455bcb349cf6750810a2a44d"> 1348</a></span>def test_countvectorizer_sort_features_64bit_sparse_indices(csr_container):</div>
<div class="line"><a id="l01349" name="l01349"></a><span class="lineno"> 1349</span>    &quot;&quot;&quot;</div>
<div class="line"><a id="l01350" name="l01350"></a><span class="lineno"> 1350</span>    Check that CountVectorizer._sort_features preserves the dtype of its sparse</div>
<div class="line"><a id="l01351" name="l01351"></a><span class="lineno"> 1351</span>    feature matrix.</div>
<div class="line"><a id="l01352" name="l01352"></a><span class="lineno"> 1352</span> </div>
<div class="line"><a id="l01353" name="l01353"></a><span class="lineno"> 1353</span>    This test is skipped on 32bit platforms, see:</div>
<div class="line"><a id="l01354" name="l01354"></a><span class="lineno"> 1354</span>        https://github.com/scikit-learn/scikit-learn/pull/11295</div>
<div class="line"><a id="l01355" name="l01355"></a><span class="lineno"> 1355</span>    for more details.</div>
<div class="line"><a id="l01356" name="l01356"></a><span class="lineno"> 1356</span>    &quot;&quot;&quot;</div>
<div class="line"><a id="l01357" name="l01357"></a><span class="lineno"> 1357</span> </div>
<div class="line"><a id="l01358" name="l01358"></a><span class="lineno"> 1358</span>    X = csr_container((5, 5), dtype=np.int64)</div>
<div class="line"><a id="l01359" name="l01359"></a><span class="lineno"> 1359</span> </div>
<div class="line"><a id="l01360" name="l01360"></a><span class="lineno"> 1360</span>    # force indices and indptr to int64.</div>
<div class="line"><a id="l01361" name="l01361"></a><span class="lineno"> 1361</span>    INDICES_DTYPE = np.int64</div>
<div class="line"><a id="l01362" name="l01362"></a><span class="lineno"> 1362</span>    X.indices = X.indices.astype(INDICES_DTYPE)</div>
<div class="line"><a id="l01363" name="l01363"></a><span class="lineno"> 1363</span>    X.indptr = X.indptr.astype(INDICES_DTYPE)</div>
<div class="line"><a id="l01364" name="l01364"></a><span class="lineno"> 1364</span> </div>
<div class="line"><a id="l01365" name="l01365"></a><span class="lineno"> 1365</span>    vocabulary = {&quot;scikit-learn&quot;: 0, &quot;is&quot;: 1, &quot;great!&quot;: 2}</div>
<div class="line"><a id="l01366" name="l01366"></a><span class="lineno"> 1366</span> </div>
<div class="line"><a id="l01367" name="l01367"></a><span class="lineno"> 1367</span>    Xs = CountVectorizer()._sort_features(X, vocabulary)</div>
<div class="line"><a id="l01368" name="l01368"></a><span class="lineno"> 1368</span> </div>
<div class="line"><a id="l01369" name="l01369"></a><span class="lineno"> 1369</span>    assert INDICES_DTYPE == Xs.indices.dtype</div>
<div class="line"><a id="l01370" name="l01370"></a><span class="lineno"> 1370</span> </div>
<div class="line"><a id="l01371" name="l01371"></a><span class="lineno"> 1371</span> </div>
<div class="line"><a id="l01372" name="l01372"></a><span class="lineno"> 1372</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01373" name="l01373"></a><span class="lineno"> 1373</span>    &quot;Estimator&quot;, [CountVectorizer, TfidfVectorizer, HashingVectorizer]</div>
<div class="line"><a id="l01374" name="l01374"></a><span class="lineno"> 1374</span>)</div>
</div>
<div class="line"><a id="l01375" name="l01375"></a><span class="lineno"> 1375</span>def test_stop_word_validation_custom_preprocessor(Estimator):</div>
<div class="line"><a id="l01376" name="l01376"></a><span class="lineno"> 1376</span>    data = [{&quot;text&quot;: &quot;some text&quot;}]</div>
<div class="line"><a id="l01377" name="l01377"></a><span class="lineno"> 1377</span> </div>
<div class="line"><a id="l01378" name="l01378"></a><span class="lineno"> 1378</span>    vec = Estimator()</div>
<div class="line"><a id="l01379" name="l01379"></a><span class="lineno"> 1379</span>    assert _check_stop_words_consistency(vec) is True</div>
<div class="line"><a id="l01380" name="l01380"></a><span class="lineno"> 1380</span> </div>
<div class="line"><a id="l01381" name="l01381"></a><span class="lineno"> 1381</span>    vec = Estimator(preprocessor=lambda x: x[&quot;text&quot;], stop_words=[&quot;and&quot;])</div>
<div class="line"><a id="l01382" name="l01382"></a><span class="lineno"> 1382</span>    assert _check_stop_words_consistency(vec) == &quot;error&quot;</div>
<div class="line"><a id="l01383" name="l01383"></a><span class="lineno"> 1383</span>    # checks are cached</div>
<div class="line"><a id="l01384" name="l01384"></a><span class="lineno"> 1384</span>    assert _check_stop_words_consistency(vec) is None</div>
<div class="line"><a id="l01385" name="l01385"></a><span class="lineno"> 1385</span>    vec.fit_transform(data)</div>
<div class="line"><a id="l01386" name="l01386"></a><span class="lineno"> 1386</span> </div>
<div class="line"><a id="l01387" name="l01387"></a><span class="lineno"> 1387</span>    class CustomEstimator(Estimator):</div>
<div class="line"><a id="l01388" name="l01388"></a><span class="lineno"> 1388</span>        def build_preprocessor(self):</div>
<div class="line"><a id="l01389" name="l01389"></a><span class="lineno"> 1389</span>            return lambda x: x[&quot;text&quot;]</div>
<div class="line"><a id="l01390" name="l01390"></a><span class="lineno"> 1390</span> </div>
<div class="line"><a id="l01391" name="l01391"></a><span class="lineno"> 1391</span>    vec = CustomEstimator(stop_words=[&quot;and&quot;])</div>
<div class="line"><a id="l01392" name="l01392"></a><span class="lineno"> 1392</span>    assert _check_stop_words_consistency(vec) == &quot;error&quot;</div>
<div class="line"><a id="l01393" name="l01393"></a><span class="lineno"> 1393</span> </div>
<div class="line"><a id="l01394" name="l01394"></a><span class="lineno"> 1394</span>    vec = Estimator(</div>
<div class="line"><a id="l01395" name="l01395"></a><span class="lineno"> 1395</span>        tokenizer=lambda doc: re.compile(r&quot;\w{1,}&quot;).findall(doc), stop_words=[&quot;and&quot;]</div>
<div class="line"><a id="l01396" name="l01396"></a><span class="lineno"> 1396</span>    )</div>
<div class="line"><a id="l01397" name="l01397"></a><span class="lineno"> 1397</span>    assert _check_stop_words_consistency(vec) is True</div>
<div class="line"><a id="l01398" name="l01398"></a><span class="lineno"> 1398</span> </div>
<div class="line"><a id="l01399" name="l01399"></a><span class="lineno"> 1399</span> </div>
<div class="line"><a id="l01400" name="l01400"></a><span class="lineno"> 1400</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01401" name="l01401"></a><span class="lineno"> 1401</span>    &quot;Estimator&quot;, [CountVectorizer, TfidfVectorizer, HashingVectorizer]</div>
<div class="line"><a id="l01402" name="l01402"></a><span class="lineno"> 1402</span>)</div>
<div class="line"><a id="l01403" name="l01403"></a><span class="lineno"> 1403</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01404" name="l01404"></a><span class="lineno"> 1404</span>    &quot;input_type, err_type, err_msg&quot;,</div>
<div class="line"><a id="l01405" name="l01405"></a><span class="lineno"> 1405</span>    [</div>
<div class="line"><a id="l01406" name="l01406"></a><span class="lineno"> 1406</span>        (&quot;filename&quot;, FileNotFoundError, &quot;&quot;),</div>
<div class="line"><a id="l01407" name="l01407"></a><span class="lineno"> 1407</span>        (&quot;file&quot;, AttributeError, &quot;&#39;str&#39; object has no attribute &#39;read&#39;&quot;),</div>
<div class="line"><a id="l01408" name="l01408"></a><span class="lineno"> 1408</span>    ],</div>
<div class="line"><a id="l01409" name="l01409"></a><span class="lineno"> 1409</span>)</div>
<div class="line"><a id="l01410" name="l01410"></a><span class="lineno"> 1410</span>def test_callable_analyzer_error(Estimator, input_type, err_type, err_msg):</div>
<div class="line"><a id="l01411" name="l01411"></a><span class="lineno"> 1411</span>    data = [&quot;this is text, not file or filename&quot;]</div>
<div class="line"><a id="l01412" name="l01412"></a><span class="lineno"> 1412</span>    with pytest.raises(err_type, match=err_msg):</div>
<div class="line"><a id="l01413" name="l01413"></a><span class="lineno"> 1413</span>        Estimator(analyzer=lambda x: x.split(), input=input_type).fit_transform(data)</div>
<div class="line"><a id="l01414" name="l01414"></a><span class="lineno"> 1414</span> </div>
<div class="line"><a id="l01415" name="l01415"></a><span class="lineno"> 1415</span> </div>
<div class="line"><a id="l01416" name="l01416"></a><span class="lineno"> 1416</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01417" name="l01417"></a><span class="lineno"> 1417</span>    &quot;Estimator&quot;,</div>
<div class="line"><a id="l01418" name="l01418"></a><span class="lineno"> 1418</span>    [</div>
<div class="line"><a id="l01419" name="l01419"></a><span class="lineno"> 1419</span>        CountVectorizer,</div>
<div class="line"><a id="l01420" name="l01420"></a><span class="lineno"> 1420</span>        TfidfVectorizer,</div>
<div class="line"><a id="l01421" name="l01421"></a><span class="lineno"> 1421</span>        pytest.param(HashingVectorizer),</div>
<div class="line"><a id="l01422" name="l01422"></a><span class="lineno"> 1422</span>    ],</div>
<div class="line"><a id="l01423" name="l01423"></a><span class="lineno"> 1423</span>)</div>
<div class="line"><a id="l01424" name="l01424"></a><span class="lineno"> 1424</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01425" name="l01425"></a><span class="lineno"> 1425</span>    &quot;analyzer&quot;, [lambda doc: open(doc, &quot;r&quot;), lambda doc: doc.read()]</div>
<div class="line"><a id="l01426" name="l01426"></a><span class="lineno"> 1426</span>)</div>
<div class="line"><a id="l01427" name="l01427"></a><span class="lineno"> 1427</span>@pytest.mark.parametrize(&quot;input_type&quot;, [&quot;file&quot;, &quot;filename&quot;])</div>
<div class="line"><a id="l01428" name="l01428"></a><span class="lineno"> 1428</span>def test_callable_analyzer_change_behavior(Estimator, analyzer, input_type):</div>
<div class="line"><a id="l01429" name="l01429"></a><span class="lineno"> 1429</span>    data = [&quot;this is text, not file or filename&quot;]</div>
<div class="line"><a id="l01430" name="l01430"></a><span class="lineno"> 1430</span>    with pytest.raises((FileNotFoundError, AttributeError)):</div>
<div class="line"><a id="l01431" name="l01431"></a><span class="lineno"> 1431</span>        Estimator(analyzer=analyzer, input=input_type).fit_transform(data)</div>
<div class="line"><a id="l01432" name="l01432"></a><span class="lineno"> 1432</span> </div>
<div class="line"><a id="l01433" name="l01433"></a><span class="lineno"> 1433</span> </div>
<div class="line"><a id="l01434" name="l01434"></a><span class="lineno"> 1434</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01435" name="l01435"></a><span class="lineno"> 1435</span>    &quot;Estimator&quot;, [CountVectorizer, TfidfVectorizer, HashingVectorizer]</div>
<div class="line"><a id="l01436" name="l01436"></a><span class="lineno"> 1436</span>)</div>
<div class="line"><a id="l01437" name="l01437"></a><span class="lineno"> 1437</span>def test_callable_analyzer_reraise_error(tmpdir, Estimator):</div>
<div class="line"><a id="l01438" name="l01438"></a><span class="lineno"> 1438</span>    # check if a custom exception from the analyzer is shown to the user</div>
<div class="line"><a id="l01439" name="l01439"></a><span class="lineno"> 1439</span>    def analyzer(doc):</div>
<div class="line"><a id="l01440" name="l01440"></a><span class="lineno"> 1440</span>        raise Exception(&quot;testing&quot;)</div>
<div class="line"><a id="l01441" name="l01441"></a><span class="lineno"> 1441</span> </div>
<div class="line"><a id="l01442" name="l01442"></a><span class="lineno"> 1442</span>    f = tmpdir.join(&quot;file.txt&quot;)</div>
<div class="line"><a id="l01443" name="l01443"></a><span class="lineno"> 1443</span>    f.write(&quot;sample content\n&quot;)</div>
<div class="line"><a id="l01444" name="l01444"></a><span class="lineno"> 1444</span> </div>
<div class="line"><a id="l01445" name="l01445"></a><span class="lineno"> 1445</span>    with pytest.raises(Exception, match=&quot;testing&quot;):</div>
<div class="line"><a id="l01446" name="l01446"></a><span class="lineno"> 1446</span>        Estimator(analyzer=analyzer, input=&quot;file&quot;).fit_transform([f])</div>
<div class="line"><a id="l01447" name="l01447"></a><span class="lineno"> 1447</span> </div>
<div class="line"><a id="l01448" name="l01448"></a><span class="lineno"> 1448</span> </div>
<div class="line"><a id="l01449" name="l01449"></a><span class="lineno"> 1449</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01450" name="l01450"></a><span class="lineno"> 1450</span>    &quot;Vectorizer&quot;, [CountVectorizer, HashingVectorizer, TfidfVectorizer]</div>
<div class="line"><a id="l01451" name="l01451"></a><span class="lineno"> 1451</span>)</div>
<div class="line"><a id="l01452" name="l01452"></a><span class="lineno"> 1452</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01453" name="l01453"></a><span class="lineno"> 1453</span>    (</div>
<div class="line"><a id="l01454" name="l01454"></a><span class="lineno"> 1454</span>        &quot;stop_words, tokenizer, preprocessor, ngram_range, token_pattern,&quot;</div>
<div class="line"><a id="l01455" name="l01455"></a><span class="lineno"> 1455</span>        &quot;analyzer, unused_name, ovrd_name, ovrd_msg&quot;</div>
<div class="line"><a id="l01456" name="l01456"></a><span class="lineno"> 1456</span>    ),</div>
<div class="line"><a id="l01457" name="l01457"></a><span class="lineno"> 1457</span>    [</div>
<div class="line"><a id="l01458" name="l01458"></a><span class="lineno"> 1458</span>        (</div>
<div class="line"><a id="l01459" name="l01459"></a><span class="lineno"> 1459</span>            [&quot;you&#39;ve&quot;, &quot;you&#39;ll&quot;],</div>
<div class="line"><a id="l01460" name="l01460"></a><span class="lineno"> 1460</span>            None,</div>
<div class="line"><a id="l01461" name="l01461"></a><span class="lineno"> 1461</span>            None,</div>
<div class="line"><a id="l01462" name="l01462"></a><span class="lineno"> 1462</span>            (1, 1),</div>
<div class="line"><a id="l01463" name="l01463"></a><span class="lineno"> 1463</span>            None,</div>
<div class="line"><a id="l01464" name="l01464"></a><span class="lineno"> 1464</span>            &quot;char&quot;,</div>
<div class="line"><a id="l01465" name="l01465"></a><span class="lineno"> 1465</span>            &quot;&#39;stop_words&#39;&quot;,</div>
<div class="line"><a id="l01466" name="l01466"></a><span class="lineno"> 1466</span>            &quot;&#39;analyzer&#39;&quot;,</div>
<div class="line"><a id="l01467" name="l01467"></a><span class="lineno"> 1467</span>            &quot;!= &#39;word&#39;&quot;,</div>
<div class="line"><a id="l01468" name="l01468"></a><span class="lineno"> 1468</span>        ),</div>
<div class="line"><a id="l01469" name="l01469"></a><span class="lineno"> 1469</span>        (</div>
<div class="line"><a id="l01470" name="l01470"></a><span class="lineno"> 1470</span>            None,</div>
<div class="line"><a id="l01471" name="l01471"></a><span class="lineno"> 1471</span>            lambda s: s.split(),</div>
<div class="line"><a id="l01472" name="l01472"></a><span class="lineno"> 1472</span>            None,</div>
<div class="line"><a id="l01473" name="l01473"></a><span class="lineno"> 1473</span>            (1, 1),</div>
<div class="line"><a id="l01474" name="l01474"></a><span class="lineno"> 1474</span>            None,</div>
<div class="line"><a id="l01475" name="l01475"></a><span class="lineno"> 1475</span>            &quot;char&quot;,</div>
<div class="line"><a id="l01476" name="l01476"></a><span class="lineno"> 1476</span>            &quot;&#39;tokenizer&#39;&quot;,</div>
<div class="line"><a id="l01477" name="l01477"></a><span class="lineno"> 1477</span>            &quot;&#39;analyzer&#39;&quot;,</div>
<div class="line"><a id="l01478" name="l01478"></a><span class="lineno"> 1478</span>            &quot;!= &#39;word&#39;&quot;,</div>
<div class="line"><a id="l01479" name="l01479"></a><span class="lineno"> 1479</span>        ),</div>
<div class="line"><a id="l01480" name="l01480"></a><span class="lineno"> 1480</span>        (</div>
<div class="line"><a id="l01481" name="l01481"></a><span class="lineno"> 1481</span>            None,</div>
<div class="line"><a id="l01482" name="l01482"></a><span class="lineno"> 1482</span>            lambda s: s.split(),</div>
<div class="line"><a id="l01483" name="l01483"></a><span class="lineno"> 1483</span>            None,</div>
<div class="line"><a id="l01484" name="l01484"></a><span class="lineno"> 1484</span>            (1, 1),</div>
<div class="line"><a id="l01485" name="l01485"></a><span class="lineno"> 1485</span>            r&quot;\w+&quot;,</div>
<div class="line"><a id="l01486" name="l01486"></a><span class="lineno"> 1486</span>            &quot;word&quot;,</div>
<div class="line"><a id="l01487" name="l01487"></a><span class="lineno"> 1487</span>            &quot;&#39;token_pattern&#39;&quot;,</div>
<div class="line"><a id="l01488" name="l01488"></a><span class="lineno"> 1488</span>            &quot;&#39;tokenizer&#39;&quot;,</div>
<div class="line"><a id="l01489" name="l01489"></a><span class="lineno"> 1489</span>            &quot;is not None&quot;,</div>
<div class="line"><a id="l01490" name="l01490"></a><span class="lineno"> 1490</span>        ),</div>
<div class="line"><a id="l01491" name="l01491"></a><span class="lineno"> 1491</span>        (</div>
<div class="line"><a id="l01492" name="l01492"></a><span class="lineno"> 1492</span>            None,</div>
<div class="line"><a id="l01493" name="l01493"></a><span class="lineno"> 1493</span>            None,</div>
<div class="line"><a id="l01494" name="l01494"></a><span class="lineno"> 1494</span>            lambda s: s.upper(),</div>
<div class="line"><a id="l01495" name="l01495"></a><span class="lineno"> 1495</span>            (1, 1),</div>
<div class="line"><a id="l01496" name="l01496"></a><span class="lineno"> 1496</span>            r&quot;\w+&quot;,</div>
<div class="line"><a id="l01497" name="l01497"></a><span class="lineno"> 1497</span>            lambda s: s.upper(),</div>
<div class="line"><a id="l01498" name="l01498"></a><span class="lineno"> 1498</span>            &quot;&#39;preprocessor&#39;&quot;,</div>
<div class="line"><a id="l01499" name="l01499"></a><span class="lineno"> 1499</span>            &quot;&#39;analyzer&#39;&quot;,</div>
<div class="line"><a id="l01500" name="l01500"></a><span class="lineno"> 1500</span>            &quot;is callable&quot;,</div>
<div class="line"><a id="l01501" name="l01501"></a><span class="lineno"> 1501</span>        ),</div>
<div class="line"><a id="l01502" name="l01502"></a><span class="lineno"> 1502</span>        (</div>
<div class="line"><a id="l01503" name="l01503"></a><span class="lineno"> 1503</span>            None,</div>
<div class="line"><a id="l01504" name="l01504"></a><span class="lineno"> 1504</span>            None,</div>
<div class="line"><a id="l01505" name="l01505"></a><span class="lineno"> 1505</span>            None,</div>
<div class="line"><a id="l01506" name="l01506"></a><span class="lineno"> 1506</span>            (1, 2),</div>
<div class="line"><a id="l01507" name="l01507"></a><span class="lineno"> 1507</span>            None,</div>
<div class="line"><a id="l01508" name="l01508"></a><span class="lineno"> 1508</span>            lambda s: s.upper(),</div>
<div class="line"><a id="l01509" name="l01509"></a><span class="lineno"> 1509</span>            &quot;&#39;ngram_range&#39;&quot;,</div>
<div class="line"><a id="l01510" name="l01510"></a><span class="lineno"> 1510</span>            &quot;&#39;analyzer&#39;&quot;,</div>
<div class="line"><a id="l01511" name="l01511"></a><span class="lineno"> 1511</span>            &quot;is callable&quot;,</div>
<div class="line"><a id="l01512" name="l01512"></a><span class="lineno"> 1512</span>        ),</div>
<div class="line"><a id="l01513" name="l01513"></a><span class="lineno"> 1513</span>        (</div>
<div class="line"><a id="l01514" name="l01514"></a><span class="lineno"> 1514</span>            None,</div>
<div class="line"><a id="l01515" name="l01515"></a><span class="lineno"> 1515</span>            None,</div>
<div class="line"><a id="l01516" name="l01516"></a><span class="lineno"> 1516</span>            None,</div>
<div class="line"><a id="l01517" name="l01517"></a><span class="lineno"> 1517</span>            (1, 1),</div>
<div class="line"><a id="l01518" name="l01518"></a><span class="lineno"> 1518</span>            r&quot;\w+&quot;,</div>
<div class="line"><a id="l01519" name="l01519"></a><span class="lineno"> 1519</span>            &quot;char&quot;,</div>
<div class="line"><a id="l01520" name="l01520"></a><span class="lineno"> 1520</span>            &quot;&#39;token_pattern&#39;&quot;,</div>
<div class="line"><a id="l01521" name="l01521"></a><span class="lineno"> 1521</span>            &quot;&#39;analyzer&#39;&quot;,</div>
<div class="line"><a id="l01522" name="l01522"></a><span class="lineno"> 1522</span>            &quot;!= &#39;word&#39;&quot;,</div>
<div class="line"><a id="l01523" name="l01523"></a><span class="lineno"> 1523</span>        ),</div>
<div class="line"><a id="l01524" name="l01524"></a><span class="lineno"> 1524</span>    ],</div>
<div class="line"><a id="l01525" name="l01525"></a><span class="lineno"> 1525</span>)</div>
<div class="line"><a id="l01526" name="l01526"></a><span class="lineno"> 1526</span>def test_unused_parameters_warn(</div>
<div class="line"><a id="l01527" name="l01527"></a><span class="lineno"> 1527</span>    Vectorizer,</div>
<div class="line"><a id="l01528" name="l01528"></a><span class="lineno"> 1528</span>    stop_words,</div>
<div class="line"><a id="l01529" name="l01529"></a><span class="lineno"> 1529</span>    tokenizer,</div>
<div class="line"><a id="l01530" name="l01530"></a><span class="lineno"> 1530</span>    preprocessor,</div>
<div class="line"><a id="l01531" name="l01531"></a><span class="lineno"> 1531</span>    ngram_range,</div>
<div class="line"><a id="l01532" name="l01532"></a><span class="lineno"> 1532</span>    token_pattern,</div>
<div class="line"><a id="l01533" name="l01533"></a><span class="lineno"> 1533</span>    analyzer,</div>
<div class="line"><a id="l01534" name="l01534"></a><span class="lineno"> 1534</span>    unused_name,</div>
<div class="line"><a id="l01535" name="l01535"></a><span class="lineno"> 1535</span>    ovrd_name,</div>
<div class="line"><a id="l01536" name="l01536"></a><span class="lineno"> 1536</span>    ovrd_msg,</div>
<div class="line"><a id="l01537" name="l01537"></a><span class="lineno"> 1537</span>):</div>
<div class="line"><a id="l01538" name="l01538"></a><span class="lineno"> 1538</span>    train_data = JUNK_FOOD_DOCS</div>
<div class="line"><a id="l01539" name="l01539"></a><span class="lineno"> 1539</span>    # setting parameter and checking for corresponding warning messages</div>
<div class="line"><a id="l01540" name="l01540"></a><span class="lineno"> 1540</span>    vect = Vectorizer()</div>
<div class="line"><a id="l01541" name="l01541"></a><span class="lineno"> 1541</span>    vect.set_params(</div>
<div class="line"><a id="l01542" name="l01542"></a><span class="lineno"> 1542</span>        stop_words=stop_words,</div>
<div class="line"><a id="l01543" name="l01543"></a><span class="lineno"> 1543</span>        tokenizer=tokenizer,</div>
<div class="line"><a id="l01544" name="l01544"></a><span class="lineno"> 1544</span>        preprocessor=preprocessor,</div>
<div class="line"><a id="l01545" name="l01545"></a><span class="lineno"> 1545</span>        ngram_range=ngram_range,</div>
<div class="line"><a id="l01546" name="l01546"></a><span class="lineno"> 1546</span>        token_pattern=token_pattern,</div>
<div class="line"><a id="l01547" name="l01547"></a><span class="lineno"> 1547</span>        analyzer=analyzer,</div>
<div class="line"><a id="l01548" name="l01548"></a><span class="lineno"> 1548</span>    )</div>
<div class="line"><a id="l01549" name="l01549"></a><span class="lineno"> 1549</span>    msg = &quot;The parameter %s will not be used since %s %s&quot; % (</div>
<div class="line"><a id="l01550" name="l01550"></a><span class="lineno"> 1550</span>        unused_name,</div>
<div class="line"><a id="l01551" name="l01551"></a><span class="lineno"> 1551</span>        ovrd_name,</div>
<div class="line"><a id="l01552" name="l01552"></a><span class="lineno"> 1552</span>        ovrd_msg,</div>
<div class="line"><a id="l01553" name="l01553"></a><span class="lineno"> 1553</span>    )</div>
<div class="line"><a id="l01554" name="l01554"></a><span class="lineno"> 1554</span>    with pytest.warns(UserWarning, match=msg):</div>
<div class="line"><a id="l01555" name="l01555"></a><span class="lineno"> 1555</span>        vect.fit(train_data)</div>
<div class="line"><a id="l01556" name="l01556"></a><span class="lineno"> 1556</span> </div>
<div class="line"><a id="l01557" name="l01557"></a><span class="lineno"> 1557</span> </div>
<div class="line"><a id="l01558" name="l01558"></a><span class="lineno"> 1558</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01559" name="l01559"></a><span class="lineno"> 1559</span>    &quot;Vectorizer, X&quot;,</div>
<div class="line"><a id="l01560" name="l01560"></a><span class="lineno"> 1560</span>    (</div>
<div class="line"><a id="l01561" name="l01561"></a><span class="lineno"> 1561</span>        (HashingVectorizer, [{&quot;foo&quot;: 1, &quot;bar&quot;: 2}, {&quot;foo&quot;: 3, &quot;baz&quot;: 1}]),</div>
<div class="line"><a id="l01562" name="l01562"></a><span class="lineno"> 1562</span>        (CountVectorizer, JUNK_FOOD_DOCS),</div>
<div class="line"><a id="l01563" name="l01563"></a><span class="lineno"> 1563</span>    ),</div>
<div class="line"><a id="l01564" name="l01564"></a><span class="lineno"> 1564</span>)</div>
<div class="line"><a id="l01565" name="l01565"></a><span class="lineno"> 1565</span>def test_n_features_in(Vectorizer, X):</div>
<div class="line"><a id="l01566" name="l01566"></a><span class="lineno"> 1566</span>    # For vectorizers, n_features_in_ does not make sense</div>
<div class="line"><a id="l01567" name="l01567"></a><span class="lineno"> 1567</span>    vectorizer = Vectorizer()</div>
<div class="line"><a id="l01568" name="l01568"></a><span class="lineno"> 1568</span>    assert not hasattr(vectorizer, &quot;n_features_in_&quot;)</div>
<div class="line"><a id="l01569" name="l01569"></a><span class="lineno"> 1569</span>    vectorizer.fit(X)</div>
<div class="line"><a id="l01570" name="l01570"></a><span class="lineno"> 1570</span>    assert not hasattr(vectorizer, &quot;n_features_in_&quot;)</div>
<div class="line"><a id="l01571" name="l01571"></a><span class="lineno"> 1571</span> </div>
<div class="line"><a id="l01572" name="l01572"></a><span class="lineno"> 1572</span> </div>
<div class="line"><a id="l01573" name="l01573"></a><span class="lineno"> 1573</span>def test_tie_breaking_sample_order_invariance():</div>
<div class="line"><a id="l01574" name="l01574"></a><span class="lineno"> 1574</span>    # Checks the sample order invariance when setting max_features</div>
<div class="line"><a id="l01575" name="l01575"></a><span class="lineno"> 1575</span>    # non-regression test for #17939</div>
<div class="line"><a id="l01576" name="l01576"></a><span class="lineno"> 1576</span>    vec = CountVectorizer(max_features=1)</div>
<div class="line"><a id="l01577" name="l01577"></a><span class="lineno"> 1577</span>    vocab1 = vec.fit([&quot;hello&quot;, &quot;world&quot;]).vocabulary_</div>
<div class="line"><a id="l01578" name="l01578"></a><span class="lineno"> 1578</span>    vocab2 = vec.fit([&quot;world&quot;, &quot;hello&quot;]).vocabulary_</div>
<div class="line"><a id="l01579" name="l01579"></a><span class="lineno"> 1579</span>    assert vocab1 == vocab2</div>
<div class="line"><a id="l01580" name="l01580"></a><span class="lineno"> 1580</span> </div>
<div class="line"><a id="l01581" name="l01581"></a><span class="lineno"> 1581</span> </div>
<div class="line"><a id="l01582" name="l01582"></a><span class="lineno"> 1582</span>def test_nonnegative_hashing_vectorizer_result_indices():</div>
<div class="line"><a id="l01583" name="l01583"></a><span class="lineno"> 1583</span>    # add test for pr 19035</div>
<div class="line"><a id="l01584" name="l01584"></a><span class="lineno"> 1584</span>    hashing = HashingVectorizer(n_features=1000000, ngram_range=(2, 3))</div>
<div class="line"><a id="l01585" name="l01585"></a><span class="lineno"> 1585</span>    indices = hashing.transform([&quot;22pcs efuture&quot;]).indices</div>
<div class="line"><a id="l01586" name="l01586"></a><span class="lineno"> 1586</span>    assert indices[0] &gt;= 0</div>
<div class="line"><a id="l01587" name="l01587"></a><span class="lineno"> 1587</span> </div>
<div class="line"><a id="l01588" name="l01588"></a><span class="lineno"> 1588</span> </div>
<div class="line"><a id="l01589" name="l01589"></a><span class="lineno"> 1589</span>@pytest.mark.parametrize(</div>
<div class="line"><a id="l01590" name="l01590"></a><span class="lineno"> 1590</span>    &quot;Estimator&quot;, [CountVectorizer, TfidfVectorizer, TfidfTransformer, HashingVectorizer]</div>
<div class="line"><a id="l01591" name="l01591"></a><span class="lineno"> 1591</span>)</div>
<div class="foldopen" id="foldopen01592" data-start="" data-end="">
<div class="line"><a id="l01592" name="l01592"></a><span class="lineno"><a class="line" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a6319d7ec6d1cbb09a4b27f55a0b79482"> 1592</a></span>def test_vectorizers_do_not_have_set_output(Estimator):</div>
<div class="line"><a id="l01593" name="l01593"></a><span class="lineno"> 1593</span>    &quot;&quot;&quot;Check that vectorizers do not define set_output.&quot;&quot;&quot;</div>
<div class="line"><a id="l01594" name="l01594"></a><span class="lineno"> 1594</span>    est = Estimator()</div>
<div class="line"><a id="l01595" name="l01595"></a><span class="lineno"> 1595</span>    assert not hasattr(est, &quot;set_output&quot;)</div>
<div class="line"><a id="l01596" name="l01596"></a><span class="lineno"> 1596</span> </div>
<div class="line"><a id="l01597" name="l01597"></a><span class="lineno"> 1597</span> </div>
<div class="line"><a id="l01598" name="l01598"></a><span class="lineno"> 1598</span>@pytest.mark.parametrize(&quot;csr_container&quot;, CSR_CONTAINERS)</div>
</div>
<div class="foldopen" id="foldopen01599" data-start="" data-end="">
<div class="line"><a id="l01599" name="l01599"></a><span class="lineno"><a class="line" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a8f0787f9db77743226430953b78be1ce"> 1599</a></span>def test_tfidf_transformer_copy(csr_container):</div>
<div class="line"><a id="l01600" name="l01600"></a><span class="lineno"> 1600</span>    &quot;&quot;&quot;Check the behaviour of TfidfTransformer.transform with the copy parameter.&quot;&quot;&quot;</div>
<div class="line"><a id="l01601" name="l01601"></a><span class="lineno"> 1601</span>    X = sparse.rand(10, 20000, dtype=np.float64, random_state=42)</div>
<div class="line"><a id="l01602" name="l01602"></a><span class="lineno"> 1602</span>    X_csr = csr_container(X)</div>
<div class="line"><a id="l01603" name="l01603"></a><span class="lineno"> 1603</span> </div>
<div class="line"><a id="l01604" name="l01604"></a><span class="lineno"> 1604</span>    # keep a copy of the original matrix for later comparison</div>
<div class="line"><a id="l01605" name="l01605"></a><span class="lineno"> 1605</span>    X_csr_original = X_csr.copy()</div>
<div class="line"><a id="l01606" name="l01606"></a><span class="lineno"> 1606</span> </div>
<div class="line"><a id="l01607" name="l01607"></a><span class="lineno"> 1607</span>    transformer = TfidfTransformer().fit(X_csr)</div>
<div class="line"><a id="l01608" name="l01608"></a><span class="lineno"> 1608</span> </div>
<div class="line"><a id="l01609" name="l01609"></a><span class="lineno"> 1609</span>    X_transform = transformer.transform(X_csr, copy=True)</div>
<div class="line"><a id="l01610" name="l01610"></a><span class="lineno"> 1610</span>    assert_allclose_dense_sparse(X_csr, X_csr_original)</div>
<div class="line"><a id="l01611" name="l01611"></a><span class="lineno"> 1611</span>    assert X_transform is not X_csr</div>
<div class="line"><a id="l01612" name="l01612"></a><span class="lineno"> 1612</span> </div>
<div class="line"><a id="l01613" name="l01613"></a><span class="lineno"> 1613</span>    X_transform = transformer.transform(X_csr, copy=False)</div>
<div class="line"><a id="l01614" name="l01614"></a><span class="lineno"> 1614</span>    assert X_transform is X_csr</div>
<div class="line"><a id="l01615" name="l01615"></a><span class="lineno"> 1615</span>    with pytest.raises(AssertionError):</div>
<div class="line"><a id="l01616" name="l01616"></a><span class="lineno"> 1616</span>        assert_allclose_dense_sparse(X_csr, X_csr_original)</div>
<div class="line"><a id="l01617" name="l01617"></a><span class="lineno"> 1617</span> </div>
<div class="line"><a id="l01618" name="l01618"></a><span class="lineno"> 1618</span> </div>
<div class="line"><a id="l01619" name="l01619"></a><span class="lineno"> 1619</span>@pytest.mark.parametrize(&quot;dtype&quot;, [np.float32, np.float64])</div>
</div>
<div class="foldopen" id="foldopen01620" data-start="" data-end="">
<div class="line"><a id="l01620" name="l01620"></a><span class="lineno"><a class="line" href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a3662c6bea728e66a3992dd5d9d5ccafb"> 1620</a></span>def test_tfidf_vectorizer_perserve_dtype_idf(dtype):</div>
<div class="line"><a id="l01621" name="l01621"></a><span class="lineno"> 1621</span>    &quot;&quot;&quot;Check that `idf_` has the same dtype as the input data.</div>
<div class="line"><a id="l01622" name="l01622"></a><span class="lineno"> 1622</span> </div>
<div class="line"><a id="l01623" name="l01623"></a><span class="lineno"> 1623</span>    Non-regression test for:</div>
<div class="line"><a id="l01624" name="l01624"></a><span class="lineno"> 1624</span>    https://github.com/scikit-learn/scikit-learn/issues/30016</div>
<div class="line"><a id="l01625" name="l01625"></a><span class="lineno"> 1625</span>    &quot;&quot;&quot;</div>
<div class="line"><a id="l01626" name="l01626"></a><span class="lineno"> 1626</span>    X = [str(uuid.uuid4()) for i in range(100_000)]</div>
<div class="line"><a id="l01627" name="l01627"></a><span class="lineno"> 1627</span>    vectorizer = TfidfVectorizer(dtype=dtype).fit(X)</div>
<div class="line"><a id="l01628" name="l01628"></a><span class="lineno"> 1628</span>    assert vectorizer.idf_.dtype == dtype</div>
</div>
<div class="ttc" id="aclassStringIO_html"><div class="ttname"><a href="../../d1/d8d/classStringIO.html">StringIO</a></div></div>
<div class="ttc" id="aclasssklearn_1_1feature__extraction_1_1text_1_1CountVectorizer_html"><div class="ttname"><a href="../../d6/d16/classsklearn_1_1feature__extraction_1_1text_1_1CountVectorizer.html">sklearn.feature_extraction.text.CountVectorizer</a></div><div class="ttdef"><b>Definition</b> <a href="../../d4/d12/sklearn_2feature__extraction_2text_8py_source.html#l00928">text.py:928</a></div></div>
<div class="ttc" id="aclasssklearn_1_1feature__extraction_1_1text_1_1TfidfTransformer_html"><div class="ttname"><a href="../../d4/d08/classsklearn_1_1feature__extraction_1_1text_1_1TfidfTransformer.html">sklearn.feature_extraction.text.TfidfTransformer</a></div><div class="ttdef"><b>Definition</b> <a href="../../d4/d12/sklearn_2feature__extraction_2text_8py_source.html#l01490">text.py:1492</a></div></div>
<div class="ttc" id="aclasssklearn_1_1pipeline_1_1Pipeline_html"><div class="ttname"><a href="../../dc/dbb/classsklearn_1_1pipeline_1_1Pipeline.html">sklearn.pipeline.Pipeline</a></div><div class="ttdef"><b>Definition</b> <a href="../../d3/d31/pipeline_8py_source.html#l00123">pipeline.py:123</a></div></div>
<div class="ttc" id="anamespacecollections_1_1abc_html"><div class="ttname"><a href="../../d3/d39/namespacecollections_1_1abc.html">collections.abc</a></div></div>
<div class="ttc" id="anamespacenumpy_1_1testing_html"><div class="ttname"><a href="../../df/d7e/namespacenumpy_1_1testing.html">numpy.testing</a></div><div class="ttdef"><b>Definition</b> <a href="../../d9/dcc/numpy_2testing_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1base_html"><div class="ttname"><a href="../../d6/da3/namespacesklearn_1_1base.html">sklearn.base</a></div><div class="ttdef"><b>Definition</b> <a href="../../d7/d3d/sklearn_2base_8py_source.html#l00001">base.py:1</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1feature__extraction_1_1tests_1_1test__text_html_a557512858124fb8cd8ac2369d112b4c1"><div class="ttname"><a href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a557512858124fb8cd8ac2369d112b4c1">sklearn.feature_extraction.tests.test_text.test_tf_transformer_feature_names_out</a></div><div class="ttdeci">test_tf_transformer_feature_names_out()</div><div class="ttdef"><b>Definition</b> <a href="#l00451">test_text.py:451</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1feature__extraction_1_1tests_1_1test__text_html_a77e574bb766b18279d1a9a7d62b69825"><div class="ttname"><a href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#a77e574bb766b18279d1a9a7d62b69825">sklearn.feature_extraction.tests.test_text.test_countvectorizer_custom_token_pattern_with_several_group</a></div><div class="ttdeci">test_countvectorizer_custom_token_pattern_with_several_group()</div><div class="ttdef"><b>Definition</b> <a href="#l00411">test_text.py:411</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1feature__extraction_1_1tests_1_1test__text_html_ac54253d945d359f90e71b1e619433cfc"><div class="ttname"><a href="../../de/d22/namespacesklearn_1_1feature__extraction_1_1tests_1_1test__text.html#ac54253d945d359f90e71b1e619433cfc">sklearn.feature_extraction.tests.test_text.test_countvectorizer_custom_token_pattern</a></div><div class="ttdeci">test_countvectorizer_custom_token_pattern()</div><div class="ttdef"><b>Definition</b> <a href="#l00392">test_text.py:392</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1feature__extraction_1_1text_html"><div class="ttname"><a href="../../da/d65/namespacesklearn_1_1feature__extraction_1_1text.html">sklearn.feature_extraction.text</a></div><div class="ttdef"><b>Definition</b> <a href="../../d4/d12/sklearn_2feature__extraction_2text_8py_source.html#l00001">text.py:1</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1model__selection_html"><div class="ttname"><a href="../../d0/d54/namespacesklearn_1_1model__selection.html">sklearn.model_selection</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/d3e/sklearn_2model__selection_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1pipeline_html"><div class="ttname"><a href="../../dc/d8e/namespacesklearn_1_1pipeline.html">sklearn.pipeline</a></div><div class="ttdef"><b>Definition</b> <a href="../../d3/d31/pipeline_8py_source.html#l00001">pipeline.py:1</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1svm_html"><div class="ttname"><a href="../../d9/d80/namespacesklearn_1_1svm.html">sklearn.svm</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/ddc/sklearn_2svm_2____init_____8py_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1utils_1_1__testing_html"><div class="ttname"><a href="../../d8/d2d/namespacesklearn_1_1utils_1_1__testing.html">sklearn.utils._testing</a></div><div class="ttdef"><b>Definition</b> <a href="../../db/d3f/utils_2__testing_8py_source.html#l00001">_testing.py:1</a></div></div>
<div class="ttc" id="anamespacesklearn_1_1utils_1_1fixes_html"><div class="ttname"><a href="../../d1/d3f/namespacesklearn_1_1utils_1_1fixes.html">sklearn.utils.fixes</a></div><div class="ttdef"><b>Definition</b> <a href="../../d3/d59/fixes_8py_source.html#l00001">fixes.py:1</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="../../dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="../../dir_f6da99e2877b0632a7e4a834e7483fed.html">llm-scripts</a></li><li class="navelem"><a class="el" href="../../dir_70c99b0173b62e0b00f95d6bf5d77b0f.html">testing</a></li><li class="navelem"><a class="el" href="../../dir_c90555aa24febdaeb0b43db3ed65d5d9.html">hypothesis-testing</a></li><li class="navelem"><a class="el" href="../../dir_5d121c57859a2187a176663451f456b7.html">hyp-env</a></li><li class="navelem"><a class="el" href="../../dir_bd811e5d8688c3c2df683649a5255528.html">lib</a></li><li class="navelem"><a class="el" href="../../dir_ed8133538883844379882c9fac17a38e.html">python3.12</a></li><li class="navelem"><a class="el" href="../../dir_ec5d4580713abd487320f8eae4ae4e88.html">site-packages</a></li><li class="navelem"><a class="el" href="../../dir_95412a8f6746b9685e089ed9447bfec4.html">sklearn</a></li><li class="navelem"><a class="el" href="../../dir_a549d2c4cad259f750fc70ccc8ffe46c.html">feature_extraction</a></li><li class="navelem"><a class="el" href="../../dir_2cbda96fd45ea3cd5c08b9e827561bcd.html">tests</a></li><li class="navelem"><b>test_text.py</b></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
