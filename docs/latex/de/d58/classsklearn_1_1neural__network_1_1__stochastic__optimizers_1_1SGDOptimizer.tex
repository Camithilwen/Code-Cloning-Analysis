\doxysection{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer Class Reference}
\hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer}{}\label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer}\index{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}}


Inheritance diagram for sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer\+:
% FIG 0


Collaboration diagram for sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer\+:
% FIG 1
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_adea40ec222c7a0da4eb9a50911305054}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, params, learning\+\_\+rate\+\_\+init=0.\+1, lr\+\_\+schedule="{}constant"{}, momentum=0.\+9, nesterov=\mbox{\hyperlink{classTrue}{True}}, power\+\_\+t=0.\+5)
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a94cef6294a4a466a5954ae16135d2a59}{iteration\+\_\+ends}} (self, time\+\_\+step)
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a89122ecbecd6649d51b412b3e3886f81}{trigger\+\_\+stopping}} (self, msg, verbose)
\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a5695074d302d0ce580863d1cba1731aa}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, learning\+\_\+rate\+\_\+init=0.\+1)
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a840bd3275bac4a6db219ca7370977baf}{update\+\_\+params}} (self, params, grads)
\end{DoxyCompactItemize}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
str \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a5f01d6fdde478110353a4ce8c9b4a2e4}{lr\+\_\+schedule}} = lr\+\_\+schedule
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a9c7a8564a2c0a0fe5455759a66ed58c4}{momentum}} = momentum
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a6bef0537230d045f78f54066d39631d5}{nesterov}} = nesterov
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_ac1a453d8bdb0a114690ca79f3b6d6458}{power\+\_\+t}} = power\+\_\+t
\item 
list \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_af105b8a0251ed901fc672d7dcb552b4d}{velocities}} = \mbox{[}np.\+zeros\+\_\+like(param) for param in params\mbox{]}
\end{DoxyCompactItemize}
\doxysubsection*{Public Attributes inherited from \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_ab5689b36eec135b26ea1378a0c1e0ac2}{learning\+\_\+rate\+\_\+init}} = learning\+\_\+rate\+\_\+init
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a909a1524f14f1c374998e353818c5830}{learning\+\_\+rate}} = float(learning\+\_\+rate\+\_\+init)
\end{DoxyCompactItemize}
\doxysubsubsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a8fa46424589d48d987f0e9e3d512bc37}{\+\_\+get\+\_\+updates}} (self, grads)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Stochastic gradient descent optimizer with momentum

Parameters
----------
params : list, length = len(coefs_) + len(intercepts_)
    The concatenated list containing coefs_ and intercepts_ in MLP model.
    Used for initializing velocities and updating params

learning_rate_init : float, default=0.1
    The initial learning rate used. It controls the step-size in updating
    the weights

lr_schedule : {'constant', 'adaptive', 'invscaling'}, default='constant'
    Learning rate schedule for weight updates.

    -'constant', is a constant learning rate given by
     'learning_rate_init'.

    -'invscaling' gradually decreases the learning rate 'learning_rate_' at
      each time step 't' using an inverse scaling exponent of 'power_t'.
      learning_rate_ = learning_rate_init / pow(t, power_t)

    -'adaptive', keeps the learning rate constant to
     'learning_rate_init' as long as the training keeps decreasing.
     Each time 2 consecutive epochs fail to decrease the training loss by
     tol, or fail to increase validation score by tol if 'early_stopping'
     is on, the current learning rate is divided by 5.

momentum : float, default=0.9
    Value of momentum used, must be larger than or equal to 0

nesterov : bool, default=True
    Whether to use nesterov's momentum or not. Use nesterov's if True

power_t : float, default=0.5
    Power of time step 't' in inverse scaling. See `lr_schedule` for
    more details.

Attributes
----------
learning_rate : float
    the current learning rate

velocities : list, length = len(params)
    velocities that are used to update params
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00072}{72}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_adea40ec222c7a0da4eb9a50911305054}\index{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}}
\doxysubsubsection{\texorpdfstring{\_\_init\_\_()}{\_\_init\_\_()}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_adea40ec222c7a0da4eb9a50911305054} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{params}{, }\item[{}]{learning\+\_\+rate\+\_\+init}{ = {\ttfamily 0.1}, }\item[{}]{lr\+\_\+schedule}{ = {\ttfamily "{}constant"{}}, }\item[{}]{momentum}{ = {\ttfamily 0.9}, }\item[{}]{nesterov}{ = {\ttfamily \mbox{\hyperlink{classTrue}{True}}}, }\item[{}]{power\+\_\+t}{ = {\ttfamily 0.5}}\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00120}{120}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



Referenced by \mbox{\hyperlink{kernels_8py_source_l00178}{sklearn.\+gaussian\+\_\+process.\+kernels.\+Kernel.\+get\+\_\+params()}}.



\doxysubsection{Member Function Documentation}
\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a8fa46424589d48d987f0e9e3d512bc37}\index{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}!\_get\_updates@{\_get\_updates}}
\index{\_get\_updates@{\_get\_updates}!sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}}
\doxysubsubsection{\texorpdfstring{\_get\_updates()}{\_get\_updates()}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a8fa46424589d48d987f0e9e3d512bc37} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+\_\+get\+\_\+updates (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{grads}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}

\begin{DoxyVerb}Get the values used to update params with given gradients

Parameters
----------
grads : list, length = len(coefs_) + len(intercepts_)
    Containing gradients with respect to coefs_ and intercepts_ in MLP
    model. So length should be aligned with params

Returns
-------
updates : list, length = len(grads)
    The values to add to params
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00168}{168}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



References \mbox{\hyperlink{__gb_8py_source_l00398}{sklearn.\+ensemble.\+\_\+gb.\+Base\+Gradient\+Boosting.\+learning\+\_\+rate}}, \mbox{\hyperlink{gradient__boosting_8py_source_l00202}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting.\+learning\+\_\+rate}}, \mbox{\hyperlink{__weight__boosting_8py_source_l00089}{sklearn.\+ensemble.\+\_\+weight\+\_\+boosting.\+Base\+Weight\+Boosting.\+learning\+\_\+rate}}, \mbox{\hyperlink{__stochastic__gradient_8py_source_l00119}{sklearn.\+linear\+\_\+model.\+\_\+stochastic\+\_\+gradient.\+Base\+SGD.\+learning\+\_\+rate}}, \mbox{\hyperlink{__t__sne_8py_source_l00832}{sklearn.\+manifold.\+\_\+t\+\_\+sne.\+TSNE.\+learning\+\_\+rate}}, \mbox{\hyperlink{__multilayer__perceptron_8py_source_l00130}{sklearn.\+neural\+\_\+network.\+\_\+multilayer\+\_\+perceptron.\+Base\+Multilayer\+Perceptron.\+learning\+\_\+rate}}, \mbox{\hyperlink{__rbm_8py_source_l00151}{sklearn.\+neural\+\_\+network.\+\_\+rbm.\+Bernoulli\+RBM.\+learning\+\_\+rate}}, \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00026}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+learning\+\_\+rate}}, \mbox{\hyperlink{__multilayer__perceptron_8py_source_l00141}{sklearn.\+neural\+\_\+network.\+\_\+multilayer\+\_\+perceptron.\+Base\+Multilayer\+Perceptron.\+momentum}}, \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00132}{momentum}}, \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00133}{nesterov}}, and \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00135}{velocities}}.



Referenced by \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00028}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+update\+\_\+params()}}.

\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a94cef6294a4a466a5954ae16135d2a59}\index{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}!iteration\_ends@{iteration\_ends}}
\index{iteration\_ends@{iteration\_ends}!sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}}
\doxysubsubsection{\texorpdfstring{iteration\_ends()}{iteration\_ends()}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a94cef6294a4a466a5954ae16135d2a59} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+iteration\+\_\+ends (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{time\+\_\+step}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Perform updates to learning rate and potential other states at the
end of an iteration

Parameters
----------
time_step : int
    number of training samples trained on so far, used to update
    learning rate for 'invscaling'
\end{DoxyVerb}
 

Reimplemented from \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a23867e22d6b166756b2cf4faebc12c9d}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer}}.



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00137}{137}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



References \mbox{\hyperlink{__gb_8py_source_l00398}{sklearn.\+ensemble.\+\_\+gb.\+Base\+Gradient\+Boosting.\+learning\+\_\+rate}}, \mbox{\hyperlink{gradient__boosting_8py_source_l00202}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting.\+learning\+\_\+rate}}, \mbox{\hyperlink{__weight__boosting_8py_source_l00089}{sklearn.\+ensemble.\+\_\+weight\+\_\+boosting.\+Base\+Weight\+Boosting.\+learning\+\_\+rate}}, \mbox{\hyperlink{__stochastic__gradient_8py_source_l00119}{sklearn.\+linear\+\_\+model.\+\_\+stochastic\+\_\+gradient.\+Base\+SGD.\+learning\+\_\+rate}}, \mbox{\hyperlink{__t__sne_8py_source_l00832}{sklearn.\+manifold.\+\_\+t\+\_\+sne.\+TSNE.\+learning\+\_\+rate}}, \mbox{\hyperlink{__multilayer__perceptron_8py_source_l00130}{sklearn.\+neural\+\_\+network.\+\_\+multilayer\+\_\+perceptron.\+Base\+Multilayer\+Perceptron.\+learning\+\_\+rate}}, \mbox{\hyperlink{__rbm_8py_source_l00151}{sklearn.\+neural\+\_\+network.\+\_\+rbm.\+Bernoulli\+RBM.\+learning\+\_\+rate}}, \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00026}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+learning\+\_\+rate}}, \mbox{\hyperlink{__multilayer__perceptron_8py_source_l00131}{sklearn.\+neural\+\_\+network.\+\_\+multilayer\+\_\+perceptron.\+Base\+Multilayer\+Perceptron.\+learning\+\_\+rate\+\_\+init}}, \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00025}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+learning\+\_\+rate\+\_\+init}}, \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00131}{lr\+\_\+schedule}}, \mbox{\hyperlink{__stochastic__gradient_8py_source_l00129}{sklearn.\+linear\+\_\+model.\+\_\+stochastic\+\_\+gradient.\+Base\+SGD.\+power\+\_\+t}}, \mbox{\hyperlink{__multilayer__perceptron_8py_source_l00132}{sklearn.\+neural\+\_\+network.\+\_\+multilayer\+\_\+perceptron.\+Base\+Multilayer\+Perceptron.\+power\+\_\+t}}, and \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00134}{power\+\_\+t}}.

\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a89122ecbecd6649d51b412b3e3886f81}\index{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}!trigger\_stopping@{trigger\_stopping}}
\index{trigger\_stopping@{trigger\_stopping}!sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}}
\doxysubsubsection{\texorpdfstring{trigger\_stopping()}{trigger\_stopping()}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a89122ecbecd6649d51b412b3e3886f81} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+trigger\+\_\+stopping (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{msg}{, }\item[{}]{verbose}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Decides whether it is time to stop training

Parameters
----------
msg : str
    Message passed in for verbose output

verbose : bool
    Print message to stdin if True

Returns
-------
is_stopping : bool
    True if training needs to stop
\end{DoxyVerb}
 

Reimplemented from \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_aeeb3ca05e9540cba44a543cd9a39cc87}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer}}.



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00152}{152}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



References \mbox{\hyperlink{__gb_8py_source_l00398}{sklearn.\+ensemble.\+\_\+gb.\+Base\+Gradient\+Boosting.\+learning\+\_\+rate}}, \mbox{\hyperlink{gradient__boosting_8py_source_l00202}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting.\+learning\+\_\+rate}}, \mbox{\hyperlink{__weight__boosting_8py_source_l00089}{sklearn.\+ensemble.\+\_\+weight\+\_\+boosting.\+Base\+Weight\+Boosting.\+learning\+\_\+rate}}, \mbox{\hyperlink{__stochastic__gradient_8py_source_l00119}{sklearn.\+linear\+\_\+model.\+\_\+stochastic\+\_\+gradient.\+Base\+SGD.\+learning\+\_\+rate}}, \mbox{\hyperlink{__t__sne_8py_source_l00832}{sklearn.\+manifold.\+\_\+t\+\_\+sne.\+TSNE.\+learning\+\_\+rate}}, \mbox{\hyperlink{__multilayer__perceptron_8py_source_l00130}{sklearn.\+neural\+\_\+network.\+\_\+multilayer\+\_\+perceptron.\+Base\+Multilayer\+Perceptron.\+learning\+\_\+rate}}, \mbox{\hyperlink{__rbm_8py_source_l00151}{sklearn.\+neural\+\_\+network.\+\_\+rbm.\+Bernoulli\+RBM.\+learning\+\_\+rate}}, \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00026}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+learning\+\_\+rate}}, and \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00131}{lr\+\_\+schedule}}.



\doxysubsection{Member Data Documentation}
\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a5f01d6fdde478110353a4ce8c9b4a2e4}\index{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}!lr\_schedule@{lr\_schedule}}
\index{lr\_schedule@{lr\_schedule}!sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}}
\doxysubsubsection{\texorpdfstring{lr\_schedule}{lr\_schedule}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a5f01d6fdde478110353a4ce8c9b4a2e4} 
str sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+lr\+\_\+schedule = lr\+\_\+schedule}



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00131}{131}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



Referenced by \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00137}{iteration\+\_\+ends()}}, and \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00152}{trigger\+\_\+stopping()}}.

\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a9c7a8564a2c0a0fe5455759a66ed58c4}\index{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}!momentum@{momentum}}
\index{momentum@{momentum}!sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}}
\doxysubsubsection{\texorpdfstring{momentum}{momentum}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a9c7a8564a2c0a0fe5455759a66ed58c4} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+momentum = momentum}



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00132}{132}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



Referenced by \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00168}{\+\_\+get\+\_\+updates()}}.

\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a6bef0537230d045f78f54066d39631d5}\index{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}!nesterov@{nesterov}}
\index{nesterov@{nesterov}!sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}}
\doxysubsubsection{\texorpdfstring{nesterov}{nesterov}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a6bef0537230d045f78f54066d39631d5} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+nesterov = nesterov}



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00133}{133}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



Referenced by \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00168}{\+\_\+get\+\_\+updates()}}.

\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_ac1a453d8bdb0a114690ca79f3b6d6458}\index{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}!power\_t@{power\_t}}
\index{power\_t@{power\_t}!sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}}
\doxysubsubsection{\texorpdfstring{power\_t}{power\_t}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_ac1a453d8bdb0a114690ca79f3b6d6458} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+power\+\_\+t = power\+\_\+t}



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00134}{134}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



Referenced by \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00137}{iteration\+\_\+ends()}}.

\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_af105b8a0251ed901fc672d7dcb552b4d}\index{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}!velocities@{velocities}}
\index{velocities@{velocities}!sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.SGDOptimizer}}
\doxysubsubsection{\texorpdfstring{velocities}{velocities}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_af105b8a0251ed901fc672d7dcb552b4d} 
list sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+velocities = \mbox{[}np.\+zeros\+\_\+like(param) for param in params\mbox{]}}



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00135}{135}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



Referenced by \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00168}{\+\_\+get\+\_\+updates()}}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/jam/\+Research/\+IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.\+12/site-\/packages/sklearn/neural\+\_\+network/\+\_\+stochastic\+\_\+optimizers.\+py\end{DoxyCompactItemize}
