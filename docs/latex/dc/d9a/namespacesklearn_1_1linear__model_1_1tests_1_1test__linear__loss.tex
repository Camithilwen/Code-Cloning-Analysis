\doxysection{sklearn.\+linear\+\_\+model.\+tests.\+test\+\_\+linear\+\_\+loss Namespace Reference}
\hypertarget{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss}{}\label{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss}\index{sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_aba6de1423bd923f8d4a792fb44100f4e}{random\+\_\+\+X\+\_\+y\+\_\+coef}} (linear\+\_\+model\+\_\+loss, n\+\_\+samples, n\+\_\+features, coef\+\_\+bound=(-\/2, 2), seed=42)
\item 
\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_ada4e0d385b593936e1cd56f4a349dece}{test\+\_\+init\+\_\+zero\+\_\+coef}} (base\+\_\+loss, fit\+\_\+intercept, n\+\_\+features, dtype, global\+\_\+random\+\_\+seed)
\item 
\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a5f883ca3bb26105181811613663acd28}{test\+\_\+loss\+\_\+grad\+\_\+hess\+\_\+are\+\_\+the\+\_\+same}} (base\+\_\+loss, fit\+\_\+intercept, sample\+\_\+weight, l2\+\_\+reg\+\_\+strength, csr\+\_\+container, global\+\_\+random\+\_\+seed)
\item 
\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_ae7d1832a0beb1cd6066e5ef8f70db9c7}{test\+\_\+loss\+\_\+gradients\+\_\+hessp\+\_\+intercept}} (base\+\_\+loss, sample\+\_\+weight, l2\+\_\+reg\+\_\+strength, X\+\_\+container, global\+\_\+random\+\_\+seed)
\item 
\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a2146538f9ab20b014d199d6f389c6524}{test\+\_\+gradients\+\_\+hessians\+\_\+numerically}} (base\+\_\+loss, fit\+\_\+intercept, sample\+\_\+weight, l2\+\_\+reg\+\_\+strength, global\+\_\+random\+\_\+seed)
\item 
\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a5465428a317bee7e2af1ae69ac4807ab}{test\+\_\+multinomial\+\_\+coef\+\_\+shape}} (fit\+\_\+intercept, global\+\_\+random\+\_\+seed)
\item 
\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a50324b92cf016067abf81649d5d0202b}{test\+\_\+multinomial\+\_\+hessian\+\_\+3\+\_\+classes}} (sample\+\_\+weight, global\+\_\+random\+\_\+seed)
\item 
\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_aa56641957a85c6cf5960e69c7bd54bc0}{test\+\_\+linear\+\_\+loss\+\_\+gradient\+\_\+hessian\+\_\+raises\+\_\+wrong\+\_\+out\+\_\+parameters}} ()
\end{DoxyCompactItemize}
\doxysubsubsection*{Variables}
\begin{DoxyCompactItemize}
\item 
list \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_ae0121dcc583e66a2a93666c2beb23f9d}{LOSSES}} = \mbox{[}\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfBinomialLoss}{Half\+Binomial\+Loss}}, \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfMultinomialLoss}{Half\+Multinomial\+Loss}}, \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfPoissonLoss}{Half\+Poisson\+Loss}}\mbox{]}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Tests for LinearModelLoss

Note that correctness of losses (which compose LinearModelLoss) is already well
covered in the _loss module.
\end{DoxyVerb}
 

\doxysubsection{Function Documentation}
\Hypertarget{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_aba6de1423bd923f8d4a792fb44100f4e}\index{sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}!random\_X\_y\_coef@{random\_X\_y\_coef}}
\index{random\_X\_y\_coef@{random\_X\_y\_coef}!sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}}
\doxysubsubsection{\texorpdfstring{random\_X\_y\_coef()}{random\_X\_y\_coef()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_aba6de1423bd923f8d4a792fb44100f4e} 
sklearn.\+linear\+\_\+model.\+tests.\+test\+\_\+linear\+\_\+loss.\+random\+\_\+\+X\+\_\+y\+\_\+coef (\begin{DoxyParamCaption}\item[{}]{linear\+\_\+model\+\_\+loss}{, }\item[{}]{n\+\_\+samples}{, }\item[{}]{n\+\_\+features}{, }\item[{}]{coef\+\_\+bound}{ = {\ttfamily (-\/2,~2)}, }\item[{}]{seed}{ = {\ttfamily 42}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Random generate y, X and coef in valid range.\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{test__linear__loss_8py_source_l00028}{28}} of file \mbox{\hyperlink{test__linear__loss_8py_source}{test\+\_\+linear\+\_\+loss.\+py}}.



Referenced by \mbox{\hyperlink{test__linear__loss_8py_source_l00268}{test\+\_\+gradients\+\_\+hessians\+\_\+numerically()}}, \mbox{\hyperlink{test__linear__loss_8py_source_l00119}{test\+\_\+loss\+\_\+grad\+\_\+hess\+\_\+are\+\_\+the\+\_\+same()}}, \mbox{\hyperlink{test__linear__loss_8py_source_l00209}{test\+\_\+loss\+\_\+gradients\+\_\+hessp\+\_\+intercept()}}, \mbox{\hyperlink{test__linear__loss_8py_source_l00351}{test\+\_\+multinomial\+\_\+coef\+\_\+shape()}}, and \mbox{\hyperlink{test__linear__loss_8py_source_l00392}{test\+\_\+multinomial\+\_\+hessian\+\_\+3\+\_\+classes()}}.

\Hypertarget{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a2146538f9ab20b014d199d6f389c6524}\index{sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}!test\_gradients\_hessians\_numerically@{test\_gradients\_hessians\_numerically}}
\index{test\_gradients\_hessians\_numerically@{test\_gradients\_hessians\_numerically}!sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}}
\doxysubsubsection{\texorpdfstring{test\_gradients\_hessians\_numerically()}{test\_gradients\_hessians\_numerically()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a2146538f9ab20b014d199d6f389c6524} 
sklearn.\+linear\+\_\+model.\+tests.\+test\+\_\+linear\+\_\+loss.\+test\+\_\+gradients\+\_\+hessians\+\_\+numerically (\begin{DoxyParamCaption}\item[{}]{base\+\_\+loss}{, }\item[{}]{fit\+\_\+intercept}{, }\item[{}]{sample\+\_\+weight}{, }\item[{}]{l2\+\_\+reg\+\_\+strength}{, }\item[{}]{global\+\_\+random\+\_\+seed}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Test gradients and hessians with numerical derivatives.

Gradient should equal the numerical derivatives of the loss function.
Hessians should equal the numerical derivatives of gradients.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{test__linear__loss_8py_source_l00266}{266}} of file \mbox{\hyperlink{test__linear__loss_8py_source}{test\+\_\+linear\+\_\+loss.\+py}}.



References \mbox{\hyperlink{test__linear__loss_8py_source_l00030}{random\+\_\+\+X\+\_\+y\+\_\+coef()}}.

\Hypertarget{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_ada4e0d385b593936e1cd56f4a349dece}\index{sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}!test\_init\_zero\_coef@{test\_init\_zero\_coef}}
\index{test\_init\_zero\_coef@{test\_init\_zero\_coef}!sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}}
\doxysubsubsection{\texorpdfstring{test\_init\_zero\_coef()}{test\_init\_zero\_coef()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_ada4e0d385b593936e1cd56f4a349dece} 
sklearn.\+linear\+\_\+model.\+tests.\+test\+\_\+linear\+\_\+loss.\+test\+\_\+init\+\_\+zero\+\_\+coef (\begin{DoxyParamCaption}\item[{}]{base\+\_\+loss}{, }\item[{}]{fit\+\_\+intercept}{, }\item[{}]{n\+\_\+features}{, }\item[{}]{dtype}{, }\item[{}]{global\+\_\+random\+\_\+seed}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Test that init_zero_coef initializes coef correctly.\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{test__linear__loss_8py_source_l00084}{84}} of file \mbox{\hyperlink{test__linear__loss_8py_source}{test\+\_\+linear\+\_\+loss.\+py}}.

\Hypertarget{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_aa56641957a85c6cf5960e69c7bd54bc0}\index{sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}!test\_linear\_loss\_gradient\_hessian\_raises\_wrong\_out\_parameters@{test\_linear\_loss\_gradient\_hessian\_raises\_wrong\_out\_parameters}}
\index{test\_linear\_loss\_gradient\_hessian\_raises\_wrong\_out\_parameters@{test\_linear\_loss\_gradient\_hessian\_raises\_wrong\_out\_parameters}!sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}}
\doxysubsubsection{\texorpdfstring{test\_linear\_loss\_gradient\_hessian\_raises\_wrong\_out\_parameters()}{test\_linear\_loss\_gradient\_hessian\_raises\_wrong\_out\_parameters()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_aa56641957a85c6cf5960e69c7bd54bc0} 
sklearn.\+linear\+\_\+model.\+tests.\+test\+\_\+linear\+\_\+loss.\+test\+\_\+linear\+\_\+loss\+\_\+gradient\+\_\+hessian\+\_\+raises\+\_\+wrong\+\_\+out\+\_\+parameters (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Test that wrong gradient_out and hessian_out raises errors.\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{test__linear__loss_8py_source_l00464}{464}} of file \mbox{\hyperlink{test__linear__loss_8py_source}{test\+\_\+linear\+\_\+loss.\+py}}.

\Hypertarget{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a5f883ca3bb26105181811613663acd28}\index{sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}!test\_loss\_grad\_hess\_are\_the\_same@{test\_loss\_grad\_hess\_are\_the\_same}}
\index{test\_loss\_grad\_hess\_are\_the\_same@{test\_loss\_grad\_hess\_are\_the\_same}!sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}}
\doxysubsubsection{\texorpdfstring{test\_loss\_grad\_hess\_are\_the\_same()}{test\_loss\_grad\_hess\_are\_the\_same()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a5f883ca3bb26105181811613663acd28} 
sklearn.\+linear\+\_\+model.\+tests.\+test\+\_\+linear\+\_\+loss.\+test\+\_\+loss\+\_\+grad\+\_\+hess\+\_\+are\+\_\+the\+\_\+same (\begin{DoxyParamCaption}\item[{}]{base\+\_\+loss}{, }\item[{}]{fit\+\_\+intercept}{, }\item[{}]{sample\+\_\+weight}{, }\item[{}]{l2\+\_\+reg\+\_\+strength}{, }\item[{}]{csr\+\_\+container}{, }\item[{}]{global\+\_\+random\+\_\+seed}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Test that loss and gradient are the same across different functions.\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{test__linear__loss_8py_source_l00112}{112}} of file \mbox{\hyperlink{test__linear__loss_8py_source}{test\+\_\+linear\+\_\+loss.\+py}}.



References \mbox{\hyperlink{test__linear__loss_8py_source_l00030}{random\+\_\+\+X\+\_\+y\+\_\+coef()}}.

\Hypertarget{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_ae7d1832a0beb1cd6066e5ef8f70db9c7}\index{sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}!test\_loss\_gradients\_hessp\_intercept@{test\_loss\_gradients\_hessp\_intercept}}
\index{test\_loss\_gradients\_hessp\_intercept@{test\_loss\_gradients\_hessp\_intercept}!sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}}
\doxysubsubsection{\texorpdfstring{test\_loss\_gradients\_hessp\_intercept()}{test\_loss\_gradients\_hessp\_intercept()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_ae7d1832a0beb1cd6066e5ef8f70db9c7} 
sklearn.\+linear\+\_\+model.\+tests.\+test\+\_\+linear\+\_\+loss.\+test\+\_\+loss\+\_\+gradients\+\_\+hessp\+\_\+intercept (\begin{DoxyParamCaption}\item[{}]{base\+\_\+loss}{, }\item[{}]{sample\+\_\+weight}{, }\item[{}]{l2\+\_\+reg\+\_\+strength}{, }\item[{}]{X\+\_\+container}{, }\item[{}]{global\+\_\+random\+\_\+seed}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Test that loss and gradient handle intercept correctly.\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{test__linear__loss_8py_source_l00207}{207}} of file \mbox{\hyperlink{test__linear__loss_8py_source}{test\+\_\+linear\+\_\+loss.\+py}}.



References \mbox{\hyperlink{test__linear__loss_8py_source_l00030}{random\+\_\+\+X\+\_\+y\+\_\+coef()}}.

\Hypertarget{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a5465428a317bee7e2af1ae69ac4807ab}\index{sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}!test\_multinomial\_coef\_shape@{test\_multinomial\_coef\_shape}}
\index{test\_multinomial\_coef\_shape@{test\_multinomial\_coef\_shape}!sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}}
\doxysubsubsection{\texorpdfstring{test\_multinomial\_coef\_shape()}{test\_multinomial\_coef\_shape()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a5465428a317bee7e2af1ae69ac4807ab} 
sklearn.\+linear\+\_\+model.\+tests.\+test\+\_\+linear\+\_\+loss.\+test\+\_\+multinomial\+\_\+coef\+\_\+shape (\begin{DoxyParamCaption}\item[{}]{fit\+\_\+intercept}{, }\item[{}]{global\+\_\+random\+\_\+seed}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Test that multinomial LinearModelLoss respects shape of coef.\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{test__linear__loss_8py_source_l00351}{351}} of file \mbox{\hyperlink{test__linear__loss_8py_source}{test\+\_\+linear\+\_\+loss.\+py}}.



References \mbox{\hyperlink{test__linear__loss_8py_source_l00030}{random\+\_\+\+X\+\_\+y\+\_\+coef()}}.

\Hypertarget{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a50324b92cf016067abf81649d5d0202b}\index{sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}!test\_multinomial\_hessian\_3\_classes@{test\_multinomial\_hessian\_3\_classes}}
\index{test\_multinomial\_hessian\_3\_classes@{test\_multinomial\_hessian\_3\_classes}!sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}}
\doxysubsubsection{\texorpdfstring{test\_multinomial\_hessian\_3\_classes()}{test\_multinomial\_hessian\_3\_classes()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_a50324b92cf016067abf81649d5d0202b} 
sklearn.\+linear\+\_\+model.\+tests.\+test\+\_\+linear\+\_\+loss.\+test\+\_\+multinomial\+\_\+hessian\+\_\+3\+\_\+classes (\begin{DoxyParamCaption}\item[{}]{sample\+\_\+weight}{, }\item[{}]{global\+\_\+random\+\_\+seed}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Test multinomial hessian for 3 classes and 2 points.

For n_classes = 3 and n_samples = 2, we have
  p0 = [p0_0, p0_1]
  p1 = [p1_0, p1_1]
  p2 = [p2_0, p2_1]
and with 2 x 2 diagonal subblocks
  H = [p0 * (1-p0),    -p0 * p1,    -p0 * p2]
      [   -p0 * p1, p1 * (1-p1),    -p1 * p2]
      [   -p0 * p2,    -p1 * p2, p2 * (1-p2)]
  hess = X' H X
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{test__linear__loss_8py_source_l00392}{392}} of file \mbox{\hyperlink{test__linear__loss_8py_source}{test\+\_\+linear\+\_\+loss.\+py}}.



References \mbox{\hyperlink{test__linear__loss_8py_source_l00030}{random\+\_\+\+X\+\_\+y\+\_\+coef()}}.



\doxysubsection{Variable Documentation}
\Hypertarget{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_ae0121dcc583e66a2a93666c2beb23f9d}\index{sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}!LOSSES@{LOSSES}}
\index{LOSSES@{LOSSES}!sklearn.linear\_model.tests.test\_linear\_loss@{sklearn.linear\_model.tests.test\_linear\_loss}}
\doxysubsubsection{\texorpdfstring{LOSSES}{LOSSES}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1linear__model_1_1tests_1_1test__linear__loss_ae0121dcc583e66a2a93666c2beb23f9d} 
list sklearn.\+linear\+\_\+model.\+tests.\+test\+\_\+linear\+\_\+loss.\+LOSSES = \mbox{[}\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfBinomialLoss}{Half\+Binomial\+Loss}}, \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfMultinomialLoss}{Half\+Multinomial\+Loss}}, \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfPoissonLoss}{Half\+Poisson\+Loss}}\mbox{]}}



Definition at line \mbox{\hyperlink{test__linear__loss_8py_source_l00025}{25}} of file \mbox{\hyperlink{test__linear__loss_8py_source}{test\+\_\+linear\+\_\+loss.\+py}}.

