\doxysection{sklearn.\+base.\+Regressor\+Mixin Class Reference}
\hypertarget{classsklearn_1_1base_1_1RegressorMixin}{}\label{classsklearn_1_1base_1_1RegressorMixin}\index{sklearn.base.RegressorMixin@{sklearn.base.RegressorMixin}}


Inheritance diagram for sklearn.\+base.\+Regressor\+Mixin\+:
% FIG 0


Collaboration diagram for sklearn.\+base.\+Regressor\+Mixin\+:
% FIG 1
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1RegressorMixin_ae29a40b01c8029a8cfb329b0a61dd142}{\+\_\+\+\_\+sklearn\+\_\+tags\+\_\+\+\_\+}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1RegressorMixin_adce4557f75f598bbc92379cd10c43a7d}{score}} (self, X, y, sample\+\_\+weight=None)
\end{DoxyCompactItemize}
\doxysubsubsection*{Static Protected Attributes}
\begin{DoxyCompactItemize}
\item 
str \mbox{\hyperlink{classsklearn_1_1base_1_1RegressorMixin_aba1660973f816763e0ab74f0becd1a06}{\+\_\+estimator\+\_\+type}} = "{}regressor"{}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Mixin class for all regression estimators in scikit-learn.

This mixin defines the following functionality:

- set estimator type to `"regressor"` through the `estimator_type` tag;
- `score` method that default to :func:`~sklearn.metrics.r2_score`.
- enforce that `fit` requires `y` to be passed through the `requires_y` tag,
  which is done by setting the regressor type tag.

Read more in the :ref:`User Guide <rolling_your_own_estimator>`.

Examples
--------
>>> import numpy as np
>>> from sklearn.base import BaseEstimator, RegressorMixin
>>> # Mixin classes should always be on the left-hand side for a correct MRO
>>> class MyEstimator(RegressorMixin, BaseEstimator):
...     def __init__(self, *, param=1):
...         self.param = param
...     def fit(self, X, y=None):
...         self.is_fitted_ = True
...         return self
...     def predict(self, X):
...         return np.full(shape=X.shape[0], fill_value=self.param)
>>> estimator = MyEstimator(param=0)
>>> X = np.array([[1, 2], [2, 3], [3, 4]])
>>> y = np.array([-1, 0, 1])
>>> estimator.fit(X, y).predict(X)
array([0, 0, 0])
>>> estimator.score(X, y)
0.0
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2base_8py_source_l00551}{551}} of file \mbox{\hyperlink{sklearn_2base_8py_source}{base.\+py}}.



\doxysubsection{Member Function Documentation}
\Hypertarget{classsklearn_1_1base_1_1RegressorMixin_ae29a40b01c8029a8cfb329b0a61dd142}\index{sklearn.base.RegressorMixin@{sklearn.base.RegressorMixin}!\_\_sklearn\_tags\_\_@{\_\_sklearn\_tags\_\_}}
\index{\_\_sklearn\_tags\_\_@{\_\_sklearn\_tags\_\_}!sklearn.base.RegressorMixin@{sklearn.base.RegressorMixin}}
\doxysubsubsection{\texorpdfstring{\_\_sklearn\_tags\_\_()}{\_\_sklearn\_tags\_\_()}}
{\footnotesize\ttfamily \label{classsklearn_1_1base_1_1RegressorMixin_ae29a40b01c8029a8cfb329b0a61dd142} 
sklearn.\+base.\+Regressor\+Mixin.\+\_\+\+\_\+sklearn\+\_\+tags\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self}{}\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{sklearn_2base_8py_source_l00588}{588}} of file \mbox{\hyperlink{sklearn_2base_8py_source}{base.\+py}}.

\Hypertarget{classsklearn_1_1base_1_1RegressorMixin_adce4557f75f598bbc92379cd10c43a7d}\index{sklearn.base.RegressorMixin@{sklearn.base.RegressorMixin}!score@{score}}
\index{score@{score}!sklearn.base.RegressorMixin@{sklearn.base.RegressorMixin}}
\doxysubsubsection{\texorpdfstring{score()}{score()}}
{\footnotesize\ttfamily \label{classsklearn_1_1base_1_1RegressorMixin_adce4557f75f598bbc92379cd10c43a7d} 
sklearn.\+base.\+Regressor\+Mixin.\+score (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{X}{, }\item[{}]{y}{, }\item[{}]{sample\+\_\+weight}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Return :ref:`coefficient of determination <r2_score>` on test data.

The coefficient of determination, :math:`R^2`, is defined as
:math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual
sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`
is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of `y`, disregarding the input features, would get
a :math:`R^2` score of 0.0.

Parameters
----------
X : array-like of shape (n_samples, n_features)
    Test samples. For some estimators this may be a precomputed
    kernel matrix or a list of generic objects instead with shape
    ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``
    is the number of samples used in the fitting for the estimator.

y : array-like of shape (n_samples,) or (n_samples, n_outputs)
    True values for `X`.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
score : float
    :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.

Notes
-----
The :math:`R^2` score used when calling ``score`` on a regressor uses
``multioutput='uniform_average'`` from version 0.23 to keep consistent
with default value of :func:`~sklearn.metrics.r2_score`.
This influences the ``score`` method of all the multioutput
regressors (except for
:class:`~sklearn.multioutput.MultiOutputRegressor`).
\end{DoxyVerb}
 

Reimplemented in \mbox{\hyperlink{classsklearn_1_1dummy_1_1DummyRegressor_a2cde58a2b8e4881f3802c0f944df5d12}{sklearn.\+dummy.\+Dummy\+Regressor}}, \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__glm_1_1glm_1_1__GeneralizedLinearRegressor_a99c849640998478154423c389441f686}{sklearn.\+linear\+\_\+model.\+\_\+glm.\+glm.\+\_\+\+Generalized\+Linear\+Regressor}}, \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__ransac_1_1RANSACRegressor_aacdaefcb32ea60585f66f33a21b28321}{sklearn.\+linear\+\_\+model.\+\_\+ransac.\+RANSACRegressor}}, and \mbox{\hyperlink{classsklearn_1_1tests_1_1metadata__routing__common_1_1ConsumingRegressor_af72529e5abdb7cf5aeb9b6805b4a8192}{sklearn.\+tests.\+metadata\+\_\+routing\+\_\+common.\+Consuming\+Regressor}}.



Definition at line \mbox{\hyperlink{sklearn_2base_8py_source_l00595}{595}} of file \mbox{\hyperlink{sklearn_2base_8py_source}{base.\+py}}.



Referenced by \mbox{\hyperlink{__gaussian__mixture_8py_source_l00918}{sklearn.\+mixture.\+\_\+gaussian\+\_\+mixture.\+Gaussian\+Mixture.\+aic()}}, and \mbox{\hyperlink{__gaussian__mixture_8py_source_l00895}{sklearn.\+mixture.\+\_\+gaussian\+\_\+mixture.\+Gaussian\+Mixture.\+bic()}}.



\doxysubsection{Member Data Documentation}
\Hypertarget{classsklearn_1_1base_1_1RegressorMixin_aba1660973f816763e0ab74f0becd1a06}\index{sklearn.base.RegressorMixin@{sklearn.base.RegressorMixin}!\_estimator\_type@{\_estimator\_type}}
\index{\_estimator\_type@{\_estimator\_type}!sklearn.base.RegressorMixin@{sklearn.base.RegressorMixin}}
\doxysubsubsection{\texorpdfstring{\_estimator\_type}{\_estimator\_type}}
{\footnotesize\ttfamily \label{classsklearn_1_1base_1_1RegressorMixin_aba1660973f816763e0ab74f0becd1a06} 
str sklearn.\+base.\+Regressor\+Mixin.\+\_\+estimator\+\_\+type = "{}regressor"{}\hspace{0.3cm}{\ttfamily [static]}, {\ttfamily [protected]}}



Definition at line \mbox{\hyperlink{sklearn_2base_8py_source_l00586}{586}} of file \mbox{\hyperlink{sklearn_2base_8py_source}{base.\+py}}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/jam/\+Research/\+IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.\+12/site-\/packages/sklearn/base.\+py\end{DoxyCompactItemize}
