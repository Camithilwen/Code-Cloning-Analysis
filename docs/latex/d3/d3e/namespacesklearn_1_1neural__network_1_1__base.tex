\doxysection{sklearn.\+neural\+\_\+network.\+\_\+base Namespace Reference}
\hypertarget{namespacesklearn_1_1neural__network_1_1__base}{}\label{namespacesklearn_1_1neural__network_1_1__base}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_abd773b27e38652bd5e569fec7f5f3bfe}{inplace\+\_\+identity}} (X)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_ab91bc66088bad403c7c1a22a241453f6}{inplace\+\_\+exp}} (X)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a441c6cede976b16945f2295a2a858ae6}{inplace\+\_\+logistic}} (X)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a54e94c50758828317afc2623c8c624a9}{inplace\+\_\+tanh}} (X)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a741e5a1f3eca3a4edd15eb6aa7186274}{inplace\+\_\+relu}} (X)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a69172d11735085e9dac5b6334bd77082}{inplace\+\_\+softmax}} (X)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a3cf16c0a300ff34c77d0f22901389cdb}{inplace\+\_\+identity\+\_\+derivative}} (Z, delta)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a3acfc92f66a2b3046cb0c10d76784d5a}{inplace\+\_\+logistic\+\_\+derivative}} (Z, delta)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_ae8948759bb7486dc5810e7cf80a5da83}{inplace\+\_\+tanh\+\_\+derivative}} (Z, delta)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a1e296a7d51d41314b31657972d366c93}{inplace\+\_\+relu\+\_\+derivative}} (Z, delta)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_ae9be5d4bcb51c8839e63a94099a61065}{squared\+\_\+loss}} (y\+\_\+true, y\+\_\+pred, sample\+\_\+weight=None)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a9369de9ccc4948913061368c8681cf6a}{poisson\+\_\+loss}} (y\+\_\+true, y\+\_\+pred, sample\+\_\+weight=None)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_ae308c0d2c08b778c429f9b85abd7970e}{log\+\_\+loss}} (y\+\_\+true, y\+\_\+prob, sample\+\_\+weight=None)
\item 
\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_af549aff373374bde8608b8ede3399fcf}{binary\+\_\+log\+\_\+loss}} (y\+\_\+true, y\+\_\+prob, sample\+\_\+weight=None)
\end{DoxyCompactItemize}
\doxysubsubsection*{Variables}
\begin{DoxyCompactItemize}
\item 
dict \mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a3470f871309c2c25acf19e2c8e129176}{ACTIVATIONS}}
\item 
dict \mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a4debc5c7b65bc52decc4aef1a8866239}{DERIVATIVES}}
\item 
dict \mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__base_a782d13a30e8c639281a64505574724c3}{LOSS\+\_\+\+FUNCTIONS}}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Utilities for the neural network modules\end{DoxyVerb}
 

\doxysubsection{Function Documentation}
\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_af549aff373374bde8608b8ede3399fcf}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!binary\_log\_loss@{binary\_log\_loss}}
\index{binary\_log\_loss@{binary\_log\_loss}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{binary\_log\_loss()}{binary\_log\_loss()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_af549aff373374bde8608b8ede3399fcf} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+binary\+\_\+log\+\_\+loss (\begin{DoxyParamCaption}\item[{}]{y\+\_\+true}{, }\item[{}]{y\+\_\+prob}{, }\item[{}]{sample\+\_\+weight}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute binary logistic loss for classification.

This is identical to log_loss in binary classification case,
but is kept for its use in multilabel case.

Parameters
----------
y_true : array-like or label indicator matrix
    Ground truth (correct) labels.

y_prob : array-like of float, shape = (n_samples, 1)
    Predicted probabilities, as returned by a classifier's
    predict_proba method.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
loss : float
    The degree to which the samples are correctly predicted.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00250}{250}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_ab91bc66088bad403c7c1a22a241453f6}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!inplace\_exp@{inplace\_exp}}
\index{inplace\_exp@{inplace\_exp}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{inplace\_exp()}{inplace\_exp()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_ab91bc66088bad403c7c1a22a241453f6} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+inplace\+\_\+exp (\begin{DoxyParamCaption}\item[{}]{X}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute the exponential inplace.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    The input data.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00023}{23}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_abd773b27e38652bd5e569fec7f5f3bfe}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!inplace\_identity@{inplace\_identity}}
\index{inplace\_identity@{inplace\_identity}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{inplace\_identity()}{inplace\_identity()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_abd773b27e38652bd5e569fec7f5f3bfe} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+inplace\+\_\+identity (\begin{DoxyParamCaption}\item[{}]{X}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Simply leave the input array unchanged.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    Data, where `n_samples` is the number of samples
    and `n_features` is the number of features.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00011}{11}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a3cf16c0a300ff34c77d0f22901389cdb}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!inplace\_identity\_derivative@{inplace\_identity\_derivative}}
\index{inplace\_identity\_derivative@{inplace\_identity\_derivative}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{inplace\_identity\_derivative()}{inplace\_identity\_derivative()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a3cf16c0a300ff34c77d0f22901389cdb} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+inplace\+\_\+identity\+\_\+derivative (\begin{DoxyParamCaption}\item[{}]{Z}{, }\item[{}]{delta}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Apply the derivative of the identity function: do nothing.

Parameters
----------
Z : {array-like, sparse matrix}, shape (n_samples, n_features)
    The data which was output from the identity activation function during
    the forward pass.

delta : {array-like}, shape (n_samples, n_features)
     The backpropagated error signal to be modified inplace.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00090}{90}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a441c6cede976b16945f2295a2a858ae6}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!inplace\_logistic@{inplace\_logistic}}
\index{inplace\_logistic@{inplace\_logistic}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{inplace\_logistic()}{inplace\_logistic()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a441c6cede976b16945f2295a2a858ae6} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+inplace\+\_\+logistic (\begin{DoxyParamCaption}\item[{}]{X}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute the logistic function inplace.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    The input data.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00034}{34}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a3acfc92f66a2b3046cb0c10d76784d5a}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!inplace\_logistic\_derivative@{inplace\_logistic\_derivative}}
\index{inplace\_logistic\_derivative@{inplace\_logistic\_derivative}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{inplace\_logistic\_derivative()}{inplace\_logistic\_derivative()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a3acfc92f66a2b3046cb0c10d76784d5a} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+inplace\+\_\+logistic\+\_\+derivative (\begin{DoxyParamCaption}\item[{}]{Z}{, }\item[{}]{delta}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Apply the derivative of the logistic sigmoid function.

It exploits the fact that the derivative is a simple function of the output
value from logistic function.

Parameters
----------
Z : {array-like, sparse matrix}, shape (n_samples, n_features)
    The data which was output from the logistic activation function during
    the forward pass.

delta : {array-like}, shape (n_samples, n_features)
     The backpropagated error signal to be modified inplace.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00105}{105}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a741e5a1f3eca3a4edd15eb6aa7186274}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!inplace\_relu@{inplace\_relu}}
\index{inplace\_relu@{inplace\_relu}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{inplace\_relu()}{inplace\_relu()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a741e5a1f3eca3a4edd15eb6aa7186274} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+inplace\+\_\+relu (\begin{DoxyParamCaption}\item[{}]{X}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute the rectified linear unit function inplace.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    The input data.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00056}{56}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a1e296a7d51d41314b31657972d366c93}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!inplace\_relu\_derivative@{inplace\_relu\_derivative}}
\index{inplace\_relu\_derivative@{inplace\_relu\_derivative}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{inplace\_relu\_derivative()}{inplace\_relu\_derivative()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a1e296a7d51d41314b31657972d366c93} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+inplace\+\_\+relu\+\_\+derivative (\begin{DoxyParamCaption}\item[{}]{Z}{, }\item[{}]{delta}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Apply the derivative of the relu function.

It exploits the fact that the derivative is a simple function of the output
value from rectified linear units activation function.

Parameters
----------
Z : {array-like, sparse matrix}, shape (n_samples, n_features)
    The data which was output from the rectified linear units activation
    function during the forward pass.

delta : {array-like}, shape (n_samples, n_features)
     The backpropagated error signal to be modified inplace.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00142}{142}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a69172d11735085e9dac5b6334bd77082}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!inplace\_softmax@{inplace\_softmax}}
\index{inplace\_softmax@{inplace\_softmax}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{inplace\_softmax()}{inplace\_softmax()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a69172d11735085e9dac5b6334bd77082} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+inplace\+\_\+softmax (\begin{DoxyParamCaption}\item[{}]{X}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute the K-way softmax function inplace.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    The input data.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00067}{67}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a54e94c50758828317afc2623c8c624a9}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!inplace\_tanh@{inplace\_tanh}}
\index{inplace\_tanh@{inplace\_tanh}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{inplace\_tanh()}{inplace\_tanh()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a54e94c50758828317afc2623c8c624a9} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+inplace\+\_\+tanh (\begin{DoxyParamCaption}\item[{}]{X}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute the hyperbolic tan function inplace.

Parameters
----------
X : {array-like, sparse matrix}, shape (n_samples, n_features)
    The input data.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00045}{45}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_ae8948759bb7486dc5810e7cf80a5da83}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!inplace\_tanh\_derivative@{inplace\_tanh\_derivative}}
\index{inplace\_tanh\_derivative@{inplace\_tanh\_derivative}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{inplace\_tanh\_derivative()}{inplace\_tanh\_derivative()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_ae8948759bb7486dc5810e7cf80a5da83} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+inplace\+\_\+tanh\+\_\+derivative (\begin{DoxyParamCaption}\item[{}]{Z}{, }\item[{}]{delta}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Apply the derivative of the hyperbolic tanh function.

It exploits the fact that the derivative is a simple function of the output
value from hyperbolic tangent.

Parameters
----------
Z : {array-like, sparse matrix}, shape (n_samples, n_features)
    The data which was output from the hyperbolic tangent activation
    function during the forward pass.

delta : {array-like}, shape (n_samples, n_features)
     The backpropagated error signal to be modified inplace.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00124}{124}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_ae308c0d2c08b778c429f9b85abd7970e}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!log\_loss@{log\_loss}}
\index{log\_loss@{log\_loss}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{log\_loss()}{log\_loss()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_ae308c0d2c08b778c429f9b85abd7970e} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+log\+\_\+loss (\begin{DoxyParamCaption}\item[{}]{y\+\_\+true}{, }\item[{}]{y\+\_\+prob}{, }\item[{}]{sample\+\_\+weight}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute Logistic loss for classification.

Parameters
----------
y_true : array-like or label indicator matrix
    Ground truth (correct) labels.

y_prob : array-like of float, shape = (n_samples, n_classes)
    Predicted probabilities, as returned by a classifier's
    predict_proba method.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
loss : float
    The degree to which the samples are correctly predicted.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00219}{219}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a9369de9ccc4948913061368c8681cf6a}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!poisson\_loss@{poisson\_loss}}
\index{poisson\_loss@{poisson\_loss}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{poisson\_loss()}{poisson\_loss()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a9369de9ccc4948913061368c8681cf6a} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+poisson\+\_\+loss (\begin{DoxyParamCaption}\item[{}]{y\+\_\+true}{, }\item[{}]{y\+\_\+pred}{, }\item[{}]{sample\+\_\+weight}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute (half of the) Poisson deviance loss for regression.

Parameters
----------
y_true : array-like or label indicator matrix
    Ground truth (correct) labels.

y_pred : array-like or label indicator matrix
    Predicted values, as returned by a regression estimator.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
loss : float
    The degree to which the samples are correctly predicted.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00192}{192}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_ae9be5d4bcb51c8839e63a94099a61065}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!squared\_loss@{squared\_loss}}
\index{squared\_loss@{squared\_loss}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{squared\_loss()}{squared\_loss()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_ae9be5d4bcb51c8839e63a94099a61065} 
sklearn.\+neural\+\_\+network.\+\_\+base.\+squared\+\_\+loss (\begin{DoxyParamCaption}\item[{}]{y\+\_\+true}{, }\item[{}]{y\+\_\+pred}{, }\item[{}]{sample\+\_\+weight}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute the squared loss for regression.

Parameters
----------
y_true : array-like or label indicator matrix
    Ground truth (correct) values.

y_pred : array-like or label indicator matrix
    Predicted values, as returned by a regression estimator.

sample_weight : array-like of shape (n_samples,), default=None
    Sample weights.

Returns
-------
loss : float
    The degree to which the samples are correctly predicted.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00168}{168}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.



\doxysubsection{Variable Documentation}
\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a3470f871309c2c25acf19e2c8e129176}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!ACTIVATIONS@{ACTIVATIONS}}
\index{ACTIVATIONS@{ACTIVATIONS}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{ACTIVATIONS}{ACTIVATIONS}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a3470f871309c2c25acf19e2c8e129176} 
dict sklearn.\+neural\+\_\+network.\+\_\+base.\+ACTIVATIONS}

{\bfseries Initial value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{00001\ =\ \ \{}
\DoxyCodeLine{00002\ \ \ \ \ \textcolor{stringliteral}{"{}identity"{}}:\ inplace\_identity,}
\DoxyCodeLine{00003\ \ \ \ \ \textcolor{stringliteral}{"{}exp"{}}:\ inplace\_exp,}
\DoxyCodeLine{00004\ \ \ \ \ \textcolor{stringliteral}{"{}tanh"{}}:\ inplace\_tanh,}
\DoxyCodeLine{00005\ \ \ \ \ \textcolor{stringliteral}{"{}logistic"{}}:\ inplace\_logistic,}
\DoxyCodeLine{00006\ \ \ \ \ \textcolor{stringliteral}{"{}relu"{}}:\ inplace\_relu,}
\DoxyCodeLine{00007\ \ \ \ \ \textcolor{stringliteral}{"{}softmax"{}}:\ inplace\_softmax,}
\DoxyCodeLine{00008\ \}}

\end{DoxyCode}


Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00080}{80}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a4debc5c7b65bc52decc4aef1a8866239}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!DERIVATIVES@{DERIVATIVES}}
\index{DERIVATIVES@{DERIVATIVES}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{DERIVATIVES}{DERIVATIVES}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a4debc5c7b65bc52decc4aef1a8866239} 
dict sklearn.\+neural\+\_\+network.\+\_\+base.\+DERIVATIVES}

{\bfseries Initial value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{00001\ =\ \ \{}
\DoxyCodeLine{00002\ \ \ \ \ \textcolor{stringliteral}{"{}identity"{}}:\ inplace\_identity\_derivative,}
\DoxyCodeLine{00003\ \ \ \ \ \textcolor{stringliteral}{"{}tanh"{}}:\ inplace\_tanh\_derivative,}
\DoxyCodeLine{00004\ \ \ \ \ \textcolor{stringliteral}{"{}logistic"{}}:\ inplace\_logistic\_derivative,}
\DoxyCodeLine{00005\ \ \ \ \ \textcolor{stringliteral}{"{}relu"{}}:\ inplace\_relu\_derivative,}
\DoxyCodeLine{00006\ \}}

\end{DoxyCode}


Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00160}{160}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

\Hypertarget{namespacesklearn_1_1neural__network_1_1__base_a782d13a30e8c639281a64505574724c3}\index{sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}!LOSS\_FUNCTIONS@{LOSS\_FUNCTIONS}}
\index{LOSS\_FUNCTIONS@{LOSS\_FUNCTIONS}!sklearn.neural\_network.\_base@{sklearn.neural\_network.\_base}}
\doxysubsubsection{\texorpdfstring{LOSS\_FUNCTIONS}{LOSS\_FUNCTIONS}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1neural__network_1_1__base_a782d13a30e8c639281a64505574724c3} 
dict sklearn.\+neural\+\_\+network.\+\_\+base.\+LOSS\+\_\+\+FUNCTIONS}

{\bfseries Initial value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{00001\ =\ \ \{}
\DoxyCodeLine{00002\ \ \ \ \ \textcolor{stringliteral}{"{}squared\_error"{}}:\ squared\_loss,}
\DoxyCodeLine{00003\ \ \ \ \ \textcolor{stringliteral}{"{}poisson"{}}:\ poisson\_loss,}
\DoxyCodeLine{00004\ \ \ \ \ \textcolor{stringliteral}{"{}log\_loss"{}}:\ log\_loss,}
\DoxyCodeLine{00005\ \ \ \ \ \textcolor{stringliteral}{"{}binary\_log\_loss"{}}:\ binary\_log\_loss,}
\DoxyCodeLine{00006\ \}}

\end{DoxyCode}


Definition at line \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source_l00282}{282}} of file \mbox{\hyperlink{sklearn_2neural__network_2__base_8py_source}{\+\_\+base.\+py}}.

