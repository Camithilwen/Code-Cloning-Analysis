\doxysection{sklearn.\+utils.\+\_\+chunking Namespace Reference}
\hypertarget{namespacesklearn_1_1utils_1_1__chunking}{}\label{namespacesklearn_1_1utils_1_1__chunking}\index{sklearn.utils.\_chunking@{sklearn.utils.\_chunking}}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacesklearn_1_1utils_1_1__chunking_a7c2d42bf7f4a6d6222067d86467c7705}{chunk\+\_\+generator}} (gen, chunksize)
\item 
\mbox{\hyperlink{namespacesklearn_1_1utils_1_1__chunking_a7b92230aeed4e2604e2addd2f99fa964}{gen\+\_\+batches}} (n, batch\+\_\+size, \texorpdfstring{$\ast$}{*}, min\+\_\+batch\+\_\+size=0)
\item 
\mbox{\hyperlink{namespacesklearn_1_1utils_1_1__chunking_a25f33bf96fd18b8cab98dc0203aec29a}{gen\+\_\+even\+\_\+slices}} (n, n\+\_\+packs, \texorpdfstring{$\ast$}{*}, n\+\_\+samples=None)
\item 
\mbox{\hyperlink{namespacesklearn_1_1utils_1_1__chunking_af0fd706818cb8c25feb8e24403cd916b}{get\+\_\+chunk\+\_\+n\+\_\+rows}} (row\+\_\+bytes, \texorpdfstring{$\ast$}{*}, max\+\_\+n\+\_\+rows=None, working\+\_\+memory=None)
\end{DoxyCompactItemize}


\doxysubsection{Function Documentation}
\Hypertarget{namespacesklearn_1_1utils_1_1__chunking_a7c2d42bf7f4a6d6222067d86467c7705}\index{sklearn.utils.\_chunking@{sklearn.utils.\_chunking}!chunk\_generator@{chunk\_generator}}
\index{chunk\_generator@{chunk\_generator}!sklearn.utils.\_chunking@{sklearn.utils.\_chunking}}
\doxysubsubsection{\texorpdfstring{chunk\_generator()}{chunk\_generator()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1utils_1_1__chunking_a7c2d42bf7f4a6d6222067d86467c7705} 
sklearn.\+utils.\+\_\+chunking.\+chunk\+\_\+generator (\begin{DoxyParamCaption}\item[{}]{gen}{, }\item[{}]{chunksize}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Chunk generator, ``gen`` into lists of length ``chunksize``. The last
chunk may have a length less than ``chunksize``.\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__chunking_8py_source_l00014}{14}} of file \mbox{\hyperlink{__chunking_8py_source}{\+\_\+chunking.\+py}}.

\Hypertarget{namespacesklearn_1_1utils_1_1__chunking_a7b92230aeed4e2604e2addd2f99fa964}\index{sklearn.utils.\_chunking@{sklearn.utils.\_chunking}!gen\_batches@{gen\_batches}}
\index{gen\_batches@{gen\_batches}!sklearn.utils.\_chunking@{sklearn.utils.\_chunking}}
\doxysubsubsection{\texorpdfstring{gen\_batches()}{gen\_batches()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1utils_1_1__chunking_a7b92230aeed4e2604e2addd2f99fa964} 
sklearn.\+utils.\+\_\+chunking.\+gen\+\_\+batches (\begin{DoxyParamCaption}\item[{}]{n}{, }\item[{}]{batch\+\_\+size}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{min\+\_\+batch\+\_\+size}{ = {\ttfamily 0}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Generator to create slices containing `batch_size` elements from 0 to `n`.

The last slice may contain less than `batch_size` elements, when
`batch_size` does not divide `n`.

Parameters
----------
n : int
    Size of the sequence.
batch_size : int
    Number of elements in each batch.
min_batch_size : int, default=0
    Minimum number of elements in each batch.

Yields
------
slice of `batch_size` elements

See Also
--------
gen_even_slices: Generator to create n_packs slices going up to n.

Examples
--------
>>> from sklearn.utils import gen_batches
>>> list(gen_batches(7, 3))
[slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]
>>> list(gen_batches(6, 3))
[slice(0, 3, None), slice(3, 6, None)]
>>> list(gen_batches(2, 3))
[slice(0, 2, None)]
>>> list(gen_batches(7, 3, min_batch_size=0))
[slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]
>>> list(gen_batches(7, 3, min_batch_size=2))
[slice(0, 3, None), slice(3, 7, None)]
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__chunking_8py_source_l00033}{33}} of file \mbox{\hyperlink{__chunking_8py_source}{\+\_\+chunking.\+py}}.

\Hypertarget{namespacesklearn_1_1utils_1_1__chunking_a25f33bf96fd18b8cab98dc0203aec29a}\index{sklearn.utils.\_chunking@{sklearn.utils.\_chunking}!gen\_even\_slices@{gen\_even\_slices}}
\index{gen\_even\_slices@{gen\_even\_slices}!sklearn.utils.\_chunking@{sklearn.utils.\_chunking}}
\doxysubsubsection{\texorpdfstring{gen\_even\_slices()}{gen\_even\_slices()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1utils_1_1__chunking_a25f33bf96fd18b8cab98dc0203aec29a} 
sklearn.\+utils.\+\_\+chunking.\+gen\+\_\+even\+\_\+slices (\begin{DoxyParamCaption}\item[{}]{n}{, }\item[{}]{n\+\_\+packs}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{n\+\_\+samples}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Generator to create `n_packs` evenly spaced slices going up to `n`.

If `n_packs` does not divide `n`, except for the first `n % n_packs`
slices, remaining slices may contain fewer elements.

Parameters
----------
n : int
    Size of the sequence.
n_packs : int
    Number of slices to generate.
n_samples : int, default=None
    Number of samples. Pass `n_samples` when the slices are to be used for
    sparse matrix indexing; slicing off-the-end raises an exception, while
    it works for NumPy arrays.

Yields
------
`slice` representing a set of indices from 0 to n.

See Also
--------
gen_batches: Generator to create slices containing batch_size elements
    from 0 to n.

Examples
--------
>>> from sklearn.utils import gen_even_slices
>>> list(gen_even_slices(10, 1))
[slice(0, 10, None)]
>>> list(gen_even_slices(10, 10))
[slice(0, 1, None), slice(1, 2, None), ..., slice(9, 10, None)]
>>> list(gen_even_slices(10, 5))
[slice(0, 2, None), slice(2, 4, None), ..., slice(8, 10, None)]
>>> list(gen_even_slices(10, 3))
[slice(0, 4, None), slice(4, 7, None), slice(7, 10, None)]
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__chunking_8py_source_l00089}{89}} of file \mbox{\hyperlink{__chunking_8py_source}{\+\_\+chunking.\+py}}.

\Hypertarget{namespacesklearn_1_1utils_1_1__chunking_af0fd706818cb8c25feb8e24403cd916b}\index{sklearn.utils.\_chunking@{sklearn.utils.\_chunking}!get\_chunk\_n\_rows@{get\_chunk\_n\_rows}}
\index{get\_chunk\_n\_rows@{get\_chunk\_n\_rows}!sklearn.utils.\_chunking@{sklearn.utils.\_chunking}}
\doxysubsubsection{\texorpdfstring{get\_chunk\_n\_rows()}{get\_chunk\_n\_rows()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1utils_1_1__chunking_af0fd706818cb8c25feb8e24403cd916b} 
sklearn.\+utils.\+\_\+chunking.\+get\+\_\+chunk\+\_\+n\+\_\+rows (\begin{DoxyParamCaption}\item[{}]{row\+\_\+bytes}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{max\+\_\+n\+\_\+rows}{ = {\ttfamily None}, }\item[{}]{working\+\_\+memory}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Calculate how many rows can be processed within `working_memory`.

Parameters
----------
row_bytes : int
    The expected number of bytes of memory that will be consumed
    during the processing of each row.
max_n_rows : int, default=None
    The maximum return value.
working_memory : int or float, default=None
    The number of rows to fit inside this number of MiB will be
    returned. When None (default), the value of
    ``sklearn.get_config()['working_memory']`` is used.

Returns
-------
int
    The number of rows which can be processed within `working_memory`.

Warns
-----
Issues a UserWarning if `row_bytes exceeds `working_memory` MiB.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__chunking_8py_source_l00140}{140}} of file \mbox{\hyperlink{__chunking_8py_source}{\+\_\+chunking.\+py}}.

