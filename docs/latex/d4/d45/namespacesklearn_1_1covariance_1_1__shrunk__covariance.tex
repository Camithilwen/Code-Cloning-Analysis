\doxysection{sklearn.\+covariance.\+\_\+shrunk\+\_\+covariance Namespace Reference}
\hypertarget{namespacesklearn_1_1covariance_1_1__shrunk__covariance}{}\label{namespacesklearn_1_1covariance_1_1__shrunk__covariance}\index{sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}}
\doxysubsubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{classsklearn_1_1covariance_1_1__shrunk__covariance_1_1LedoitWolf}{Ledoit\+Wolf}}
\item 
class \mbox{\hyperlink{classsklearn_1_1covariance_1_1__shrunk__covariance_1_1OAS}{OAS}}
\item 
class \mbox{\hyperlink{classsklearn_1_1covariance_1_1__shrunk__covariance_1_1ShrunkCovariance}{Shrunk\+Covariance}}
\end{DoxyCompactItemize}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacesklearn_1_1covariance_1_1__shrunk__covariance_acc8fda222e3644301949d6c0074266b9}{\+\_\+ledoit\+\_\+wolf}} (X, \texorpdfstring{$\ast$}{*}, assume\+\_\+centered, block\+\_\+size)
\item 
\mbox{\hyperlink{namespacesklearn_1_1covariance_1_1__shrunk__covariance_a1aab57c784cdb1f0bde8e53e5fad6874}{\+\_\+oas}} (X, \texorpdfstring{$\ast$}{*}, assume\+\_\+centered=False)
\item 
\mbox{\hyperlink{namespacesklearn_1_1covariance_1_1__shrunk__covariance_a209d3d41c1355ac7f739fcddace238d8}{shrunk\+\_\+covariance}} (emp\+\_\+cov, shrinkage=0.\+1)
\begin{DoxyCompactList}\small\item\em Public API \doxylink{classsklearn_1_1covariance_1_1__shrunk__covariance_1_1ShrunkCovariance}{Shrunk\+Covariance} estimator. \end{DoxyCompactList}\item 
\mbox{\hyperlink{namespacesklearn_1_1covariance_1_1__shrunk__covariance_add11f8d21f68ce1d1a9bbe59a09d4248}{ledoit\+\_\+wolf\+\_\+shrinkage}} (X, assume\+\_\+centered=False, block\+\_\+size=1000)
\item 
\mbox{\hyperlink{namespacesklearn_1_1covariance_1_1__shrunk__covariance_a309742045bb2f34916b7fb24fcd668f6}{ledoit\+\_\+wolf}} (X, \texorpdfstring{$\ast$}{*}, assume\+\_\+centered=False, block\+\_\+size=1000)
\item 
\mbox{\hyperlink{namespacesklearn_1_1covariance_1_1__shrunk__covariance_af8b8e92e68f41a83b59e408263296eb1}{oas}} (X, \texorpdfstring{$\ast$}{*}, assume\+\_\+centered=False)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Covariance estimators using shrinkage.

Shrinkage corresponds to regularising `cov` using a convex combination:
shrunk_cov = (1-shrinkage)*cov + shrinkage*structured_estimate.
\end{DoxyVerb}
 

\doxysubsection{Function Documentation}
\Hypertarget{namespacesklearn_1_1covariance_1_1__shrunk__covariance_acc8fda222e3644301949d6c0074266b9}\index{sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}!\_ledoit\_wolf@{\_ledoit\_wolf}}
\index{\_ledoit\_wolf@{\_ledoit\_wolf}!sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}}
\doxysubsubsection{\texorpdfstring{\_ledoit\_wolf()}{\_ledoit\_wolf()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1covariance_1_1__shrunk__covariance_acc8fda222e3644301949d6c0074266b9} 
sklearn.\+covariance.\+\_\+shrunk\+\_\+covariance.\+\_\+ledoit\+\_\+wolf (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{assume\+\_\+centered}{, }\item[{}]{block\+\_\+size}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}

\begin{DoxyVerb}Estimate the shrunk Ledoit-Wolf covariance matrix.\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__shrunk__covariance_8py_source_l00025}{25}} of file \mbox{\hyperlink{__shrunk__covariance_8py_source}{\+\_\+shrunk\+\_\+covariance.\+py}}.



References \mbox{\hyperlink{__shrunk__covariance_8py_source_l00297}{ledoit\+\_\+wolf\+\_\+shrinkage()}}.



Referenced by \mbox{\hyperlink{__shrunk__covariance_8py_source_l00584}{sklearn.\+covariance.\+\_\+shrunk\+\_\+covariance.\+Ledoit\+Wolf.\+fit()}}.

\Hypertarget{namespacesklearn_1_1covariance_1_1__shrunk__covariance_a1aab57c784cdb1f0bde8e53e5fad6874}\index{sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}!\_oas@{\_oas}}
\index{\_oas@{\_oas}!sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}}
\doxysubsubsection{\texorpdfstring{\_oas()}{\_oas()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1covariance_1_1__shrunk__covariance_a1aab57c784cdb1f0bde8e53e5fad6874} 
sklearn.\+covariance.\+\_\+shrunk\+\_\+covariance.\+\_\+oas (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{assume\+\_\+centered}{ = {\ttfamily False}}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}

\begin{DoxyVerb}Estimate covariance with the Oracle Approximating Shrinkage algorithm.

The formulation is based on [1]_.
[1] "Shrinkage algorithms for MMSE covariance estimation.",
    Chen, Y., Wiesel, A., Eldar, Y. C., & Hero, A. O.
    IEEE Transactions on Signal Processing, 58(10), 5016-5029, 2010.
    https://arxiv.org/pdf/0907.4698.pdf
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__shrunk__covariance_8py_source_l00046}{46}} of file \mbox{\hyperlink{__shrunk__covariance_8py_source}{\+\_\+shrunk\+\_\+covariance.\+py}}.



Referenced by \mbox{\hyperlink{__shrunk__covariance_8py_source_l00794}{sklearn.\+covariance.\+\_\+shrunk\+\_\+covariance.\+OAS.\+fit()}}.

\Hypertarget{namespacesklearn_1_1covariance_1_1__shrunk__covariance_a309742045bb2f34916b7fb24fcd668f6}\index{sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}!ledoit\_wolf@{ledoit\_wolf}}
\index{ledoit\_wolf@{ledoit\_wolf}!sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}}
\doxysubsubsection{\texorpdfstring{ledoit\_wolf()}{ledoit\_wolf()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1covariance_1_1__shrunk__covariance_a309742045bb2f34916b7fb24fcd668f6} 
sklearn.\+covariance.\+\_\+shrunk\+\_\+covariance.\+ledoit\+\_\+wolf (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{assume\+\_\+centered}{ = {\ttfamily False}, }\item[{}]{block\+\_\+size}{ = {\ttfamily 1000}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Estimate the shrunk Ledoit-Wolf covariance matrix.

Read more in the :ref:`User Guide <shrunk_covariance>`.

Parameters
----------
X : array-like of shape (n_samples, n_features)
    Data from which to compute the covariance estimate.

assume_centered : bool, default=False
    If True, data will not be centered before computation.
    Useful to work with data whose mean is significantly equal to
    zero but is not exactly zero.
    If False, data will be centered before computation.

block_size : int, default=1000
    Size of blocks into which the covariance matrix will be split.
    This is purely a memory optimization and does not affect results.

Returns
-------
shrunk_cov : ndarray of shape (n_features, n_features)
    Shrunk covariance.

shrinkage : float
    Coefficient in the convex combination used for the computation
    of the shrunk estimate.

Notes
-----
The regularized (shrunk) covariance is:

(1 - shrinkage) * cov + shrinkage * mu * np.identity(n_features)

where mu = trace(cov) / n_features

Examples
--------
>>> import numpy as np
>>> from sklearn.covariance import empirical_covariance, ledoit_wolf
>>> real_cov = np.array([[.4, .2], [.2, .8]])
>>> rng = np.random.RandomState(0)
>>> X = rng.multivariate_normal(mean=[0, 0], cov=real_cov, size=50)
>>> covariance, shrinkage = ledoit_wolf(X)
>>> covariance
array([[0.44, 0.16],
       [0.16, 0.80]])
>>> shrinkage
np.float64(0.23)
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__shrunk__covariance_8py_source_l00407}{407}} of file \mbox{\hyperlink{__shrunk__covariance_8py_source}{\+\_\+shrunk\+\_\+covariance.\+py}}.

\Hypertarget{namespacesklearn_1_1covariance_1_1__shrunk__covariance_add11f8d21f68ce1d1a9bbe59a09d4248}\index{sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}!ledoit\_wolf\_shrinkage@{ledoit\_wolf\_shrinkage}}
\index{ledoit\_wolf\_shrinkage@{ledoit\_wolf\_shrinkage}!sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}}
\doxysubsubsection{\texorpdfstring{ledoit\_wolf\_shrinkage()}{ledoit\_wolf\_shrinkage()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1covariance_1_1__shrunk__covariance_add11f8d21f68ce1d1a9bbe59a09d4248} 
sklearn.\+covariance.\+\_\+shrunk\+\_\+covariance.\+ledoit\+\_\+wolf\+\_\+shrinkage (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{}]{assume\+\_\+centered}{ = {\ttfamily False}, }\item[{}]{block\+\_\+size}{ = {\ttfamily 1000}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Estimate the shrunk Ledoit-Wolf covariance matrix.

Read more in the :ref:`User Guide <shrunk_covariance>`.

Parameters
----------
X : array-like of shape (n_samples, n_features)
    Data from which to compute the Ledoit-Wolf shrunk covariance shrinkage.

assume_centered : bool, default=False
    If True, data will not be centered before computation.
    Useful to work with data whose mean is significantly equal to
    zero but is not exactly zero.
    If False, data will be centered before computation.

block_size : int, default=1000
    Size of blocks into which the covariance matrix will be split.

Returns
-------
shrinkage : float
    Coefficient in the convex combination used for the computation
    of the shrunk estimate.

Notes
-----
The regularized (shrunk) covariance is:

(1 - shrinkage) * cov + shrinkage * mu * np.identity(n_features)

where mu = trace(cov) / n_features

Examples
--------
>>> import numpy as np
>>> from sklearn.covariance import ledoit_wolf_shrinkage
>>> real_cov = np.array([[.4, .2], [.2, .8]])
>>> rng = np.random.RandomState(0)
>>> X = rng.multivariate_normal(mean=[0, 0], cov=real_cov, size=50)
>>> shrinkage_coefficient = ledoit_wolf_shrinkage(X)
>>> shrinkage_coefficient
np.float64(0.23)
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__shrunk__covariance_8py_source_l00297}{297}} of file \mbox{\hyperlink{__shrunk__covariance_8py_source}{\+\_\+shrunk\+\_\+covariance.\+py}}.



Referenced by \mbox{\hyperlink{__shrunk__covariance_8py_source_l00025}{\+\_\+ledoit\+\_\+wolf()}}.

\Hypertarget{namespacesklearn_1_1covariance_1_1__shrunk__covariance_af8b8e92e68f41a83b59e408263296eb1}\index{sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}!oas@{oas}}
\index{oas@{oas}!sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}}
\doxysubsubsection{\texorpdfstring{oas()}{oas()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1covariance_1_1__shrunk__covariance_af8b8e92e68f41a83b59e408263296eb1} 
sklearn.\+covariance.\+\_\+shrunk\+\_\+covariance.\+oas (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{assume\+\_\+centered}{ = {\ttfamily False}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Estimate covariance with the Oracle Approximating Shrinkage.

Read more in the :ref:`User Guide <shrunk_covariance>`.

Parameters
----------
X : array-like of shape (n_samples, n_features)
    Data from which to compute the covariance estimate.

assume_centered : bool, default=False
  If True, data will not be centered before computation.
  Useful to work with data whose mean is significantly equal to
  zero but is not exactly zero.
  If False, data will be centered before computation.

Returns
-------
shrunk_cov : array-like of shape (n_features, n_features)
    Shrunk covariance.

shrinkage : float
    Coefficient in the convex combination used for the computation
    of the shrunk estimate.

Notes
-----
The regularised covariance is:

(1 - shrinkage) * cov + shrinkage * mu * np.identity(n_features),

where mu = trace(cov) / n_features and shrinkage is given by the OAS formula
(see [1]_).

The shrinkage formulation implemented here differs from Eq. 23 in [1]_. In
the original article, formula (23) states that 2/p (p being the number of
features) is multiplied by Trace(cov*cov) in both the numerator and
denominator, but this operation is omitted because for a large p, the value
of 2/p is so small that it doesn't affect the value of the estimator.

References
----------
.. [1] :arxiv:`"Shrinkage algorithms for MMSE covariance estimation.",
       Chen, Y., Wiesel, A., Eldar, Y. C., & Hero, A. O.
       IEEE Transactions on Signal Processing, 58(10), 5016-5029, 2010.
       <0907.4698>`

Examples
--------
>>> import numpy as np
>>> from sklearn.covariance import oas
>>> rng = np.random.RandomState(0)
>>> real_cov = [[.8, .3], [.3, .4]]
>>> X = rng.multivariate_normal(mean=[0, 0], cov=real_cov, size=500)
>>> shrunk_cov, shrinkage = oas(X)
>>> shrunk_cov
array([[0.7533, 0.2763],
       [0.2763, 0.3964]])
>>> shrinkage
np.float64(0.0195)
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__shrunk__covariance_8py_source_l00621}{621}} of file \mbox{\hyperlink{__shrunk__covariance_8py_source}{\+\_\+shrunk\+\_\+covariance.\+py}}.

\Hypertarget{namespacesklearn_1_1covariance_1_1__shrunk__covariance_a209d3d41c1355ac7f739fcddace238d8}\index{sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}!shrunk\_covariance@{shrunk\_covariance}}
\index{shrunk\_covariance@{shrunk\_covariance}!sklearn.covariance.\_shrunk\_covariance@{sklearn.covariance.\_shrunk\_covariance}}
\doxysubsubsection{\texorpdfstring{shrunk\_covariance()}{shrunk\_covariance()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1covariance_1_1__shrunk__covariance_a209d3d41c1355ac7f739fcddace238d8} 
sklearn.\+covariance.\+\_\+shrunk\+\_\+covariance.\+shrunk\+\_\+covariance (\begin{DoxyParamCaption}\item[{}]{emp\+\_\+cov}{, }\item[{}]{shrinkage}{ = {\ttfamily 0.1}}\end{DoxyParamCaption})}



Public API \doxylink{classsklearn_1_1covariance_1_1__shrunk__covariance_1_1ShrunkCovariance}{Shrunk\+Covariance} estimator. 

\begin{DoxyVerb}Calculate covariance matrices shrunk on the diagonal.

Read more in the :ref:`User Guide <shrunk_covariance>`.

Parameters
----------
emp_cov : array-like of shape (..., n_features, n_features)
    Covariance matrices to be shrunk, at least 2D ndarray.

shrinkage : float, default=0.1
    Coefficient in the convex combination used for the computation
    of the shrunk estimate. Range is [0, 1].

Returns
-------
shrunk_cov : ndarray of shape (..., n_features, n_features)
    Shrunk covariance matrices.

Notes
-----
The regularized (shrunk) covariance is given by::

    (1 - shrinkage) * cov + shrinkage * mu * np.identity(n_features)

where `mu = trace(cov) / n_features`.

Examples
--------
>>> import numpy as np
>>> from sklearn.datasets import make_gaussian_quantiles
>>> from sklearn.covariance import empirical_covariance, shrunk_covariance
>>> real_cov = np.array([[.8, .3], [.3, .4]])
>>> rng = np.random.RandomState(0)
>>> X = rng.multivariate_normal(mean=[0, 0], cov=real_cov, size=500)
>>> shrunk_covariance(empirical_covariance(X))
array([[0.739, 0.254],
       [0.254, 0.411]])
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__shrunk__covariance_8py_source_l00109}{109}} of file \mbox{\hyperlink{__shrunk__covariance_8py_source}{\+\_\+shrunk\+\_\+covariance.\+py}}.



Referenced by \mbox{\hyperlink{__shrunk__covariance_8py_source_l00255}{sklearn.\+covariance.\+\_\+shrunk\+\_\+covariance.\+Shrunk\+Covariance.\+fit()}}.

