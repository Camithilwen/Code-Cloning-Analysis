\doxysection{test\+\_\+mlp.\+py}
\hypertarget{test__mlp_8py_source}{}\label{test__mlp_8py_source}\index{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/neural\_network/tests/test\_mlp.py@{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/neural\_network/tests/test\_mlp.py}}

\begin{DoxyCode}{0}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00001}\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp}{00001}}\ \textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00002}00002\ \textcolor{stringliteral}{Testing\ for\ Multi-\/layer\ Perceptron\ module\ (sklearn.neural\_network)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00003}00003\ \textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00004}00004\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00005}00005\ \textcolor{comment}{\#\ Authors:\ The\ scikit-\/learn\ developers}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00006}00006\ \textcolor{comment}{\#\ SPDX-\/License-\/Identifier:\ BSD-\/3-\/Clause}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00007}00007\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00008}00008\ \textcolor{keyword}{import}\ re}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00009}00009\ \textcolor{keyword}{import}\ sys}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00010}00010\ \textcolor{keyword}{import}\ warnings}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00011}00011\ \textcolor{keyword}{from}\ io\ \textcolor{keyword}{import}\ StringIO}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00012}00012\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00013}00013\ \textcolor{keyword}{import}\ joblib}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00014}00014\ \textcolor{keyword}{import}\ numpy\ \textcolor{keyword}{as}\ np}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00015}00015\ \textcolor{keyword}{import}\ pytest}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00016}00016\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00017}00017\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1datasets}{sklearn.datasets}}\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00018}00018\ \ \ \ \ load\_digits,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00019}00019\ \ \ \ \ load\_iris,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00020}00020\ \ \ \ \ make\_multilabel\_classification,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00021}00021\ \ \ \ \ make\_regression,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00022}00022\ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00023}00023\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1exceptions}{sklearn.exceptions}}\ \textcolor{keyword}{import}\ ConvergenceWarning}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00024}00024\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1linear__model}{sklearn.linear\_model}}\ \textcolor{keyword}{import}\ PoissonRegressor}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00025}00025\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1metrics}{sklearn.metrics}}\ \textcolor{keyword}{import}\ roc\_auc\_score}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00026}00026\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1neural__network}{sklearn.neural\_network}}\ \textcolor{keyword}{import}\ MLPClassifier,\ MLPRegressor}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00027}00027\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1preprocessing}{sklearn.preprocessing}}\ \textcolor{keyword}{import}\ LabelBinarizer,\ MinMaxScaler,\ scale}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00028}00028\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils_1_1__testing}{sklearn.utils.\_testing}}\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00029}00029\ \ \ \ \ assert\_allclose,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00030}00030\ \ \ \ \ assert\_almost\_equal,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00031}00031\ \ \ \ \ assert\_array\_equal,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00032}00032\ \ \ \ \ ignore\_warnings,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00033}00033\ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00034}00034\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils_1_1fixes}{sklearn.utils.fixes}}\ \textcolor{keyword}{import}\ CSR\_CONTAINERS}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00035}00035\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00036}00036\ ACTIVATION\_TYPES\ =\ [\textcolor{stringliteral}{"{}identity"{}},\ \textcolor{stringliteral}{"{}logistic"{}},\ \textcolor{stringliteral}{"{}tanh"{}},\ \textcolor{stringliteral}{"{}relu"{}}]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00037}00037\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00038}00038\ X\_digits,\ y\_digits\ =\ load\_digits(n\_class=3,\ return\_X\_y=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00039}00039\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00040}00040\ X\_digits\_multi\ =\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__data_1_1MinMaxScaler}{MinMaxScaler}}().fit\_transform(X\_digits[:200])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00041}00041\ y\_digits\_multi\ =\ y\_digits[:200]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00042}00042\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00043}00043\ X\_digits,\ y\_digits\ =\ load\_digits(n\_class=2,\ return\_X\_y=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00044}00044\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00045}00045\ X\_digits\_binary\ =\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__data_1_1MinMaxScaler}{MinMaxScaler}}().fit\_transform(X\_digits[:200])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00046}00046\ y\_digits\_binary\ =\ y\_digits[:200]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00047}00047\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00048}00048\ classification\_datasets\ =\ [}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00049}00049\ \ \ \ \ (X\_digits\_multi,\ y\_digits\_multi),}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00050}00050\ \ \ \ \ (X\_digits\_binary,\ y\_digits\_binary),}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00051}00051\ ]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00052}00052\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00053}00053\ X\_reg,\ y\_reg\ =\ make\_regression(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00054}00054\ \ \ \ \ n\_samples=200,\ n\_features=10,\ bias=20.0,\ noise=100.0,\ random\_state=7}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00055}00055\ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00056}00056\ y\_reg\ =\ scale(y\_reg)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00057}00057\ regression\_datasets\ =\ [(X\_reg,\ y\_reg)]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00058}00058\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00059}00059\ iris\ =\ load\_iris()}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00060}00060\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00061}00061\ X\_iris\ =\ iris.data}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00062}00062\ y\_iris\ =\ iris.target}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00063}00063\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00064}00064\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00065}00065\ \textcolor{keyword}{def\ }test\_alpha():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00066}00066\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ larger\ alpha\ yields\ weights\ closer\ to\ zero}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00067}00067\ \ \ \ \ X\ =\ X\_digits\_binary[:100]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00068}00068\ \ \ \ \ y\ =\ y\_digits\_binary[:100]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00069}00069\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00070}00070\ \ \ \ \ alpha\_vectors\ =\ []}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00071}00071\ \ \ \ \ alpha\_values\ =\ np.arange(2)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00072}00072\ \ \ \ \ absolute\_sum\ =\ \textcolor{keyword}{lambda}\ x:\ np.sum(np.abs(x))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00073}00073\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00074}00074\ \ \ \ \ \textcolor{keywordflow}{for}\ alpha\ \textcolor{keywordflow}{in}\ alpha\_values:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00075}00075\ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(hidden\_layer\_sizes=10,\ alpha=alpha,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00076}00076\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ ignore\_warnings(category=ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00077}00077\ \ \ \ \ \ \ \ \ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00078}00078\ \ \ \ \ \ \ \ \ alpha\_vectors.append(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00079}00079\ \ \ \ \ \ \ \ \ \ \ \ \ np.array([absolute\_sum(mlp.coefs\_[0]),\ absolute\_sum(mlp.coefs\_[1])])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00080}00080\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00081}00081\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00082}00082\ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(len(alpha\_values)\ -\/\ 1):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00083}00083\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ (alpha\_vectors[i]\ >\ alpha\_vectors[i\ +\ 1]).all()}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00084}00084\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00085}00085\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00086}00086\ \textcolor{keyword}{def\ }test\_fit():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00087}00087\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ the\ algorithm\ solution\ is\ equal\ to\ a\ worked\ out\ example.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00088}00088\ \ \ \ \ X\ =\ np.array([[0.6,\ 0.8,\ 0.7]])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00089}00089\ \ \ \ \ y\ =\ np.array([0])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00090}00090\ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00091}00091\ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}sgd"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00092}00092\ \ \ \ \ \ \ \ \ learning\_rate\_init=0.1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00093}00093\ \ \ \ \ \ \ \ \ alpha=0.1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00094}00094\ \ \ \ \ \ \ \ \ activation=\textcolor{stringliteral}{"{}logistic"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00095}00095\ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00096}00096\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00097}00097\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=2,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00098}00098\ \ \ \ \ \ \ \ \ momentum=0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00099}00099\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00100}00100\ \ \ \ \ \textcolor{comment}{\#\ set\ weights}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00101}00101\ \ \ \ \ mlp.coefs\_\ =\ [0]\ *\ 2}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00102}00102\ \ \ \ \ mlp.intercepts\_\ =\ [0]\ *\ 2}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00103}00103\ \ \ \ \ mlp.n\_outputs\_\ =\ 1}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00104}00104\ \ \ \ \ mlp.coefs\_[0]\ =\ np.array([[0.1,\ 0.2],\ [0.3,\ 0.1],\ [0.5,\ 0]])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00105}00105\ \ \ \ \ mlp.coefs\_[1]\ =\ np.array([[0.1],\ [0.2]])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00106}00106\ \ \ \ \ mlp.intercepts\_[0]\ =\ np.array([0.1,\ 0.1])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00107}00107\ \ \ \ \ mlp.intercepts\_[1]\ =\ np.array([1.0])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00108}00108\ \ \ \ \ mlp.\_coef\_grads\ =\ []\ *\ 2}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00109}00109\ \ \ \ \ mlp.\_intercept\_grads\ =\ []\ *\ 2}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00110}00110\ \ \ \ \ mlp.n\_features\_in\_\ =\ 3}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00111}00111\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00112}00112\ \ \ \ \ \textcolor{comment}{\#\ Initialize\ parameters}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00113}00113\ \ \ \ \ mlp.n\_iter\_\ =\ 0}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00114}00114\ \ \ \ \ mlp.learning\_rate\_\ =\ 0.1}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00115}00115\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00116}00116\ \ \ \ \ \textcolor{comment}{\#\ Compute\ the\ number\ of\ layers}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00117}00117\ \ \ \ \ mlp.n\_layers\_\ =\ 3}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00118}00118\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00119}00119\ \ \ \ \ \textcolor{comment}{\#\ Pre-\/allocate\ gradient\ matrices}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00120}00120\ \ \ \ \ mlp.\_coef\_grads\ =\ [0]\ *\ (mlp.n\_layers\_\ -\/\ 1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00121}00121\ \ \ \ \ mlp.\_intercept\_grads\ =\ [0]\ *\ (mlp.n\_layers\_\ -\/\ 1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00122}00122\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00123}00123\ \ \ \ \ mlp.out\_activation\_\ =\ \textcolor{stringliteral}{"{}logistic"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00124}00124\ \ \ \ \ mlp.t\_\ =\ 0}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00125}00125\ \ \ \ \ mlp.best\_loss\_\ =\ np.inf}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00126}00126\ \ \ \ \ mlp.loss\_curve\_\ =\ []}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00127}00127\ \ \ \ \ mlp.\_no\_improvement\_count\ =\ 0}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00128}00128\ \ \ \ \ mlp.\_intercept\_velocity\ =\ [}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00129}00129\ \ \ \ \ \ \ \ \ np.zeros\_like(intercepts)\ \textcolor{keywordflow}{for}\ intercepts\ \textcolor{keywordflow}{in}\ mlp.intercepts\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00130}00130\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00131}00131\ \ \ \ \ mlp.\_coef\_velocity\ =\ [np.zeros\_like(coefs)\ \textcolor{keywordflow}{for}\ coefs\ \textcolor{keywordflow}{in}\ mlp.coefs\_]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00132}00132\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00133}00133\ \ \ \ \ mlp.partial\_fit(X,\ y,\ classes=[0,\ 1])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00134}00134\ \ \ \ \ \textcolor{comment}{\#\ Manually\ worked\ out\ example}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00135}00135\ \ \ \ \ \textcolor{comment}{\#\ h1\ =\ g(X1\ *\ W\_i1\ +\ b11)\ =\ g(0.6\ *\ 0.1\ +\ 0.8\ *\ 0.3\ +\ 0.7\ *\ 0.5\ +\ 0.1)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00136}00136\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ =\ \ 0.679178699175393}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00137}00137\ \ \ \ \ \textcolor{comment}{\#\ h2\ =\ g(X2\ *\ W\_i2\ +\ b12)\ =\ g(0.6\ *\ 0.2\ +\ 0.8\ *\ 0.1\ +\ 0.7\ *\ 0\ +\ 0.1)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00138}00138\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ \ =\ 0.574442516811659}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00139}00139\ \ \ \ \ \textcolor{comment}{\#\ o1\ =\ g(h\ *\ W2\ +\ b21)\ =\ g(0.679\ *\ 0.1\ +\ 0.574\ *\ 0.2\ +\ 1)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00140}00140\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ =\ 0.7654329236196236}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00141}00141\ \ \ \ \ \textcolor{comment}{\#\ d21\ =\ -\/(0\ -\/\ 0.765)\ =\ 0.765}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00142}00142\ \ \ \ \ \textcolor{comment}{\#\ d11\ =\ (1\ -\/\ 0.679)\ *\ 0.679\ *\ 0.765\ *\ 0.1\ =\ 0.01667}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00143}00143\ \ \ \ \ \textcolor{comment}{\#\ d12\ =\ (1\ -\/\ 0.574)\ *\ 0.574\ *\ 0.765\ *\ 0.2\ =\ 0.0374}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00144}00144\ \ \ \ \ \textcolor{comment}{\#\ W1grad11\ =\ X1\ *\ d11\ +\ alpha\ *\ W11\ =\ 0.6\ *\ 0.01667\ +\ 0.1\ *\ 0.1\ =\ 0.0200}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00145}00145\ \ \ \ \ \textcolor{comment}{\#\ W1grad11\ =\ X1\ *\ d12\ +\ alpha\ *\ W12\ =\ 0.6\ *\ 0.0374\ +\ 0.1\ *\ 0.2\ =\ 0.04244}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00146}00146\ \ \ \ \ \textcolor{comment}{\#\ W1grad21\ =\ X2\ *\ d11\ +\ alpha\ *\ W13\ =\ 0.8\ *\ 0.01667\ +\ 0.1\ *\ 0.3\ =\ 0.043336}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00147}00147\ \ \ \ \ \textcolor{comment}{\#\ W1grad22\ =\ X2\ *\ d12\ +\ alpha\ *\ W14\ =\ 0.8\ *\ 0.0374\ +\ 0.1\ *\ 0.1\ =\ 0.03992}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00148}00148\ \ \ \ \ \textcolor{comment}{\#\ W1grad31\ =\ X3\ *\ d11\ +\ alpha\ *\ W15\ =\ 0.6\ *\ 0.01667\ +\ 0.1\ *\ 0.5\ =\ 0.060002}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00149}00149\ \ \ \ \ \textcolor{comment}{\#\ W1grad32\ =\ X3\ *\ d12\ +\ alpha\ *\ W16\ =\ 0.6\ *\ 0.0374\ +\ 0.1\ *\ 0\ =\ 0.02244}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00150}00150\ \ \ \ \ \textcolor{comment}{\#\ W2grad1\ =\ h1\ *\ d21\ +\ alpha\ *\ W21\ =\ 0.679\ *\ 0.765\ +\ 0.1\ *\ 0.1\ =\ 0.5294}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00151}00151\ \ \ \ \ \textcolor{comment}{\#\ W2grad2\ =\ h2\ *\ d21\ +\ alpha\ *\ W22\ =\ 0.574\ *\ 0.765\ +\ 0.1\ *\ 0.2\ =\ 0.45911}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00152}00152\ \ \ \ \ \textcolor{comment}{\#\ b1grad1\ =\ d11\ =\ 0.01667}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00153}00153\ \ \ \ \ \textcolor{comment}{\#\ b1grad2\ =\ d12\ =\ 0.0374}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00154}00154\ \ \ \ \ \textcolor{comment}{\#\ b2grad\ =\ d21\ =\ 0.765}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00155}00155\ \ \ \ \ \textcolor{comment}{\#\ W1\ =\ W1\ -\/\ eta\ *\ [W1grad11,\ ..,\ W1grad32]\ =\ [[0.1,\ 0.2],\ [0.3,\ 0.1],}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00156}00156\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ \ \ [0.5,\ 0]]\ -\/\ 0.1\ *\ [[0.0200,\ 0.04244],\ [0.043336,\ 0.03992],}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00157}00157\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ \ \ [0.060002,\ 0.02244]]\ =\ [[0.098,\ 0.195756],\ [0.2956664,}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00158}00158\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ \ \ 0.096008],\ [0.4939998,\ -\/0.002244]]}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00159}00159\ \ \ \ \ \textcolor{comment}{\#\ W2\ =\ W2\ -\/\ eta\ *\ [W2grad1,\ W2grad2]\ =\ [[0.1],\ [0.2]]\ -\/\ 0.1\ *}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00160}00160\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ [[0.5294],\ [0.45911]]\ =\ [[0.04706],\ [0.154089]]}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00161}00161\ \ \ \ \ \textcolor{comment}{\#\ b1\ =\ b1\ -\/\ eta\ *\ [b1grad1,\ b1grad2]\ =\ 0.1\ -\/\ 0.1\ *\ [0.01667,\ 0.0374]}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00162}00162\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ \ =\ [0.098333,\ 0.09626]}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00163}00163\ \ \ \ \ \textcolor{comment}{\#\ b2\ =\ b2\ -\/\ eta\ *\ b2grad\ =\ 1.0\ -\/\ 0.1\ *\ 0.765\ =\ 0.9235}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00164}00164\ \ \ \ \ assert\_almost\_equal(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00165}00165\ \ \ \ \ \ \ \ \ mlp.coefs\_[0],}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00166}00166\ \ \ \ \ \ \ \ \ np.array([[0.098,\ 0.195756],\ [0.2956664,\ 0.096008],\ [0.4939998,\ -\/0.002244]]),}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00167}00167\ \ \ \ \ \ \ \ \ decimal=3,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00168}00168\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00169}00169\ \ \ \ \ assert\_almost\_equal(mlp.coefs\_[1],\ np.array([[0.04706],\ [0.154089]]),\ decimal=3)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00170}00170\ \ \ \ \ assert\_almost\_equal(mlp.intercepts\_[0],\ np.array([0.098333,\ 0.09626]),\ decimal=3)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00171}00171\ \ \ \ \ assert\_almost\_equal(mlp.intercepts\_[1],\ np.array(0.9235),\ decimal=3)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00172}00172\ \ \ \ \ \textcolor{comment}{\#\ Testing\ output}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00173}00173\ \ \ \ \ \textcolor{comment}{\#\ \ h1\ =\ g(X1\ *\ W\_i1\ +\ b11)\ =\ g(0.6\ *\ 0.098\ +\ 0.8\ *\ 0.2956664\ +}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00174}00174\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 0.7\ *\ 0.4939998\ +\ 0.098333)\ =\ 0.677}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00175}00175\ \ \ \ \ \textcolor{comment}{\#\ \ h2\ =\ g(X2\ *\ W\_i2\ +\ b12)\ =\ g(0.6\ *\ 0.195756\ +\ 0.8\ *\ 0.096008\ +}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00176}00176\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ \ \ \ \ 0.7\ *\ -\/0.002244\ +\ 0.09626)\ =\ 0.572}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00177}00177\ \ \ \ \ \textcolor{comment}{\#\ \ o1\ =\ h\ *\ W2\ +\ b21\ =\ 0.677\ *\ 0.04706\ +}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00178}00178\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ \ \ \ \ \ 0.572\ *\ 0.154089\ +\ 0.9235\ =\ 1.043}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00179}00179\ \ \ \ \ \textcolor{comment}{\#\ \ prob\ =\ sigmoid(o1)\ =\ 0.739}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00180}00180\ \ \ \ \ assert\_almost\_equal(mlp.predict\_proba(X)[0,\ 1],\ 0.739,\ decimal=3)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00181}00181\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00182}00182\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00183}00183\ \textcolor{keyword}{def\ }test\_gradient():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00184}00184\ \ \ \ \ \textcolor{comment}{\#\ Test\ gradient.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00185}00185\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00186}00186\ \ \ \ \ \textcolor{comment}{\#\ This\ makes\ sure\ that\ the\ activation\ functions\ and\ their\ derivatives}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00187}00187\ \ \ \ \ \textcolor{comment}{\#\ are\ correct.\ The\ numerical\ and\ analytical\ computation\ of\ the\ gradient}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00188}00188\ \ \ \ \ \textcolor{comment}{\#\ should\ be\ close.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00189}00189\ \ \ \ \ \textcolor{keywordflow}{for}\ n\_labels\ \textcolor{keywordflow}{in}\ [2,\ 3]:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00190}00190\ \ \ \ \ \ \ \ \ n\_samples\ =\ 5}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00191}00191\ \ \ \ \ \ \ \ \ n\_features\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00192}00192\ \ \ \ \ \ \ \ \ random\_state\ =\ np.random.RandomState(seed=42)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00193}00193\ \ \ \ \ \ \ \ \ X\ =\ random\_state.rand(n\_samples,\ n\_features)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00194}00194\ \ \ \ \ \ \ \ \ y\ =\ 1\ +\ np.mod(np.arange(n\_samples)\ +\ 1,\ n\_labels)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00195}00195\ \ \ \ \ \ \ \ \ Y\ =\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__label_1_1LabelBinarizer}{LabelBinarizer}}().fit\_transform(y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00196}00196\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00197}00197\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ activation\ \textcolor{keywordflow}{in}\ ACTIVATION\_TYPES:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00198}00198\ \ \ \ \ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00199}00199\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ activation=activation,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00200}00200\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=10,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00201}00201\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}lbfgs"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00202}00202\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ alpha=1e-\/5,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00203}00203\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ learning\_rate\_init=0.2,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00204}00204\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00205}00205\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00206}00206\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00207}00207\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00208}00208\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}ignore"{}},\ ConvergenceWarning)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00209}00209\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00210}00210\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00211}00211\ \ \ \ \ \ \ \ \ \ \ \ \ theta\ =\ np.hstack([l.ravel()\ \textcolor{keywordflow}{for}\ l\ \textcolor{keywordflow}{in}\ mlp.coefs\_\ +\ mlp.intercepts\_])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00212}00212\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00213}00213\ \ \ \ \ \ \ \ \ \ \ \ \ layer\_units\ =\ [X.shape[1]]\ +\ [mlp.hidden\_layer\_sizes]\ +\ [mlp.n\_outputs\_]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00214}00214\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00215}00215\ \ \ \ \ \ \ \ \ \ \ \ \ activations\ =\ []}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00216}00216\ \ \ \ \ \ \ \ \ \ \ \ \ deltas\ =\ []}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00217}00217\ \ \ \ \ \ \ \ \ \ \ \ \ coef\_grads\ =\ []}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00218}00218\ \ \ \ \ \ \ \ \ \ \ \ \ intercept\_grads\ =\ []}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00219}00219\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00220}00220\ \ \ \ \ \ \ \ \ \ \ \ \ activations.append(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00221}00221\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(mlp.n\_layers\_\ -\/\ 1):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00222}00222\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ activations.append(np.empty((X.shape[0],\ layer\_units[i\ +\ 1])))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00223}00223\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ deltas.append(np.empty((X.shape[0],\ layer\_units[i\ +\ 1])))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00224}00224\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00225}00225\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ fan\_in\ =\ layer\_units[i]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00226}00226\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ fan\_out\ =\ layer\_units[i\ +\ 1]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00227}00227\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ coef\_grads.append(np.empty((fan\_in,\ fan\_out)))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00228}00228\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ intercept\_grads.append(np.empty(fan\_out))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00229}00229\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00230}00230\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ analytically\ compute\ the\ gradients}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00231}00231\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{def\ }loss\_grad\_fun(t):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00232}00232\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ mlp.\_loss\_grad\_lbfgs(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00233}00233\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ t,\ X,\ Y,\ \textcolor{keywordtype}{None},\ activations,\ deltas,\ coef\_grads,\ intercept\_grads}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00234}00234\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00235}00235\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00236}00236\ \ \ \ \ \ \ \ \ \ \ \ \ [value,\ grad]\ =\ loss\_grad\_fun(theta)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00237}00237\ \ \ \ \ \ \ \ \ \ \ \ \ numgrad\ =\ np.zeros(np.size(theta))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00238}00238\ \ \ \ \ \ \ \ \ \ \ \ \ n\ =\ np.size(theta,\ 0)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00239}00239\ \ \ \ \ \ \ \ \ \ \ \ \ E\ =\ np.eye(n)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00240}00240\ \ \ \ \ \ \ \ \ \ \ \ \ epsilon\ =\ 1e-\/5}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00241}00241\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ numerically\ compute\ the\ gradients}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00242}00242\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(n):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00243}00243\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ dtheta\ =\ E[:,\ i]\ *\ epsilon}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00244}00244\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ numgrad[i]\ =\ (}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00245}00245\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ loss\_grad\_fun(theta\ +\ dtheta)[0]\ -\/\ loss\_grad\_fun(theta\ -\/\ dtheta)[0]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00246}00246\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )\ /\ (epsilon\ *\ 2.0)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00247}00247\ \ \ \ \ \ \ \ \ \ \ \ \ assert\_almost\_equal(numgrad,\ grad)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00248}00248\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00249}00249\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00250}00250\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}X,y"{},\ classification\_datasets)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00251}00251\ \textcolor{keyword}{def\ }test\_lbfgs\_classification(X,\ y):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00252}00252\ \ \ \ \ \textcolor{comment}{\#\ Test\ lbfgs\ on\ classification.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00253}00253\ \ \ \ \ \textcolor{comment}{\#\ It\ should\ achieve\ a\ score\ higher\ than\ 0.95\ for\ the\ binary\ and\ multi-\/class}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00254}00254\ \ \ \ \ \textcolor{comment}{\#\ versions\ of\ the\ digits\ dataset.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00255}00255\ \ \ \ \ X\_train\ =\ X[:150]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00256}00256\ \ \ \ \ y\_train\ =\ y[:150]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00257}00257\ \ \ \ \ X\_test\ =\ X[150:]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00258}00258\ \ \ \ \ expected\_shape\_dtype\ =\ (X\_test.shape[0],\ y\_train.dtype.kind)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00259}00259\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00260}00260\ \ \ \ \ \textcolor{keywordflow}{for}\ activation\ \textcolor{keywordflow}{in}\ ACTIVATION\_TYPES:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00261}00261\ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00262}00262\ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}lbfgs"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00263}00263\ \ \ \ \ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=50,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00264}00264\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=150,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00265}00265\ \ \ \ \ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00266}00266\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00267}00267\ \ \ \ \ \ \ \ \ \ \ \ \ activation=activation,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00268}00268\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00269}00269\ \ \ \ \ \ \ \ \ mlp.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00270}00270\ \ \ \ \ \ \ \ \ y\_predict\ =\ mlp.predict(X\_test)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00271}00271\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ mlp.score(X\_train,\ y\_train)\ >\ 0.95}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00272}00272\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ (y\_predict.shape[0],\ y\_predict.dtype.kind)\ ==\ expected\_shape\_dtype}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00273}00273\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00274}00274\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00275}00275\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}X,y"{},\ regression\_datasets)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00276}00276\ \textcolor{keyword}{def\ }test\_lbfgs\_regression(X,\ y):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00277}00277\ \ \ \ \ \textcolor{comment}{\#\ Test\ lbfgs\ on\ the\ regression\ dataset.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00278}00278\ \ \ \ \ \textcolor{keywordflow}{for}\ activation\ \textcolor{keywordflow}{in}\ ACTIVATION\_TYPES:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00279}00279\ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00280}00280\ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}lbfgs"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00281}00281\ \ \ \ \ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=50,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00282}00282\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=200,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00283}00283\ \ \ \ \ \ \ \ \ \ \ \ \ tol=1e-\/3,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00284}00284\ \ \ \ \ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00285}00285\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00286}00286\ \ \ \ \ \ \ \ \ \ \ \ \ activation=activation,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00287}00287\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00288}00288\ \ \ \ \ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00289}00289\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ activation\ ==\ \textcolor{stringliteral}{"{}identity"{}}:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00290}00290\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ mlp.score(X,\ y)\ >\ 0.80}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00291}00291\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00292}00292\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Non\ linear\ models\ perform\ much\ better\ than\ linear\ bottleneck:}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00293}00293\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ mlp.score(X,\ y)\ >\ 0.98}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00294}00294\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00295}00295\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00296}00296\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}X,y"{},\ classification\_datasets)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00297}00297\ \textcolor{keyword}{def\ }test\_lbfgs\_classification\_maxfun(X,\ y):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00298}00298\ \ \ \ \ \textcolor{comment}{\#\ Test\ lbfgs\ parameter\ max\_fun.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00299}00299\ \ \ \ \ \textcolor{comment}{\#\ It\ should\ independently\ limit\ the\ number\ of\ iterations\ for\ lbfgs.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00300}00300\ \ \ \ \ max\_fun\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00301}00301\ \ \ \ \ \textcolor{comment}{\#\ classification\ tests}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00302}00302\ \ \ \ \ \textcolor{keywordflow}{for}\ activation\ \textcolor{keywordflow}{in}\ ACTIVATION\_TYPES:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00303}00303\ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00304}00304\ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}lbfgs"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00305}00305\ \ \ \ \ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=50,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00306}00306\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=150,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00307}00307\ \ \ \ \ \ \ \ \ \ \ \ \ max\_fun=max\_fun,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00308}00308\ \ \ \ \ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00309}00309\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00310}00310\ \ \ \ \ \ \ \ \ \ \ \ \ activation=activation,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00311}00311\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00312}00312\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ pytest.warns(ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00313}00313\ \ \ \ \ \ \ \ \ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00314}00314\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ max\_fun\ >=\ mlp.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00315}00315\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00316}00316\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00317}00317\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}X,y"{},\ regression\_datasets)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00318}00318\ \textcolor{keyword}{def\ }test\_lbfgs\_regression\_maxfun(X,\ y):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00319}00319\ \ \ \ \ \textcolor{comment}{\#\ Test\ lbfgs\ parameter\ max\_fun.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00320}00320\ \ \ \ \ \textcolor{comment}{\#\ It\ should\ independently\ limit\ the\ number\ of\ iterations\ for\ lbfgs.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00321}00321\ \ \ \ \ max\_fun\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00322}00322\ \ \ \ \ \textcolor{comment}{\#\ regression\ tests}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00323}00323\ \ \ \ \ \textcolor{keywordflow}{for}\ activation\ \textcolor{keywordflow}{in}\ ACTIVATION\_TYPES:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00324}00324\ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00325}00325\ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}lbfgs"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00326}00326\ \ \ \ \ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=50,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00327}00327\ \ \ \ \ \ \ \ \ \ \ \ \ tol=0.0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00328}00328\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=150,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00329}00329\ \ \ \ \ \ \ \ \ \ \ \ \ max\_fun=max\_fun,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00330}00330\ \ \ \ \ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00331}00331\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00332}00332\ \ \ \ \ \ \ \ \ \ \ \ \ activation=activation,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00333}00333\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00334}00334\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ pytest.warns(ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00335}00335\ \ \ \ \ \ \ \ \ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00336}00336\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ max\_fun\ >=\ mlp.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00337}00337\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00338}00338\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00339}00339\ \textcolor{keyword}{def\ }test\_learning\_rate\_warmstart():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00340}00340\ \ \ \ \ \textcolor{comment}{\#\ Tests\ that\ warm\_start\ reuse\ past\ solutions.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00341}00341\ \ \ \ \ X\ =\ [[3,\ 2],\ [1,\ 6],\ [5,\ 6],\ [-\/2,\ -\/4]]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00342}00342\ \ \ \ \ y\ =\ [1,\ 1,\ 1,\ 0]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00343}00343\ \ \ \ \ \textcolor{keywordflow}{for}\ learning\_rate\ \textcolor{keywordflow}{in}\ [\textcolor{stringliteral}{"{}invscaling"{}},\ \textcolor{stringliteral}{"{}constant"{}}]:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00344}00344\ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00345}00345\ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}sgd"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00346}00346\ \ \ \ \ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=4,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00347}00347\ \ \ \ \ \ \ \ \ \ \ \ \ learning\_rate=learning\_rate,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00348}00348\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00349}00349\ \ \ \ \ \ \ \ \ \ \ \ \ power\_t=0.25,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00350}00350\ \ \ \ \ \ \ \ \ \ \ \ \ warm\_start=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00351}00351\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00352}00352\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ ignore\_warnings(category=ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00353}00353\ \ \ \ \ \ \ \ \ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00354}00354\ \ \ \ \ \ \ \ \ \ \ \ \ prev\_eta\ =\ mlp.\_optimizer.learning\_rate}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00355}00355\ \ \ \ \ \ \ \ \ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00356}00356\ \ \ \ \ \ \ \ \ \ \ \ \ post\_eta\ =\ mlp.\_optimizer.learning\_rate}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00357}00357\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00358}00358\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ learning\_rate\ ==\ \textcolor{stringliteral}{"{}constant"{}}:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00359}00359\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ prev\_eta\ ==\ post\_eta}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00360}00360\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{elif}\ learning\_rate\ ==\ \textcolor{stringliteral}{"{}invscaling"{}}:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00361}00361\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ mlp.learning\_rate\_init\ /\ pow(8\ +\ 1,\ mlp.power\_t)\ ==\ post\_eta}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00362}00362\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00363}00363\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00364}00364\ \textcolor{keyword}{def\ }test\_multilabel\_classification():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00365}00365\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ multi-\/label\ classification\ works\ as\ expected.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00366}00366\ \ \ \ \ \textcolor{comment}{\#\ test\ fit\ method}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00367}00367\ \ \ \ \ X,\ y\ =\ make\_multilabel\_classification(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00368}00368\ \ \ \ \ \ \ \ \ n\_samples=50,\ random\_state=0,\ return\_indicator=\textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00369}00369\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00370}00370\ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00371}00371\ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}lbfgs"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00372}00372\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=50,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00373}00373\ \ \ \ \ \ \ \ \ alpha=1e-\/5,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00374}00374\ \ \ \ \ \ \ \ \ max\_iter=150,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00375}00375\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00376}00376\ \ \ \ \ \ \ \ \ activation=\textcolor{stringliteral}{"{}logistic"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00377}00377\ \ \ \ \ \ \ \ \ learning\_rate\_init=0.2,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00378}00378\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00379}00379\ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00380}00380\ \ \ \ \ \textcolor{keyword}{assert}\ mlp.score(X,\ y)\ >\ 0.97}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00381}00381\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00382}00382\ \ \ \ \ \textcolor{comment}{\#\ test\ partial\ fit\ method}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00383}00383\ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00384}00384\ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}sgd"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00385}00385\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=50,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00386}00386\ \ \ \ \ \ \ \ \ max\_iter=150,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00387}00387\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00388}00388\ \ \ \ \ \ \ \ \ activation=\textcolor{stringliteral}{"{}logistic"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00389}00389\ \ \ \ \ \ \ \ \ alpha=1e-\/5,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00390}00390\ \ \ \ \ \ \ \ \ learning\_rate\_init=0.2,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00391}00391\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00392}00392\ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(100):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00393}00393\ \ \ \ \ \ \ \ \ mlp.partial\_fit(X,\ y,\ classes=[0,\ 1,\ 2,\ 3,\ 4])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00394}00394\ \ \ \ \ \textcolor{keyword}{assert}\ mlp.score(X,\ y)\ >\ 0.9}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00395}00395\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00396}00396\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ early\ stopping\ still\ work\ now\ that\ splitting\ is\ stratified\ by}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00397}00397\ \ \ \ \ \textcolor{comment}{\#\ default\ (it\ is\ disabled\ for\ multilabel\ classification)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00398}00398\ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(early\_stopping=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00399}00399\ \ \ \ \ mlp.fit(X,\ y).predict(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00400}00400\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00401}00401\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00402}00402\ \textcolor{keyword}{def\ }test\_multioutput\_regression():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00403}00403\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ multi-\/output\ regression\ works\ as\ expected}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00404}00404\ \ \ \ \ X,\ y\ =\ make\_regression(n\_samples=200,\ n\_targets=5,\ random\_state=11)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00405}00405\ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00406}00406\ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}lbfgs"{}},\ hidden\_layer\_sizes=50,\ max\_iter=200,\ tol=1e-\/2,\ random\_state=1}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00407}00407\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00408}00408\ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00409}00409\ \ \ \ \ \textcolor{keyword}{assert}\ mlp.score(X,\ y)\ >\ 0.9}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00410}00410\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00411}00411\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00412}00412\ \textcolor{keyword}{def\ }test\_partial\_fit\_classes\_error():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00413}00413\ \ \ \ \ \textcolor{comment}{\#\ Tests\ that\ passing\ different\ classes\ to\ partial\_fit\ raises\ an\ error}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00414}00414\ \ \ \ \ X\ =\ [[3,\ 2]]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00415}00415\ \ \ \ \ y\ =\ [0]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00416}00416\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(solver=\textcolor{stringliteral}{"{}sgd"{}})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00417}00417\ \ \ \ \ clf.partial\_fit(X,\ y,\ classes=[0,\ 1])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00418}00418\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00419}00419\ \ \ \ \ \ \ \ \ clf.partial\_fit(X,\ y,\ classes=[1,\ 2])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00420}00420\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00421}00421\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00422}00422\ \textcolor{keyword}{def\ }test\_partial\_fit\_classification():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00423}00423\ \ \ \ \ \textcolor{comment}{\#\ Test\ partial\_fit\ on\ classification.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00424}00424\ \ \ \ \ \textcolor{comment}{\#\ \`{}partial\_fit`\ should\ yield\ the\ same\ results\ as\ 'fit'\ for\ binary\ and}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00425}00425\ \ \ \ \ \textcolor{comment}{\#\ multi-\/class\ classification.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00426}00426\ \ \ \ \ \textcolor{keywordflow}{for}\ X,\ y\ \textcolor{keywordflow}{in}\ classification\_datasets:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00427}00427\ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00428}00428\ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}sgd"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00429}00429\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=100,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00430}00430\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00431}00431\ \ \ \ \ \ \ \ \ \ \ \ \ tol=0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00432}00432\ \ \ \ \ \ \ \ \ \ \ \ \ alpha=1e-\/5,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00433}00433\ \ \ \ \ \ \ \ \ \ \ \ \ learning\_rate\_init=0.2,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00434}00434\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00435}00435\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00436}00436\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ ignore\_warnings(category=ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00437}00437\ \ \ \ \ \ \ \ \ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00438}00438\ \ \ \ \ \ \ \ \ pred1\ =\ mlp.predict(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00439}00439\ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00440}00440\ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}sgd"{}},\ random\_state=1,\ alpha=1e-\/5,\ learning\_rate\_init=0.2}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00441}00441\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00442}00442\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(100):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00443}00443\ \ \ \ \ \ \ \ \ \ \ \ \ mlp.partial\_fit(X,\ y,\ classes=np.unique(y))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00444}00444\ \ \ \ \ \ \ \ \ pred2\ =\ mlp.predict(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00445}00445\ \ \ \ \ \ \ \ \ assert\_array\_equal(pred1,\ pred2)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00446}00446\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ mlp.score(X,\ y)\ >\ 0.95}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00447}00447\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00448}00448\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00449}00449\ \textcolor{keyword}{def\ }test\_partial\_fit\_unseen\_classes():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00450}00450\ \ \ \ \ \textcolor{comment}{\#\ Non\ regression\ test\ for\ bug\ 6994}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00451}00451\ \ \ \ \ \textcolor{comment}{\#\ Tests\ for\ labeling\ errors\ in\ partial\ fit}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00452}00452\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00453}00453\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(random\_state=0)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00454}00454\ \ \ \ \ clf.partial\_fit([[1],\ [2],\ [3]],\ [\textcolor{stringliteral}{"{}a"{}},\ \textcolor{stringliteral}{"{}b"{}},\ \textcolor{stringliteral}{"{}c"{}}],\ classes=[\textcolor{stringliteral}{"{}a"{}},\ \textcolor{stringliteral}{"{}b"{}},\ \textcolor{stringliteral}{"{}c"{}},\ \textcolor{stringliteral}{"{}d"{}}])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00455}00455\ \ \ \ \ clf.partial\_fit([[4]],\ [\textcolor{stringliteral}{"{}d"{}}])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00456}00456\ \ \ \ \ \textcolor{keyword}{assert}\ clf.score([[1],\ [2],\ [3],\ [4]],\ [\textcolor{stringliteral}{"{}a"{}},\ \textcolor{stringliteral}{"{}b"{}},\ \textcolor{stringliteral}{"{}c"{}},\ \textcolor{stringliteral}{"{}d"{}}])\ >\ 0}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00457}00457\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00458}00458\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00459}00459\ \textcolor{keyword}{def\ }test\_partial\_fit\_regression():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00460}00460\ \ \ \ \ \textcolor{comment}{\#\ Test\ partial\_fit\ on\ regression.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00461}00461\ \ \ \ \ \textcolor{comment}{\#\ \`{}partial\_fit`\ should\ yield\ the\ same\ results\ as\ 'fit'\ for\ regression.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00462}00462\ \ \ \ \ X\ =\ X\_reg}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00463}00463\ \ \ \ \ y\ =\ y\_reg}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00464}00464\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00465}00465\ \ \ \ \ \textcolor{keywordflow}{for}\ momentum\ \textcolor{keywordflow}{in}\ [0,\ 0.9]:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00466}00466\ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00467}00467\ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}sgd"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00468}00468\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=100,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00469}00469\ \ \ \ \ \ \ \ \ \ \ \ \ activation=\textcolor{stringliteral}{"{}relu"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00470}00470\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00471}00471\ \ \ \ \ \ \ \ \ \ \ \ \ learning\_rate\_init=0.01,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00472}00472\ \ \ \ \ \ \ \ \ \ \ \ \ batch\_size=X.shape[0],}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00473}00473\ \ \ \ \ \ \ \ \ \ \ \ \ momentum=momentum,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00474}00474\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00475}00475\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00476}00476\ \ \ \ \ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}ignore"{}},\ ConvergenceWarning)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00477}00477\ \ \ \ \ \ \ \ \ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00478}00478\ \ \ \ \ \ \ \ \ pred1\ =\ mlp.predict(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00479}00479\ \ \ \ \ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00480}00480\ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}sgd"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00481}00481\ \ \ \ \ \ \ \ \ \ \ \ \ activation=\textcolor{stringliteral}{"{}relu"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00482}00482\ \ \ \ \ \ \ \ \ \ \ \ \ learning\_rate\_init=0.01,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00483}00483\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00484}00484\ \ \ \ \ \ \ \ \ \ \ \ \ batch\_size=X.shape[0],}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00485}00485\ \ \ \ \ \ \ \ \ \ \ \ \ momentum=momentum,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00486}00486\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00487}00487\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(100):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00488}00488\ \ \ \ \ \ \ \ \ \ \ \ \ mlp.partial\_fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00489}00489\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00490}00490\ \ \ \ \ \ \ \ \ pred2\ =\ mlp.predict(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00491}00491\ \ \ \ \ \ \ \ \ assert\_allclose(pred1,\ pred2)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00492}00492\ \ \ \ \ \ \ \ \ score\ =\ mlp.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00493}00493\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ score\ >\ 0.65}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00494}00494\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00495}00495\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00496}00496\ \textcolor{keyword}{def\ }test\_partial\_fit\_errors():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00497}00497\ \ \ \ \ \textcolor{comment}{\#\ Test\ partial\_fit\ error\ handling.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00498}00498\ \ \ \ \ X\ =\ [[3,\ 2],\ [1,\ 6]]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00499}00499\ \ \ \ \ y\ =\ [1,\ 0]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00500}00500\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00501}00501\ \ \ \ \ \textcolor{comment}{\#\ no\ classes\ passed}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00502}00502\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00503}00503\ \ \ \ \ \ \ \ \ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(solver=\textcolor{stringliteral}{"{}sgd"{}}).partial\_fit(X,\ y,\ classes=[2])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00504}00504\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00505}00505\ \ \ \ \ \textcolor{comment}{\#\ lbfgs\ doesn't\ support\ partial\_fit}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00506}00506\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ hasattr(\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(solver=\textcolor{stringliteral}{"{}lbfgs"{}}),\ \textcolor{stringliteral}{"{}partial\_fit"{}})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00507}00507\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00508}00508\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00509}00509\ \textcolor{keyword}{def\ }test\_nonfinite\_params():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00510}00510\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ MLPRegressor\ throws\ ValueError\ when\ dealing\ with\ non-\/finite}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00511}00511\ \ \ \ \ \textcolor{comment}{\#\ parameter\ values}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00512}00512\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00513}00513\ \ \ \ \ n\_samples\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00514}00514\ \ \ \ \ fmax\ =\ np.finfo(np.float64).max}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00515}00515\ \ \ \ \ X\ =\ fmax\ *\ rng.uniform(size=(n\_samples,\ 2))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00516}00516\ \ \ \ \ y\ =\ rng.standard\_normal(size=n\_samples)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00517}00517\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00518}00518\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}()}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00519}00519\ \ \ \ \ msg\ =\ (}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00520}00520\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Solver\ produced\ non-\/finite\ parameter\ weights.\ The\ input\ data\ may\ contain\ large"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00521}00521\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\ values\ and\ need\ to\ be\ preprocessed."{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00522}00522\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00523}00523\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=msg):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00524}00524\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00525}00525\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ RuntimeWarning:\ overflow\ encountered\ in\ square}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00526}00526\ \ \ \ \ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}ignore"{}})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00527}00527\ \ \ \ \ \ \ \ \ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00528}00528\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00529}00529\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00530}00530\ \textcolor{keyword}{def\ }test\_predict\_proba\_binary():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00531}00531\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ predict\_proba\ works\ as\ expected\ for\ binary\ class.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00532}00532\ \ \ \ \ X\ =\ X\_digits\_binary[:50]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00533}00533\ \ \ \ \ y\ =\ y\_digits\_binary[:50]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00534}00534\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00535}00535\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(hidden\_layer\_sizes=5,\ activation=\textcolor{stringliteral}{"{}logistic"{}},\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00536}00536\ \ \ \ \ \textcolor{keyword}{with}\ ignore\_warnings(category=ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00537}00537\ \ \ \ \ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00538}00538\ \ \ \ \ y\_proba\ =\ clf.predict\_proba(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00539}00539\ \ \ \ \ y\_log\_proba\ =\ clf.predict\_log\_proba(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00540}00540\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00541}00541\ \ \ \ \ (n\_samples,\ n\_classes)\ =\ y.shape[0],\ 2}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00542}00542\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00543}00543\ \ \ \ \ proba\_max\ =\ y\_proba.argmax(axis=1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00544}00544\ \ \ \ \ proba\_log\_max\ =\ y\_log\_proba.argmax(axis=1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00545}00545\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00546}00546\ \ \ \ \ \textcolor{keyword}{assert}\ y\_proba.shape\ ==\ (n\_samples,\ n\_classes)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00547}00547\ \ \ \ \ assert\_array\_equal(proba\_max,\ proba\_log\_max)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00548}00548\ \ \ \ \ assert\_allclose(y\_log\_proba,\ np.log(y\_proba))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00549}00549\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00550}00550\ \ \ \ \ \textcolor{keyword}{assert}\ roc\_auc\_score(y,\ y\_proba[:,\ 1])\ ==\ 1.0}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00551}00551\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00552}00552\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00553}00553\ \textcolor{keyword}{def\ }test\_predict\_proba\_multiclass():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00554}00554\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ predict\_proba\ works\ as\ expected\ for\ multi\ class.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00555}00555\ \ \ \ \ X\ =\ X\_digits\_multi[:10]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00556}00556\ \ \ \ \ y\ =\ y\_digits\_multi[:10]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00557}00557\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00558}00558\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(hidden\_layer\_sizes=5)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00559}00559\ \ \ \ \ \textcolor{keyword}{with}\ ignore\_warnings(category=ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00560}00560\ \ \ \ \ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00561}00561\ \ \ \ \ y\_proba\ =\ clf.predict\_proba(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00562}00562\ \ \ \ \ y\_log\_proba\ =\ clf.predict\_log\_proba(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00563}00563\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00564}00564\ \ \ \ \ (n\_samples,\ n\_classes)\ =\ y.shape[0],\ np.unique(y).size}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00565}00565\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00566}00566\ \ \ \ \ proba\_max\ =\ y\_proba.argmax(axis=1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00567}00567\ \ \ \ \ proba\_log\_max\ =\ y\_log\_proba.argmax(axis=1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00568}00568\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00569}00569\ \ \ \ \ \textcolor{keyword}{assert}\ y\_proba.shape\ ==\ (n\_samples,\ n\_classes)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00570}00570\ \ \ \ \ assert\_array\_equal(proba\_max,\ proba\_log\_max)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00571}00571\ \ \ \ \ assert\_allclose(y\_log\_proba,\ np.log(y\_proba))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00572}00572\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00573}00573\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00574}00574\ \textcolor{keyword}{def\ }test\_predict\_proba\_multilabel():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00575}00575\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ predict\_proba\ works\ as\ expected\ for\ multilabel.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00576}00576\ \ \ \ \ \textcolor{comment}{\#\ Multilabel\ should\ not\ use\ softmax\ which\ makes\ probabilities\ sum\ to\ 1}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00577}00577\ \ \ \ \ X,\ Y\ =\ make\_multilabel\_classification(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00578}00578\ \ \ \ \ \ \ \ \ n\_samples=50,\ random\_state=0,\ return\_indicator=\textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00579}00579\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00580}00580\ \ \ \ \ n\_samples,\ n\_classes\ =\ Y.shape}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00581}00581\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00582}00582\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(solver=\textcolor{stringliteral}{"{}lbfgs"{}},\ hidden\_layer\_sizes=30,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00583}00583\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00584}00584\ \ \ \ \ y\_proba\ =\ clf.predict\_proba(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00585}00585\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00586}00586\ \ \ \ \ \textcolor{keyword}{assert}\ y\_proba.shape\ ==\ (n\_samples,\ n\_classes)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00587}00587\ \ \ \ \ assert\_array\_equal(y\_proba\ >\ 0.5,\ Y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00588}00588\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00589}00589\ \ \ \ \ y\_log\_proba\ =\ clf.predict\_log\_proba(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00590}00590\ \ \ \ \ proba\_max\ =\ y\_proba.argmax(axis=1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00591}00591\ \ \ \ \ proba\_log\_max\ =\ y\_log\_proba.argmax(axis=1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00592}00592\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00593}00593\ \ \ \ \ \textcolor{keyword}{assert}\ (y\_proba.sum(1)\ -\/\ 1).dot(y\_proba.sum(1)\ -\/\ 1)\ >\ 1e-\/10}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00594}00594\ \ \ \ \ assert\_array\_equal(proba\_max,\ proba\_log\_max)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00595}00595\ \ \ \ \ assert\_allclose(y\_log\_proba,\ np.log(y\_proba))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00596}00596\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00597}00597\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00598}00598\ \textcolor{keyword}{def\ }test\_shuffle():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00599}00599\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ the\ shuffle\ parameter\ affects\ the\ training\ process\ (it\ should)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00600}00600\ \ \ \ \ X,\ y\ =\ make\_regression(n\_samples=50,\ n\_features=5,\ n\_targets=1,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00601}00601\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00602}00602\ \ \ \ \ \textcolor{comment}{\#\ The\ coefficients\ will\ be\ identical\ if\ both\ do\ or\ do\ not\ shuffle}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00603}00603\ \ \ \ \ \textcolor{keywordflow}{for}\ shuffle\ \textcolor{keywordflow}{in}\ [\textcolor{keyword}{True},\ \textcolor{keyword}{False}]:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00604}00604\ \ \ \ \ \ \ \ \ mlp1\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00605}00605\ \ \ \ \ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00606}00606\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00607}00607\ \ \ \ \ \ \ \ \ \ \ \ \ batch\_size=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00608}00608\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00609}00609\ \ \ \ \ \ \ \ \ \ \ \ \ shuffle=shuffle,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00610}00610\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00611}00611\ \ \ \ \ \ \ \ \ mlp2\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00612}00612\ \ \ \ \ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00613}00613\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00614}00614\ \ \ \ \ \ \ \ \ \ \ \ \ batch\_size=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00615}00615\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00616}00616\ \ \ \ \ \ \ \ \ \ \ \ \ shuffle=shuffle,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00617}00617\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00618}00618\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00619}00619\ \ \ \ \ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}ignore"{}},\ ConvergenceWarning)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00620}00620\ \ \ \ \ \ \ \ \ \ \ \ \ mlp1.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00621}00621\ \ \ \ \ \ \ \ \ \ \ \ \ mlp2.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00622}00622\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00623}00623\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ np.array\_equal(mlp1.coefs\_[0],\ mlp2.coefs\_[0])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00624}00624\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00625}00625\ \ \ \ \ \textcolor{comment}{\#\ The\ coefficients\ will\ be\ slightly\ different\ if\ shuffle=True}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00626}00626\ \ \ \ \ mlp1\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00627}00627\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=1,\ max\_iter=1,\ batch\_size=1,\ random\_state=0,\ shuffle=\textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00628}00628\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00629}00629\ \ \ \ \ mlp2\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00630}00630\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=1,\ max\_iter=1,\ batch\_size=1,\ random\_state=0,\ shuffle=\textcolor{keyword}{False}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00631}00631\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00632}00632\ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00633}00633\ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}ignore"{}},\ ConvergenceWarning)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00634}00634\ \ \ \ \ \ \ \ \ mlp1.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00635}00635\ \ \ \ \ \ \ \ \ mlp2.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00636}00636\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00637}00637\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ np.array\_equal(mlp1.coefs\_[0],\ mlp2.coefs\_[0])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00638}00638\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00639}00639\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00640}00640\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}csr\_container"{},\ CSR\_CONTAINERS)}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00641}00641\ \textcolor{keyword}{def\ }test\_sparse\_matrices(csr\_container):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00642}00642\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ sparse\ and\ dense\ input\ matrices\ output\ the\ same\ results.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00643}00643\ \ \ \ \ X\ =\ X\_digits\_binary[:50]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00644}00644\ \ \ \ \ y\ =\ y\_digits\_binary[:50]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00645}00645\ \ \ \ \ X\_sparse\ =\ csr\_container(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00646}00646\ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(solver=\textcolor{stringliteral}{"{}lbfgs"{}},\ hidden\_layer\_sizes=15,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00647}00647\ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00648}00648\ \ \ \ \ pred1\ =\ mlp.predict(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00649}00649\ \ \ \ \ mlp.fit(X\_sparse,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00650}00650\ \ \ \ \ pred2\ =\ mlp.predict(X\_sparse)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00651}00651\ \ \ \ \ assert\_almost\_equal(pred1,\ pred2)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00652}00652\ \ \ \ \ pred1\ =\ mlp.predict(X)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00653}00653\ \ \ \ \ pred2\ =\ mlp.predict(X\_sparse)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00654}00654\ \ \ \ \ assert\_array\_equal(pred1,\ pred2)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00655}00655\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00656}00656\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00657}00657\ \textcolor{keyword}{def\ }test\_tolerance():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00658}00658\ \ \ \ \ \textcolor{comment}{\#\ Test\ tolerance.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00659}00659\ \ \ \ \ \textcolor{comment}{\#\ It\ should\ force\ the\ solver\ to\ exit\ the\ loop\ when\ it\ converges.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00660}00660\ \ \ \ \ X\ =\ [[3,\ 2],\ [1,\ 6]]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00661}00661\ \ \ \ \ y\ =\ [1,\ 0]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00662}00662\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(tol=0.5,\ max\_iter=3000,\ solver=\textcolor{stringliteral}{"{}sgd"{}})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00663}00663\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00664}00664\ \ \ \ \ \textcolor{keyword}{assert}\ clf.max\_iter\ >\ clf.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00665}00665\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00666}00666\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00667}00667\ \textcolor{keyword}{def\ }test\_verbose\_sgd():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00668}00668\ \ \ \ \ \textcolor{comment}{\#\ Test\ verbose.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00669}00669\ \ \ \ \ X\ =\ [[3,\ 2],\ [1,\ 6]]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00670}00670\ \ \ \ \ y\ =\ [1,\ 0]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00671}00671\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(solver=\textcolor{stringliteral}{"{}sgd"{}},\ max\_iter=2,\ verbose=10,\ hidden\_layer\_sizes=2)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00672}00672\ \ \ \ \ old\_stdout\ =\ sys.stdout}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00673}00673\ \ \ \ \ sys.stdout\ =\ output\ =\ \mbox{\hyperlink{classStringIO}{StringIO}}()}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00674}00674\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00675}00675\ \ \ \ \ \textcolor{keyword}{with}\ ignore\_warnings(category=ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00676}00676\ \ \ \ \ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00677}00677\ \ \ \ \ clf.partial\_fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00678}00678\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00679}00679\ \ \ \ \ sys.stdout\ =\ old\_stdout}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00680}00680\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{stringliteral}{"{}Iteration"{}}\ \textcolor{keywordflow}{in}\ output.getvalue()}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00681}00681\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00682}00682\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00683}00683\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}MLPEstimator"{},\ [MLPClassifier,\ MLPRegressor])}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00684}00684\ \textcolor{keyword}{def\ }test\_early\_stopping(MLPEstimator):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00685}00685\ \ \ \ \ X\ =\ X\_digits\_binary[:100]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00686}00686\ \ \ \ \ y\ =\ y\_digits\_binary[:100]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00687}00687\ \ \ \ \ tol\ =\ 0.2}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00688}00688\ \ \ \ \ mlp\_estimator\ =\ MLPEstimator(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00689}00689\ \ \ \ \ \ \ \ \ tol=tol,\ max\_iter=3000,\ solver=\textcolor{stringliteral}{"{}sgd"{}},\ early\_stopping=\textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00690}00690\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00691}00691\ \ \ \ \ mlp\_estimator.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00692}00692\ \ \ \ \ \textcolor{keyword}{assert}\ mlp\_estimator.max\_iter\ >\ mlp\_estimator.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00693}00693\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00694}00694\ \ \ \ \ \textcolor{keyword}{assert}\ mlp\_estimator.best\_loss\_\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00695}00695\ \ \ \ \ \textcolor{keyword}{assert}\ isinstance(mlp\_estimator.validation\_scores\_,\ list)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00696}00696\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00697}00697\ \ \ \ \ valid\_scores\ =\ mlp\_estimator.validation\_scores\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00698}00698\ \ \ \ \ best\_valid\_score\ =\ mlp\_estimator.best\_validation\_score\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00699}00699\ \ \ \ \ \textcolor{keyword}{assert}\ max(valid\_scores)\ ==\ best\_valid\_score}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00700}00700\ \ \ \ \ \textcolor{keyword}{assert}\ best\_valid\_score\ +\ tol\ >\ valid\_scores[-\/2]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00701}00701\ \ \ \ \ \textcolor{keyword}{assert}\ best\_valid\_score\ +\ tol\ >\ valid\_scores[-\/1]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00702}00702\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00703}00703\ \ \ \ \ \textcolor{comment}{\#\ check\ that\ the\ attributes\ \`{}validation\_scores\_`\ and\ \`{}best\_validation\_score\_`}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00704}00704\ \ \ \ \ \textcolor{comment}{\#\ are\ set\ to\ None\ when\ \`{}early\_stopping=False`}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00705}00705\ \ \ \ \ mlp\_estimator\ =\ MLPEstimator(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00706}00706\ \ \ \ \ \ \ \ \ tol=tol,\ max\_iter=3000,\ solver=\textcolor{stringliteral}{"{}sgd"{}},\ early\_stopping=\textcolor{keyword}{False}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00707}00707\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00708}00708\ \ \ \ \ mlp\_estimator.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00709}00709\ \ \ \ \ \textcolor{keyword}{assert}\ mlp\_estimator.validation\_scores\_\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00710}00710\ \ \ \ \ \textcolor{keyword}{assert}\ mlp\_estimator.best\_validation\_score\_\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00711}00711\ \ \ \ \ \textcolor{keyword}{assert}\ mlp\_estimator.best\_loss\_\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00712}00712\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00713}00713\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00714}00714\ \textcolor{keyword}{def\ }test\_adaptive\_learning\_rate():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00715}00715\ \ \ \ \ X\ =\ [[3,\ 2],\ [1,\ 6]]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00716}00716\ \ \ \ \ y\ =\ [1,\ 0]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00717}00717\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(tol=0.5,\ max\_iter=3000,\ solver=\textcolor{stringliteral}{"{}sgd"{}},\ learning\_rate=\textcolor{stringliteral}{"{}adaptive"{}})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00718}00718\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00719}00719\ \ \ \ \ \textcolor{keyword}{assert}\ clf.max\_iter\ >\ clf.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00720}00720\ \ \ \ \ \textcolor{keyword}{assert}\ 1e-\/6\ >\ clf.\_optimizer.learning\_rate}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00721}00721\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00722}00722\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00723}00723\ \textcolor{keyword}{def\ }test\_warm\_start():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00724}00724\ \ \ \ \ X\ =\ X\_iris}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00725}00725\ \ \ \ \ y\ =\ y\_iris}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00726}00726\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00727}00727\ \ \ \ \ y\_2classes\ =\ np.array([0]\ *\ 75\ +\ [1]\ *\ 75)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00728}00728\ \ \ \ \ y\_3classes\ =\ np.array([0]\ *\ 40\ +\ [1]\ *\ 40\ +\ [2]\ *\ 70)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00729}00729\ \ \ \ \ y\_3classes\_alt\ =\ np.array([0]\ *\ 50\ +\ [1]\ *\ 50\ +\ [3]\ *\ 50)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00730}00730\ \ \ \ \ y\_4classes\ =\ np.array([0]\ *\ 37\ +\ [1]\ *\ 37\ +\ [2]\ *\ 38\ +\ [3]\ *\ 38)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00731}00731\ \ \ \ \ y\_5classes\ =\ np.array([0]\ *\ 30\ +\ [1]\ *\ 30\ +\ [2]\ *\ 30\ +\ [3]\ *\ 30\ +\ [4]\ *\ 30)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00732}00732\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00733}00733\ \ \ \ \ \textcolor{comment}{\#\ No\ error\ raised}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00734}00734\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00735}00735\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=2,\ solver=\textcolor{stringliteral}{"{}lbfgs"{}},\ warm\_start=\textcolor{keyword}{True},\ random\_state=42,\ tol=1e-\/2}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00736}00736\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00737}00737\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00738}00738\ \ \ \ \ clf.fit(X,\ y\_3classes)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00739}00739\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00740}00740\ \ \ \ \ \textcolor{keywordflow}{for}\ y\_i\ \textcolor{keywordflow}{in}\ (y\_2classes,\ y\_3classes\_alt,\ y\_4classes,\ y\_5classes):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00741}00741\ \ \ \ \ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00742}00742\ \ \ \ \ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=2,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00743}00743\ \ \ \ \ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}lbfgs"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00744}00744\ \ \ \ \ \ \ \ \ \ \ \ \ warm\_start=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00745}00745\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=42,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00746}00746\ \ \ \ \ \ \ \ \ \ \ \ \ tol=1e-\/2,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00747}00747\ \ \ \ \ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00748}00748\ \ \ \ \ \ \ \ \ message\ =\ (}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00749}00749\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}warm\_start\ can\ only\ be\ used\ where\ \`{}y`\ has\ the\ same\ "{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00750}00750\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}classes\ as\ in\ the\ previous\ call\ to\ fit."{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00751}00751\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\ Previously\ got\ [0\ 1\ 2],\ \`{}y`\ has\ \%s"{}}\ \%\ np.unique(y\_i)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00752}00752\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00753}00753\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=re.escape(message)):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00754}00754\ \ \ \ \ \ \ \ \ \ \ \ \ clf.fit(X,\ y\_i)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00755}00755\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00756}00756\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00757}00757\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}MLPEstimator"{},\ [MLPClassifier,\ MLPRegressor])}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00758}00758\ \textcolor{keyword}{def\ }test\_warm\_start\_full\_iteration(MLPEstimator):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00759}00759\ \ \ \ \ \textcolor{comment}{\#\ Non-\/regression\ test\ for:}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00760}00760\ \ \ \ \ \textcolor{comment}{\#\ https://github.com/scikit-\/learn/scikit-\/learn/issues/16812}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00761}00761\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ the\ MLP\ estimator\ accomplish\ \`{}max\_iter`\ with\ a}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00762}00762\ \ \ \ \ \textcolor{comment}{\#\ warm\ started\ estimator.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00763}00763\ \ \ \ \ X,\ y\ =\ X\_iris,\ y\_iris}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00764}00764\ \ \ \ \ max\_iter\ =\ 3}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00765}00765\ \ \ \ \ clf\ =\ MLPEstimator(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00766}00766\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=2,\ solver=\textcolor{stringliteral}{"{}sgd"{}},\ warm\_start=\textcolor{keyword}{True},\ max\_iter=max\_iter}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00767}00767\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00768}00768\ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00769}00769\ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}ignore"{}},\ ConvergenceWarning)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00770}00770\ \ \ \ \ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00771}00771\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ max\_iter\ ==\ clf.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00772}00772\ \ \ \ \ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00773}00773\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ max\_iter\ ==\ clf.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00774}00774\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00775}00775\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00776}00776\ \textcolor{keyword}{def\ }test\_n\_iter\_no\_change():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00777}00777\ \ \ \ \ \textcolor{comment}{\#\ test\ n\_iter\_no\_change\ using\ binary\ data\ set}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00778}00778\ \ \ \ \ \textcolor{comment}{\#\ the\ classifying\ fitting\ process\ is\ not\ prone\ to\ loss\ curve\ fluctuations}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00779}00779\ \ \ \ \ X\ =\ X\_digits\_binary[:100]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00780}00780\ \ \ \ \ y\ =\ y\_digits\_binary[:100]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00781}00781\ \ \ \ \ tol\ =\ 0.01}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00782}00782\ \ \ \ \ max\_iter\ =\ 3000}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00783}00783\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00784}00784\ \ \ \ \ \textcolor{comment}{\#\ test\ multiple\ n\_iter\_no\_change}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00785}00785\ \ \ \ \ \textcolor{keywordflow}{for}\ n\_iter\_no\_change\ \textcolor{keywordflow}{in}\ [2,\ 5,\ 10,\ 50,\ 100]:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00786}00786\ \ \ \ \ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00787}00787\ \ \ \ \ \ \ \ \ \ \ \ \ tol=tol,\ max\_iter=max\_iter,\ solver=\textcolor{stringliteral}{"{}sgd"{}},\ n\_iter\_no\_change=n\_iter\_no\_change}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00788}00788\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00789}00789\ \ \ \ \ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00790}00790\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00791}00791\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ validate\ n\_iter\_no\_change}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00792}00792\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ clf.\_no\_improvement\_count\ ==\ n\_iter\_no\_change\ +\ 1}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00793}00793\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ max\_iter\ >\ clf.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00794}00794\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00795}00795\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00796}00796\ \textcolor{preprocessor}{@pytest.mark.filterwarnings("{}ignore::sklearn.exceptions.ConvergenceWarning"{})}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00797}00797\ \textcolor{keyword}{def\ }test\_n\_iter\_no\_change\_inf():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00798}00798\ \ \ \ \ \textcolor{comment}{\#\ test\ n\_iter\_no\_change\ using\ binary\ data\ set}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00799}00799\ \ \ \ \ \textcolor{comment}{\#\ the\ fitting\ process\ should\ go\ to\ max\_iter\ iterations}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00800}00800\ \ \ \ \ X\ =\ X\_digits\_binary[:100]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00801}00801\ \ \ \ \ y\ =\ y\_digits\_binary[:100]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00802}00802\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00803}00803\ \ \ \ \ \textcolor{comment}{\#\ set\ a\ ridiculous\ tolerance}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00804}00804\ \ \ \ \ \textcolor{comment}{\#\ this\ should\ always\ trigger\ \_update\_no\_improvement\_count()}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00805}00805\ \ \ \ \ tol\ =\ 1e9}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00806}00806\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00807}00807\ \ \ \ \ \textcolor{comment}{\#\ fit}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00808}00808\ \ \ \ \ n\_iter\_no\_change\ =\ np.inf}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00809}00809\ \ \ \ \ max\_iter\ =\ 3000}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00810}00810\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00811}00811\ \ \ \ \ \ \ \ \ tol=tol,\ max\_iter=max\_iter,\ solver=\textcolor{stringliteral}{"{}sgd"{}},\ n\_iter\_no\_change=n\_iter\_no\_change}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00812}00812\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00813}00813\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00814}00814\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00815}00815\ \ \ \ \ \textcolor{comment}{\#\ validate\ n\_iter\_no\_change\ doesn't\ cause\ early\ stopping}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00816}00816\ \ \ \ \ \textcolor{keyword}{assert}\ clf.n\_iter\_\ ==\ max\_iter}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00817}00817\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00818}00818\ \ \ \ \ \textcolor{comment}{\#\ validate\ \_update\_no\_improvement\_count()\ was\ always\ triggered}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00819}00819\ \ \ \ \ \textcolor{keyword}{assert}\ clf.\_no\_improvement\_count\ ==\ clf.n\_iter\_\ -\/\ 1}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00820}00820\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00821}00821\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00822}00822\ \textcolor{keyword}{def\ }test\_early\_stopping\_stratified():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00823}00823\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ data\ splitting\ for\ early\ stopping\ is\ stratified}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00824}00824\ \ \ \ \ X\ =\ [[1,\ 2],\ [2,\ 3],\ [3,\ 4],\ [4,\ 5]]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00825}00825\ \ \ \ \ y\ =\ [0,\ 0,\ 0,\ 1]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00826}00826\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00827}00827\ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(early\_stopping=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00828}00828\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00829}00829\ \ \ \ \ \ \ \ \ ValueError,\ match=\textcolor{stringliteral}{"{}The\ least\ populated\ class\ in\ y\ has\ only\ 1\ member"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00830}00830\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00831}00831\ \ \ \ \ \ \ \ \ mlp.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00832}00832\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00833}00833\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00834}00834\ \textcolor{keyword}{def\ }test\_mlp\_classifier\_dtypes\_casting():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00835}00835\ \ \ \ \ \textcolor{comment}{\#\ Compare\ predictions\ for\ different\ dtypes}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00836}00836\ \ \ \ \ mlp\_64\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00837}00837\ \ \ \ \ \ \ \ \ alpha=1e-\/5,\ hidden\_layer\_sizes=(5,\ 3),\ random\_state=1,\ max\_iter=100,\ tol=1e-\/1}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00838}00838\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00839}00839\ \ \ \ \ mlp\_64.fit(X\_digits[:300],\ y\_digits[:300])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00840}00840\ \ \ \ \ pred\_64\ =\ mlp\_64.predict(X\_digits[300:])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00841}00841\ \ \ \ \ proba\_64\ =\ mlp\_64.predict\_proba(X\_digits[300:])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00842}00842\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00843}00843\ \ \ \ \ mlp\_32\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPClassifier}{MLPClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00844}00844\ \ \ \ \ \ \ \ \ alpha=1e-\/5,\ hidden\_layer\_sizes=(5,\ 3),\ random\_state=1,\ max\_iter=100,\ tol=1e-\/1}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00845}00845\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00846}00846\ \ \ \ \ mlp\_32.fit(X\_digits[:300].astype(np.float32),\ y\_digits[:300])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00847}00847\ \ \ \ \ pred\_32\ =\ mlp\_32.predict(X\_digits[300:].astype(np.float32))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00848}00848\ \ \ \ \ proba\_32\ =\ mlp\_32.predict\_proba(X\_digits[300:].astype(np.float32))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00849}00849\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00850}00850\ \ \ \ \ assert\_array\_equal(pred\_64,\ pred\_32)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00851}00851\ \ \ \ \ assert\_allclose(proba\_64,\ proba\_32,\ rtol=1e-\/02)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00852}00852\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00853}00853\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00854}00854\ \textcolor{keyword}{def\ }test\_mlp\_regressor\_dtypes\_casting():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00855}00855\ \ \ \ \ mlp\_64\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00856}00856\ \ \ \ \ \ \ \ \ alpha=1e-\/5,\ hidden\_layer\_sizes=(5,\ 3),\ random\_state=1,\ max\_iter=150,\ tol=1e-\/3}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00857}00857\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00858}00858\ \ \ \ \ mlp\_64.fit(X\_digits[:300],\ y\_digits[:300])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00859}00859\ \ \ \ \ pred\_64\ =\ mlp\_64.predict(X\_digits[300:])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00860}00860\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00861}00861\ \ \ \ \ mlp\_32\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00862}00862\ \ \ \ \ \ \ \ \ alpha=1e-\/5,\ hidden\_layer\_sizes=(5,\ 3),\ random\_state=1,\ max\_iter=150,\ tol=1e-\/3}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00863}00863\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00864}00864\ \ \ \ \ mlp\_32.fit(X\_digits[:300].astype(np.float32),\ y\_digits[:300])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00865}00865\ \ \ \ \ pred\_32\ =\ mlp\_32.predict(X\_digits[300:].astype(np.float32))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00866}00866\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00867}00867\ \ \ \ \ assert\_allclose(pred\_64,\ pred\_32,\ rtol=5e-\/04)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00868}00868\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00869}00869\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00870}00870\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}dtype"{},\ [np.float32,\ np.float64])}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00871}00871\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Estimator"{},\ [MLPClassifier,\ MLPRegressor])}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00872}00872\ \textcolor{keyword}{def\ }test\_mlp\_param\_dtypes(dtype,\ Estimator):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00873}00873\ \ \ \ \ \textcolor{comment}{\#\ Checks\ if\ input\ dtype\ is\ used\ for\ network\ parameters}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00874}00874\ \ \ \ \ \textcolor{comment}{\#\ and\ predictions}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00875}00875\ \ \ \ \ X,\ y\ =\ X\_digits.astype(dtype),\ y\_digits}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00876}00876\ \ \ \ \ mlp\ =\ Estimator(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00877}00877\ \ \ \ \ \ \ \ \ alpha=1e-\/5,\ hidden\_layer\_sizes=(5,\ 3),\ random\_state=1,\ max\_iter=50,\ tol=1e-\/1}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00878}00878\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00879}00879\ \ \ \ \ mlp.fit(X[:300],\ y[:300])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00880}00880\ \ \ \ \ pred\ =\ mlp.predict(X[300:])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00881}00881\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00882}00882\ \ \ \ \ \textcolor{keyword}{assert}\ all([intercept.dtype\ ==\ dtype\ \textcolor{keywordflow}{for}\ intercept\ \textcolor{keywordflow}{in}\ mlp.intercepts\_])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00883}00883\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00884}00884\ \ \ \ \ \textcolor{keyword}{assert}\ all([coef.dtype\ ==\ dtype\ \textcolor{keywordflow}{for}\ coef\ \textcolor{keywordflow}{in}\ mlp.coefs\_])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00885}00885\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00886}00886\ \ \ \ \ \textcolor{keywordflow}{if}\ Estimator\ ==\ MLPRegressor:}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00887}00887\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ pred.dtype\ ==\ dtype}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00888}00888\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00889}00889\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00890}\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_ae9ccb270d00fc93b4c05644f49981f50}{00890}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_ae9ccb270d00fc93b4c05644f49981f50}{test\_mlp\_loading\_from\_joblib\_partial\_fit}}(tmp\_path):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00891}00891\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Loading\ from\ MLP\ and\ partial\ fitting\ updates\ weights.\ Non-\/regression}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00892}00892\ \textcolor{stringliteral}{\ \ \ \ test\ for\ \#19626."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00893}00893\ \ \ \ \ pre\_trained\_estimator\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00894}00894\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=(42,),\ random\_state=42,\ learning\_rate\_init=0.01,\ max\_iter=200}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00895}00895\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00896}00896\ \ \ \ \ features,\ target\ =\ [[2]],\ [4]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00897}00897\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00898}00898\ \ \ \ \ \textcolor{comment}{\#\ Fit\ on\ x=2,\ y=4}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00899}00899\ \ \ \ \ pre\_trained\_estimator.fit(features,\ target)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00900}00900\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00901}00901\ \ \ \ \ \textcolor{comment}{\#\ dump\ and\ load\ model}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00902}00902\ \ \ \ \ pickled\_file\ =\ tmp\_path\ /\ \textcolor{stringliteral}{"{}mlp.pkl"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00903}00903\ \ \ \ \ joblib.dump(pre\_trained\_estimator,\ pickled\_file)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00904}00904\ \ \ \ \ load\_estimator\ =\ joblib.load(pickled\_file)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00905}00905\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00906}00906\ \ \ \ \ \textcolor{comment}{\#\ Train\ for\ a\ more\ epochs\ on\ point\ x=2,\ y=1}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00907}00907\ \ \ \ \ fine\_tune\_features,\ fine\_tune\_target\ =\ [[2]],\ [1]}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00908}00908\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00909}00909\ \ \ \ \ \textcolor{keywordflow}{for}\ \_\ \textcolor{keywordflow}{in}\ range(200):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00910}00910\ \ \ \ \ \ \ \ \ load\_estimator.partial\_fit(fine\_tune\_features,\ fine\_tune\_target)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00911}00911\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00912}00912\ \ \ \ \ \textcolor{comment}{\#\ finetuned\ model\ learned\ the\ new\ target}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00913}00913\ \ \ \ \ predicted\_value\ =\ load\_estimator.predict(fine\_tune\_features)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00914}00914\ \ \ \ \ assert\_allclose(predicted\_value,\ fine\_tune\_target,\ rtol=1e-\/4)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00915}00915\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00916}00916\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00917}00917\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Estimator"{},\ [MLPClassifier,\ MLPRegressor])}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00918}\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_abc01ae7561b0dab5e710a9cc3561fda3}{00918}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_abc01ae7561b0dab5e710a9cc3561fda3}{test\_preserve\_feature\_names}}(Estimator):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00919}00919\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ feature\ names\ are\ preserved\ when\ early\ stopping\ is\ enabled.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00920}00920\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00921}00921\ \textcolor{stringliteral}{\ \ \ \ Feature\ names\ are\ required\ for\ consistency\ checks\ during\ scoring.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00922}00922\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00923}00923\ \textcolor{stringliteral}{\ \ \ \ Non-\/regression\ test\ for\ gh-\/24846}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00924}00924\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00925}00925\ \ \ \ \ pd\ =\ pytest.importorskip(\textcolor{stringliteral}{"{}pandas"{}})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00926}00926\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00927}00927\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00928}00928\ \ \ \ \ X\ =\ pd.DataFrame(data=rng.randn(10,\ 2),\ columns=[\textcolor{stringliteral}{"{}colname\_a"{}},\ \textcolor{stringliteral}{"{}colname\_b"{}}])}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00929}00929\ \ \ \ \ y\ =\ pd.Series(data=np.full(10,\ 1),\ name=\textcolor{stringliteral}{"{}colname\_y"{}})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00930}00930\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00931}00931\ \ \ \ \ model\ =\ Estimator(early\_stopping=\textcolor{keyword}{True},\ validation\_fraction=0.2)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00932}00932\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00933}00933\ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00934}00934\ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}error"{}},\ UserWarning)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00935}00935\ \ \ \ \ \ \ \ \ model.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00936}00936\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00937}00937\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00938}00938\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}MLPEstimator"{},\ [MLPClassifier,\ MLPRegressor])}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00939}\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_a5644282e1908d38f78c3631893316875}{00939}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_a5644282e1908d38f78c3631893316875}{test\_mlp\_warm\_start\_with\_early\_stopping}}(MLPEstimator):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00940}00940\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ early\ stopping\ works\ with\ warm\ start."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00941}00941\ \ \ \ \ mlp\ =\ MLPEstimator(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00942}00942\ \ \ \ \ \ \ \ \ max\_iter=10,\ random\_state=0,\ warm\_start=\textcolor{keyword}{True},\ early\_stopping=\textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00943}00943\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00944}00944\ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00945}00945\ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}ignore"{}},\ ConvergenceWarning)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00946}00946\ \ \ \ \ \ \ \ \ mlp.fit(X\_iris,\ y\_iris)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00947}00947\ \ \ \ \ \ \ \ \ n\_validation\_scores\ =\ len(mlp.validation\_scores\_)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00948}00948\ \ \ \ \ \ \ \ \ mlp.set\_params(max\_iter=20)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00949}00949\ \ \ \ \ \ \ \ \ mlp.fit(X\_iris,\ y\_iris)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00950}00950\ \ \ \ \ \textcolor{keyword}{assert}\ len(mlp.validation\_scores\_)\ >\ n\_validation\_scores}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00951}00951\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00952}00952\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00953}00953\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}MLPEstimator"{},\ [MLPClassifier,\ MLPRegressor])}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00954}00954\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}solver"{},\ ["{}sgd"{},\ "{}adam"{},\ "{}lbfgs"{}])}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00955}\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_a31232008b9f12e88451669cb34f6c5d4}{00955}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_a31232008b9f12e88451669cb34f6c5d4}{test\_mlp\_warm\_start\_no\_convergence}}(MLPEstimator,\ solver):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00956}00956\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ we\ stop\ the\ number\ of\ iteration\ at\ \`{}max\_iter\`{}\ when\ warm\ starting.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00957}00957\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00958}00958\ \textcolor{stringliteral}{\ \ \ \ Non-\/regression\ test\ for:}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00959}00959\ \textcolor{stringliteral}{\ \ \ \ https://github.com/scikit-\/learn/scikit-\/learn/issues/24764}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00960}00960\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00961}00961\ \ \ \ \ model\ =\ MLPEstimator(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00962}00962\ \ \ \ \ \ \ \ \ solver=solver,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00963}00963\ \ \ \ \ \ \ \ \ warm\_start=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00964}00964\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00965}00965\ \ \ \ \ \ \ \ \ max\_iter=10,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00966}00966\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=np.inf,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00967}00967\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00968}00968\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00969}00969\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00970}00970\ \ \ \ \ \textcolor{keyword}{with}\ pytest.warns(ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00971}00971\ \ \ \ \ \ \ \ \ model.fit(X\_iris,\ y\_iris)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00972}00972\ \ \ \ \ \textcolor{keyword}{assert}\ model.n\_iter\_\ ==\ 10}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00973}00973\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00974}00974\ \ \ \ \ model.set\_params(max\_iter=20)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00975}00975\ \ \ \ \ \textcolor{keyword}{with}\ pytest.warns(ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00976}00976\ \ \ \ \ \ \ \ \ model.fit(X\_iris,\ y\_iris)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00977}00977\ \ \ \ \ \textcolor{keyword}{assert}\ model.n\_iter\_\ ==\ 20}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00978}00978\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00979}00979\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00980}00980\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}MLPEstimator"{},\ [MLPClassifier,\ MLPRegressor])}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00981}\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_a39068bccaf2787e06f1ccc9ef0374129}{00981}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_a39068bccaf2787e06f1ccc9ef0374129}{test\_mlp\_partial\_fit\_after\_fit}}(MLPEstimator):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00982}00982\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ partial\ fit\ does\ not\ fail\ after\ fit\ when\ early\_stopping=True.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00983}00983\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00984}00984\ \textcolor{stringliteral}{\ \ \ \ Non-\/regression\ test\ for\ gh-\/25693.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00985}00985\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00986}00986\ \ \ \ \ mlp\ =\ MLPEstimator(early\_stopping=\textcolor{keyword}{True},\ random\_state=0).fit(X\_iris,\ y\_iris)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00987}00987\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00988}00988\ \ \ \ \ msg\ =\ \textcolor{stringliteral}{"{}partial\_fit\ does\ not\ support\ early\_stopping=True"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00989}00989\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=msg):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00990}00990\ \ \ \ \ \ \ \ \ mlp.partial\_fit(X\_iris,\ y\_iris)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00991}00991\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00992}00992\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00993}\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_adaf4fabd75b709fb8500878bb0cdf30f}{00993}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_adaf4fabd75b709fb8500878bb0cdf30f}{test\_mlp\_diverging\_loss}}():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00994}00994\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ that\ a\ diverging\ model\ does\ not\ raise\ errors\ when\ early\ stopping\ is\ enabled.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00995}00995\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00996}00996\ \textcolor{stringliteral}{\ \ \ \ Non-\/regression\ test\ for:}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00997}00997\ \textcolor{stringliteral}{\ \ \ \ https://github.com/scikit-\/learn/scikit-\/learn/issues/29504}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00998}00998\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l00999}00999\ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01000}01000\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=100,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01001}01001\ \ \ \ \ \ \ \ \ activation=\textcolor{stringliteral}{"{}identity"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01002}01002\ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}sgd"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01003}01003\ \ \ \ \ \ \ \ \ alpha=0.0001,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01004}01004\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01005}01005\ \ \ \ \ \ \ \ \ learning\_rate\_init=1,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01006}01006\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01007}01007\ \ \ \ \ \ \ \ \ max\_iter=20,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01008}01008\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01009}01009\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=10,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01010}01010\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01011}01011\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01012}01012\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01013}01013\ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01014}01014\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ RuntimeWarning:\ overflow\ encountered\ in\ matmul}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01015}01015\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ ConvergenceWarning:\ Stochastic\ Optimizer:\ Maximum\ iteration}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01016}01016\ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}ignore"{}},\ RuntimeWarning)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01017}01017\ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}ignore"{}},\ ConvergenceWarning)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01018}01018\ \ \ \ \ \ \ \ \ mlp.fit(X\_iris,\ y\_iris)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01019}01019\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01020}01020\ \ \ \ \ \textcolor{comment}{\#\ In\ python,\ float("{}nan"{})\ !=\ float("{}nan"{})}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01021}01021\ \ \ \ \ \textcolor{keyword}{assert}\ str(mlp.validation\_scores\_[-\/1])\ ==\ str(np.nan)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01022}01022\ \ \ \ \ \textcolor{keyword}{assert}\ isinstance(mlp.validation\_scores\_[-\/1],\ float)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01023}01023\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01024}01024\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01025}01025\ \textcolor{keyword}{def\ }test\_mlp\_sample\_weight\_with\_early\_stopping():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01026}01026\ \ \ \ \ \textcolor{comment}{\#\ Test\ code\ path\ for\ inner\ validation\ set\ splitting.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01027}01027\ \ \ \ \ X,\ y\ =\ make\_regression(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01028}01028\ \ \ \ \ \ \ \ \ n\_samples=100,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01029}01029\ \ \ \ \ \ \ \ \ n\_features=2,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01030}01030\ \ \ \ \ \ \ \ \ n\_informative=2,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01031}01031\ \ \ \ \ \ \ \ \ random\_state=42,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01032}01032\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01033}01033\ \ \ \ \ sw\ =\ np.ones\_like(y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01034}01034\ \ \ \ \ params\ =\ dict(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01035}01035\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=10,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01036}01036\ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}adam"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01037}01037\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01038}01038\ \ \ \ \ \ \ \ \ tol=1e-\/2,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01039}01039\ \ \ \ \ \ \ \ \ learning\_rate\_init=0.01,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01040}01040\ \ \ \ \ \ \ \ \ batch\_size=10,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01041}01041\ \ \ \ \ \ \ \ \ random\_state=42,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01042}01042\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01043}01043\ \ \ \ \ m1\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01044}01044\ \ \ \ \ \ \ \ \ **params,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01045}01045\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01046}01046\ \ \ \ \ m1.fit(X,\ y,\ sample\_weight=sw)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01047}01047\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01048}01048\ \ \ \ \ m2\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(**params).fit(X,\ y,\ sample\_weight=\textcolor{keywordtype}{None})}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01049}01049\ \ \ \ \ assert\_allclose(m1.predict(X),\ m2.predict(X))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01050}01050\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01051}01051\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01052}\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_aea0a02662c843892b3b4cb8916cae19d}{01052}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_aea0a02662c843892b3b4cb8916cae19d}{test\_mlp\_vs\_poisson\_glm\_equivalent}}(global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01053}01053\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ MLP\ with\ Poisson\ loss\ and\ no\ hidden\ layer\ equals\ GLM."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01054}01054\ \ \ \ \ n\ =\ 100}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01055}01055\ \ \ \ \ rng\ =\ np.random.default\_rng(global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01056}01056\ \ \ \ \ X\ =\ np.linspace(0,\ 1,\ n)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01057}01057\ \ \ \ \ y\ =\ rng.poisson(np.exp(X\ +\ 1))}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01058}01058\ \ \ \ \ X\ =\ X.reshape(n,\ -\/1)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01059}01059\ \ \ \ \ glm\ =\ PoissonRegressor(alpha=0,\ tol=1e-\/7).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01060}01060\ \ \ \ \ \textcolor{comment}{\#\ Unfortunately,\ we\ can't\ set\ a\ zero\ hidden\_layer\_size,\ so\ we\ use\ a\ trick\ by\ using}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01061}01061\ \ \ \ \ \textcolor{comment}{\#\ just\ one\ hidden\ layer\ node\ with\ an\ identity\ activation.\ Coefficients\ will}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01062}01062\ \ \ \ \ \textcolor{comment}{\#\ therefore\ be\ different,\ but\ predictions\ are\ the\ same.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01063}01063\ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01064}01064\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}poisson"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01065}01065\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=(1,),}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01066}01066\ \ \ \ \ \ \ \ \ activation=\textcolor{stringliteral}{"{}identity"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01067}01067\ \ \ \ \ \ \ \ \ alpha=0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01068}01068\ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}lbfgs"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01069}01069\ \ \ \ \ \ \ \ \ tol=1e-\/7,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01070}01070\ \ \ \ \ \ \ \ \ random\_state=np.random.RandomState(global\_random\_seed\ +\ 1),}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01071}01071\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01072}01072\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01073}01073\ \ \ \ \ assert\_allclose(mlp.predict(X),\ glm.predict(X),\ rtol=1e-\/4)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01074}01074\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01075}01075\ \ \ \ \ \textcolor{comment}{\#\ The\ same\ does\ not\ work\ with\ the\ squared\ error\ because\ the\ output\ activation\ is}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01076}01076\ \ \ \ \ \textcolor{comment}{\#\ the\ identity\ instead\ of\ the\ exponential.}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01077}01077\ \ \ \ \ mlp\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01078}01078\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01079}01079\ \ \ \ \ \ \ \ \ hidden\_layer\_sizes=(1,),}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01080}01080\ \ \ \ \ \ \ \ \ activation=\textcolor{stringliteral}{"{}identity"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01081}01081\ \ \ \ \ \ \ \ \ alpha=0,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01082}01082\ \ \ \ \ \ \ \ \ solver=\textcolor{stringliteral}{"{}lbfgs"{}},}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01083}01083\ \ \ \ \ \ \ \ \ tol=1e-\/7,}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01084}01084\ \ \ \ \ \ \ \ \ random\_state=np.random.RandomState(global\_random\_seed\ +\ 1),}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01085}01085\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01086}01086\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ np.allclose(mlp.predict(X),\ glm.predict(X),\ rtol=1e-\/4)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01087}01087\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01088}01088\ }
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01089}\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_a3d7a5c0b1931a88726fea70176eae9ee}{01089}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__mlp_a3d7a5c0b1931a88726fea70176eae9ee}{test\_minimum\_input\_sample\_size}}():}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01090}01090\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ error\ message\ when\ the\ validation\ set\ is\ too\ small."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01091}01091\ \ \ \ \ X,\ y\ =\ make\_regression(n\_samples=2,\ n\_features=5,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01092}01092\ \ \ \ \ model\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__multilayer__perceptron_1_1MLPRegressor}{MLPRegressor}}(early\_stopping=\textcolor{keyword}{True},\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01093}01093\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=\textcolor{stringliteral}{"{}The\ validation\ set\ is\ too\ small"{}}):}
\DoxyCodeLine{\Hypertarget{test__mlp_8py_source_l01094}01094\ \ \ \ \ \ \ \ \ model.fit(X,\ y)}

\end{DoxyCode}
