\doxysection{gradient\+\_\+boosting.\+py}
\hypertarget{gradient__boosting_8py_source}{}\label{gradient__boosting_8py_source}\index{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/ensemble/\_hist\_gradient\_boosting/gradient\_boosting.py@{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/ensemble/\_hist\_gradient\_boosting/gradient\_boosting.py}}

\begin{DoxyCode}{0}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00001}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting}{00001}}\ \textcolor{stringliteral}{"{}"{}"{}Fast\ Gradient\ Boosting\ decision\ trees\ for\ classification\ and\ regression."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00002}00002\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00003}00003\ \textcolor{comment}{\#\ Authors:\ The\ scikit-\/learn\ developers}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00004}00004\ \textcolor{comment}{\#\ SPDX-\/License-\/Identifier:\ BSD-\/3-\/Clause}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00005}00005\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00006}00006\ \textcolor{keyword}{import}\ itertools}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00007}00007\ \textcolor{keyword}{from}\ abc\ \textcolor{keyword}{import}\ ABC,\ abstractmethod}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00008}00008\ \textcolor{keyword}{from}\ contextlib\ \textcolor{keyword}{import}\ contextmanager,\ nullcontext,\ suppress}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00009}00009\ \textcolor{keyword}{from}\ functools\ \textcolor{keyword}{import}\ partial}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00010}00010\ \textcolor{keyword}{from}\ numbers\ \textcolor{keyword}{import}\ Integral,\ Real}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00011}00011\ \textcolor{keyword}{from}\ time\ \textcolor{keyword}{import}\ time}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00012}00012\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00013}00013\ \textcolor{keyword}{import}\ numpy\ \textcolor{keyword}{as}\ np}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00014}00014\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00015}00015\ \textcolor{keyword}{from}\ ...\_loss.loss\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00016}00016\ \ \ \ \ \_LOSSES,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00017}00017\ \ \ \ \ BaseLoss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00018}00018\ \ \ \ \ HalfBinomialLoss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00019}00019\ \ \ \ \ HalfGammaLoss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00020}00020\ \ \ \ \ HalfMultinomialLoss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00021}00021\ \ \ \ \ HalfPoissonLoss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00022}00022\ \ \ \ \ PinballLoss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00023}00023\ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00024}00024\ \textcolor{keyword}{from}\ ...base\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00025}00025\ \ \ \ \ BaseEstimator,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00026}00026\ \ \ \ \ ClassifierMixin,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00027}00027\ \ \ \ \ RegressorMixin,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00028}00028\ \ \ \ \ \_fit\_context,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00029}00029\ \ \ \ \ is\_classifier,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00030}00030\ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00031}00031\ \textcolor{keyword}{from}\ ...compose\ \textcolor{keyword}{import}\ ColumnTransformer}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00032}00032\ \textcolor{keyword}{from}\ ...metrics\ \textcolor{keyword}{import}\ check\_scoring}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00033}00033\ \textcolor{keyword}{from}\ ...metrics.\_scorer\ \textcolor{keyword}{import}\ \_SCORERS}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00034}00034\ \textcolor{keyword}{from}\ ...model\_selection\ \textcolor{keyword}{import}\ train\_test\_split}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00035}00035\ \textcolor{keyword}{from}\ ...preprocessing\ \textcolor{keyword}{import}\ FunctionTransformer,\ LabelEncoder,\ OrdinalEncoder}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00036}00036\ \textcolor{keyword}{from}\ ...utils\ \textcolor{keyword}{import}\ check\_random\_state,\ compute\_sample\_weight,\ resample}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00037}00037\ \textcolor{keyword}{from}\ ...utils.\_missing\ \textcolor{keyword}{import}\ is\_scalar\_nan}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00038}00038\ \textcolor{keyword}{from}\ ...utils.\_openmp\_helpers\ \textcolor{keyword}{import}\ \_openmp\_effective\_n\_threads}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00039}00039\ \textcolor{keyword}{from}\ ...utils.\_param\_validation\ \textcolor{keyword}{import}\ Interval,\ RealNotInt,\ StrOptions}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00040}00040\ \textcolor{keyword}{from}\ ...utils.multiclass\ \textcolor{keyword}{import}\ check\_classification\_targets}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00041}00041\ \textcolor{keyword}{from}\ ...utils.validation\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00042}00042\ \ \ \ \ \_check\_monotonic\_cst,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00043}00043\ \ \ \ \ \_check\_sample\_weight,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00044}00044\ \ \ \ \ \_check\_y,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00045}00045\ \ \ \ \ \_is\_pandas\_df,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00046}00046\ \ \ \ \ check\_array,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00047}00047\ \ \ \ \ check\_consistent\_length,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00048}00048\ \ \ \ \ check\_is\_fitted,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00049}00049\ \ \ \ \ validate\_data,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00050}00050\ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00051}00051\ \textcolor{keyword}{from}\ .\_gradient\_boosting\ \textcolor{keyword}{import}\ \_update\_raw\_predictions}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00052}00052\ \textcolor{keyword}{from}\ .binning\ \textcolor{keyword}{import}\ \_BinMapper}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00053}00053\ \textcolor{keyword}{from}\ .common\ \textcolor{keyword}{import}\ G\_H\_DTYPE,\ X\_DTYPE,\ Y\_DTYPE}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00054}00054\ \textcolor{keyword}{from}\ .grower\ \textcolor{keyword}{import}\ TreeGrower}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00055}00055\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00056}00056\ \_LOSSES\ =\ \_LOSSES.copy()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00057}00057\ \_LOSSES.update(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00058}00058\ \ \ \ \ \{}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00059}00059\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}poisson"{}}:\ HalfPoissonLoss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00060}00060\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}gamma"{}}:\ HalfGammaLoss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00061}00061\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}quantile"{}}:\ PinballLoss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00062}00062\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00063}00063\ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00064}00064\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00065}00065\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00066}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_a792e2e12a4c12db534fb1b6ce74c5b04}{00066}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_a792e2e12a4c12db534fb1b6ce74c5b04}{\_update\_leaves\_values}}(loss,\ grower,\ y\_true,\ raw\_prediction,\ sample\_weight):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00067}00067\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Update\ the\ leaf\ values\ to\ be\ predicted\ by\ the\ tree.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00068}00068\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00069}00069\ \textcolor{stringliteral}{\ \ \ \ Update\ equals:}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00070}00070\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ loss.fit\_intercept\_only(y\_true\ -\/\ raw\_prediction)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00071}00071\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00072}00072\ \textcolor{stringliteral}{\ \ \ \ This\ is\ only\ applied\ if\ loss.differentiable\ is\ False.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00073}00073\ \textcolor{stringliteral}{\ \ \ \ Note:\ It\ only\ works,\ if\ the\ loss\ is\ a\ function\ of\ the\ residual,\ as\ is\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00074}00074\ \textcolor{stringliteral}{\ \ \ \ case\ for\ AbsoluteError\ and\ PinballLoss.\ Otherwise,\ one\ would\ need\ to\ get}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00075}00075\ \textcolor{stringliteral}{\ \ \ \ the\ minimum\ of\ loss(y\_true,\ raw\_prediction\ +\ x)\ in\ x.\ A\ few\ examples:}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00076}00076\ \textcolor{stringliteral}{\ \ \ \ \ \ -\/\ AbsoluteError:\ median(y\_true\ -\/\ raw\_prediction).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00077}00077\ \textcolor{stringliteral}{\ \ \ \ \ \ -\/\ PinballLoss:\ quantile(y\_true\ -\/\ raw\_prediction).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00078}00078\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00079}00079\ \textcolor{stringliteral}{\ \ \ \ More\ background:}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00080}00080\ \textcolor{stringliteral}{\ \ \ \ For\ the\ standard\ gradient\ descent\ method\ according\ to\ "{}Greedy\ Function}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00081}00081\ \textcolor{stringliteral}{\ \ \ \ Approximation:\ A\ Gradient\ Boosting\ Machine"{}\ by\ Friedman,\ all\ loss\ functions\ but\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00082}00082\ \textcolor{stringliteral}{\ \ \ \ squared\ loss\ need\ a\ line\ search\ step.\ BaseHistGradientBoosting,\ however,\ implements}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00083}00083\ \textcolor{stringliteral}{\ \ \ \ a\ so\ called\ Newton\ boosting\ where\ the\ trees\ are\ fitted\ to\ a\ 2nd\ order}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00084}00084\ \textcolor{stringliteral}{\ \ \ \ approximations\ of\ the\ loss\ in\ terms\ of\ gradients\ and\ hessians.\ In\ this\ case,\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00085}00085\ \textcolor{stringliteral}{\ \ \ \ line\ search\ step\ is\ only\ necessary\ if\ the\ loss\ is\ not\ smooth,\ i.e.\ not}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00086}00086\ \textcolor{stringliteral}{\ \ \ \ differentiable,\ which\ renders\ the\ 2nd\ order\ approximation\ invalid.\ In\ fact,}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00087}00087\ \textcolor{stringliteral}{\ \ \ \ non-\/smooth\ losses\ arbitrarily\ set\ hessians\ to\ 1\ and\ effectively\ use\ the\ standard}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00088}00088\ \textcolor{stringliteral}{\ \ \ \ gradient\ descent\ method\ with\ line\ search.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00089}00089\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00090}00090\ \ \ \ \ \textcolor{comment}{\#\ TODO:\ Ideally\ this\ should\ be\ computed\ in\ parallel\ over\ the\ leaves\ using\ something}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00091}00091\ \ \ \ \ \textcolor{comment}{\#\ similar\ to\ \_update\_raw\_predictions(),\ but\ this\ requires\ a\ cython\ version\ of}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00092}00092\ \ \ \ \ \textcolor{comment}{\#\ median().}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00093}00093\ \ \ \ \ \textcolor{keywordflow}{for}\ leaf\ \textcolor{keywordflow}{in}\ grower.finalized\_leaves:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00094}00094\ \ \ \ \ \ \ \ \ indices\ =\ leaf.sample\_indices}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00095}00095\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ sample\_weight\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00096}00096\ \ \ \ \ \ \ \ \ \ \ \ \ sw\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00097}00097\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00098}00098\ \ \ \ \ \ \ \ \ \ \ \ \ sw\ =\ sample\_weight[indices]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00099}00099\ \ \ \ \ \ \ \ \ update\ =\ loss.fit\_intercept\_only(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00100}00100\ \ \ \ \ \ \ \ \ \ \ \ \ y\_true=y\_true[indices]\ -\/\ raw\_prediction[indices],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00101}00101\ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight=sw,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00102}00102\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00103}00103\ \ \ \ \ \ \ \ \ leaf.value\ =\ grower.shrinkage\ *\ update}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00104}00104\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Note\ that\ the\ regularization\ is\ ignored\ here}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00105}00105\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00106}00106\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00107}00107\ \textcolor{preprocessor}{@contextmanager}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00108}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_a4cf3085f0d80a3d32f5fbc2a96f6b28a}{00108}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_a4cf3085f0d80a3d32f5fbc2a96f6b28a}{\_patch\_raw\_predict}}(estimator,\ raw\_predictions):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00109}00109\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Context\ manager\ that\ patches\ \_raw\_predict\ to\ return\ raw\_predictions.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00110}00110\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00111}00111\ \textcolor{stringliteral}{\ \ \ \ \`{}raw\_predictions\`{}\ is\ typically\ a\ precomputed\ array\ to\ avoid\ redundant}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00112}00112\ \textcolor{stringliteral}{\ \ \ \ state-\/wise\ computations\ fitting\ with\ early\ stopping\ enabled:\ in\ this\ case}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00113}00113\ \textcolor{stringliteral}{\ \ \ \ \`{}raw\_predictions\`{}\ is\ incrementally\ updated\ whenever\ we\ add\ a\ tree\ to\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00114}00114\ \textcolor{stringliteral}{\ \ \ \ boosted\ ensemble.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00115}00115\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00116}00116\ \textcolor{stringliteral}{\ \ \ \ Note:\ this\ makes\ fitting\ HistGradientBoosting*\ models\ inherently\ non\ thread}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00117}00117\ \textcolor{stringliteral}{\ \ \ \ safe\ at\ fit\ time.\ However\ thread-\/safety\ at\ fit\ time\ was\ never\ guaranteed\ nor}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00118}00118\ \textcolor{stringliteral}{\ \ \ \ enforced\ for\ scikit-\/learn\ estimators\ in\ general.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00119}00119\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00120}00120\ \textcolor{stringliteral}{\ \ \ \ Thread-\/safety\ at\ prediction/transform\ time\ is\ another\ matter\ as\ those}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00121}00121\ \textcolor{stringliteral}{\ \ \ \ operations\ are\ typically\ side-\/effect\ free\ and\ therefore\ often\ thread-\/safe\ by}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00122}00122\ \textcolor{stringliteral}{\ \ \ \ default\ for\ most\ scikit-\/learn\ models\ and\ would\ like\ to\ keep\ it\ that\ way.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00123}00123\ \textcolor{stringliteral}{\ \ \ \ Therefore\ this\ context\ manager\ should\ only\ be\ used\ at\ fit\ time.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00124}00124\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00125}00125\ \textcolor{stringliteral}{\ \ \ \ TODO:\ in\ the\ future,\ we\ could\ explore\ the\ possibility\ to\ extend\ the\ scorer}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00126}00126\ \textcolor{stringliteral}{\ \ \ \ public\ API\ to\ expose\ a\ way\ to\ compute\ vales\ from\ raw\ predictions.\ That\ would}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00127}00127\ \textcolor{stringliteral}{\ \ \ \ probably\ require\ also\ making\ the\ scorer\ aware\ of\ the\ inverse\ link\ function}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00128}00128\ \textcolor{stringliteral}{\ \ \ \ used\ by\ the\ estimator\ which\ is\ typically\ private\ API\ for\ now,\ hence\ the\ need}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00129}00129\ \textcolor{stringliteral}{\ \ \ \ for\ this\ patching\ mechanism.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00130}00130\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00131}00131\ \ \ \ \ orig\_raw\_predict\ =\ estimator.\_raw\_predict}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00132}00132\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00133}00133\ \ \ \ \ \textcolor{keyword}{def\ }\_patched\_raw\_predicts(*args,\ **kwargs):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00134}00134\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ raw\_predictions}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00135}00135\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00136}00136\ \ \ \ \ estimator.\_raw\_predict\ =\ \_patched\_raw\_predicts}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00137}00137\ \ \ \ \ \textcolor{keywordflow}{yield}\ estimator}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00138}00138\ \ \ \ \ estimator.\_raw\_predict\ =\ orig\_raw\_predict}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00139}00139\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00140}00140\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00141}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{00141}}\ \textcolor{keyword}{class\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{BaseHistGradientBoosting}}(\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator}{BaseEstimator}},\ \mbox{\hyperlink{classABC}{ABC}}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00142}00142\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Base\ class\ for\ histogram-\/based\ gradient\ boosting\ estimators."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00143}00143\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00144}00144\ \ \ \ \ \_parameter\_constraints:\ dict\ =\ \{}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00145}00145\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}loss"{}}:\ [BaseLoss],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00146}00146\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}learning\_rate"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Real,\ 0,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}neither"{}})],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00147}00147\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_iter"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Integral,\ 1,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}})],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00148}00148\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_leaf\_nodes"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Integral,\ 2,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}}),\ \textcolor{keywordtype}{None}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00149}00149\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_depth"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Integral,\ 1,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}}),\ \textcolor{keywordtype}{None}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00150}00150\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}min\_samples\_leaf"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Integral,\ 1,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}})],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00151}00151\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}l2\_regularization"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Real,\ 0,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}})],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00152}00152\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_features"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(RealNotInt,\ 0,\ 1,\ closed=\textcolor{stringliteral}{"{}right"{}})],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00153}00153\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}monotonic\_cst"{}}:\ [\textcolor{stringliteral}{"{}array-\/like"{}},\ dict,\ \textcolor{keywordtype}{None}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00154}00154\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}interaction\_cst"{}}:\ [}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00155}00155\ \ \ \ \ \ \ \ \ \ \ \ \ list,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00156}00156\ \ \ \ \ \ \ \ \ \ \ \ \ tuple,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00157}00157\ \ \ \ \ \ \ \ \ \ \ \ \ \mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1StrOptions}{StrOptions}}(\{\textcolor{stringliteral}{"{}pairwise"{}},\ \textcolor{stringliteral}{"{}no\_interactions"{}}\}),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00158}00158\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00159}00159\ \ \ \ \ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00160}00160\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}n\_iter\_no\_change"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Integral,\ 1,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}})],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00161}00161\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}validation\_fraction"{}}:\ [}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00162}00162\ \ \ \ \ \ \ \ \ \ \ \ \ \mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(RealNotInt,\ 0,\ 1,\ closed=\textcolor{stringliteral}{"{}neither"{}}),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00163}00163\ \ \ \ \ \ \ \ \ \ \ \ \ \mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Integral,\ 1,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}}),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00164}00164\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00165}00165\ \ \ \ \ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00166}00166\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}tol"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Real,\ 0,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}})],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00167}00167\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_bins"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Integral,\ 2,\ 255,\ closed=\textcolor{stringliteral}{"{}both"{}})],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00168}00168\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features"{}}:\ [\textcolor{stringliteral}{"{}array-\/like"{}},\ \mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1StrOptions}{StrOptions}}(\{\textcolor{stringliteral}{"{}from\_dtype"{}}\}),\ \textcolor{keywordtype}{None}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00169}00169\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}warm\_start"{}}:\ [\textcolor{stringliteral}{"{}boolean"{}}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00170}00170\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}early\_stopping"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1StrOptions}{StrOptions}}(\{\textcolor{stringliteral}{"{}auto"{}}\}),\ \textcolor{stringliteral}{"{}boolean"{}}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00171}00171\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}scoring"{}}:\ [str,\ callable,\ \textcolor{keywordtype}{None}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00172}00172\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}verbose"{}}:\ [\textcolor{stringliteral}{"{}verbose"{}}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00173}00173\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}random\_state"{}}:\ [\textcolor{stringliteral}{"{}random\_state"{}}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00174}00174\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00175}00175\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00176}00176\ \ \ \ \ \textcolor{preprocessor}{@abstractmethod}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00177}00177\ \ \ \ \ \textcolor{keyword}{def\ }\_\_init\_\_(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00178}00178\ \ \ \ \ \ \ \ \ self,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00179}00179\ \ \ \ \ \ \ \ \ loss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00180}00180\ \ \ \ \ \ \ \ \ *,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00181}00181\ \ \ \ \ \ \ \ \ learning\_rate,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00182}00182\ \ \ \ \ \ \ \ \ max\_iter,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00183}00183\ \ \ \ \ \ \ \ \ max\_leaf\_nodes,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00184}00184\ \ \ \ \ \ \ \ \ max\_depth,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00185}00185\ \ \ \ \ \ \ \ \ min\_samples\_leaf,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00186}00186\ \ \ \ \ \ \ \ \ l2\_regularization,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00187}00187\ \ \ \ \ \ \ \ \ max\_features,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00188}00188\ \ \ \ \ \ \ \ \ max\_bins,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00189}00189\ \ \ \ \ \ \ \ \ categorical\_features,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00190}00190\ \ \ \ \ \ \ \ \ monotonic\_cst,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00191}00191\ \ \ \ \ \ \ \ \ interaction\_cst,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00192}00192\ \ \ \ \ \ \ \ \ warm\_start,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00193}00193\ \ \ \ \ \ \ \ \ early\_stopping,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00194}00194\ \ \ \ \ \ \ \ \ scoring,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00195}00195\ \ \ \ \ \ \ \ \ validation\_fraction,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00196}00196\ \ \ \ \ \ \ \ \ n\_iter\_no\_change,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00197}00197\ \ \ \ \ \ \ \ \ tol,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00198}00198\ \ \ \ \ \ \ \ \ verbose,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00199}00199\ \ \ \ \ \ \ \ \ random\_state,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00200}00200\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00201}00201\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1f71d4fd84cefb07d3a4187160d3bf9b}{loss}}\ =\ loss}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00202}00202\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a65f2e8d6111cc97abb7202708a046962}{learning\_rate}}\ =\ learning\_rate}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00203}00203\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8c4630fd50d86dfd270c7b0afbd636fb}{max\_iter}}\ =\ max\_iter}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00204}00204\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a691ad0349a8339079183cefbae38e1d0}{max\_leaf\_nodes}}\ =\ max\_leaf\_nodes}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00205}00205\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abef4a3ea1fbc76cd3d15dceaa39fe0de}{max\_depth}}\ =\ max\_depth}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00206}00206\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab5cbe9de4a5232f8130abbcd2c433605}{min\_samples\_leaf}}\ =\ min\_samples\_leaf}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00207}00207\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ac342bd1bcea4f67b50a928cd1e75a915}{l2\_regularization}}\ =\ l2\_regularization}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00208}00208\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa533d0a8ec3767c97c888844491558c2}{max\_features}}\ =\ max\_features}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00209}00209\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a04540760d13c6f706f3fa44a2141f375}{max\_bins}}\ =\ max\_bins}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00210}00210\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad5f1696e1fd74498621f3a2e13cef6f6}{monotonic\_cst}}\ =\ monotonic\_cst}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00211}00211\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a0ce6a6d7576db5ab409ae2f8f1d6b7b7}{interaction\_cst}}\ =\ interaction\_cst}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00212}00212\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_afc1328f9cf64db2c2a6adfa861b83061}{categorical\_features}}\ =\ categorical\_features}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00213}00213\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a396309db1f0dbf7fda8fcafeaa229df3}{warm\_start}}\ =\ warm\_start}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00214}00214\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a7c1bb95883298c852627543f531c89bf}{early\_stopping}}\ =\ early\_stopping}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00215}00215\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a77783dab5cef4f645a5d0ff93e4deb11}{scoring}}\ =\ scoring}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00216}00216\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa7961cd8f3763607f578eceac4515b18}{validation\_fraction}}\ =\ validation\_fraction}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00217}00217\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a59c410ffee3831ed0c00add4d3a0c6e6}{n\_iter\_no\_change}}\ =\ n\_iter\_no\_change}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00218}00218\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6fe4dfcee2bff69d971f26f7b0398d93}{tol}}\ =\ tol}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00219}00219\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a39a3969984cde73a5dc0879387502020}{verbose}}\ =\ verbose}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00220}00220\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a82a4dbec8808de99c79d689c08e15af0}{random\_state}}\ =\ random\_state}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00221}00221\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00222}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a42806b43b1e86cb64f2366ff04a2d3d6}{00222}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a42806b43b1e86cb64f2366ff04a2d3d6}{\_validate\_parameters}}(self):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00223}00223\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Validate\ parameters\ passed\ to\ \_\_init\_\_.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00224}00224\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00225}00225\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ parameters\ that\ are\ directly\ passed\ to\ the\ grower\ are\ checked\ in}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00226}00226\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ TreeGrower."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00227}00227\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad5f1696e1fd74498621f3a2e13cef6f6}{monotonic\_cst}}\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}\ \textcolor{keywordflow}{and}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}}\ !=\ 1:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00228}00228\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00229}00229\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}monotonic\ constraints\ are\ not\ supported\ for\ multiclass\ classification."{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00230}00230\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00231}00231\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00232}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a3c6c73d838fa46ad6f3c0ccfc2ff4cdb}{00232}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a3c6c73d838fa46ad6f3c0ccfc2ff4cdb}{\_finalize\_sample\_weight}}(self,\ sample\_weight,\ y):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00233}00233\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Finalize\ sample\ weight.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00234}00234\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00235}00235\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Used\ by\ subclasses\ to\ adjust\ sample\_weights.\ This\ is\ useful\ for\ implementing}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00236}00236\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ class\ weights.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00237}00237\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00238}00238\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ sample\_weight}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00239}00239\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00240}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab6a1278c0901cb920029746815bcd824}{00240}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab6a1278c0901cb920029746815bcd824}{\_preprocess\_X}}(self,\ X,\ *,\ reset):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00241}00241\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Preprocess\ and\ validate\ X.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00242}00242\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00243}00243\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00244}00244\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00245}00245\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ \{array-\/like,\ pandas\ DataFrame\}\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00246}00246\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Input\ data.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00247}00247\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00248}00248\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ reset\ :\ bool}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00249}00249\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Whether\ to\ reset\ the\ \`{}n\_features\_in\_\`{}\ and\ \`{}feature\_names\_in\_\ attributes.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00250}00250\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00251}00251\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00252}00252\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00253}00253\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ ndarray\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00254}00254\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Validated\ input\ data.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00255}00255\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00256}00256\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ known\_categories\ :\ list\ of\ ndarray\ of\ shape\ (n\_categories,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00257}00257\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ List\ of\ known\ categories\ for\ each\ categorical\ feature.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00258}00258\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00259}00259\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ If\ there\ is\ a\ preprocessor,\ we\ let\ the\ preprocessor\ handle\ the\ validation.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00260}00260\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Otherwise,\ we\ validate\ the\ data\ ourselves.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00261}00261\ \ \ \ \ \ \ \ \ check\_X\_kwargs\ =\ dict(dtype=[X\_DTYPE],\ ensure\_all\_finite=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00262}00262\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ reset:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00263}00263\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00264}00264\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ validate\_data(self,\ X,\ reset=\textcolor{keyword}{False},\ **check\_X\_kwargs)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00265}00265\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}.transform(X)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00266}00266\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00267}00267\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ At\ this\ point,\ reset\ is\ False,\ which\ runs\ during\ \`{}fit`.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00268}00268\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4c7b7421627b7fdb5197779d589fabc0}{is\_categorical\_}}\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a143ca27c8faef910d8263f7daa255392}{\_check\_categorical\_features}}(X)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00269}00269\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00270}00270\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4c7b7421627b7fdb5197779d589fabc0}{is\_categorical\_}}\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00271}00271\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00272}00272\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_acfcab46edcccc4aa05409934159cd588}{\_is\_categorical\_remapped}}\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00273}00273\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00274}00274\ \ \ \ \ \ \ \ \ \ \ \ \ X\ =\ validate\_data(self,\ X,\ **check\_X\_kwargs)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00275}00275\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ X,\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00276}00276\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00277}00277\ \ \ \ \ \ \ \ \ n\_features\ =\ X.shape[1]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00278}00278\ \ \ \ \ \ \ \ \ ordinal\_encoder\ =\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__encoders_1_1OrdinalEncoder}{OrdinalEncoder}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00279}00279\ \ \ \ \ \ \ \ \ \ \ \ \ categories=\textcolor{stringliteral}{"{}auto"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00280}00280\ \ \ \ \ \ \ \ \ \ \ \ \ handle\_unknown=\textcolor{stringliteral}{"{}use\_encoded\_value"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00281}00281\ \ \ \ \ \ \ \ \ \ \ \ \ unknown\_value=np.nan,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00282}00282\ \ \ \ \ \ \ \ \ \ \ \ \ encoded\_missing\_value=np.nan,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00283}00283\ \ \ \ \ \ \ \ \ \ \ \ \ dtype=X\_DTYPE,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00284}00284\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00285}00285\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00286}00286\ \ \ \ \ \ \ \ \ check\_X\ =\ partial(check\_array,\ **check\_X\_kwargs)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00287}00287\ \ \ \ \ \ \ \ \ numerical\_preprocessor\ =\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__function__transformer_1_1FunctionTransformer}{FunctionTransformer}}(check\_X)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00288}00288\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}\ =\ \mbox{\hyperlink{classsklearn_1_1compose_1_1__column__transformer_1_1ColumnTransformer}{ColumnTransformer}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00289}00289\ \ \ \ \ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00290}00290\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}encoder"{}},\ ordinal\_encoder,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4c7b7421627b7fdb5197779d589fabc0}{is\_categorical\_}}),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00291}00291\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}numerical"{}},\ numerical\_preprocessor,\ \string~self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4c7b7421627b7fdb5197779d589fabc0}{is\_categorical\_}}),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00292}00292\ \ \ \ \ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00293}00293\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00294}00294\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}.set\_output(transform=\textcolor{stringliteral}{"{}default"{}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00295}00295\ \ \ \ \ \ \ \ \ X\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}.fit\_transform(X)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00296}00296\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ check\ categories\ found\ by\ the\ OrdinalEncoder\ and\ get\ their\ encoded\ values}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00297}00297\ \ \ \ \ \ \ \ \ known\_categories\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a61ed6d93a6abcb0671fd2cc990131a81}{\_check\_categories}}()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00298}00298\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad5e24fe1ddcb337a0a56660f3c61ba2d}{n\_features\_in\_}}\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}.n\_features\_in\_}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00299}00299\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ suppress(AttributeError):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00300}00300\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6d72f6367d82bbff8ce2b056ae5c75ff}{feature\_names\_in\_}}\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}.feature\_names\_in\_}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00301}00301\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00302}00302\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ The\ ColumnTransformer's\ output\ places\ the\ categorical\ features\ at\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00303}00303\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ beginning}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00304}00304\ \ \ \ \ \ \ \ \ categorical\_remapped\ =\ np.zeros(n\_features,\ dtype=bool)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00305}00305\ \ \ \ \ \ \ \ \ categorical\_remapped[self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}.output\_indices\_[\textcolor{stringliteral}{"{}encoder"{}}]]\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00306}00306\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_acfcab46edcccc4aa05409934159cd588}{\_is\_categorical\_remapped}}\ =\ categorical\_remapped}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00307}00307\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00308}00308\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ X,\ known\_categories}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00309}00309\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00310}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a61ed6d93a6abcb0671fd2cc990131a81}{00310}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a61ed6d93a6abcb0671fd2cc990131a81}{\_check\_categories}}(self):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00311}00311\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ categories\ found\ by\ the\ preprocessor\ and\ return\ their\ encoded\ values.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00312}00312\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00313}00313\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns\ a\ list\ of\ length\ \`{}\`{}self.n\_features\_in\_\`{}\`{},\ with\ one\ entry\ per}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00314}00314\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ input\ feature.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00315}00315\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00316}00316\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ For\ non-\/categorical\ features,\ the\ corresponding\ entry\ is\ \`{}\`{}None\`{}\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00317}00317\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00318}00318\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ For\ categorical\ features,\ the\ corresponding\ entry\ is\ an\ array}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00319}00319\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ containing\ the\ categories\ as\ encoded\ by\ the\ preprocessor\ (an}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00320}00320\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \`{}\`{}OrdinalEncoder\`{}\`{}),\ excluding\ missing\ values.\ The\ entry\ is\ therefore}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00321}00321\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \`{}\`{}np.arange(n\_categories)\`{}\`{}\ where\ \`{}\`{}n\_categories\`{}\`{}\ is\ the\ number\ of}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00322}00322\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ unique\ values\ in\ the\ considered\ feature\ column,\ after\ removing\ missing}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00323}00323\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ values.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00324}00324\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00325}00325\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ \`{}\`{}n\_categories\ >\ self.max\_bins\`{}\`{}\ for\ any\ feature,\ a\ \`{}\`{}ValueError\`{}\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00326}00326\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ raised.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00327}00327\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00328}00328\ \ \ \ \ \ \ \ \ encoder\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}.named\_transformers\_[\textcolor{stringliteral}{"{}encoder"{}}]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00329}00329\ \ \ \ \ \ \ \ \ known\_categories\ =\ [\textcolor{keywordtype}{None}]\ *\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}.n\_features\_in\_}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00330}00330\ \ \ \ \ \ \ \ \ categorical\_column\_indices\ =\ np.arange(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}.n\_features\_in\_)[}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00331}00331\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\_preprocessor}}.output\_indices\_[\textcolor{stringliteral}{"{}encoder"{}}]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00332}00332\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00333}00333\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ feature\_idx,\ categories\ \textcolor{keywordflow}{in}\ zip(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00334}00334\ \ \ \ \ \ \ \ \ \ \ \ \ categorical\_column\_indices,\ encoder.categories\_}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00335}00335\ \ \ \ \ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00336}00336\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ OrdinalEncoder\ always\ puts\ np.nan\ as\ the\ last\ category\ if\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00337}00337\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ training\ data\ has\ missing\ values.\ Here\ we\ remove\ it\ because\ it\ is}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00338}00338\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ already\ added\ by\ the\ \_BinMapper.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00339}00339\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ len(categories)\ \textcolor{keywordflow}{and}\ is\_scalar\_nan(categories[-\/1]):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00340}00340\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ categories\ =\ categories[:-\/1]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00341}00341\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ categories.size\ >\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a04540760d13c6f706f3fa44a2141f375}{max\_bins}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00342}00342\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{try}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00343}00343\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ feature\_name\ =\ repr(encoder.feature\_names\_in\_[feature\_idx])}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00344}00344\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{except}\ AttributeError:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00345}00345\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ feature\_name\ =\ f\textcolor{stringliteral}{"{}at\ index\ \{feature\_idx\}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00346}00346\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00347}00347\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}Categorical\ feature\ \{feature\_name\}\ is\ expected\ to\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00348}00348\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}have\ a\ cardinality\ <=\ \{self.max\_bins\}\ but\ actually\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00349}00349\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}has\ a\ cardinality\ of\ \{categories.size\}."{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00350}00350\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00351}00351\ \ \ \ \ \ \ \ \ \ \ \ \ known\_categories[feature\_idx]\ =\ np.arange(len(categories),\ dtype=X\_DTYPE)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00352}00352\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ known\_categories}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00353}00353\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00354}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a143ca27c8faef910d8263f7daa255392}{00354}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a143ca27c8faef910d8263f7daa255392}{\_check\_categorical\_features}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00355}00355\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ and\ validate\ categorical\ features\ in\ X}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00356}00356\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00357}00357\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00358}00358\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00359}00359\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ \{array-\/like,\ pandas\ DataFrame\}\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00360}00360\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Input\ data.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00361}00361\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00362}00362\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Return}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00363}00363\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00364}00364\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\_categorical\ :\ ndarray\ of\ shape\ (n\_features,)\ or\ None,\ dtype=bool}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00365}00365\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Indicates\ whether\ a\ feature\ is\ categorical.\ If\ no\ feature\ is}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00366}00366\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ categorical,\ this\ is\ None.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00367}00367\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00368}00368\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Special\ code\ for\ pandas\ because\ of\ a\ bug\ in\ recent\ pandas,\ which\ is}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00369}00369\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ fixed\ in\ main\ and\ maybe\ included\ in\ 2.2.1,\ see}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00370}00370\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ https://github.com/pandas-\/dev/pandas/pull/57173.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00371}00371\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Also\ pandas\ versions\ <\ 1.5.1\ do\ not\ support\ the\ dataframe\ interchange}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00372}00372\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \_is\_pandas\_df(X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00373}00373\ \ \ \ \ \ \ \ \ \ \ \ \ X\_is\_dataframe\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00374}00374\ \ \ \ \ \ \ \ \ \ \ \ \ categorical\_columns\_mask\ =\ np.asarray(X.dtypes\ ==\ \textcolor{stringliteral}{"{}category"{}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00375}00375\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{elif}\ hasattr(X,\ \textcolor{stringliteral}{"{}\_\_dataframe\_\_"{}}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00376}00376\ \ \ \ \ \ \ \ \ \ \ \ \ X\_is\_dataframe\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00377}00377\ \ \ \ \ \ \ \ \ \ \ \ \ categorical\_columns\_mask\ =\ np.asarray(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00378}00378\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00379}00379\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ c.dtype[0].name\ ==\ \textcolor{stringliteral}{"{}CATEGORICAL"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00380}00380\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ c\ \textcolor{keywordflow}{in}\ X.\_\_dataframe\_\_().get\_columns()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00381}00381\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00382}00382\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00383}00383\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00384}00384\ \ \ \ \ \ \ \ \ \ \ \ \ X\_is\_dataframe\ =\ \textcolor{keyword}{False}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00385}00385\ \ \ \ \ \ \ \ \ \ \ \ \ categorical\_columns\_mask\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00386}00386\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00387}00387\ \ \ \ \ \ \ \ \ categorical\_features\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_afc1328f9cf64db2c2a6adfa861b83061}{categorical\_features}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00388}00388\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00389}00389\ \ \ \ \ \ \ \ \ categorical\_by\_dtype\ =\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00390}00390\ \ \ \ \ \ \ \ \ \ \ \ \ isinstance(categorical\_features,\ str)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00391}00391\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{and}\ categorical\_features\ ==\ \textcolor{stringliteral}{"{}from\_dtype"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00392}00392\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00393}00393\ \ \ \ \ \ \ \ \ no\_categorical\_dtype\ =\ categorical\_features\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}\ \textcolor{keywordflow}{or}\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00394}00394\ \ \ \ \ \ \ \ \ \ \ \ \ categorical\_by\_dtype\ \textcolor{keywordflow}{and}\ \textcolor{keywordflow}{not}\ X\_is\_dataframe}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00395}00395\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00396}00396\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00397}00397\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ no\_categorical\_dtype:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00398}00398\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00399}00399\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00400}00400\ \ \ \ \ \ \ \ \ use\_pandas\_categorical\ =\ categorical\_by\_dtype\ \textcolor{keywordflow}{and}\ X\_is\_dataframe}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00401}00401\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ use\_pandas\_categorical:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00402}00402\ \ \ \ \ \ \ \ \ \ \ \ \ categorical\_features\ =\ categorical\_columns\_mask}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00403}00403\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00404}00404\ \ \ \ \ \ \ \ \ \ \ \ \ categorical\_features\ =\ np.asarray(categorical\_features)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00405}00405\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00406}00406\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ categorical\_features.size\ ==\ 0:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00407}00407\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00408}00408\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00409}00409\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ categorical\_features.dtype.kind\ \textcolor{keywordflow}{not}\ \textcolor{keywordflow}{in}\ (\textcolor{stringliteral}{"{}i"{}},\ \textcolor{stringliteral}{"{}b"{}},\ \textcolor{stringliteral}{"{}U"{}},\ \textcolor{stringliteral}{"{}O"{}}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00410}00410\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00411}00411\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ must\ be\ an\ array-\/like\ of\ bool,\ int\ or\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00412}00412\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}str,\ got:\ \{categorical\_features.dtype.name\}."{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00413}00413\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00414}00414\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00415}00415\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ categorical\_features.dtype.kind\ ==\ \textcolor{stringliteral}{"{}O"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00416}00416\ \ \ \ \ \ \ \ \ \ \ \ \ types\ =\ set(type(f)\ \textcolor{keywordflow}{for}\ f\ \textcolor{keywordflow}{in}\ categorical\_features)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00417}00417\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ types\ !=\ \{str\}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00418}00418\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00419}00419\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ must\ be\ an\ array-\/like\ of\ bool,\ int\ or\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00420}00420\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}str,\ got:\ \{',\ '.join(sorted(t.\_\_name\_\_\ for\ t\ in\ types))\}."{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00421}00421\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00422}00422\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00423}00423\ \ \ \ \ \ \ \ \ n\_features\ =\ X.shape[1]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00424}00424\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ At\ this\ point\ \`{}validate\_data`\ was\ not\ called\ yet\ because\ we\ use\ the\ original}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00425}00425\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ dtypes\ to\ discover\ the\ categorical\ features.\ Thus\ \`{}feature\_names\_in\_`}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00426}00426\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ is\ not\ defined\ yet.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00427}00427\ \ \ \ \ \ \ \ \ feature\_names\_in\_\ =\ getattr(X,\ \textcolor{stringliteral}{"{}columns"{}},\ \textcolor{keywordtype}{None})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00428}00428\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00429}00429\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ categorical\_features.dtype.kind\ \textcolor{keywordflow}{in}\ (\textcolor{stringliteral}{"{}U"{}},\ \textcolor{stringliteral}{"{}O"{}}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00430}00430\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ check\ for\ feature\ names}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00431}00431\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ feature\_names\_in\_\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00432}00432\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00433}00433\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ should\ be\ passed\ as\ an\ array\ of\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00434}00434\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}integers\ or\ as\ a\ boolean\ mask\ when\ the\ model\ is\ fitted\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00435}00435\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}on\ data\ without\ feature\ names."{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00436}00436\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00437}00437\ \ \ \ \ \ \ \ \ \ \ \ \ is\_categorical\ =\ np.zeros(n\_features,\ dtype=bool)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00438}00438\ \ \ \ \ \ \ \ \ \ \ \ \ feature\_names\ =\ list(feature\_names\_in\_)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00439}00439\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ feature\_name\ \textcolor{keywordflow}{in}\ categorical\_features:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00440}00440\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{try}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00441}00441\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ is\_categorical[feature\_names.index(feature\_name)]\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00442}00442\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{except}\ ValueError\ \textcolor{keyword}{as}\ e:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00443}00443\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00444}00444\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}categorical\_features\ has\ a\ item\ value\ '\{feature\_name\}'\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00445}00445\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}which\ is\ not\ a\ valid\ feature\ name\ of\ the\ training\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00446}00446\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}data.\ Observed\ feature\ names:\ \{feature\_names\}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00447}00447\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )\ \textcolor{keyword}{from}\ e}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00448}00448\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{elif}\ categorical\_features.dtype.kind\ ==\ \textcolor{stringliteral}{"{}i"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00449}00449\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ check\ for\ categorical\ features\ as\ indices}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00450}00450\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00451}00451\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ np.max(categorical\_features)\ >=\ n\_features}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00452}00452\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{or}\ np.min(categorical\_features)\ <\ 0}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00453}00453\ \ \ \ \ \ \ \ \ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00454}00454\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00455}00455\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ set\ as\ integer\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00456}00456\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}indices\ must\ be\ in\ [0,\ n\_features\ -\/\ 1]"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00457}00457\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00458}00458\ \ \ \ \ \ \ \ \ \ \ \ \ is\_categorical\ =\ np.zeros(n\_features,\ dtype=bool)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00459}00459\ \ \ \ \ \ \ \ \ \ \ \ \ is\_categorical[categorical\_features]\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00460}00460\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00461}00461\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ categorical\_features.shape[0]\ !=\ n\_features:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00462}00462\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00463}00463\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ set\ as\ a\ boolean\ mask\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00464}00464\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}must\ have\ shape\ (n\_features,),\ got:\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00465}00465\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}\{categorical\_features.shape\}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00466}00466\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00467}00467\ \ \ \ \ \ \ \ \ \ \ \ \ is\_categorical\ =\ categorical\_features}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00468}00468\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00469}00469\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ np.any(is\_categorical):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00470}00470\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00471}00471\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ is\_categorical}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00472}00472\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00473}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a85388db29ea4b4a6436c756b97b3197e}{00473}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a85388db29ea4b4a6436c756b97b3197e}{\_check\_interaction\_cst}}(self,\ n\_features):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00474}00474\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ and\ validation\ for\ interaction\ constraints."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00475}00475\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a0ce6a6d7576db5ab409ae2f8f1d6b7b7}{interaction\_cst}}\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00476}00476\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00477}00477\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00478}00478\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a0ce6a6d7576db5ab409ae2f8f1d6b7b7}{interaction\_cst}}\ ==\ \textcolor{stringliteral}{"{}no\_interactions"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00479}00479\ \ \ \ \ \ \ \ \ \ \ \ \ interaction\_cst\ =\ [[i]\ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(n\_features)]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00480}00480\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{elif}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a0ce6a6d7576db5ab409ae2f8f1d6b7b7}{interaction\_cst}}\ ==\ \textcolor{stringliteral}{"{}pairwise"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00481}00481\ \ \ \ \ \ \ \ \ \ \ \ \ interaction\_cst\ =\ itertools.combinations(range(n\_features),\ 2)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00482}00482\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00483}00483\ \ \ \ \ \ \ \ \ \ \ \ \ interaction\_cst\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a0ce6a6d7576db5ab409ae2f8f1d6b7b7}{interaction\_cst}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00484}00484\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00485}00485\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{try}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00486}00486\ \ \ \ \ \ \ \ \ \ \ \ \ constraints\ =\ [set(group)\ \textcolor{keywordflow}{for}\ group\ \textcolor{keywordflow}{in}\ interaction\_cst]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00487}00487\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{except}\ TypeError:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00488}00488\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00489}00489\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Interaction\ constraints\ must\ be\ a\ sequence\ of\ tuples\ or\ lists,\ got:"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00490}00490\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}\ \{self.interaction\_cst!r\}."{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00491}00491\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00492}00492\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00493}00493\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ group\ \textcolor{keywordflow}{in}\ constraints:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00494}00494\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ x\ \textcolor{keywordflow}{in}\ group:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00495}00495\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ (isinstance(x,\ Integral)\ \textcolor{keywordflow}{and}\ 0\ <=\ x\ <\ n\_features):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00496}00496\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00497}00497\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Interaction\ constraints\ must\ consist\ of\ integer\ indices\ in"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00498}00498\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}\ [0,\ n\_features\ -\/\ 1]\ =\ [0,\ \{n\_features\ -\/\ 1\}],\ specifying\ the"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00499}00499\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\ position\ of\ features,\ got\ invalid\ indices:"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00500}00500\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}\ \{group!r\}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00501}00501\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00502}00502\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00503}00503\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Add\ all\ not\ listed\ features\ as\ own\ group\ by\ default.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00504}00504\ \ \ \ \ \ \ \ \ rest\ =\ set(range(n\_features))\ -\/\ set().union(*constraints)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00505}00505\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ len(rest)\ >\ 0:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00506}00506\ \ \ \ \ \ \ \ \ \ \ \ \ constraints.append(rest)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00507}00507\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00508}00508\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ constraints}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00509}00509\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00510}00510\ \ \ \ \ \textcolor{preprocessor}{@\_fit\_context(prefer\_skip\_nested\_validation=True)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00511}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aba1c789013d8236ed9a2c14764603920}{00511}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aba1c789013d8236ed9a2c14764603920}{fit}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00512}00512\ \ \ \ \ \ \ \ \ self,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00513}00513\ \ \ \ \ \ \ \ \ X,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00514}00514\ \ \ \ \ \ \ \ \ y,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00515}00515\ \ \ \ \ \ \ \ \ sample\_weight=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00516}00516\ \ \ \ \ \ \ \ \ *,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00517}00517\ \ \ \ \ \ \ \ \ X\_val=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00518}00518\ \ \ \ \ \ \ \ \ y\_val=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00519}00519\ \ \ \ \ \ \ \ \ sample\_weight\_val=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00520}00520\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00521}00521\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Fit\ the\ gradient\ boosting\ model.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00522}00522\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00523}00523\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00524}00524\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00525}00525\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00526}00526\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00527}00527\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00528}00528\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ y\ :\ array-\/like\ of\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00529}00529\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Target\ values.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00530}00530\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00531}00531\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ sample\_weight\ :\ array-\/like\ of\ shape\ (n\_samples,)\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00532}00532\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Weights\ of\ training\ data.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00533}00533\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00534}00534\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ ..\ versionadded::\ 0.23}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00535}00535\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00536}00536\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\_val\ :\ array-\/like\ of\ shape\ (n\_val,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00537}00537\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Additional\ sample\ of\ features\ for\ validation\ used\ in\ early\ stopping.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00538}00538\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ In\ a\ \`{}Pipeline\`{},\ \`{}X\_val\`{}\ can\ be\ transformed\ the\ same\ way\ as\ \`{}X\`{}\ with}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00539}00539\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ \`{}Pipeline(...,\ transform\_input=["{}X\_val"{}])\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00540}00540\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00541}00541\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ ..\ versionadded::\ 1.7}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00542}00542\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00543}00543\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ y\_val\ :\ array-\/like\ of\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00544}00544\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Additional\ sample\ of\ target\ values\ for\ validation\ used\ in\ early\ stopping.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00545}00545\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00546}00546\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ ..\ versionadded::\ 1.7}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00547}00547\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00548}00548\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ sample\_weight\_val\ :\ array-\/like\ of\ shape\ (n\_samples,)\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00549}00549\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Additional\ weights\ for\ validation\ used\ in\ early\ stopping.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00550}00550\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00551}00551\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ ..\ versionadded::\ 1.7}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00552}00552\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00553}00553\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00554}00554\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00555}00555\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ self\ :\ object}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00556}00556\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Fitted\ estimator.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00557}00557\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00558}00558\ \ \ \ \ \ \ \ \ fit\_start\_time\ =\ time()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00559}00559\ \ \ \ \ \ \ \ \ acc\_find\_split\_time\ =\ 0.0\ \ \textcolor{comment}{\#\ time\ spent\ finding\ the\ best\ splits}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00560}00560\ \ \ \ \ \ \ \ \ acc\_apply\_split\_time\ =\ 0.0\ \ \textcolor{comment}{\#\ time\ spent\ splitting\ nodes}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00561}00561\ \ \ \ \ \ \ \ \ acc\_compute\_hist\_time\ =\ 0.0\ \ \textcolor{comment}{\#\ time\ spent\ computing\ histograms}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00562}00562\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ time\ spent\ predicting\ X\ for\ gradient\ and\ hessians\ update}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00563}00563\ \ \ \ \ \ \ \ \ acc\_prediction\_time\ =\ 0.0}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00564}00564\ \ \ \ \ \ \ \ \ X,\ known\_categories\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab6a1278c0901cb920029746815bcd824}{\_preprocess\_X}}(X,\ reset=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00565}00565\ \ \ \ \ \ \ \ \ y\ =\ \_check\_y(y,\ estimator=self)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00566}00566\ \ \ \ \ \ \ \ \ y\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab17dd70a33da6ddd55769a4ed508940d}{\_encode\_y}}(y)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00567}00567\ \ \ \ \ \ \ \ \ check\_consistent\_length(X,\ y)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00568}00568\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Do\ not\ create\ unit\ sample\ weights\ by\ default\ to\ later\ skip\ some}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00569}00569\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ computation}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00570}00570\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ sample\_weight\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00571}00571\ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\ =\ \_check\_sample\_weight(sample\_weight,\ X,\ dtype=np.float64)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00572}00572\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ TODO:\ remove\ when\ PDP\ supports\ sample\ weights}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00573}00573\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a3fc3ed969cf9ec1b7e614eae599e1d66}{\_fitted\_with\_sw}}\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00574}00574\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00575}00575\ \ \ \ \ \ \ \ \ sample\_weight\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a3c6c73d838fa46ad6f3c0ccfc2ff4cdb}{\_finalize\_sample\_weight}}(sample\_weight,\ y)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00576}00576\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00577}00577\ \ \ \ \ \ \ \ \ validation\_data\_provided\ =\ X\_val\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}\ \textcolor{keywordflow}{or}\ y\_val\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00578}00578\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ validation\_data\_provided:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00579}00579\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ y\_val\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00580}00580\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(\textcolor{stringliteral}{"{}X\_val\ is\ provided,\ but\ y\_val\ was\ not\ provided."{}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00581}00581\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ X\_val\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00582}00582\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(\textcolor{stringliteral}{"{}y\_val\ is\ provided,\ but\ X\_val\ was\ not\ provided."{}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00583}00583\ \ \ \ \ \ \ \ \ \ \ \ \ X\_val\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab6a1278c0901cb920029746815bcd824}{\_preprocess\_X}}(X\_val,\ reset=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00584}00584\ \ \ \ \ \ \ \ \ \ \ \ \ y\_val\ =\ \_check\_y(y\_val,\ estimator=self)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00585}00585\ \ \ \ \ \ \ \ \ \ \ \ \ y\_val\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a2b993e758e4ca456cf54c92f72a982b9}{\_encode\_y\_val}}(y\_val)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00586}00586\ \ \ \ \ \ \ \ \ \ \ \ \ check\_consistent\_length(X\_val,\ y\_val)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00587}00587\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ sample\_weight\_val\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00588}00588\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_val\ =\ \_check\_sample\_weight(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00589}00589\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_val,\ X\_val,\ dtype=np.float64}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00590}00590\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00591}00591\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a7c1bb95883298c852627543f531c89bf}{early\_stopping}}\ \textcolor{keywordflow}{is}\ \textcolor{keyword}{False}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00592}00592\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00593}00593\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}X\_val\ and\ y\_val\ are\ passed\ to\ fit\ while\ at\ the\ same\ time\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00594}00594\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}early\_stopping\ is\ False.\ When\ passing\ X\_val\ and\ y\_val\ to\ fit,"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00595}00595\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}early\_stopping\ should\ be\ set\ to\ either\ 'auto'\ or\ True."{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00596}00596\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00597}00597\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00598}00598\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Note:\ At\ this\ point,\ we\ could\ delete\ self.\_label\_encoder\ if\ it\ exists.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00599}00599\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ But\ we\ don't\ to\ keep\ the\ code\ even\ simpler.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00600}00600\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00601}00601\ \ \ \ \ \ \ \ \ rng\ =\ check\_random\_state(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a82a4dbec8808de99c79d689c08e15af0}{random\_state}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00602}00602\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00603}00603\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ When\ warm\ starting,\ we\ want\ to\ reuse\ the\ same\ seed\ that\ was\ used}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00604}00604\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ the\ first\ time\ fit\ was\ called\ (e.g.\ train/val\ split).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00605}00605\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ For\ feature\ subsampling,\ we\ want\ to\ continue\ with\ the\ rng\ we\ started\ with.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00606}00606\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a396309db1f0dbf7fda8fcafeaa229df3}{warm\_start}}\ \textcolor{keywordflow}{or}\ \textcolor{keywordflow}{not}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a62834f9ffe3a13cbb18586f837d39d5b}{\_is\_fitted}}():}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00607}00607\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1abec81a6e54982be76ec308ce533dc3}{\_random\_seed}}\ =\ rng.randint(np.iinfo(np.uint32).max,\ dtype=\textcolor{stringliteral}{"{}u8"{}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00608}00608\ \ \ \ \ \ \ \ \ \ \ \ \ feature\_subsample\_seed\ =\ rng.randint(np.iinfo(np.uint32).max,\ dtype=\textcolor{stringliteral}{"{}u8"{}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00609}00609\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_accbd70f6b5b1826c48e1dd38bf5ce355}{\_feature\_subsample\_rng}}\ =\ np.random.default\_rng(feature\_subsample\_seed)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00610}00610\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00611}00611\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a42806b43b1e86cb64f2366ff04a2d3d6}{\_validate\_parameters}}()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00612}00612\ \ \ \ \ \ \ \ \ monotonic\_cst\ =\ \_check\_monotonic\_cst(self,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad5f1696e1fd74498621f3a2e13cef6f6}{monotonic\_cst}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00613}00613\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ \_preprocess\_X\ places\ the\ categorical\ features\ at\ the\ beginning,}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00614}00614\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ change\ the\ order\ of\ monotonic\_cst\ accordingly}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00615}00615\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4c7b7421627b7fdb5197779d589fabc0}{is\_categorical\_}}\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00616}00616\ \ \ \ \ \ \ \ \ \ \ \ \ monotonic\_cst\_remapped\ =\ np.concatenate(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00617}00617\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00618}00618\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ monotonic\_cst[self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4c7b7421627b7fdb5197779d589fabc0}{is\_categorical\_}}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00619}00619\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ monotonic\_cst[\string~self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4c7b7421627b7fdb5197779d589fabc0}{is\_categorical\_}}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00620}00620\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00621}00621\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00622}00622\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00623}00623\ \ \ \ \ \ \ \ \ \ \ \ \ monotonic\_cst\_remapped\ =\ monotonic\_cst}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00624}00624\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00625}00625\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ used\ for\ validation\ in\ predict}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00626}00626\ \ \ \ \ \ \ \ \ n\_samples,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfa366e1408cc8abaf718dbc73586042}{\_n\_features}}\ =\ X.shape}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00627}00627\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00628}00628\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Encode\ constraints\ into\ a\ list\ of\ sets\ of\ features\ indices\ (integers).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00629}00629\ \ \ \ \ \ \ \ \ interaction\_cst\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a85388db29ea4b4a6436c756b97b3197e}{\_check\_interaction\_cst}}(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfa366e1408cc8abaf718dbc73586042}{\_n\_features}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00630}00630\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00631}00631\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ we\ need\ this\ stateful\ variable\ to\ tell\ raw\_predict()\ that\ it\ was}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00632}00632\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ called\ from\ fit()\ (this\ current\ method),\ and\ that\ the\ data\ it\ has}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00633}00633\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ received\ is\ pre-\/binned.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00634}00634\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ predicting\ is\ faster\ on\ pre-\/binned\ data,\ so\ we\ want\ early\ stopping}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00635}00635\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ predictions\ to\ be\ made\ on\ pre-\/binned\ data.\ Unfortunately\ the\ \_scorer}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00636}00636\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ can\ only\ call\ predict()\ or\ predict\_proba(),\ not\ raw\_predict(),\ and}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00637}00637\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ there's\ no\ way\ to\ tell\ the\ scorer\ that\ it\ needs\ to\ predict\ binned}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00638}00638\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ data.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00639}00639\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a9fe0089caa05ed5692ffbff1b47a119d}{\_in\_fit}}\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00640}00640\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00641}00641\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ \`{}\_openmp\_effective\_n\_threads`\ is\ used\ to\ take\ cgroups\ CPU\ quotes}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00642}00642\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ into\ account\ when\ determine\ the\ maximum\ number\ of\ threads\ to\ use.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00643}00643\ \ \ \ \ \ \ \ \ n\_threads\ =\ \_openmp\_effective\_n\_threads()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00644}00644\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00645}00645\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ isinstance(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1f71d4fd84cefb07d3a4187160d3bf9b}{loss}},\ str):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00646}00646\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a7101a9aabf502252e29ad1c2b2c45cc6}{\_get\_loss}}(sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00647}00647\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{elif}\ isinstance(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1f71d4fd84cefb07d3a4187160d3bf9b}{loss}},\ BaseLoss):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00648}00648\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1f71d4fd84cefb07d3a4187160d3bf9b}{loss}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00649}00649\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00650}00650\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a7c1bb95883298c852627543f531c89bf}{early\_stopping}}\ ==\ \textcolor{stringliteral}{"{}auto"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00651}00651\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa98b01cc7ca7beefda4cec76e10c29ac}{do\_early\_stopping\_}}\ =\ n\_samples\ >\ 10\_000}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00652}00652\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00653}00653\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa98b01cc7ca7beefda4cec76e10c29ac}{do\_early\_stopping\_}}\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a7c1bb95883298c852627543f531c89bf}{early\_stopping}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00654}00654\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00655}00655\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ create\ validation\ data\ if\ needed}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00656}00656\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a12bb6a5453b140706a0da21a0d4ab62b}{\_use\_validation\_data}}\ =\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00657}00657\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa7961cd8f3763607f578eceac4515b18}{validation\_fraction}}\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}\ \textcolor{keywordflow}{or}\ validation\_data\_provided}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00658}00658\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00659}00659\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00660}00660\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa98b01cc7ca7beefda4cec76e10c29ac}{do\_early\_stopping\_}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00661}00661\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{and}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a12bb6a5453b140706a0da21a0d4ab62b}{\_use\_validation\_data}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00662}00662\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{and}\ \textcolor{keywordflow}{not}\ validation\_data\_provided}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00663}00663\ \ \ \ \ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00664}00664\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ stratify\ for\ classification}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00665}00665\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ instead\ of\ checking\ predict\_proba,\ loss.n\_classes\ >=\ 2\ would\ also\ work}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00666}00666\ \ \ \ \ \ \ \ \ \ \ \ \ stratify\ =\ y\ \textcolor{keywordflow}{if}\ hasattr(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}},\ \textcolor{stringliteral}{"{}predict\_proba"{}})\ \textcolor{keywordflow}{else}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00667}00667\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00668}00668\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Save\ the\ state\ of\ the\ RNG\ for\ the\ training\ and\ validation\ split.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00669}00669\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ This\ is\ needed\ in\ order\ to\ have\ the\ same\ split\ when\ using}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00670}00670\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ warm\ starting.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00671}00671\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00672}00672\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ sample\_weight\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00673}00673\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_train,\ X\_val,\ y\_train,\ y\_val\ =\ train\_test\_split(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00674}00674\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00675}00675\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00676}00676\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ test\_size=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa7961cd8f3763607f578eceac4515b18}{validation\_fraction}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00677}00677\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ stratify=stratify,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00678}00678\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1abec81a6e54982be76ec308ce533dc3}{\_random\_seed}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00679}00679\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00680}00680\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_train\ =\ sample\_weight\_val\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00681}00681\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00682}00682\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ TODO:\ incorporate\ sample\_weight\ in\ sampling\ here,\ as\ well\ as}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00683}00683\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ stratify}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00684}00684\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00685}00685\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00686}00686\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00687}00687\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00688}00688\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00689}00689\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00690}00690\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00691}00691\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )\ =\ train\_test\_split(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00692}00692\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00693}00693\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00694}00694\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00695}00695\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ test\_size=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa7961cd8f3763607f578eceac4515b18}{validation\_fraction}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00696}00696\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ stratify=stratify,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00697}00697\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1abec81a6e54982be76ec308ce533dc3}{\_random\_seed}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00698}00698\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00699}00699\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00700}00700\ \ \ \ \ \ \ \ \ \ \ \ \ X\_train,\ y\_train,\ sample\_weight\_train\ =\ X,\ y,\ sample\_weight}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00701}00701\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ validation\_data\_provided:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00702}00702\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_val\ =\ y\_val\ =\ sample\_weight\_val\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00703}00703\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00704}00704\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Bin\ the\ data}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00705}00705\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ For\ ease\ of\ use\ of\ the\ API,\ the\ user-\/facing\ GBDT\ classes\ accept\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00706}00706\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ parameter\ max\_bins,\ which\ doesn't\ take\ into\ account\ the\ bin\ for}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00707}00707\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ missing\ values\ (which\ is\ always\ allocated).\ However,\ since\ max\_bins}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00708}00708\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ isn't\ the\ true\ maximal\ number\ of\ bins,\ all\ other\ private\ classes}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00709}00709\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ (binmapper,\ histbuilder...)\ accept\ n\_bins\ instead,\ which\ is\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00710}00710\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ actual\ total\ number\ of\ bins.\ Everywhere\ in\ the\ code,\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00711}00711\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ convention\ is\ that\ n\_bins\ ==\ max\_bins\ +\ 1}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00712}00712\ \ \ \ \ \ \ \ \ n\_bins\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a04540760d13c6f706f3fa44a2141f375}{max\_bins}}\ +\ 1\ \ \textcolor{comment}{\#\ +\ 1\ for\ missing\ values}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00713}00713\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af07b37765017ed0b88be84e4fb9aeedb}{\_bin\_mapper}}\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1binning_1_1__BinMapper}{\_BinMapper}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00714}00714\ \ \ \ \ \ \ \ \ \ \ \ \ n\_bins=n\_bins,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00715}00715\ \ \ \ \ \ \ \ \ \ \ \ \ is\_categorical=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_acfcab46edcccc4aa05409934159cd588}{\_is\_categorical\_remapped}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00716}00716\ \ \ \ \ \ \ \ \ \ \ \ \ known\_categories=known\_categories,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00717}00717\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1abec81a6e54982be76ec308ce533dc3}{\_random\_seed}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00718}00718\ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00719}00719\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00720}00720\ \ \ \ \ \ \ \ \ X\_binned\_train\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af18b1289a37ebf4c07a0417a040f4a0c}{\_bin\_data}}(X\_train,\ is\_training\_data=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00721}00721\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ X\_val\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00722}00722\ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_val\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af18b1289a37ebf4c07a0417a040f4a0c}{\_bin\_data}}(X\_val,\ is\_training\_data=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00723}00723\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00724}00724\ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_val\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00725}00725\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00726}00726\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Uses\ binned\ data\ to\ check\ for\ missing\ values}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00727}00727\ \ \ \ \ \ \ \ \ has\_missing\_values\ =\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00728}00728\ \ \ \ \ \ \ \ \ \ \ \ \ (X\_binned\_train\ ==\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af07b37765017ed0b88be84e4fb9aeedb}{\_bin\_mapper}}.missing\_values\_bin\_idx\_)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00729}00729\ \ \ \ \ \ \ \ \ \ \ \ \ .any(axis=0)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00730}00730\ \ \ \ \ \ \ \ \ \ \ \ \ .astype(np.uint8)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00731}00731\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00732}00732\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00733}00733\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a39a3969984cde73a5dc0879387502020}{verbose}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00734}00734\ \ \ \ \ \ \ \ \ \ \ \ \ print(\textcolor{stringliteral}{"{}Fitting\ gradient\ boosted\ rounds:"{}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00735}00735\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00736}00736\ \ \ \ \ \ \ \ \ n\_samples\ =\ X\_binned\_train.shape[0]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00737}00737\ \ \ \ \ \ \ \ \ scoring\_is\_predefined\_string\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a77783dab5cef4f645a5d0ff93e4deb11}{scoring}}\ \textcolor{keywordflow}{in}\ \_SCORERS}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00738}00738\ \ \ \ \ \ \ \ \ need\_raw\_predictions\_val\ =\ X\_binned\_val\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}\ \textcolor{keywordflow}{and}\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00739}00739\ \ \ \ \ \ \ \ \ \ \ \ \ scoring\_is\_predefined\_string\ \textcolor{keywordflow}{or}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a77783dab5cef4f645a5d0ff93e4deb11}{scoring}}\ ==\ \textcolor{stringliteral}{"{}loss"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00740}00740\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00741}00741\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ First\ time\ calling\ fit,\ or\ no\ warm\ start}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00742}00742\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ (self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a62834f9ffe3a13cbb18586f837d39d5b}{\_is\_fitted}}()\ \textcolor{keywordflow}{and}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a396309db1f0dbf7fda8fcafeaa229df3}{warm\_start}}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00743}00743\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Clear\ random\ state\ and\ score\ attributes}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00744}00744\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a0792fbcff561bb817840f5214c3d9dd6}{\_clear\_state}}()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00745}00745\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00746}00746\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ initialize\ raw\_predictions:\ those\ are\ the\ accumulated\ values}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00747}00747\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ predicted\ by\ the\ trees\ for\ the\ training\ data.\ raw\_predictions\ has}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00748}00748\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ shape\ (n\_samples,\ n\_trees\_per\_iteration)\ where}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00749}00749\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ n\_trees\_per\_iterations\ is\ n\_classes\ in\ multiclass\ classification,}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00750}00750\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ else\ 1.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00751}00751\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ self.\_baseline\_prediction\ has\ shape\ (1,\ n\_trees\_per\_iteration)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00752}00752\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa8cf30a8c23006d33229e1abf8a1c087}{\_baseline\_prediction}}\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}.fit\_intercept\_only(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00753}00753\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_true=y\_train,\ sample\_weight=sample\_weight\_train}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00754}00754\ \ \ \ \ \ \ \ \ \ \ \ \ ).reshape((1,\ -\/1))}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00755}00755\ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\ =\ np.zeros(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00756}00756\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ shape=(n\_samples,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}}),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00757}00757\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ dtype=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa8cf30a8c23006d33229e1abf8a1c087}{\_baseline\_prediction}}.dtype,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00758}00758\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ order=\textcolor{stringliteral}{"{}F"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00759}00759\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00760}00760\ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\ +=\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa8cf30a8c23006d33229e1abf8a1c087}{\_baseline\_prediction}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00761}00761\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00762}00762\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ predictors\ is\ a\ matrix\ (list\ of\ lists)\ of\ TreePredictor\ objects}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00763}00763\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ with\ shape\ (n\_iter\_,\ n\_trees\_per\_iteration)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00764}00764\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}}\ =\ predictors\ =\ []}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00765}00765\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00766}00766\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Initialize\ structures\ and\ attributes\ related\ to\ early\ stopping}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00767}00767\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a583f9f75f3267a2610ff33c46cf28474}{\_scorer}}\ =\ \textcolor{keywordtype}{None}\ \ \textcolor{comment}{\#\ set\ if\ scoring\ !=\ loss}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00768}00768\ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_val\ =\ \textcolor{keywordtype}{None}\ \ \textcolor{comment}{\#\ set\ if\ use\ val\ and\ scoring\ is\ a\ string}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00769}00769\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\_score\_}}\ =\ []}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00770}00770\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\_score\_}}\ =\ []}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00771}00771\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00772}00772\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa98b01cc7ca7beefda4cec76e10c29ac}{do\_early\_stopping\_}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00773}00773\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ populate\ train\_score\ and\ validation\_score\ with\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00774}00774\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ predictions\ of\ the\ initial\ model\ (before\ the\ first\ tree)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00775}00775\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00776}00776\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Create\ raw\_predictions\_val\ for\ storing\ the\ raw\ predictions\ of}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00777}00777\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ the\ validation\ data.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00778}00778\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ need\_raw\_predictions\_val:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00779}00779\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_val\ =\ np.zeros(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00780}00780\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ shape=(X\_binned\_val.shape[0],\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}}),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00781}00781\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ dtype=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa8cf30a8c23006d33229e1abf8a1c087}{\_baseline\_prediction}}.dtype,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00782}00782\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ order=\textcolor{stringliteral}{"{}F"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00783}00783\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00784}00784\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00785}00785\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_val\ +=\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa8cf30a8c23006d33229e1abf8a1c087}{\_baseline\_prediction}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00786}00786\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00787}00787\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a77783dab5cef4f645a5d0ff93e4deb11}{scoring}}\ ==\ \textcolor{stringliteral}{"{}loss"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00788}00788\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ we're\ going\ to\ compute\ scoring\ w.r.t\ the\ loss.\ As\ losses}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00789}00789\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ take\ raw\ predictions\ as\ input\ (unlike\ the\ scorers),\ we}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00790}00790\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ can\ optimize\ a\ bit\ and\ avoid\ repeating\ computing\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00791}00791\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ predictions\ of\ the\ previous\ trees.\ We'll\ reuse}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00792}00792\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ raw\_predictions\ (as\ it's\ needed\ for\ training\ anyway)\ for}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00793}00793\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ evaluating\ the\ training\ loss.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00794}00794\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00795}00795\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a689244514867e65787fc11c5520170f7}{\_check\_early\_stopping\_loss}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00796}00796\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions=raw\_predictions,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00797}00797\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_train=y\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00798}00798\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_train=sample\_weight\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00799}00799\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_val=raw\_predictions\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00800}00800\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_val=y\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00801}00801\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_val=sample\_weight\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00802}00802\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00803}00803\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00804}00804\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00805}00805\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a583f9f75f3267a2610ff33c46cf28474}{\_scorer}}\ =\ check\_scoring(self,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a77783dab5cef4f645a5d0ff93e4deb11}{scoring}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00806}00806\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ \_scorer\ is\ a\ callable\ with\ signature\ (est,\ X,\ y)\ and}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00807}00807\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ calls\ est.predict()\ or\ est.predict\_proba()\ depending\ on}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00808}00808\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ its\ nature.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00809}00809\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Unfortunately,\ each\ call\ to\ \_scorer()\ will\ compute}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00810}00810\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ the\ predictions\ of\ all\ the\ trees.\ So\ we\ use\ a\ subset\ of}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00811}00811\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ the\ training\ set\ to\ compute\ train\ scores.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00812}00812\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00813}00813\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Compute\ the\ subsample\ set}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00814}00814\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00815}00815\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00816}00816\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00817}00817\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00818}00818\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ indices\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00819}00819\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1d9017aa611476cd705da844cfa93034}{\_get\_small\_trainset}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00820}00820\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00821}00821\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00822}00822\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00823}00823\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1abec81a6e54982be76ec308ce533dc3}{\_random\_seed}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00824}00824\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00825}00825\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00826}00826\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ If\ the\ scorer\ is\ a\ predefined\ string,\ then\ we\ optimize}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00827}00827\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ the\ evaluation\ by\ reusing\ the\ incrementally\ updated\ raw}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00828}00828\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ predictions.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00829}00829\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ scoring\_is\_predefined\_string:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00830}00830\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_small\_train\ =\ raw\_predictions[}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00831}00831\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ indices\_small\_train}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00832}00832\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00833}00833\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00834}00834\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_small\_train\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00835}00835\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00836}00836\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad3e56b83f7d785263ddc43e0acc6342c}{\_check\_early\_stopping\_scorer}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00837}00837\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00838}00838\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00839}00839\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00840}00840\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00841}00841\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00842}00842\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00843}00843\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_small\_train=raw\_predictions\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00844}00844\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_val=raw\_predictions\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00845}00845\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00846}00846\ \ \ \ \ \ \ \ \ \ \ \ \ begin\_at\_stage\ =\ 0}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00847}00847\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00848}00848\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ warm\ start:\ this\ is\ not\ the\ first\ time\ fit\ was\ called}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00849}00849\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00850}00850\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ the\ maximum\ number\ of\ iterations\ is\ not\ smaller}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00851}00851\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ than\ the\ number\ of\ iterations\ from\ the\ previous\ fit}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00852}00852\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8c4630fd50d86dfd270c7b0afbd636fb}{max\_iter}}\ <\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a68e87816ed5daf6e6c99c3d59fc22166}{n\_iter\_}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00853}00853\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00854}00854\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_iter=\%d\ must\ be\ larger\ than\ or\ equal\ to\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00855}00855\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}n\_iter\_=\%d\ when\ warm\_start==True"{}}\ \%\ (self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8c4630fd50d86dfd270c7b0afbd636fb}{max\_iter}},\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a68e87816ed5daf6e6c99c3d59fc22166}{n\_iter\_}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00856}00856\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00857}00857\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00858}00858\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Convert\ array\ attributes\ to\ lists}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00859}00859\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\_score\_}}\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\_score\_}}.tolist()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00860}00860\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\_score\_}}\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\_score\_}}.tolist()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00861}00861\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00862}00862\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Compute\ raw\ predictions}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00863}00863\ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa4a8356439ef87a220f9ec262a885137}{\_raw\_predict}}(X\_binned\_train,\ n\_threads=n\_threads)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00864}00864\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa98b01cc7ca7beefda4cec76e10c29ac}{do\_early\_stopping\_}}\ \textcolor{keywordflow}{and}\ need\_raw\_predictions\_val:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00865}00865\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_val\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa4a8356439ef87a220f9ec262a885137}{\_raw\_predict}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00866}00866\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_val,\ n\_threads=n\_threads}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00867}00867\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00868}00868\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00869}00869\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_val\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00870}00870\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00871}00871\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa98b01cc7ca7beefda4cec76e10c29ac}{do\_early\_stopping\_}}\ \textcolor{keywordflow}{and}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a77783dab5cef4f645a5d0ff93e4deb11}{scoring}}\ !=\ \textcolor{stringliteral}{"{}loss"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00872}00872\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Compute\ the\ subsample\ set}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00873}00873\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00874}00874\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00875}00875\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00876}00876\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00877}00877\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ indices\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00878}00878\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1d9017aa611476cd705da844cfa93034}{\_get\_small\_trainset}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00879}00879\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_train,\ y\_train,\ sample\_weight\_train,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1abec81a6e54982be76ec308ce533dc3}{\_random\_seed}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00880}00880\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00881}00881\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00882}00882\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Get\ the\ predictors\ from\ the\ previous\ fit}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00883}00883\ \ \ \ \ \ \ \ \ \ \ \ \ predictors\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00884}00884\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00885}00885\ \ \ \ \ \ \ \ \ \ \ \ \ begin\_at\_stage\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a68e87816ed5daf6e6c99c3d59fc22166}{n\_iter\_}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00886}00886\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00887}00887\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ initialize\ gradients\ and\ hessians\ (empty\ arrays).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00888}00888\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ shape\ =\ (n\_samples,\ n\_trees\_per\_iteration).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00889}00889\ \ \ \ \ \ \ \ \ gradient,\ hessian\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}.init\_gradient\_and\_hessian(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00890}00890\ \ \ \ \ \ \ \ \ \ \ \ \ n\_samples=n\_samples,\ dtype=G\_H\_DTYPE,\ order=\textcolor{stringliteral}{"{}F"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00891}00891\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00892}00892\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00893}00893\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ iteration\ \textcolor{keywordflow}{in}\ range(begin\_at\_stage,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8c4630fd50d86dfd270c7b0afbd636fb}{max\_iter}}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00894}00894\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a39a3969984cde73a5dc0879387502020}{verbose}}\ >=\ 2:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00895}00895\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ iteration\_start\_time\ =\ time()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00896}00896\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ print(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00897}00897\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}[\{\}/\{\}]\ "{}}.format(iteration\ +\ 1,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8c4630fd50d86dfd270c7b0afbd636fb}{max\_iter}}),\ end=\textcolor{stringliteral}{"{}"{}},\ flush=\textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00898}00898\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00899}00899\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00900}00900\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Update\ gradients\ and\ hessians,\ inplace}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00901}00901\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Note\ that\ self.\_loss\ expects\ shape\ (n\_samples,)\ for}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00902}00902\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ n\_trees\_per\_iteration\ =\ 1\ else\ shape\ (n\_samples,\ n\_trees\_per\_iteration).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00903}00903\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}.constant\_hessian:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00904}00904\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}.gradient(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00905}00905\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_true=y\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00906}00906\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_prediction=raw\_predictions,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00907}00907\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight=sample\_weight\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00908}00908\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ gradient\_out=gradient,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00909}00909\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00910}00910\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00911}00911\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00912}00912\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}.gradient\_hessian(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00913}00913\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_true=y\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00914}00914\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_prediction=raw\_predictions,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00915}00915\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight=sample\_weight\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00916}00916\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ gradient\_out=gradient,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00917}00917\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ hessian\_out=hessian,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00918}00918\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00919}00919\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00920}00920\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00921}00921\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Append\ a\ list\ since\ there\ may\ be\ more\ than\ 1\ predictor\ per\ iter}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00922}00922\ \ \ \ \ \ \ \ \ \ \ \ \ predictors.append([])}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00923}00923\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00924}00924\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ 2-\/d\ views\ of\ shape\ (n\_samples,\ n\_trees\_per\_iteration\_)\ or\ (n\_samples,\ 1)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00925}00925\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ on\ gradient\ and\ hessian\ to\ simplify\ the\ loop\ over\ n\_trees\_per\_iteration\_.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00926}00926\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ gradient.ndim\ ==\ 1:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00927}00927\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ g\_view\ =\ gradient.reshape((-\/1,\ 1))}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00928}00928\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ h\_view\ =\ hessian.reshape((-\/1,\ 1))}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00929}00929\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00930}00930\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ g\_view\ =\ gradient}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00931}00931\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ h\_view\ =\ hessian}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00932}00932\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00933}00933\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Build\ \`{}n\_trees\_per\_iteration`\ trees.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00934}00934\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ k\ \textcolor{keywordflow}{in}\ range(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00935}00935\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ grower\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1grower_1_1TreeGrower}{TreeGrower}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00936}00936\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned=X\_binned\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00937}00937\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ gradients=g\_view[:,\ k],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00938}00938\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ hessians=h\_view[:,\ k],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00939}00939\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_bins=n\_bins,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00940}00940\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_bins\_non\_missing=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af07b37765017ed0b88be84e4fb9aeedb}{\_bin\_mapper}}.n\_bins\_non\_missing\_,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00941}00941\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ has\_missing\_values=has\_missing\_values,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00942}00942\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ is\_categorical=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_acfcab46edcccc4aa05409934159cd588}{\_is\_categorical\_remapped}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00943}00943\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ monotonic\_cst=monotonic\_cst\_remapped,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00944}00944\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ interaction\_cst=interaction\_cst,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00945}00945\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ max\_leaf\_nodes=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a691ad0349a8339079183cefbae38e1d0}{max\_leaf\_nodes}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00946}00946\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ max\_depth=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abef4a3ea1fbc76cd3d15dceaa39fe0de}{max\_depth}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00947}00947\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ min\_samples\_leaf=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab5cbe9de4a5232f8130abbcd2c433605}{min\_samples\_leaf}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00948}00948\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ l2\_regularization=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ac342bd1bcea4f67b50a928cd1e75a915}{l2\_regularization}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00949}00949\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ feature\_fraction\_per\_split=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa533d0a8ec3767c97c888844491558c2}{max\_features}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00950}00950\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ rng=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_accbd70f6b5b1826c48e1dd38bf5ce355}{\_feature\_subsample\_rng}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00951}00951\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ shrinkage=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a65f2e8d6111cc97abb7202708a046962}{learning\_rate}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00952}00952\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00953}00953\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00954}00954\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ grower.grow()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00955}00955\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00956}00956\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ acc\_apply\_split\_time\ +=\ grower.total\_apply\_split\_time}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00957}00957\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ acc\_find\_split\_time\ +=\ grower.total\_find\_split\_time}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00958}00958\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ acc\_compute\_hist\_time\ +=\ grower.total\_compute\_hist\_time}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00959}00959\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00960}00960\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}.differentiable:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00961}00961\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_a792e2e12a4c12db534fb1b6ce74c5b04}{\_update\_leaves\_values}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00962}00962\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ loss=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00963}00963\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ grower=grower,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00964}00964\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_true=y\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00965}00965\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_prediction=raw\_predictions[:,\ k],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00966}00966\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight=sample\_weight\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00967}00967\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00968}00968\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00969}00969\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ predictor\ =\ grower.make\_predictor(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00970}00970\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ binning\_thresholds=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af07b37765017ed0b88be84e4fb9aeedb}{\_bin\_mapper}}.bin\_thresholds\_}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00971}00971\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00972}00972\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ predictors[-\/1].append(predictor)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00973}00973\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00974}00974\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Update\ raw\_predictions\ with\ the\ predictions\ of\ the\ newly}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00975}00975\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ created\ tree.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00976}00976\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ tic\_pred\ =\ time()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00977}00977\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \_update\_raw\_predictions(raw\_predictions[:,\ k],\ grower,\ n\_threads)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00978}00978\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ toc\_pred\ =\ time()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00979}00979\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ acc\_prediction\_time\ +=\ toc\_pred\ -\/\ tic\_pred}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00980}00980\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00981}00981\ \ \ \ \ \ \ \ \ \ \ \ \ should\_early\_stop\ =\ \textcolor{keyword}{False}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00982}00982\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa98b01cc7ca7beefda4cec76e10c29ac}{do\_early\_stopping\_}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00983}00983\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Update\ raw\_predictions\_val\ with\ the\ newest\ tree(s)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00984}00984\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ need\_raw\_predictions\_val:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00985}00985\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ k,\ pred\ \textcolor{keywordflow}{in}\ enumerate(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}}[-\/1]):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00986}00986\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_val[:,\ k]\ +=\ pred.predict\_binned(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00987}00987\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00988}00988\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af07b37765017ed0b88be84e4fb9aeedb}{\_bin\_mapper}}.missing\_values\_bin\_idx\_,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00989}00989\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00990}00990\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00991}00991\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00992}00992\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a77783dab5cef4f645a5d0ff93e4deb11}{scoring}}\ ==\ \textcolor{stringliteral}{"{}loss"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00993}00993\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ should\_early\_stop\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a689244514867e65787fc11c5520170f7}{\_check\_early\_stopping\_loss}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00994}00994\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions=raw\_predictions,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00995}00995\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_train=y\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00996}00996\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_train=sample\_weight\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00997}00997\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_val=raw\_predictions\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00998}00998\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_val=y\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l00999}00999\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_val=sample\_weight\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01000}01000\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01001}01001\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01002}01002\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01003}01003\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01004}01004\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ If\ the\ scorer\ is\ a\ predefined\ string,\ then\ we\ optimize\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01005}01005\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ evaluation\ by\ reusing\ the\ incrementally\ computed\ raw\ predictions.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01006}01006\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ scoring\_is\_predefined\_string:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01007}01007\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_small\_train\ =\ raw\_predictions[}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01008}01008\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ indices\_small\_train}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01009}01009\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01010}01010\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01011}01011\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_small\_train\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01012}01012\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01013}01013\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ should\_early\_stop\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad3e56b83f7d785263ddc43e0acc6342c}{\_check\_early\_stopping\_scorer}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01014}01014\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01015}01015\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01016}01016\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01017}01017\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01018}01018\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01019}01019\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01020}01020\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_small\_train=raw\_predictions\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01021}01021\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_val=raw\_predictions\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01022}01022\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01023}01023\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01024}01024\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a39a3969984cde73a5dc0879387502020}{verbose}}\ >=\ 2:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01025}01025\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57679008c858757379aae8e3918370e4}{\_print\_iteration\_stats}}(iteration\_start\_time)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01026}01026\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01027}01027\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ maybe\ we\ could\ also\ early\ stop\ if\ all\ the\ trees\ are\ stumps?}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01028}01028\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ should\_early\_stop:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01029}01029\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{break}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01030}01030\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01031}01031\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a39a3969984cde73a5dc0879387502020}{verbose}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01032}01032\ \ \ \ \ \ \ \ \ \ \ \ \ duration\ =\ time()\ -\/\ fit\_start\_time}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01033}01033\ \ \ \ \ \ \ \ \ \ \ \ \ n\_total\_leaves\ =\ sum(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01034}01034\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ predictor.get\_n\_leaf\_nodes()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01035}01035\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ predictors\_at\_ith\_iteration\ \textcolor{keywordflow}{in}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01036}01036\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ predictor\ \textcolor{keywordflow}{in}\ predictors\_at\_ith\_iteration}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01037}01037\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01038}01038\ \ \ \ \ \ \ \ \ \ \ \ \ n\_predictors\ =\ sum(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01039}01039\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ len(predictors\_at\_ith\_iteration)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01040}01040\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ predictors\_at\_ith\_iteration\ \textcolor{keywordflow}{in}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01041}01041\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01042}01042\ \ \ \ \ \ \ \ \ \ \ \ \ print(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01043}01043\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Fit\ \{\}\ trees\ in\ \{:.3f\}\ s,\ (\{\}\ total\ leaves)"{}}.format(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01044}01044\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_predictors,\ duration,\ n\_total\_leaves}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01045}01045\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01046}01046\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01047}01047\ \ \ \ \ \ \ \ \ \ \ \ \ print(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01048}01048\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\{:<32\}\ \{:.3f\}s"{}}.format(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01049}01049\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Time\ spent\ computing\ histograms:"{}},\ acc\_compute\_hist\_time}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01050}01050\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01051}01051\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01052}01052\ \ \ \ \ \ \ \ \ \ \ \ \ print(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01053}01053\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\{:<32\}\ \{:.3f\}s"{}}.format(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01054}01054\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Time\ spent\ finding\ best\ splits:"{}},\ acc\_find\_split\_time}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01055}01055\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01056}01056\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01057}01057\ \ \ \ \ \ \ \ \ \ \ \ \ print(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01058}01058\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\{:<32\}\ \{:.3f\}s"{}}.format(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01059}01059\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Time\ spent\ applying\ splits:"{}},\ acc\_apply\_split\_time}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01060}01060\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01061}01061\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01062}01062\ \ \ \ \ \ \ \ \ \ \ \ \ print(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01063}01063\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\{:<32\}\ \{:.3f\}s"{}}.format(\textcolor{stringliteral}{"{}Time\ spent\ predicting:"{}},\ acc\_prediction\_time)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01064}01064\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01065}01065\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01066}01066\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\_score\_}}\ =\ np.asarray(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\_score\_}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01067}01067\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\_score\_}}\ =\ np.asarray(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\_score\_}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01068}01068\ \ \ \ \ \ \ \ \ del\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a9fe0089caa05ed5692ffbff1b47a119d}{\_in\_fit}}\ \ \textcolor{comment}{\#\ hard\ delete\ so\ we're\ sure\ it\ can't\ be\ used\ anymore}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01069}01069\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01070}01070\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01071}01071\ \ \ \ \ \textcolor{keyword}{def\ }\_is\_fitted(self):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01072}01072\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ len(getattr(self,\ \textcolor{stringliteral}{"{}\_predictors"{}},\ []))\ >\ 0}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01073}01073\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01074}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a0792fbcff561bb817840f5214c3d9dd6}{01074}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a0792fbcff561bb817840f5214c3d9dd6}{\_clear\_state}}(self):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01075}01075\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Clear\ the\ state\ of\ the\ gradient\ boosting\ model."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01076}01076\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ var\ \textcolor{keywordflow}{in}\ (\textcolor{stringliteral}{"{}train\_score\_"{}},\ \textcolor{stringliteral}{"{}validation\_score\_"{}}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01077}01077\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ hasattr(self,\ var):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01078}01078\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ delattr(self,\ var)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01079}01079\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01080}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1d9017aa611476cd705da844cfa93034}{01080}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1d9017aa611476cd705da844cfa93034}{\_get\_small\_trainset}}(self,\ X\_binned\_train,\ y\_train,\ sample\_weight\_train,\ seed):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01081}01081\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Compute\ the\ indices\ of\ the\ subsample\ set\ and\ return\ this\ set.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01082}01082\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01083}01083\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ For\ efficiency,\ we\ need\ to\ subsample\ the\ training\ set\ to\ compute\ scores}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01084}01084\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ with\ scorers.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01085}01085\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01086}01086\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ TODO:\ incorporate\ sample\_weights\ here\ in\ \`{}resample`}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01087}01087\ \ \ \ \ \ \ \ \ subsample\_size\ =\ 10000}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01088}01088\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ X\_binned\_train.shape[0]\ >\ subsample\_size:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01089}01089\ \ \ \ \ \ \ \ \ \ \ \ \ indices\ =\ np.arange(X\_binned\_train.shape[0])}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01090}01090\ \ \ \ \ \ \ \ \ \ \ \ \ stratify\ =\ y\_train\ \textcolor{keywordflow}{if}\ is\_classifier(self)\ \textcolor{keywordflow}{else}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01091}01091\ \ \ \ \ \ \ \ \ \ \ \ \ indices\ =\ resample(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01092}01092\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ indices,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01093}01093\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_samples=subsample\_size,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01094}01094\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ replace=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01095}01095\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=seed,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01096}01096\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ stratify=stratify,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01097}01097\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01098}01098\ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_small\_train\ =\ X\_binned\_train[indices]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01099}01099\ \ \ \ \ \ \ \ \ \ \ \ \ y\_small\_train\ =\ y\_train[indices]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01100}01100\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ sample\_weight\_train\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01101}01101\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_small\_train\ =\ sample\_weight\_train[indices]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01102}01102\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01103}01103\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_small\_train\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01104}01104\ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_small\_train\ =\ np.ascontiguousarray(X\_binned\_small\_train)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01105}01105\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01106}01106\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01107}01107\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01108}01108\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01109}01109\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ indices,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01110}01110\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01111}01111\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01112}01112\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ X\_binned\_train,\ y\_train,\ sample\_weight\_train,\ slice(\textcolor{keywordtype}{None})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01113}01113\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01114}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad3e56b83f7d785263ddc43e0acc6342c}{01114}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad3e56b83f7d785263ddc43e0acc6342c}{\_check\_early\_stopping\_scorer}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01115}01115\ \ \ \ \ \ \ \ \ self,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01116}01116\ \ \ \ \ \ \ \ \ X\_binned\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01117}01117\ \ \ \ \ \ \ \ \ y\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01118}01118\ \ \ \ \ \ \ \ \ sample\_weight\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01119}01119\ \ \ \ \ \ \ \ \ X\_binned\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01120}01120\ \ \ \ \ \ \ \ \ y\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01121}01121\ \ \ \ \ \ \ \ \ sample\_weight\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01122}01122\ \ \ \ \ \ \ \ \ raw\_predictions\_small\_train=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01123}01123\ \ \ \ \ \ \ \ \ raw\_predictions\_val=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01124}01124\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01125}01125\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ if\ fitting\ should\ be\ early-\/stopped\ based\ on\ scorer.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01126}01126\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01127}01127\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Scores\ are\ computed\ on\ validation\ data\ or\ on\ training\ data.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01128}01128\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01129}01129\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ is\_classifier(self):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01130}01130\ \ \ \ \ \ \ \ \ \ \ \ \ y\_small\_train\ =\ self.classes\_[y\_small\_train.astype(int)]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01131}01131\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01132}01132\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\_score\_}}.append(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01133}01133\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a564589da451187a1f20a7da1bb4f6bce}{\_score\_with\_raw\_predictions}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01134}01134\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01135}01135\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01136}01136\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01137}01137\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions\_small\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01138}01138\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01139}01139\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01140}01140\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01141}01141\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a12bb6a5453b140706a0da21a0d4ab62b}{\_use\_validation\_data}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01142}01142\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ is\_classifier(self):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01143}01143\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_val\ =\ self.classes\_[y\_val.astype(int)]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01144}01144\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\_score\_}}.append(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01145}01145\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a564589da451187a1f20a7da1bb4f6bce}{\_score\_with\_raw\_predictions}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01146}01146\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\_val,\ y\_val,\ sample\_weight\_val,\ raw\_predictions\_val}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01147}01147\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01148}01148\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01149}01149\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6a5b038a6b5daf407a725b68c41a1793}{\_should\_stop}}(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\_score\_}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01150}01150\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01151}01151\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6a5b038a6b5daf407a725b68c41a1793}{\_should\_stop}}(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\_score\_}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01152}01152\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01153}01153\ \ \ \ \ \textcolor{keyword}{def\ }\_score\_with\_raw\_predictions(self,\ X,\ y,\ sample\_weight,\ raw\_predictions=None):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01154}01154\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ raw\_predictions\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01155}01155\ \ \ \ \ \ \ \ \ \ \ \ \ patcher\_raw\_predict\ =\ nullcontext()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01156}01156\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01157}01157\ \ \ \ \ \ \ \ \ \ \ \ \ patcher\_raw\_predict\ =\ \mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_a4cf3085f0d80a3d32f5fbc2a96f6b28a}{\_patch\_raw\_predict}}(self,\ raw\_predictions)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01158}01158\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01159}01159\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ patcher\_raw\_predict:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01160}01160\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ sample\_weight\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01161}01161\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a583f9f75f3267a2610ff33c46cf28474}{\_scorer}}(self,\ X,\ y)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01162}01162\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01163}01163\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a583f9f75f3267a2610ff33c46cf28474}{\_scorer}}(self,\ X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01164}01164\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01165}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a689244514867e65787fc11c5520170f7}{01165}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a689244514867e65787fc11c5520170f7}{\_check\_early\_stopping\_loss}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01166}01166\ \ \ \ \ \ \ \ \ self,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01167}01167\ \ \ \ \ \ \ \ \ raw\_predictions,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01168}01168\ \ \ \ \ \ \ \ \ y\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01169}01169\ \ \ \ \ \ \ \ \ sample\_weight\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01170}01170\ \ \ \ \ \ \ \ \ raw\_predictions\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01171}01171\ \ \ \ \ \ \ \ \ y\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01172}01172\ \ \ \ \ \ \ \ \ sample\_weight\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01173}01173\ \ \ \ \ \ \ \ \ n\_threads=1,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01174}01174\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01175}01175\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ if\ fitting\ should\ be\ early-\/stopped\ based\ on\ loss.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01176}01176\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01177}01177\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Scores\ are\ computed\ on\ validation\ data\ or\ on\ training\ data.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01178}01178\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01179}01179\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\_score\_}}.append(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01180}01180\ \ \ \ \ \ \ \ \ \ \ \ \ -\/self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01181}01181\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_true=y\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01182}01182\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_prediction=raw\_predictions,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01183}01183\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight=sample\_weight\_train,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01184}01184\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01185}01185\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01186}01186\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01187}01187\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01188}01188\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a12bb6a5453b140706a0da21a0d4ab62b}{\_use\_validation\_data}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01189}01189\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\_score\_}}.append(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01190}01190\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ -\/self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01191}01191\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ y\_true=y\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01192}01192\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_prediction=raw\_predictions\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01193}01193\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight=sample\_weight\_val,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01194}01194\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01195}01195\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01196}01196\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01197}01197\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6a5b038a6b5daf407a725b68c41a1793}{\_should\_stop}}(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\_score\_}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01198}01198\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01199}01199\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6a5b038a6b5daf407a725b68c41a1793}{\_should\_stop}}(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\_score\_}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01200}01200\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01201}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6a5b038a6b5daf407a725b68c41a1793}{01201}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6a5b038a6b5daf407a725b68c41a1793}{\_should\_stop}}(self,\ scores):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01202}01202\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01203}01203\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Return\ True\ (do\ early\ stopping)\ if\ the\ last\ n\ scores\ aren't\ better}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01204}01204\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ than\ the\ (n-\/1)th-\/to-\/last\ score,\ up\ to\ some\ tolerance.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01205}01205\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01206}01206\ \ \ \ \ \ \ \ \ reference\_position\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a59c410ffee3831ed0c00add4d3a0c6e6}{n\_iter\_no\_change}}\ +\ 1}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01207}01207\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ len(scores)\ <\ reference\_position:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01208}01208\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{keyword}{False}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01209}01209\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01210}01210\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ A\ higher\ score\ is\ always\ better.\ Higher\ tol\ means\ that\ it\ will\ be}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01211}01211\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ harder\ for\ subsequent\ iteration\ to\ be\ considered\ an\ improvement\ upon}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01212}01212\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ the\ reference\ score,\ and\ therefore\ it\ is\ more\ likely\ to\ early\ stop}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01213}01213\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ because\ of\ the\ lack\ of\ significant\ improvement.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01214}01214\ \ \ \ \ \ \ \ \ reference\_score\ =\ scores[-\/reference\_position]\ +\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6fe4dfcee2bff69d971f26f7b0398d93}{tol}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01215}01215\ \ \ \ \ \ \ \ \ recent\_scores\ =\ scores[-\/reference\_position\ +\ 1\ :]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01216}01216\ \ \ \ \ \ \ \ \ recent\_improvements\ =\ [score\ >\ reference\_score\ \textcolor{keywordflow}{for}\ score\ \textcolor{keywordflow}{in}\ recent\_scores]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01217}01217\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{keywordflow}{not}\ any(recent\_improvements)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01218}01218\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01219}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af18b1289a37ebf4c07a0417a040f4a0c}{01219}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af18b1289a37ebf4c07a0417a040f4a0c}{\_bin\_data}}(self,\ X,\ is\_training\_data):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01220}01220\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Bin\ data\ X.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01221}01221\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01222}01222\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ is\_training\_data,\ then\ fit\ the\ \_bin\_mapper\ attribute.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01223}01223\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Else,\ the\ binned\ data\ is\ converted\ to\ a\ C-\/contiguous\ array.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01224}01224\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01225}01225\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01226}01226\ \ \ \ \ \ \ \ \ description\ =\ \textcolor{stringliteral}{"{}training"{}}\ \textcolor{keywordflow}{if}\ is\_training\_data\ \textcolor{keywordflow}{else}\ \textcolor{stringliteral}{"{}validation"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01227}01227\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a39a3969984cde73a5dc0879387502020}{verbose}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01228}01228\ \ \ \ \ \ \ \ \ \ \ \ \ print(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01229}01229\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Binning\ \{:.3f\}\ GB\ of\ \{\}\ data:\ "{}}.format(X.nbytes\ /\ 1e9,\ description),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01230}01230\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ end=\textcolor{stringliteral}{"{}"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01231}01231\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ flush=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01232}01232\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01233}01233\ \ \ \ \ \ \ \ \ tic\ =\ time()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01234}01234\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ is\_training\_data:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01235}01235\ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af07b37765017ed0b88be84e4fb9aeedb}{\_bin\_mapper}}.fit\_transform(X)\ \ \textcolor{comment}{\#\ F-\/aligned\ array}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01236}01236\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01237}01237\ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af07b37765017ed0b88be84e4fb9aeedb}{\_bin\_mapper}}.transform(X)\ \ \textcolor{comment}{\#\ F-\/aligned\ array}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01238}01238\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ We\ convert\ the\ array\ to\ C-\/contiguous\ since\ predicting\ is\ faster}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01239}01239\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ with\ this\ layout\ (training\ is\ faster\ on\ F-\/arrays\ though)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01240}01240\ \ \ \ \ \ \ \ \ \ \ \ \ X\_binned\ =\ np.ascontiguousarray(X\_binned)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01241}01241\ \ \ \ \ \ \ \ \ toc\ =\ time()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01242}01242\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a39a3969984cde73a5dc0879387502020}{verbose}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01243}01243\ \ \ \ \ \ \ \ \ \ \ \ \ duration\ =\ toc\ -\/\ tic}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01244}01244\ \ \ \ \ \ \ \ \ \ \ \ \ print(\textcolor{stringliteral}{"{}\{:.3f\}\ s"{}}.format(duration))}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01245}01245\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01246}01246\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ X\_binned}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01247}01247\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01248}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57679008c858757379aae8e3918370e4}{01248}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57679008c858757379aae8e3918370e4}{\_print\_iteration\_stats}}(self,\ iteration\_start\_time):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01249}01249\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Print\ info\ about\ the\ current\ fitting\ iteration."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01250}01250\ \ \ \ \ \ \ \ \ log\_msg\ =\ \textcolor{stringliteral}{"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01251}01251\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01252}01252\ \ \ \ \ \ \ \ \ predictors\_of\_ith\_iteration\ =\ [}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01253}01253\ \ \ \ \ \ \ \ \ \ \ \ \ predictors\_list}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01254}01254\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ predictors\_list\ \textcolor{keywordflow}{in}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}}[-\/1]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01255}01255\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ predictors\_list}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01256}01256\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01257}01257\ \ \ \ \ \ \ \ \ n\_trees\ =\ len(predictors\_of\_ith\_iteration)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01258}01258\ \ \ \ \ \ \ \ \ max\_depth\ =\ max(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01259}01259\ \ \ \ \ \ \ \ \ \ \ \ \ predictor.get\_max\_depth()\ \textcolor{keywordflow}{for}\ predictor\ \textcolor{keywordflow}{in}\ predictors\_of\_ith\_iteration}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01260}01260\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01261}01261\ \ \ \ \ \ \ \ \ n\_leaves\ =\ sum(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01262}01262\ \ \ \ \ \ \ \ \ \ \ \ \ predictor.get\_n\_leaf\_nodes()\ \textcolor{keywordflow}{for}\ predictor\ \textcolor{keywordflow}{in}\ predictors\_of\_ith\_iteration}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01263}01263\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01264}01264\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01265}01265\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ n\_trees\ ==\ 1:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01266}01266\ \ \ \ \ \ \ \ \ \ \ \ \ log\_msg\ +=\ \textcolor{stringliteral}{"{}\{\}\ tree,\ \{\}\ leaves,\ "{}}.format(n\_trees,\ n\_leaves)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01267}01267\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01268}01268\ \ \ \ \ \ \ \ \ \ \ \ \ log\_msg\ +=\ \textcolor{stringliteral}{"{}\{\}\ trees,\ \{\}\ leaves\ "{}}.format(n\_trees,\ n\_leaves)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01269}01269\ \ \ \ \ \ \ \ \ \ \ \ \ log\_msg\ +=\ \textcolor{stringliteral}{"{}(\{\}\ on\ avg),\ "{}}.format(int(n\_leaves\ /\ n\_trees))}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01270}01270\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01271}01271\ \ \ \ \ \ \ \ \ log\_msg\ +=\ \textcolor{stringliteral}{"{}max\ depth\ =\ \{\},\ "{}}.format(max\_depth)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01272}01272\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01273}01273\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa98b01cc7ca7beefda4cec76e10c29ac}{do\_early\_stopping\_}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01274}01274\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a77783dab5cef4f645a5d0ff93e4deb11}{scoring}}\ ==\ \textcolor{stringliteral}{"{}loss"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01275}01275\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ factor\ =\ -\/1\ \ \textcolor{comment}{\#\ score\_\ arrays\ contain\ the\ negative\ loss}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01276}01276\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ name\ =\ \textcolor{stringliteral}{"{}loss"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01277}01277\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01278}01278\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ factor\ =\ 1}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01279}01279\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ name\ =\ \textcolor{stringliteral}{"{}score"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01280}01280\ \ \ \ \ \ \ \ \ \ \ \ \ log\_msg\ +=\ \textcolor{stringliteral}{"{}train\ \{\}:\ \{:.5f\},\ "{}}.format(name,\ factor\ *\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\_score\_}}[-\/1])}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01281}01281\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a12bb6a5453b140706a0da21a0d4ab62b}{\_use\_validation\_data}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01282}01282\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ log\_msg\ +=\ \textcolor{stringliteral}{"{}val\ \{\}:\ \{:.5f\},\ "{}}.format(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01283}01283\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ name,\ factor\ *\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\_score\_}}[-\/1]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01284}01284\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01285}01285\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01286}01286\ \ \ \ \ \ \ \ \ iteration\_time\ =\ time()\ -\/\ iteration\_start\_time}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01287}01287\ \ \ \ \ \ \ \ \ log\_msg\ +=\ \textcolor{stringliteral}{"{}in\ \{:0.3f\}s"{}}.format(iteration\_time)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01288}01288\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01289}01289\ \ \ \ \ \ \ \ \ print(log\_msg)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01290}01290\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01291}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa4a8356439ef87a220f9ec262a885137}{01291}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa4a8356439ef87a220f9ec262a885137}{\_raw\_predict}}(self,\ X,\ n\_threads=None):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01292}01292\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Return\ the\ sum\ of\ the\ leaves\ values\ over\ all\ predictors.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01293}01293\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01294}01294\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01295}01295\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01296}01296\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01297}01297\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01298}01298\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ n\_threads\ :\ int,\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01299}01299\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Number\ of\ OpenMP\ threads\ to\ use.\ \`{}\_openmp\_effective\_n\_threads\`{}\ is\ called}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01300}01300\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ to\ determine\ the\ effective\ number\ of\ threads\ use,\ which\ takes\ cgroups\ CPU}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01301}01301\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ quotes\ into\ account.\ See\ the\ docstring\ of\ \`{}\_openmp\_effective\_n\_threads\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01302}01302\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ for\ details.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01303}01303\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01304}01304\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01305}01305\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01306}01306\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ raw\_predictions\ :\ array,\ shape\ (n\_samples,\ n\_trees\_per\_iteration)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01307}01307\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ raw\ predicted\ values.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01308}01308\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01309}01309\ \ \ \ \ \ \ \ \ check\_is\_fitted(self)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01310}01310\ \ \ \ \ \ \ \ \ is\_binned\ =\ getattr(self,\ \textcolor{stringliteral}{"{}\_in\_fit"{}},\ \textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01311}01311\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ is\_binned:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01312}01312\ \ \ \ \ \ \ \ \ \ \ \ \ X\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab6a1278c0901cb920029746815bcd824}{\_preprocess\_X}}(X,\ reset=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01313}01313\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01314}01314\ \ \ \ \ \ \ \ \ n\_samples\ =\ X.shape[0]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01315}01315\ \ \ \ \ \ \ \ \ raw\_predictions\ =\ np.zeros(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01316}01316\ \ \ \ \ \ \ \ \ \ \ \ \ shape=(n\_samples,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}}),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01317}01317\ \ \ \ \ \ \ \ \ \ \ \ \ dtype=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa8cf30a8c23006d33229e1abf8a1c087}{\_baseline\_prediction}}.dtype,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01318}01318\ \ \ \ \ \ \ \ \ \ \ \ \ order=\textcolor{stringliteral}{"{}F"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01319}01319\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01320}01320\ \ \ \ \ \ \ \ \ raw\_predictions\ +=\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa8cf30a8c23006d33229e1abf8a1c087}{\_baseline\_prediction}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01321}01321\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01322}01322\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ We\ intentionally\ decouple\ the\ number\ of\ threads\ used\ at\ prediction}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01323}01323\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ time\ from\ the\ number\ of\ threads\ used\ at\ fit\ time\ because\ the\ model}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01324}01324\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ can\ be\ deployed\ on\ a\ different\ machine\ for\ prediction\ purposes.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01325}01325\ \ \ \ \ \ \ \ \ n\_threads\ =\ \_openmp\_effective\_n\_threads(n\_threads)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01326}01326\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a25e59afbf20b7b65de0e92a49ea4b54e}{\_predict\_iterations}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01327}01327\ \ \ \ \ \ \ \ \ \ \ \ \ X,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}},\ raw\_predictions,\ is\_binned,\ n\_threads}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01328}01328\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01329}01329\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ raw\_predictions}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01330}01330\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01331}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a25e59afbf20b7b65de0e92a49ea4b54e}{01331}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a25e59afbf20b7b65de0e92a49ea4b54e}{\_predict\_iterations}}(self,\ X,\ predictors,\ raw\_predictions,\ is\_binned,\ n\_threads):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01332}01332\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Add\ the\ predictions\ of\ the\ predictors\ to\ raw\_predictions."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01333}01333\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ is\_binned:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01334}01334\ \ \ \ \ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01335}01335\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ known\_cat\_bitsets,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01336}01336\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\_idx\_map,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01337}01337\ \ \ \ \ \ \ \ \ \ \ \ \ )\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af07b37765017ed0b88be84e4fb9aeedb}{\_bin\_mapper}}.make\_known\_categories\_bitsets()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01338}01338\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01339}01339\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ predictors\_of\_ith\_iteration\ \textcolor{keywordflow}{in}\ predictors:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01340}01340\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ k,\ predictor\ \textcolor{keywordflow}{in}\ enumerate(predictors\_of\_ith\_iteration):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01341}01341\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ is\_binned:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01342}01342\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ predict\ =\ partial(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01343}01343\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ predictor.predict\_binned,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01344}01344\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ missing\_values\_bin\_idx=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af07b37765017ed0b88be84e4fb9aeedb}{\_bin\_mapper}}.missing\_values\_bin\_idx\_,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01345}01345\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01346}01346\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01347}01347\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01348}01348\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ predict\ =\ partial(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01349}01349\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ predictor.predict,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01350}01350\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ known\_cat\_bitsets=known\_cat\_bitsets,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01351}01351\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ f\_idx\_map=f\_idx\_map,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01352}01352\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01353}01353\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01354}01354\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions[:,\ k]\ +=\ predict(X)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01355}01355\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01356}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57f54f37a2214f8e4a93b3dcf4488cd7}{01356}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57f54f37a2214f8e4a93b3dcf4488cd7}{\_staged\_raw\_predict}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01357}01357\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Compute\ raw\ predictions\ of\ \`{}\`{}X\`{}\`{}\ for\ each\ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01358}01358\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01359}01359\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ This\ method\ allows\ monitoring\ (i.e.\ determine\ error\ on\ testing\ set)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01360}01360\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ after\ each\ stage.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01361}01361\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01362}01362\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01363}01363\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01364}01364\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01365}01365\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01366}01366\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01367}01367\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Yields}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01368}01368\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01369}01369\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ raw\_predictions\ :\ generator\ of\ ndarray\ of\ shape\ \(\backslash\)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01370}01370\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ (n\_samples,\ n\_trees\_per\_iteration)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01371}01371\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ raw\ predictions\ of\ the\ input\ samples.\ The\ order\ of\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01372}01372\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ classes\ corresponds\ to\ that\ in\ the\ attribute\ :term:\`{}classes\_\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01373}01373\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01374}01374\ \ \ \ \ \ \ \ \ check\_is\_fitted(self)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01375}01375\ \ \ \ \ \ \ \ \ X\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab6a1278c0901cb920029746815bcd824}{\_preprocess\_X}}(X,\ reset=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01376}01376\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ X.shape[1]\ !=\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfa366e1408cc8abaf718dbc73586042}{\_n\_features}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01377}01377\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01378}01378\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}X\ has\ \{\}\ features\ but\ this\ estimator\ was\ trained\ with\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01379}01379\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\{\}\ features."{}}.format(X.shape[1],\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfa366e1408cc8abaf718dbc73586042}{\_n\_features}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01380}01380\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01381}01381\ \ \ \ \ \ \ \ \ n\_samples\ =\ X.shape[0]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01382}01382\ \ \ \ \ \ \ \ \ raw\_predictions\ =\ np.zeros(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01383}01383\ \ \ \ \ \ \ \ \ \ \ \ \ shape=(n\_samples,\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}}),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01384}01384\ \ \ \ \ \ \ \ \ \ \ \ \ dtype=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa8cf30a8c23006d33229e1abf8a1c087}{\_baseline\_prediction}}.dtype,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01385}01385\ \ \ \ \ \ \ \ \ \ \ \ \ order=\textcolor{stringliteral}{"{}F"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01386}01386\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01387}01387\ \ \ \ \ \ \ \ \ raw\_predictions\ +=\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa8cf30a8c23006d33229e1abf8a1c087}{\_baseline\_prediction}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01388}01388\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01389}01389\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ We\ intentionally\ decouple\ the\ number\ of\ threads\ used\ at\ prediction}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01390}01390\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ time\ from\ the\ number\ of\ threads\ used\ at\ fit\ time\ because\ the\ model}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01391}01391\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ can\ be\ deployed\ on\ a\ different\ machine\ for\ prediction\ purposes.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01392}01392\ \ \ \ \ \ \ \ \ n\_threads\ =\ \_openmp\_effective\_n\_threads()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01393}01393\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ iteration\ \textcolor{keywordflow}{in}\ range(len(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}})):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01394}01394\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a25e59afbf20b7b65de0e92a49ea4b54e}{\_predict\_iterations}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01395}01395\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01396}01396\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}}[iteration\ :\ iteration\ +\ 1],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01397}01397\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ raw\_predictions,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01398}01398\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ is\_binned=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01399}01399\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01400}01400\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01401}01401\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{yield}\ raw\_predictions.copy()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01402}01402\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01403}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a7e5f2d889b2c799e41f13ed0b65035a6}{01403}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a7e5f2d889b2c799e41f13ed0b65035a6}{\_compute\_partial\_dependence\_recursion}}(self,\ grid,\ target\_features):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01404}01404\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Fast\ partial\ dependence\ computation.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01405}01405\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01406}01406\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01407}01407\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01408}01408\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ grid\ :\ ndarray,\ shape\ (n\_samples,\ n\_target\_features),\ dtype=np.float32}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01409}01409\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ grid\ points\ on\ which\ the\ partial\ dependence\ should\ be}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01410}01410\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ evaluated.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01411}01411\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ target\_features\ :\ ndarray,\ shape\ (n\_target\_features),\ dtype=np.intp}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01412}01412\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ set\ of\ target\ features\ for\ which\ the\ partial\ dependence}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01413}01413\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ should\ be\ evaluated.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01414}01414\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01415}01415\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01416}01416\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01417}01417\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ averaged\_predictions\ :\ ndarray,\ shape\ \(\backslash\)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01418}01418\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (n\_trees\_per\_iteration,\ n\_samples)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01419}01419\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ value\ of\ the\ partial\ dependence\ function\ on\ each\ grid\ point.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01420}01420\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01421}01421\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01422}01422\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ getattr(self,\ \textcolor{stringliteral}{"{}\_fitted\_with\_sw"{}},\ \textcolor{keyword}{False}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01423}01423\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classNotImplementedError}{NotImplementedError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01424}01424\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\{\}\ does\ not\ support\ partial\ dependence\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01425}01425\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}plots\ with\ the\ 'recursion'\ method\ when\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01426}01426\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}sample\ weights\ were\ given\ during\ fit\ "{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01427}01427\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}time."{}}.format(self.\_\_class\_\_.\_\_name\_\_)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01428}01428\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01429}01429\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01430}01430\ \ \ \ \ \ \ \ \ grid\ =\ np.asarray(grid,\ dtype=X\_DTYPE,\ order=\textcolor{stringliteral}{"{}C"{}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01431}01431\ \ \ \ \ \ \ \ \ averaged\_predictions\ =\ np.zeros(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01432}01432\ \ \ \ \ \ \ \ \ \ \ \ \ (self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}},\ grid.shape[0]),\ dtype=Y\_DTYPE}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01433}01433\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01434}01434\ \ \ \ \ \ \ \ \ target\_features\ =\ np.asarray(target\_features,\ dtype=np.intp,\ order=\textcolor{stringliteral}{"{}C"{}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01435}01435\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01436}01436\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ predictors\_of\_ith\_iteration\ \textcolor{keywordflow}{in}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01437}01437\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ k,\ predictor\ \textcolor{keywordflow}{in}\ enumerate(predictors\_of\_ith\_iteration):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01438}01438\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ predictor.compute\_partial\_dependence(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01439}01439\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ grid,\ target\_features,\ averaged\_predictions[k]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01440}01440\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01441}01441\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Note\ that\ the\ learning\ rate\ is\ already\ accounted\ for\ in\ the\ leaves}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01442}01442\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ values.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01443}01443\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01444}01444\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ averaged\_predictions}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01445}01445\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01446}01446\ \ \ \ \ \textcolor{keyword}{def\ }\_\_sklearn\_tags\_\_(self):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01447}01447\ \ \ \ \ \ \ \ \ tags\ =\ super().\_\_sklearn\_tags\_\_()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01448}01448\ \ \ \ \ \ \ \ \ tags.input\_tags.allow\_nan\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01449}01449\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ tags}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01450}01450\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01451}01451\ \ \ \ \ \textcolor{preprocessor}{@abstractmethod}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01452}01452\ \ \ \ \ \textcolor{keyword}{def\ }\_get\_loss(self,\ sample\_weight):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01453}01453\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{pass}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01454}01454\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01455}01455\ \ \ \ \ \textcolor{preprocessor}{@abstractmethod}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01456}01456\ \ \ \ \ \textcolor{keyword}{def\ }\_encode\_y(self,\ y=None):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01457}01457\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{pass}\ \ \textcolor{comment}{\#\ pragma:\ no\ cover}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01458}01458\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01459}01459\ \ \ \ \ \textcolor{preprocessor}{@abstractmethod}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01460}01460\ \ \ \ \ \textcolor{keyword}{def\ }\_encode\_y\_val(self,\ y=None):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01461}01461\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{pass}\ \ \textcolor{comment}{\#\ pragma:\ no\ cover}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01462}01462\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01463}01463\ \ \ \ \ \textcolor{preprocessor}{@property}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01464}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a712d3651c535805770fe09a201eca9fb}{01464}}\ \ \ \ \ \textcolor{keyword}{def\ }n\_iter\_(self):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01465}01465\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Number\ of\ iterations\ of\ the\ boosting\ process."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01466}01466\ \ \ \ \ \ \ \ \ check\_is\_fitted(self)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01467}01467\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ len(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\_predictors}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01468}01468\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01469}01469\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01470}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{01470}}\ \textcolor{keyword}{class\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(\mbox{\hyperlink{classsklearn_1_1base_1_1RegressorMixin}{RegressorMixin}},\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{BaseHistGradientBoosting}}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01471}01471\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Histogram-\/based\ Gradient\ Boosting\ Regression\ Tree.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01472}01472\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01473}01473\ \textcolor{stringliteral}{\ \ \ \ This\ estimator\ is\ much\ faster\ than}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01474}01474\ \textcolor{stringliteral}{\ \ \ \ :class:\`{}GradientBoostingRegressor<sklearn.ensemble.GradientBoostingRegressor>\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01475}01475\ \textcolor{stringliteral}{\ \ \ \ for\ big\ datasets\ (n\_samples\ >=\ 10\ 000).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01476}01476\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01477}01477\ \textcolor{stringliteral}{\ \ \ \ This\ estimator\ has\ native\ support\ for\ missing\ values\ (NaNs).\ During}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01478}01478\ \textcolor{stringliteral}{\ \ \ \ training,\ the\ tree\ grower\ learns\ at\ each\ split\ point\ whether\ samples}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01479}01479\ \textcolor{stringliteral}{\ \ \ \ with\ missing\ values\ should\ go\ to\ the\ left\ or\ right\ child,\ based\ on\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01480}01480\ \textcolor{stringliteral}{\ \ \ \ potential\ gain.\ When\ predicting,\ samples\ with\ missing\ values\ are}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01481}01481\ \textcolor{stringliteral}{\ \ \ \ assigned\ to\ the\ left\ or\ right\ child\ consequently.\ If\ no\ missing\ values}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01482}01482\ \textcolor{stringliteral}{\ \ \ \ were\ encountered\ for\ a\ given\ feature\ during\ training,\ then\ samples\ with}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01483}01483\ \textcolor{stringliteral}{\ \ \ \ missing\ values\ are\ mapped\ to\ whichever\ child\ has\ the\ most\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01484}01484\ \textcolor{stringliteral}{\ \ \ \ See\ :ref:\`{}sphx\_glr\_auto\_examples\_ensemble\_plot\_hgbt\_regression.py\`{}\ for\ a}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01485}01485\ \textcolor{stringliteral}{\ \ \ \ usecase\ example\ of\ this\ feature.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01486}01486\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01487}01487\ \textcolor{stringliteral}{\ \ \ \ This\ implementation\ is\ inspired\ by}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01488}01488\ \textcolor{stringliteral}{\ \ \ \ \`{}LightGBM\ <https://github.com/Microsoft/LightGBM>\`{}\_.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01489}01489\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01490}01490\ \textcolor{stringliteral}{\ \ \ \ Read\ more\ in\ the\ :ref:\`{}User\ Guide\ <histogram\_based\_gradient\_boosting>\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01491}01491\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01492}01492\ \textcolor{stringliteral}{\ \ \ \ ..\ versionadded::\ 0.21}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01493}01493\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01494}01494\ \textcolor{stringliteral}{\ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01495}01495\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01496}01496\ \textcolor{stringliteral}{\ \ \ \ loss\ :\ \{'squared\_error',\ 'absolute\_error',\ 'gamma',\ 'poisson',\ 'quantile'\},\ \(\backslash\)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01497}01497\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ default='squared\_error'}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01498}01498\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ loss\ function\ to\ use\ in\ the\ boosting\ process.\ Note\ that\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01499}01499\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}squared\ error"{},\ "{}gamma"{}\ and\ "{}poisson"{}\ losses\ actually\ implement}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01500}01500\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}half\ least\ squares\ loss"{},\ "{}half\ gamma\ deviance"{}\ and\ "{}half\ poisson}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01501}01501\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ deviance"{}\ to\ simplify\ the\ computation\ of\ the\ gradient.\ Furthermore,}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01502}01502\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}gamma"{}\ and\ "{}poisson"{}\ losses\ internally\ use\ a\ log-\/link,\ "{}gamma"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01503}01503\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ requires\ \`{}\`{}y\ >\ 0\`{}\`{}\ and\ "{}poisson"{}\ requires\ \`{}\`{}y\ >=\ 0\`{}\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01504}01504\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}quantile"{}\ uses\ the\ pinball\ loss.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01505}01505\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01506}01506\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 0.23}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01507}01507\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ Added\ option\ 'poisson'.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01508}01508\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01509}01509\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 1.1}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01510}01510\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ Added\ option\ 'quantile'.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01511}01511\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01512}01512\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 1.3}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01513}01513\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ Added\ option\ 'gamma'.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01514}01514\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01515}01515\ \textcolor{stringliteral}{\ \ \ \ quantile\ :\ float,\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01516}01516\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ loss\ is\ "{}quantile"{},\ this\ parameter\ specifies\ which\ quantile\ to\ be\ estimated}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01517}01517\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ and\ must\ be\ between\ 0\ and\ 1.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01518}01518\ \textcolor{stringliteral}{\ \ \ \ learning\_rate\ :\ float,\ default=0.1}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01519}01519\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ learning\ rate,\ also\ known\ as\ *shrinkage*.\ This\ is\ used\ as\ a}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01520}01520\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ multiplicative\ factor\ for\ the\ leaves\ values.\ Use\ \`{}\`{}1\`{}\`{}\ for\ no}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01521}01521\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ shrinkage.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01522}01522\ \textcolor{stringliteral}{\ \ \ \ max\_iter\ :\ int,\ default=100}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01523}01523\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ maximum\ number\ of\ iterations\ of\ the\ boosting\ process,\ i.e.\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01524}01524\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ maximum\ number\ of\ trees.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01525}01525\ \textcolor{stringliteral}{\ \ \ \ max\_leaf\_nodes\ :\ int\ or\ None,\ default=31}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01526}01526\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ maximum\ number\ of\ leaves\ for\ each\ tree.\ Must\ be\ strictly\ greater}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01527}01527\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ than\ 1.\ If\ None,\ there\ is\ no\ maximum\ limit.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01528}01528\ \textcolor{stringliteral}{\ \ \ \ max\_depth\ :\ int\ or\ None,\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01529}01529\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ maximum\ depth\ of\ each\ tree.\ The\ depth\ of\ a\ tree\ is\ the\ number\ of}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01530}01530\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ edges\ to\ go\ from\ the\ root\ to\ the\ deepest\ leaf.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01531}01531\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Depth\ isn't\ constrained\ by\ default.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01532}01532\ \textcolor{stringliteral}{\ \ \ \ min\_samples\_leaf\ :\ int,\ default=20}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01533}01533\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ minimum\ number\ of\ samples\ per\ leaf.\ For\ small\ datasets\ with\ less}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01534}01534\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ than\ a\ few\ hundred\ samples,\ it\ is\ recommended\ to\ lower\ this\ value}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01535}01535\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ since\ only\ very\ shallow\ trees\ would\ be\ built.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01536}01536\ \textcolor{stringliteral}{\ \ \ \ l2\_regularization\ :\ float,\ default=0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01537}01537\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ L2\ regularization\ parameter\ penalizing\ leaves\ with\ small\ hessians.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01538}01538\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Use\ \`{}\`{}0\`{}\`{}\ for\ no\ regularization\ (default).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01539}01539\ \textcolor{stringliteral}{\ \ \ \ max\_features\ :\ float,\ default=1.0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01540}01540\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Proportion\ of\ randomly\ chosen\ features\ in\ each\ and\ every\ node\ split.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01541}01541\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ This\ is\ a\ form\ of\ regularization,\ smaller\ values\ make\ the\ trees\ weaker}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01542}01542\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ learners\ and\ might\ prevent\ overfitting.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01543}01543\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ interaction\ constraints\ from\ \`{}interaction\_cst\`{}\ are\ present,\ only\ allowed}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01544}01544\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ features\ are\ taken\ into\ account\ for\ the\ subsampling.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01545}01545\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01546}01546\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 1.4}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01547}01547\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01548}01548\ \textcolor{stringliteral}{\ \ \ \ max\_bins\ :\ int,\ default=255}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01549}01549\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ maximum\ number\ of\ bins\ to\ use\ for\ non-\/missing\ values.\ Before}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01550}01550\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ training,\ each\ feature\ of\ the\ input\ array\ \`{}X\`{}\ is\ binned\ into}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01551}01551\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ integer-\/valued\ bins,\ which\ allows\ for\ a\ much\ faster\ training\ stage.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01552}01552\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Features\ with\ a\ small\ number\ of\ unique\ values\ may\ use\ less\ than}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01553}01553\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \`{}\`{}max\_bins\`{}\`{}\ bins.\ In\ addition\ to\ the\ \`{}\`{}max\_bins\`{}\`{}\ bins,\ one\ more\ bin}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01554}01554\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ always\ reserved\ for\ missing\ values.\ Must\ be\ no\ larger\ than\ 255.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01555}01555\ \textcolor{stringliteral}{\ \ \ \ categorical\_features\ :\ array-\/like\ of\ \{bool,\ int,\ str\}\ of\ shape\ (n\_features)\ \(\backslash\)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01556}01556\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ or\ shape\ (n\_categorical\_features,),\ default='from\_dtype'}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01557}01557\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Indicates\ the\ categorical\ features.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01558}01558\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01559}01559\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ None\ :\ no\ feature\ will\ be\ considered\ categorical.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01560}01560\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ boolean\ array-\/like\ :\ boolean\ mask\ indicating\ categorical\ features.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01561}01561\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ integer\ array-\/like\ :\ integer\ indices\ indicating\ categorical}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01562}01562\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ features.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01563}01563\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ str\ array-\/like:\ names\ of\ categorical\ features\ (assuming\ the\ training}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01564}01564\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ data\ has\ feature\ names).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01565}01565\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ \`{}"{}from\_dtype"{}\`{}:\ dataframe\ columns\ with\ dtype\ "{}category"{}\ are}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01566}01566\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ considered\ to\ be\ categorical\ features.\ The\ input\ must\ be\ an\ object}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01567}01567\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ exposing\ a\ \`{}\`{}\_\_dataframe\_\_\`{}\`{}\ method\ such\ as\ pandas\ or\ polars}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01568}01568\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ DataFrames\ to\ use\ this\ feature.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01569}01569\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01570}01570\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ For\ each\ categorical\ feature,\ there\ must\ be\ at\ most\ \`{}max\_bins\`{}\ unique}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01571}01571\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ categories.\ Negative\ values\ for\ categorical\ features\ encoded\ as\ numeric}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01572}01572\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ dtypes\ are\ treated\ as\ missing\ values.\ All\ categorical\ values\ are}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01573}01573\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ converted\ to\ floating\ point\ numbers.\ This\ means\ that\ categorical\ values}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01574}01574\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ of\ 1.0\ and\ 1\ are\ treated\ as\ the\ same\ category.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01575}01575\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01576}01576\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Read\ more\ in\ the\ :ref:\`{}User\ Guide\ <categorical\_support\_gbdt>\`{}\ and}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01577}01577\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ :ref:\`{}sphx\_glr\_auto\_examples\_ensemble\_plot\_gradient\_boosting\_categorical.py\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01578}01578\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01579}01579\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.24}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01580}01580\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01581}01581\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 1.2}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01582}01582\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ Added\ support\ for\ feature\ names.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01583}01583\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01584}01584\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 1.4}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01585}01585\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ Added\ \`{}"{}from\_dtype"{}\`{}\ option.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01586}01586\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01587}01587\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 1.6}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01588}01588\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ The\ default\ value\ changed\ from\ \`{}None\`{}\ to\ \`{}"{}from\_dtype"{}\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01589}01589\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01590}01590\ \textcolor{stringliteral}{\ \ \ \ monotonic\_cst\ :\ array-\/like\ of\ int\ of\ shape\ (n\_features)\ or\ dict,\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01591}01591\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Monotonic\ constraint\ to\ enforce\ on\ each\ feature\ are\ specified\ using\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01592}01592\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ following\ integer\ values:}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01593}01593\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01594}01594\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ 1:\ monotonic\ increase}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01595}01595\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ 0:\ no\ constraint}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01596}01596\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ -\/1:\ monotonic\ decrease}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01597}01597\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01598}01598\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ a\ dict\ with\ str\ keys,\ map\ feature\ to\ monotonic\ constraints\ by\ name.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01599}01599\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ an\ array,\ the\ features\ are\ mapped\ to\ constraints\ by\ position.\ See}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01600}01600\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ :ref:\`{}monotonic\_cst\_features\_names\`{}\ for\ a\ usage\ example.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01601}01601\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01602}01602\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Read\ more\ in\ the\ :ref:\`{}User\ Guide\ <monotonic\_cst\_gbdt>\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01603}01603\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01604}01604\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.23}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01605}01605\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01606}01606\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 1.2}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01607}01607\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ Accept\ dict\ of\ constraints\ with\ feature\ names\ as\ keys.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01608}01608\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01609}01609\ \textcolor{stringliteral}{\ \ \ \ interaction\_cst\ :\ \{"{}pairwise"{},\ "{}no\_interactions"{}\}\ or\ sequence\ of\ lists/tuples/sets\ \(\backslash\)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01610}01610\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ of\ int,\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01611}01611\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Specify\ interaction\ constraints,\ the\ sets\ of\ features\ which\ can}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01612}01612\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ interact\ with\ each\ other\ in\ child\ node\ splits.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01613}01613\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01614}01614\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Each\ item\ specifies\ the\ set\ of\ feature\ indices\ that\ are\ allowed}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01615}01615\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ to\ interact\ with\ each\ other.\ If\ there\ are\ more\ features\ than}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01616}01616\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ specified\ in\ these\ constraints,\ they\ are\ treated\ as\ if\ they\ were}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01617}01617\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ specified\ as\ an\ additional\ set.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01618}01618\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01619}01619\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ strings\ "{}pairwise"{}\ and\ "{}no\_interactions"{}\ are\ shorthands\ for}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01620}01620\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ allowing\ only\ pairwise\ or\ no\ interactions,\ respectively.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01621}01621\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01622}01622\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ For\ instance,\ with\ 5\ features\ in\ total,\ \`{}interaction\_cst=[\{0,\ 1\}]\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01623}01623\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ equivalent\ to\ \`{}interaction\_cst=[\{0,\ 1\},\ \{2,\ 3,\ 4\}]\`{},}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01624}01624\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ and\ specifies\ that\ each\ branch\ of\ a\ tree\ will\ either\ only\ split}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01625}01625\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ on\ features\ 0\ and\ 1\ or\ only\ split\ on\ features\ 2,\ 3\ and\ 4.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01626}01626\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01627}01627\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ See\ :ref:\`{}this\ example<ice-\/vs-\/pdp>\`{}\ on\ how\ to\ use\ \`{}interaction\_cst\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01628}01628\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01629}01629\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 1.2}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01630}01630\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01631}01631\ \textcolor{stringliteral}{\ \ \ \ warm\_start\ :\ bool,\ default=False}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01632}01632\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ When\ set\ to\ \`{}\`{}True\`{}\`{},\ reuse\ the\ solution\ of\ the\ previous\ call\ to\ fit}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01633}01633\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ and\ add\ more\ estimators\ to\ the\ ensemble.\ For\ results\ to\ be\ valid,\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01634}01634\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ estimator\ should\ be\ re-\/trained\ on\ the\ same\ data\ only.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01635}01635\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ See\ :term:\`{}the\ Glossary\ <warm\_start>\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01636}01636\ \textcolor{stringliteral}{\ \ \ \ early\_stopping\ :\ 'auto'\ or\ bool,\ default='auto'}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01637}01637\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ 'auto',\ early\ stopping\ is\ enabled\ if\ the\ sample\ size\ is\ larger\ than}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01638}01638\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ 10000\ or\ if\ \`{}X\_val\`{}\ and\ \`{}y\_val\`{}\ are\ passed\ to\ \`{}fit\`{}.\ If\ True,\ early\ stopping}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01639}01639\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ enabled,\ otherwise\ early\ stopping\ is\ disabled.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01640}01640\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01641}01641\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.23}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01642}01642\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01643}01643\ \textcolor{stringliteral}{\ \ \ \ scoring\ :\ str\ or\ callable\ or\ None,\ default='loss'}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01644}01644\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Scoring\ method\ to\ use\ for\ early\ stopping.\ Only\ used\ if\ \`{}early\_stopping\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01645}01645\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ enabled.\ Options:}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01646}01646\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01647}01647\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ str:\ see\ :ref:\`{}scoring\_string\_names\`{}\ for\ options.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01648}01648\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ callable:\ a\ scorer\ callable\ object\ (e.g.,\ function)\ with\ signature}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01649}01649\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \`{}\`{}scorer(estimator,\ X,\ y)\`{}\`{}.\ See\ :ref:\`{}scoring\_callable\`{}\ for\ details.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01650}01650\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ \`{}None\`{}:\ the\ :ref:\`{}coefficient\ of\ determination\ <r2\_score>\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01651}01651\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ (:math:\`{}R\string^2\`{})\ is\ used.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01652}01652\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ 'loss':\ early\ stopping\ is\ checked\ w.r.t\ the\ loss\ value.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01653}01653\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01654}01654\ \textcolor{stringliteral}{\ \ \ \ validation\_fraction\ :\ int\ or\ float\ or\ None,\ default=0.1}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01655}01655\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Proportion\ (or\ absolute\ size)\ of\ training\ data\ to\ set\ aside\ as}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01656}01656\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ validation\ data\ for\ early\ stopping.\ If\ None,\ early\ stopping\ is\ done\ on}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01657}01657\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ the\ training\ data.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01658}01658\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ value\ is\ ignored\ if\ either\ early\ stopping\ is\ not\ performed,\ e.g.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01659}01659\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \`{}early\_stopping=False\`{},\ or\ if\ \`{}X\_val\`{}\ and\ \`{}y\_val\`{}\ are\ passed\ to\ fit.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01660}01660\ \textcolor{stringliteral}{\ \ \ \ n\_iter\_no\_change\ :\ int,\ default=10}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01661}01661\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Used\ to\ determine\ when\ to\ "{}early\ stop"{}.\ The\ fitting\ process\ is}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01662}01662\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ stopped\ when\ none\ of\ the\ last\ \`{}\`{}n\_iter\_no\_change\`{}\`{}\ scores\ are\ better}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01663}01663\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ than\ the\ \`{}\`{}n\_iter\_no\_change\ -\/\ 1\`{}\`{}\ -\/th-\/to-\/last\ one,\ up\ to\ some}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01664}01664\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ tolerance.\ Only\ used\ if\ early\ stopping\ is\ performed.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01665}01665\ \textcolor{stringliteral}{\ \ \ \ tol\ :\ float,\ default=1e-\/7}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01666}01666\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ absolute\ tolerance\ to\ use\ when\ comparing\ scores\ during\ early}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01667}01667\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ stopping.\ The\ higher\ the\ tolerance,\ the\ more\ likely\ we\ are\ to\ early}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01668}01668\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ stop:\ higher\ tolerance\ means\ that\ it\ will\ be\ harder\ for\ subsequent}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01669}01669\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ iterations\ to\ be\ considered\ an\ improvement\ upon\ the\ reference\ score.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01670}01670\ \textcolor{stringliteral}{\ \ \ \ verbose\ :\ int,\ default=0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01671}01671\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ verbosity\ level.\ If\ not\ zero,\ print\ some\ information\ about\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01672}01672\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ fitting\ process.\ \`{}\`{}1\`{}\`{}\ prints\ only\ summary\ info,\ \`{}\`{}2\`{}\`{}\ prints\ info\ per}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01673}01673\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01674}01674\ \textcolor{stringliteral}{\ \ \ \ random\_state\ :\ int,\ RandomState\ instance\ or\ None,\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01675}01675\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Pseudo-\/random\ number\ generator\ to\ control\ the\ subsampling\ in\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01676}01676\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ binning\ process,\ and\ the\ train/validation\ data\ split\ if\ early\ stopping}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01677}01677\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ enabled.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01678}01678\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Pass\ an\ int\ for\ reproducible\ output\ across\ multiple\ function\ calls.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01679}01679\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ See\ :term:\`{}Glossary\ <random\_state>\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01680}01680\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01681}01681\ \textcolor{stringliteral}{\ \ \ \ Attributes}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01682}01682\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01683}01683\ \textcolor{stringliteral}{\ \ \ \ do\_early\_stopping\_\ :\ bool}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01684}01684\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Indicates\ whether\ early\ stopping\ is\ used\ during\ training.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01685}01685\ \textcolor{stringliteral}{\ \ \ \ n\_iter\_\ :\ int}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01686}01686\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ number\ of\ iterations\ as\ selected\ by\ early\ stopping,\ depending\ on}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01687}01687\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ the\ \`{}early\_stopping\`{}\ parameter.\ Otherwise\ it\ corresponds\ to\ max\_iter.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01688}01688\ \textcolor{stringliteral}{\ \ \ \ n\_trees\_per\_iteration\_\ :\ int}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01689}01689\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ number\ of\ tree\ that\ are\ built\ at\ each\ iteration.\ For\ regressors,}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01690}01690\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ this\ is\ always\ 1.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01691}01691\ \textcolor{stringliteral}{\ \ \ \ train\_score\_\ :\ ndarray,\ shape\ (n\_iter\_+1,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01692}01692\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ scores\ at\ each\ iteration\ on\ the\ training\ data.\ The\ first\ entry}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01693}01693\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ the\ score\ of\ the\ ensemble\ before\ the\ first\ iteration.\ Scores\ are}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01694}01694\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ computed\ according\ to\ the\ \`{}\`{}scoring\`{}\`{}\ parameter.\ If\ \`{}\`{}scoring\`{}\`{}\ is}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01695}01695\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ not\ 'loss',\ scores\ are\ computed\ on\ a\ subset\ of\ at\ most\ 10\ 000}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01696}01696\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ samples.\ Empty\ if\ no\ early\ stopping.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01697}01697\ \textcolor{stringliteral}{\ \ \ \ validation\_score\_\ :\ ndarray,\ shape\ (n\_iter\_+1,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01698}01698\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ scores\ at\ each\ iteration\ on\ the\ held-\/out\ validation\ data.\ The}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01699}01699\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ first\ entry\ is\ the\ score\ of\ the\ ensemble\ before\ the\ first\ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01700}01700\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Scores\ are\ computed\ according\ to\ the\ \`{}\`{}scoring\`{}\`{}\ parameter.\ Empty\ if}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01701}01701\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ no\ early\ stopping\ or\ if\ \`{}\`{}validation\_fraction\`{}\`{}\ is\ None.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01702}01702\ \textcolor{stringliteral}{\ \ \ \ is\_categorical\_\ :\ ndarray,\ shape\ (n\_features,\ )\ or\ None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01703}01703\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Boolean\ mask\ for\ the\ categorical\ features.\ \`{}\`{}None\`{}\`{}\ if\ there\ are\ no}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01704}01704\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ categorical\ features.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01705}01705\ \textcolor{stringliteral}{\ \ \ \ n\_features\_in\_\ :\ int}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01706}01706\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Number\ of\ features\ seen\ during\ :term:\`{}fit\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01707}01707\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01708}01708\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.24}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01709}01709\ \textcolor{stringliteral}{\ \ \ \ feature\_names\_in\_\ :\ ndarray\ of\ shape\ (\`{}n\_features\_in\_\`{},)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01710}01710\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Names\ of\ features\ seen\ during\ :term:\`{}fit\`{}.\ Defined\ only\ when\ \`{}X\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01711}01711\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ has\ feature\ names\ that\ are\ all\ strings.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01712}01712\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01713}01713\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 1.0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01714}01714\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01715}01715\ \textcolor{stringliteral}{\ \ \ \ See\ Also}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01716}01716\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01717}01717\ \textcolor{stringliteral}{\ \ \ \ GradientBoostingRegressor\ :\ Exact\ gradient\ boosting\ method\ that\ does\ not}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01718}01718\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ scale\ as\ good\ on\ datasets\ with\ a\ large\ number\ of\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01719}01719\ \textcolor{stringliteral}{\ \ \ \ sklearn.tree.DecisionTreeRegressor\ :\ A\ decision\ tree\ regressor.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01720}01720\ \textcolor{stringliteral}{\ \ \ \ RandomForestRegressor\ :\ A\ meta-\/estimator\ that\ fits\ a\ number\ of\ decision}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01721}01721\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ tree\ regressors\ on\ various\ sub-\/samples\ of\ the\ dataset\ and\ uses}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01722}01722\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ averaging\ to\ improve\ the\ statistical\ performance\ and\ control}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01723}01723\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ over-\/fitting.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01724}01724\ \textcolor{stringliteral}{\ \ \ \ AdaBoostRegressor\ :\ A\ meta-\/estimator\ that\ begins\ by\ fitting\ a\ regressor}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01725}01725\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ on\ the\ original\ dataset\ and\ then\ fits\ additional\ copies\ of\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01726}01726\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ regressor\ on\ the\ same\ dataset\ but\ where\ the\ weights\ of\ instances\ are}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01727}01727\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ adjusted\ according\ to\ the\ error\ of\ the\ current\ prediction.\ As\ such,}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01728}01728\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ subsequent\ regressors\ focus\ more\ on\ difficult\ cases.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01729}01729\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01730}01730\ \textcolor{stringliteral}{\ \ \ \ Examples}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01731}01731\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01732}01732\ \textcolor{stringliteral}{\ \ \ \ >>>\ from\ sklearn.ensemble\ import\ HistGradientBoostingRegressor}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01733}01733\ \textcolor{stringliteral}{\ \ \ \ >>>\ from\ sklearn.datasets\ import\ load\_diabetes}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01734}01734\ \textcolor{stringliteral}{\ \ \ \ >>>\ X,\ y\ =\ load\_diabetes(return\_X\_y=True)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01735}01735\ \textcolor{stringliteral}{\ \ \ \ >>>\ est\ =\ HistGradientBoostingRegressor().fit(X,\ y)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01736}01736\ \textcolor{stringliteral}{\ \ \ \ >>>\ est.score(X,\ y)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01737}01737\ \textcolor{stringliteral}{\ \ \ \ 0.92...}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01738}01738\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01739}01739\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01740}01740\ \ \ \ \ \_parameter\_constraints:\ dict\ =\ \{}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01741}01741\ \ \ \ \ \ \ \ \ **BaseHistGradientBoosting.\_parameter\_constraints,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01742}01742\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}loss"{}}:\ [}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01743}01743\ \ \ \ \ \ \ \ \ \ \ \ \ \mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1StrOptions}{StrOptions}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01744}01744\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \{}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01745}01745\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01746}01746\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}absolute\_error"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01747}01747\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}poisson"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01748}01748\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}gamma"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01749}01749\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}quantile"{}},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01750}01750\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01751}01751\ \ \ \ \ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01752}01752\ \ \ \ \ \ \ \ \ \ \ \ \ BaseLoss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01753}01753\ \ \ \ \ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01754}01754\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}quantile"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Real,\ 0,\ 1,\ closed=\textcolor{stringliteral}{"{}both"{}}),\ \textcolor{keywordtype}{None}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01755}01755\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01756}01756\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01757}01757\ \ \ \ \ \textcolor{keyword}{def\ }\_\_init\_\_(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01758}01758\ \ \ \ \ \ \ \ \ self,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01759}01759\ \ \ \ \ \ \ \ \ loss="{}squared\_error"{},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01760}01760\ \ \ \ \ \ \ \ \ *,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01761}01761\ \ \ \ \ \ \ \ \ quantile=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01762}01762\ \ \ \ \ \ \ \ \ learning\_rate=0.1,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01763}01763\ \ \ \ \ \ \ \ \ max\_iter=100,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01764}01764\ \ \ \ \ \ \ \ \ max\_leaf\_nodes=31,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01765}01765\ \ \ \ \ \ \ \ \ max\_depth=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01766}01766\ \ \ \ \ \ \ \ \ min\_samples\_leaf=20,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01767}01767\ \ \ \ \ \ \ \ \ l2\_regularization=0.0,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01768}01768\ \ \ \ \ \ \ \ \ max\_features=1.0,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01769}01769\ \ \ \ \ \ \ \ \ max\_bins=255,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01770}01770\ \ \ \ \ \ \ \ \ categorical\_features="{}from\_dtype"{},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01771}01771\ \ \ \ \ \ \ \ \ monotonic\_cst=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01772}01772\ \ \ \ \ \ \ \ \ interaction\_cst=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01773}01773\ \ \ \ \ \ \ \ \ warm\_start=False,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01774}01774\ \ \ \ \ \ \ \ \ early\_stopping="{}auto"{},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01775}01775\ \ \ \ \ \ \ \ \ scoring="{}loss"{},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01776}01776\ \ \ \ \ \ \ \ \ validation\_fraction=0.1,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01777}01777\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=10,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01778}01778\ \ \ \ \ \ \ \ \ tol=1e-\/7,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01779}01779\ \ \ \ \ \ \ \ \ verbose=0,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01780}01780\ \ \ \ \ \ \ \ \ random\_state=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01781}01781\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01782}01782\ \ \ \ \ \ \ \ \ super().\_\_init\_\_(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01783}01783\ \ \ \ \ \ \ \ \ \ \ \ \ loss=loss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01784}01784\ \ \ \ \ \ \ \ \ \ \ \ \ learning\_rate=learning\_rate,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01785}01785\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=max\_iter,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01786}01786\ \ \ \ \ \ \ \ \ \ \ \ \ max\_leaf\_nodes=max\_leaf\_nodes,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01787}01787\ \ \ \ \ \ \ \ \ \ \ \ \ max\_depth=max\_depth,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01788}01788\ \ \ \ \ \ \ \ \ \ \ \ \ min\_samples\_leaf=min\_samples\_leaf,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01789}01789\ \ \ \ \ \ \ \ \ \ \ \ \ l2\_regularization=l2\_regularization,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01790}01790\ \ \ \ \ \ \ \ \ \ \ \ \ max\_features=max\_features,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01791}01791\ \ \ \ \ \ \ \ \ \ \ \ \ max\_bins=max\_bins,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01792}01792\ \ \ \ \ \ \ \ \ \ \ \ \ monotonic\_cst=monotonic\_cst,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01793}01793\ \ \ \ \ \ \ \ \ \ \ \ \ interaction\_cst=interaction\_cst,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01794}01794\ \ \ \ \ \ \ \ \ \ \ \ \ categorical\_features=categorical\_features,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01795}01795\ \ \ \ \ \ \ \ \ \ \ \ \ early\_stopping=early\_stopping,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01796}01796\ \ \ \ \ \ \ \ \ \ \ \ \ warm\_start=warm\_start,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01797}01797\ \ \ \ \ \ \ \ \ \ \ \ \ scoring=scoring,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01798}01798\ \ \ \ \ \ \ \ \ \ \ \ \ validation\_fraction=validation\_fraction,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01799}01799\ \ \ \ \ \ \ \ \ \ \ \ \ n\_iter\_no\_change=n\_iter\_no\_change,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01800}01800\ \ \ \ \ \ \ \ \ \ \ \ \ tol=tol,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01801}01801\ \ \ \ \ \ \ \ \ \ \ \ \ verbose=verbose,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01802}01802\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=random\_state,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01803}01803\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01804}01804\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a895ff08edb9ba52ddecd9e40e932f93a}{quantile}}\ =\ quantile}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01805}01805\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01806}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_af18d3dbc777369d5e7d113f623bc8d03}{01806}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_af18d3dbc777369d5e7d113f623bc8d03}{predict}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01807}01807\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Predict\ values\ for\ X.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01808}01808\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01809}01809\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01810}01810\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01811}01811\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like,\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01812}01812\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01813}01813\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01814}01814\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01815}01815\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01816}01816\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ y\ :\ ndarray,\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01817}01817\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ predicted\ values.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01818}01818\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01819}01819\ \ \ \ \ \ \ \ \ check\_is\_fitted(self)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01820}01820\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Return\ inverse\ link\ of\ raw\ predictions\ after\ converting}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01821}01821\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ shape\ (n\_samples,\ 1)\ to\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01822}01822\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}.link.inverse(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa4a8356439ef87a220f9ec262a885137}{\_raw\_predict}}(X).ravel())}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01823}01823\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01824}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_ae5dcddcfcbc57ebd809a3119405dde94}{01824}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_ae5dcddcfcbc57ebd809a3119405dde94}{staged\_predict}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01825}01825\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Predict\ regression\ target\ for\ each\ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01826}01826\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01827}01827\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ This\ method\ allows\ monitoring\ (i.e.\ determine\ error\ on\ testing\ set)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01828}01828\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ after\ each\ stage.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01829}01829\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01830}01830\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.24}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01831}01831\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01832}01832\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01833}01833\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01834}01834\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01835}01835\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01836}01836\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01837}01837\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Yields}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01838}01838\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01839}01839\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ y\ :\ generator\ of\ ndarray\ of\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01840}01840\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ predicted\ values\ of\ the\ input\ samples,\ for\ each\ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01841}01841\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01842}01842\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ raw\_predictions\ \textcolor{keywordflow}{in}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57f54f37a2214f8e4a93b3dcf4488cd7}{\_staged\_raw\_predict}}(X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01843}01843\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{yield}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}.link.inverse(raw\_predictions.ravel())}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01844}01844\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01845}01845\ \ \ \ \ \textcolor{keyword}{def\ }\_encode\_y(self,\ y):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01846}01846\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Just\ convert\ y\ to\ the\ expected\ dtype}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01847}01847\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}}\ =\ 1}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01848}01848\ \ \ \ \ \ \ \ \ y\ =\ y.astype(Y\_DTYPE,\ copy=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01849}01849\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1f71d4fd84cefb07d3a4187160d3bf9b}{loss}}\ ==\ \textcolor{stringliteral}{"{}gamma"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01850}01850\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Ensure\ y\ >\ 0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01851}01851\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ np.all(y\ >\ 0):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01852}01852\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(\textcolor{stringliteral}{"{}loss='gamma'\ requires\ strictly\ positive\ y."{}})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01853}01853\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{elif}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1f71d4fd84cefb07d3a4187160d3bf9b}{loss}}\ ==\ \textcolor{stringliteral}{"{}poisson"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01854}01854\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Ensure\ y\ >=\ 0\ and\ sum(y)\ >\ 0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01855}01855\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{keywordflow}{not}\ (np.all(y\ >=\ 0)\ \textcolor{keywordflow}{and}\ np.sum(y)\ >\ 0):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01856}01856\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01857}01857\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}loss='poisson'\ requires\ non-\/negative\ y\ and\ sum(y)\ >\ 0."{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01858}01858\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01859}01859\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ y}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01860}01860\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01861}01861\ \ \ \ \ \textcolor{keyword}{def\ }\_encode\_y\_val(self,\ y=None):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01862}01862\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab17dd70a33da6ddd55769a4ed508940d}{\_encode\_y}}(y)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01863}01863\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01864}01864\ \ \ \ \ \textcolor{keyword}{def\ }\_get\_loss(self,\ sample\_weight):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01865}01865\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1f71d4fd84cefb07d3a4187160d3bf9b}{loss}}\ ==\ \textcolor{stringliteral}{"{}quantile"{}}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01866}01866\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \_LOSSES[self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1f71d4fd84cefb07d3a4187160d3bf9b}{loss}}](}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01867}01867\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight=sample\_weight,\ quantile=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a895ff08edb9ba52ddecd9e40e932f93a}{quantile}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01868}01868\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01869}01869\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01870}01870\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \_LOSSES[self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1f71d4fd84cefb07d3a4187160d3bf9b}{loss}}](sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01871}01871\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01872}01872\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01873}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{01873}}\ \textcolor{keyword}{class\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(\mbox{\hyperlink{classsklearn_1_1base_1_1ClassifierMixin}{ClassifierMixin}},\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{BaseHistGradientBoosting}}):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01874}01874\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Histogram-\/based\ Gradient\ Boosting\ Classification\ Tree.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01875}01875\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01876}01876\ \textcolor{stringliteral}{\ \ \ \ This\ estimator\ is\ much\ faster\ than}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01877}01877\ \textcolor{stringliteral}{\ \ \ \ :class:\`{}GradientBoostingClassifier<sklearn.ensemble.GradientBoostingClassifier>\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01878}01878\ \textcolor{stringliteral}{\ \ \ \ for\ big\ datasets\ (n\_samples\ >=\ 10\ 000).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01879}01879\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01880}01880\ \textcolor{stringliteral}{\ \ \ \ This\ estimator\ has\ native\ support\ for\ missing\ values\ (NaNs).\ During}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01881}01881\ \textcolor{stringliteral}{\ \ \ \ training,\ the\ tree\ grower\ learns\ at\ each\ split\ point\ whether\ samples}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01882}01882\ \textcolor{stringliteral}{\ \ \ \ with\ missing\ values\ should\ go\ to\ the\ left\ or\ right\ child,\ based\ on\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01883}01883\ \textcolor{stringliteral}{\ \ \ \ potential\ gain.\ When\ predicting,\ samples\ with\ missing\ values\ are}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01884}01884\ \textcolor{stringliteral}{\ \ \ \ assigned\ to\ the\ left\ or\ right\ child\ consequently.\ If\ no\ missing\ values}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01885}01885\ \textcolor{stringliteral}{\ \ \ \ were\ encountered\ for\ a\ given\ feature\ during\ training,\ then\ samples\ with}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01886}01886\ \textcolor{stringliteral}{\ \ \ \ missing\ values\ are\ mapped\ to\ whichever\ child\ has\ the\ most\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01887}01887\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01888}01888\ \textcolor{stringliteral}{\ \ \ \ This\ implementation\ is\ inspired\ by}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01889}01889\ \textcolor{stringliteral}{\ \ \ \ \`{}LightGBM\ <https://github.com/Microsoft/LightGBM>\`{}\_.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01890}01890\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01891}01891\ \textcolor{stringliteral}{\ \ \ \ Read\ more\ in\ the\ :ref:\`{}User\ Guide\ <histogram\_based\_gradient\_boosting>\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01892}01892\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01893}01893\ \textcolor{stringliteral}{\ \ \ \ ..\ versionadded::\ 0.21}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01894}01894\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01895}01895\ \textcolor{stringliteral}{\ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01896}01896\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01897}01897\ \textcolor{stringliteral}{\ \ \ \ loss\ :\ \{'log\_loss'\},\ default='log\_loss'}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01898}01898\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ loss\ function\ to\ use\ in\ the\ boosting\ process.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01899}01899\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01900}01900\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ For\ binary\ classification\ problems,\ 'log\_loss'\ is\ also\ known\ as\ logistic\ loss,}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01901}01901\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ binomial\ deviance\ or\ binary\ crossentropy.\ Internally,\ the\ model\ fits\ one\ tree}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01902}01902\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ per\ boosting\ iteration\ and\ uses\ the\ logistic\ sigmoid\ function\ (expit)\ as}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01903}01903\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ inverse\ link\ function\ to\ compute\ the\ predicted\ positive\ class\ probability.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01904}01904\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01905}01905\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ For\ multiclass\ classification\ problems,\ 'log\_loss'\ is\ also\ known\ as\ multinomial}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01906}01906\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ deviance\ or\ categorical\ crossentropy.\ Internally,\ the\ model\ fits\ one\ tree\ per}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01907}01907\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ boosting\ iteration\ and\ per\ class\ and\ uses\ the\ softmax\ function\ as\ inverse\ link}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01908}01908\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ function\ to\ compute\ the\ predicted\ probabilities\ of\ the\ classes.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01909}01909\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01910}01910\ \textcolor{stringliteral}{\ \ \ \ learning\_rate\ :\ float,\ default=0.1}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01911}01911\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ learning\ rate,\ also\ known\ as\ *shrinkage*.\ This\ is\ used\ as\ a}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01912}01912\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ multiplicative\ factor\ for\ the\ leaves\ values.\ Use\ \`{}\`{}1\`{}\`{}\ for\ no}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01913}01913\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ shrinkage.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01914}01914\ \textcolor{stringliteral}{\ \ \ \ max\_iter\ :\ int,\ default=100}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01915}01915\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ maximum\ number\ of\ iterations\ of\ the\ boosting\ process,\ i.e.\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01916}01916\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ maximum\ number\ of\ trees\ for\ binary\ classification.\ For\ multiclass}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01917}01917\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ classification,\ \`{}n\_classes\`{}\ trees\ per\ iteration\ are\ built.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01918}01918\ \textcolor{stringliteral}{\ \ \ \ max\_leaf\_nodes\ :\ int\ or\ None,\ default=31}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01919}01919\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ maximum\ number\ of\ leaves\ for\ each\ tree.\ Must\ be\ strictly\ greater}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01920}01920\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ than\ 1.\ If\ None,\ there\ is\ no\ maximum\ limit.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01921}01921\ \textcolor{stringliteral}{\ \ \ \ max\_depth\ :\ int\ or\ None,\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01922}01922\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ maximum\ depth\ of\ each\ tree.\ The\ depth\ of\ a\ tree\ is\ the\ number\ of}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01923}01923\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ edges\ to\ go\ from\ the\ root\ to\ the\ deepest\ leaf.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01924}01924\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Depth\ isn't\ constrained\ by\ default.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01925}01925\ \textcolor{stringliteral}{\ \ \ \ min\_samples\_leaf\ :\ int,\ default=20}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01926}01926\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ minimum\ number\ of\ samples\ per\ leaf.\ For\ small\ datasets\ with\ less}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01927}01927\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ than\ a\ few\ hundred\ samples,\ it\ is\ recommended\ to\ lower\ this\ value}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01928}01928\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ since\ only\ very\ shallow\ trees\ would\ be\ built.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01929}01929\ \textcolor{stringliteral}{\ \ \ \ l2\_regularization\ :\ float,\ default=0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01930}01930\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ L2\ regularization\ parameter\ penalizing\ leaves\ with\ small\ hessians.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01931}01931\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Use\ \`{}\`{}0\`{}\`{}\ for\ no\ regularization\ (default).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01932}01932\ \textcolor{stringliteral}{\ \ \ \ max\_features\ :\ float,\ default=1.0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01933}01933\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Proportion\ of\ randomly\ chosen\ features\ in\ each\ and\ every\ node\ split.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01934}01934\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ This\ is\ a\ form\ of\ regularization,\ smaller\ values\ make\ the\ trees\ weaker}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01935}01935\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ learners\ and\ might\ prevent\ overfitting.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01936}01936\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ interaction\ constraints\ from\ \`{}interaction\_cst\`{}\ are\ present,\ only\ allowed}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01937}01937\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ features\ are\ taken\ into\ account\ for\ the\ subsampling.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01938}01938\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01939}01939\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 1.4}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01940}01940\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01941}01941\ \textcolor{stringliteral}{\ \ \ \ max\_bins\ :\ int,\ default=255}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01942}01942\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ maximum\ number\ of\ bins\ to\ use\ for\ non-\/missing\ values.\ Before}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01943}01943\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ training,\ each\ feature\ of\ the\ input\ array\ \`{}X\`{}\ is\ binned\ into}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01944}01944\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ integer-\/valued\ bins,\ which\ allows\ for\ a\ much\ faster\ training\ stage.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01945}01945\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Features\ with\ a\ small\ number\ of\ unique\ values\ may\ use\ less\ than}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01946}01946\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \`{}\`{}max\_bins\`{}\`{}\ bins.\ In\ addition\ to\ the\ \`{}\`{}max\_bins\`{}\`{}\ bins,\ one\ more\ bin}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01947}01947\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ always\ reserved\ for\ missing\ values.\ Must\ be\ no\ larger\ than\ 255.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01948}01948\ \textcolor{stringliteral}{\ \ \ \ categorical\_features\ :\ array-\/like\ of\ \{bool,\ int,\ str\}\ of\ shape\ (n\_features)\ \(\backslash\)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01949}01949\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ or\ shape\ (n\_categorical\_features,),\ default='from\_dtype'}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01950}01950\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Indicates\ the\ categorical\ features.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01951}01951\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01952}01952\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ None\ :\ no\ feature\ will\ be\ considered\ categorical.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01953}01953\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ boolean\ array-\/like\ :\ boolean\ mask\ indicating\ categorical\ features.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01954}01954\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ integer\ array-\/like\ :\ integer\ indices\ indicating\ categorical}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01955}01955\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ features.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01956}01956\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ str\ array-\/like:\ names\ of\ categorical\ features\ (assuming\ the\ training}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01957}01957\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ data\ has\ feature\ names).}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01958}01958\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ \`{}"{}from\_dtype"{}\`{}:\ dataframe\ columns\ with\ dtype\ "{}category"{}\ are}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01959}01959\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ considered\ to\ be\ categorical\ features.\ The\ input\ must\ be\ an\ object}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01960}01960\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ exposing\ a\ \`{}\`{}\_\_dataframe\_\_\`{}\`{}\ method\ such\ as\ pandas\ or\ polars}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01961}01961\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ DataFrames\ to\ use\ this\ feature.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01962}01962\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01963}01963\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ For\ each\ categorical\ feature,\ there\ must\ be\ at\ most\ \`{}max\_bins\`{}\ unique}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01964}01964\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ categories.\ Negative\ values\ for\ categorical\ features\ encoded\ as\ numeric}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01965}01965\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ dtypes\ are\ treated\ as\ missing\ values.\ All\ categorical\ values\ are}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01966}01966\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ converted\ to\ floating\ point\ numbers.\ This\ means\ that\ categorical\ values}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01967}01967\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ of\ 1.0\ and\ 1\ are\ treated\ as\ the\ same\ category.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01968}01968\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01969}01969\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Read\ more\ in\ the\ :ref:\`{}User\ Guide\ <categorical\_support\_gbdt>\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01970}01970\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01971}01971\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.24}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01972}01972\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01973}01973\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 1.2}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01974}01974\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ Added\ support\ for\ feature\ names.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01975}01975\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01976}01976\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 1.4}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01977}01977\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ Added\ \`{}"{}from\_dtype"{}\`{}\ option.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01978}01978\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01979}01979\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 1.6}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01980}01980\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ The\ default\ value\ changed\ from\ \`{}None\`{}\ to\ \`{}"{}from\_dtype"{}\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01981}01981\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01982}01982\ \textcolor{stringliteral}{\ \ \ \ monotonic\_cst\ :\ array-\/like\ of\ int\ of\ shape\ (n\_features)\ or\ dict,\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01983}01983\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Monotonic\ constraint\ to\ enforce\ on\ each\ feature\ are\ specified\ using\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01984}01984\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ following\ integer\ values:}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01985}01985\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01986}01986\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ 1:\ monotonic\ increase}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01987}01987\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ 0:\ no\ constraint}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01988}01988\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ -\/1:\ monotonic\ decrease}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01989}01989\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01990}01990\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ a\ dict\ with\ str\ keys,\ map\ feature\ to\ monotonic\ constraints\ by\ name.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01991}01991\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ an\ array,\ the\ features\ are\ mapped\ to\ constraints\ by\ position.\ See}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01992}01992\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ :ref:\`{}monotonic\_cst\_features\_names\`{}\ for\ a\ usage\ example.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01993}01993\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01994}01994\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ constraints\ are\ only\ valid\ for\ binary\ classifications\ and\ hold}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01995}01995\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ over\ the\ probability\ of\ the\ positive\ class.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01996}01996\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Read\ more\ in\ the\ :ref:\`{}User\ Guide\ <monotonic\_cst\_gbdt>\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01997}01997\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01998}01998\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.23}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l01999}01999\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02000}02000\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 1.2}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02001}02001\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ Accept\ dict\ of\ constraints\ with\ feature\ names\ as\ keys.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02002}02002\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02003}02003\ \textcolor{stringliteral}{\ \ \ \ interaction\_cst\ :\ \{"{}pairwise"{},\ "{}no\_interactions"{}\}\ or\ sequence\ of\ lists/tuples/sets\ \(\backslash\)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02004}02004\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ of\ int,\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02005}02005\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Specify\ interaction\ constraints,\ the\ sets\ of\ features\ which\ can}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02006}02006\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ interact\ with\ each\ other\ in\ child\ node\ splits.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02007}02007\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02008}02008\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Each\ item\ specifies\ the\ set\ of\ feature\ indices\ that\ are\ allowed}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02009}02009\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ to\ interact\ with\ each\ other.\ If\ there\ are\ more\ features\ than}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02010}02010\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ specified\ in\ these\ constraints,\ they\ are\ treated\ as\ if\ they\ were}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02011}02011\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ specified\ as\ an\ additional\ set.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02012}02012\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02013}02013\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ strings\ "{}pairwise"{}\ and\ "{}no\_interactions"{}\ are\ shorthands\ for}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02014}02014\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ allowing\ only\ pairwise\ or\ no\ interactions,\ respectively.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02015}02015\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02016}02016\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ For\ instance,\ with\ 5\ features\ in\ total,\ \`{}interaction\_cst=[\{0,\ 1\}]\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02017}02017\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ equivalent\ to\ \`{}interaction\_cst=[\{0,\ 1\},\ \{2,\ 3,\ 4\}]\`{},}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02018}02018\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ and\ specifies\ that\ each\ branch\ of\ a\ tree\ will\ either\ only\ split}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02019}02019\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ on\ features\ 0\ and\ 1\ or\ only\ split\ on\ features\ 2,\ 3\ and\ 4.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02020}02020\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02021}02021\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ See\ :ref:\`{}this\ example<ice-\/vs-\/pdp>\`{}\ on\ how\ to\ use\ \`{}interaction\_cst\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02022}02022\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02023}02023\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 1.2}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02024}02024\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02025}02025\ \textcolor{stringliteral}{\ \ \ \ warm\_start\ :\ bool,\ default=False}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02026}02026\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ When\ set\ to\ \`{}\`{}True\`{}\`{},\ reuse\ the\ solution\ of\ the\ previous\ call\ to\ fit}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02027}02027\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ and\ add\ more\ estimators\ to\ the\ ensemble.\ For\ results\ to\ be\ valid,\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02028}02028\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ estimator\ should\ be\ re-\/trained\ on\ the\ same\ data\ only.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02029}02029\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ See\ :term:\`{}the\ Glossary\ <warm\_start>\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02030}02030\ \textcolor{stringliteral}{\ \ \ \ early\_stopping\ :\ 'auto'\ or\ bool,\ default='auto'}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02031}02031\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ 'auto',\ early\ stopping\ is\ enabled\ if\ the\ sample\ size\ is\ larger\ than}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02032}02032\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ 10000\ or\ if\ \`{}X\_val\`{}\ and\ \`{}y\_val\`{}\ are\ passed\ to\ \`{}fit\`{}.\ If\ True,\ early\ stopping}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02033}02033\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ enabled,\ otherwise\ early\ stopping\ is\ disabled.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02034}02034\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02035}02035\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.23}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02036}02036\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02037}02037\ \textcolor{stringliteral}{\ \ \ \ scoring\ :\ str\ or\ callable\ or\ None,\ default='loss'}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02038}02038\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Scoring\ method\ to\ use\ for\ early\ stopping.\ Only\ used\ if\ \`{}early\_stopping\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02039}02039\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ enabled.\ Options:}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02040}02040\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02041}02041\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ str:\ see\ :ref:\`{}scoring\_string\_names\`{}\ for\ options.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02042}02042\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ callable:\ a\ scorer\ callable\ object\ (e.g.,\ function)\ with\ signature}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02043}02043\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \`{}\`{}scorer(estimator,\ X,\ y)\`{}\`{}.\ See\ :ref:\`{}scoring\_callable\`{}\ for\ details.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02044}02044\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ \`{}None\`{}:\ :ref:\`{}accuracy\ <accuracy\_score>\`{}\ is\ used.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02045}02045\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/\ 'loss':\ early\ stopping\ is\ checked\ w.r.t\ the\ loss\ value.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02046}02046\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02047}02047\ \textcolor{stringliteral}{\ \ \ \ validation\_fraction\ :\ int\ or\ float\ or\ None,\ default=0.1}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02048}02048\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Proportion\ (or\ absolute\ size)\ of\ training\ data\ to\ set\ aside\ as}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02049}02049\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ validation\ data\ for\ early\ stopping.\ If\ None,\ early\ stopping\ is\ done\ on}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02050}02050\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ the\ training\ data.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02051}02051\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ value\ is\ ignored\ if\ either\ early\ stopping\ is\ not\ performed,\ e.g.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02052}02052\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \`{}early\_stopping=False\`{},\ or\ if\ \`{}X\_val\`{}\ and\ \`{}y\_val\`{}\ are\ passed\ to\ fit.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02053}02053\ \textcolor{stringliteral}{\ \ \ \ n\_iter\_no\_change\ :\ int,\ default=10}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02054}02054\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Used\ to\ determine\ when\ to\ "{}early\ stop"{}.\ The\ fitting\ process\ is}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02055}02055\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ stopped\ when\ none\ of\ the\ last\ \`{}\`{}n\_iter\_no\_change\`{}\`{}\ scores\ are\ better}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02056}02056\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ than\ the\ \`{}\`{}n\_iter\_no\_change\ -\/\ 1\`{}\`{}\ -\/th-\/to-\/last\ one,\ up\ to\ some}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02057}02057\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ tolerance.\ Only\ used\ if\ early\ stopping\ is\ performed.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02058}02058\ \textcolor{stringliteral}{\ \ \ \ tol\ :\ float,\ default=1e-\/7}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02059}02059\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ absolute\ tolerance\ to\ use\ when\ comparing\ scores.\ The\ higher\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02060}02060\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ tolerance,\ the\ more\ likely\ we\ are\ to\ early\ stop:\ higher\ tolerance}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02061}02061\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ means\ that\ it\ will\ be\ harder\ for\ subsequent\ iterations\ to\ be}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02062}02062\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ considered\ an\ improvement\ upon\ the\ reference\ score.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02063}02063\ \textcolor{stringliteral}{\ \ \ \ verbose\ :\ int,\ default=0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02064}02064\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ verbosity\ level.\ If\ not\ zero,\ print\ some\ information\ about\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02065}02065\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ fitting\ process.\ \`{}\`{}1\`{}\`{}\ prints\ only\ summary\ info,\ \`{}\`{}2\`{}\`{}\ prints\ info\ per}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02066}02066\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02067}02067\ \textcolor{stringliteral}{\ \ \ \ random\_state\ :\ int,\ RandomState\ instance\ or\ None,\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02068}02068\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Pseudo-\/random\ number\ generator\ to\ control\ the\ subsampling\ in\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02069}02069\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ binning\ process,\ and\ the\ train/validation\ data\ split\ if\ early\ stopping}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02070}02070\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ enabled.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02071}02071\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Pass\ an\ int\ for\ reproducible\ output\ across\ multiple\ function\ calls.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02072}02072\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ See\ :term:\`{}Glossary\ <random\_state>\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02073}02073\ \textcolor{stringliteral}{\ \ \ \ class\_weight\ :\ dict\ or\ 'balanced',\ default=None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02074}02074\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Weights\ associated\ with\ classes\ in\ the\ form\ \`{}\{class\_label:\ weight\}\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02075}02075\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ If\ not\ given,\ all\ classes\ are\ supposed\ to\ have\ weight\ one.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02076}02076\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ "{}balanced"{}\ mode\ uses\ the\ values\ of\ y\ to\ automatically\ adjust}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02077}02077\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ weights\ inversely\ proportional\ to\ class\ frequencies\ in\ the\ input\ data}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02078}02078\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ as\ \`{}n\_samples\ /\ (n\_classes\ *\ np.bincount(y))\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02079}02079\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Note\ that\ these\ weights\ will\ be\ multiplied\ with\ sample\_weight\ (passed}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02080}02080\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ through\ the\ fit\ method)\ if\ \`{}sample\_weight\`{}\ is\ specified.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02081}02081\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02082}02082\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 1.2}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02083}02083\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02084}02084\ \textcolor{stringliteral}{\ \ \ \ Attributes}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02085}02085\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02086}02086\ \textcolor{stringliteral}{\ \ \ \ classes\_\ :\ array,\ shape\ =\ (n\_classes,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02087}02087\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Class\ labels.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02088}02088\ \textcolor{stringliteral}{\ \ \ \ do\_early\_stopping\_\ :\ bool}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02089}02089\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Indicates\ whether\ early\ stopping\ is\ used\ during\ training.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02090}02090\ \textcolor{stringliteral}{\ \ \ \ n\_iter\_\ :\ int}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02091}02091\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ number\ of\ iterations\ as\ selected\ by\ early\ stopping,\ depending\ on}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02092}02092\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ the\ \`{}early\_stopping\`{}\ parameter.\ Otherwise\ it\ corresponds\ to\ max\_iter.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02093}02093\ \textcolor{stringliteral}{\ \ \ \ n\_trees\_per\_iteration\_\ :\ int}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02094}02094\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ number\ of\ tree\ that\ are\ built\ at\ each\ iteration.\ This\ is\ equal\ to\ 1}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02095}02095\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ for\ binary\ classification,\ and\ to\ \`{}\`{}n\_classes\`{}\`{}\ for\ multiclass}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02096}02096\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ classification.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02097}02097\ \textcolor{stringliteral}{\ \ \ \ train\_score\_\ :\ ndarray,\ shape\ (n\_iter\_+1,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02098}02098\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ scores\ at\ each\ iteration\ on\ the\ training\ data.\ The\ first\ entry}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02099}02099\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ is\ the\ score\ of\ the\ ensemble\ before\ the\ first\ iteration.\ Scores\ are}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02100}02100\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ computed\ according\ to\ the\ \`{}\`{}scoring\`{}\`{}\ parameter.\ If\ \`{}\`{}scoring\`{}\`{}\ is}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02101}02101\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ not\ 'loss',\ scores\ are\ computed\ on\ a\ subset\ of\ at\ most\ 10\ 000}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02102}02102\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ samples.\ Empty\ if\ no\ early\ stopping.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02103}02103\ \textcolor{stringliteral}{\ \ \ \ validation\_score\_\ :\ ndarray,\ shape\ (n\_iter\_+1,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02104}02104\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ scores\ at\ each\ iteration\ on\ the\ held-\/out\ validation\ data.\ The}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02105}02105\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ first\ entry\ is\ the\ score\ of\ the\ ensemble\ before\ the\ first\ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02106}02106\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Scores\ are\ computed\ according\ to\ the\ \`{}\`{}scoring\`{}\`{}\ parameter.\ Empty\ if}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02107}02107\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ no\ early\ stopping\ or\ if\ \`{}\`{}validation\_fraction\`{}\`{}\ is\ None.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02108}02108\ \textcolor{stringliteral}{\ \ \ \ is\_categorical\_\ :\ ndarray,\ shape\ (n\_features,\ )\ or\ None}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02109}02109\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Boolean\ mask\ for\ the\ categorical\ features.\ \`{}\`{}None\`{}\`{}\ if\ there\ are\ no}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02110}02110\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ categorical\ features.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02111}02111\ \textcolor{stringliteral}{\ \ \ \ n\_features\_in\_\ :\ int}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02112}02112\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Number\ of\ features\ seen\ during\ :term:\`{}fit\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02113}02113\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02114}02114\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.24}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02115}02115\ \textcolor{stringliteral}{\ \ \ \ feature\_names\_in\_\ :\ ndarray\ of\ shape\ (\`{}n\_features\_in\_\`{},)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02116}02116\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Names\ of\ features\ seen\ during\ :term:\`{}fit\`{}.\ Defined\ only\ when\ \`{}X\`{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02117}02117\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ has\ feature\ names\ that\ are\ all\ strings.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02118}02118\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02119}02119\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 1.0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02120}02120\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02121}02121\ \textcolor{stringliteral}{\ \ \ \ See\ Also}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02122}02122\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02123}02123\ \textcolor{stringliteral}{\ \ \ \ GradientBoostingClassifier\ :\ Exact\ gradient\ boosting\ method\ that\ does\ not}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02124}02124\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ scale\ as\ good\ on\ datasets\ with\ a\ large\ number\ of\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02125}02125\ \textcolor{stringliteral}{\ \ \ \ sklearn.tree.DecisionTreeClassifier\ :\ A\ decision\ tree\ classifier.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02126}02126\ \textcolor{stringliteral}{\ \ \ \ RandomForestClassifier\ :\ A\ meta-\/estimator\ that\ fits\ a\ number\ of\ decision}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02127}02127\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ tree\ classifiers\ on\ various\ sub-\/samples\ of\ the\ dataset\ and\ uses}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02128}02128\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ averaging\ to\ improve\ the\ predictive\ accuracy\ and\ control\ over-\/fitting.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02129}02129\ \textcolor{stringliteral}{\ \ \ \ AdaBoostClassifier\ :\ A\ meta-\/estimator\ that\ begins\ by\ fitting\ a\ classifier}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02130}02130\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ on\ the\ original\ dataset\ and\ then\ fits\ additional\ copies\ of\ the}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02131}02131\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ classifier\ on\ the\ same\ dataset\ where\ the\ weights\ of\ incorrectly}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02132}02132\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ classified\ instances\ are\ adjusted\ such\ that\ subsequent\ classifiers}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02133}02133\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ focus\ more\ on\ difficult\ cases.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02134}02134\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02135}02135\ \textcolor{stringliteral}{\ \ \ \ Examples}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02136}02136\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02137}02137\ \textcolor{stringliteral}{\ \ \ \ >>>\ from\ sklearn.ensemble\ import\ HistGradientBoostingClassifier}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02138}02138\ \textcolor{stringliteral}{\ \ \ \ >>>\ from\ sklearn.datasets\ import\ load\_iris}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02139}02139\ \textcolor{stringliteral}{\ \ \ \ >>>\ X,\ y\ =\ load\_iris(return\_X\_y=True)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02140}02140\ \textcolor{stringliteral}{\ \ \ \ >>>\ clf\ =\ HistGradientBoostingClassifier().fit(X,\ y)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02141}02141\ \textcolor{stringliteral}{\ \ \ \ >>>\ clf.score(X,\ y)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02142}02142\ \textcolor{stringliteral}{\ \ \ \ 1.0}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02143}02143\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02144}02144\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02145}02145\ \ \ \ \ \_parameter\_constraints:\ dict\ =\ \{}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02146}02146\ \ \ \ \ \ \ \ \ **BaseHistGradientBoosting.\_parameter\_constraints,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02147}02147\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}loss"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1StrOptions}{StrOptions}}(\{\textcolor{stringliteral}{"{}log\_loss"{}}\}),\ BaseLoss],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02148}02148\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}class\_weight"{}}:\ [dict,\ \mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1StrOptions}{StrOptions}}(\{\textcolor{stringliteral}{"{}balanced"{}}\}),\ \textcolor{keywordtype}{None}],}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02149}02149\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02150}02150\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02151}02151\ \ \ \ \ \textcolor{keyword}{def\ }\_\_init\_\_(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02152}02152\ \ \ \ \ \ \ \ \ self,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02153}02153\ \ \ \ \ \ \ \ \ loss="{}log\_loss"{},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02154}02154\ \ \ \ \ \ \ \ \ *,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02155}02155\ \ \ \ \ \ \ \ \ learning\_rate=0.1,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02156}02156\ \ \ \ \ \ \ \ \ max\_iter=100,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02157}02157\ \ \ \ \ \ \ \ \ max\_leaf\_nodes=31,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02158}02158\ \ \ \ \ \ \ \ \ max\_depth=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02159}02159\ \ \ \ \ \ \ \ \ min\_samples\_leaf=20,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02160}02160\ \ \ \ \ \ \ \ \ l2\_regularization=0.0,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02161}02161\ \ \ \ \ \ \ \ \ max\_features=1.0,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02162}02162\ \ \ \ \ \ \ \ \ max\_bins=255,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02163}02163\ \ \ \ \ \ \ \ \ categorical\_features="{}from\_dtype"{},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02164}02164\ \ \ \ \ \ \ \ \ monotonic\_cst=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02165}02165\ \ \ \ \ \ \ \ \ interaction\_cst=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02166}02166\ \ \ \ \ \ \ \ \ warm\_start=False,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02167}02167\ \ \ \ \ \ \ \ \ early\_stopping="{}auto"{},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02168}02168\ \ \ \ \ \ \ \ \ scoring="{}loss"{},}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02169}02169\ \ \ \ \ \ \ \ \ validation\_fraction=0.1,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02170}02170\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=10,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02171}02171\ \ \ \ \ \ \ \ \ tol=1e-\/7,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02172}02172\ \ \ \ \ \ \ \ \ verbose=0,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02173}02173\ \ \ \ \ \ \ \ \ random\_state=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02174}02174\ \ \ \ \ \ \ \ \ class\_weight=None,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02175}02175\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02176}02176\ \ \ \ \ \ \ \ \ super().\_\_init\_\_(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02177}02177\ \ \ \ \ \ \ \ \ \ \ \ \ loss=loss,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02178}02178\ \ \ \ \ \ \ \ \ \ \ \ \ learning\_rate=learning\_rate,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02179}02179\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=max\_iter,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02180}02180\ \ \ \ \ \ \ \ \ \ \ \ \ max\_leaf\_nodes=max\_leaf\_nodes,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02181}02181\ \ \ \ \ \ \ \ \ \ \ \ \ max\_depth=max\_depth,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02182}02182\ \ \ \ \ \ \ \ \ \ \ \ \ min\_samples\_leaf=min\_samples\_leaf,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02183}02183\ \ \ \ \ \ \ \ \ \ \ \ \ l2\_regularization=l2\_regularization,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02184}02184\ \ \ \ \ \ \ \ \ \ \ \ \ max\_features=max\_features,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02185}02185\ \ \ \ \ \ \ \ \ \ \ \ \ max\_bins=max\_bins,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02186}02186\ \ \ \ \ \ \ \ \ \ \ \ \ categorical\_features=categorical\_features,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02187}02187\ \ \ \ \ \ \ \ \ \ \ \ \ monotonic\_cst=monotonic\_cst,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02188}02188\ \ \ \ \ \ \ \ \ \ \ \ \ interaction\_cst=interaction\_cst,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02189}02189\ \ \ \ \ \ \ \ \ \ \ \ \ warm\_start=warm\_start,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02190}02190\ \ \ \ \ \ \ \ \ \ \ \ \ early\_stopping=early\_stopping,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02191}02191\ \ \ \ \ \ \ \ \ \ \ \ \ scoring=scoring,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02192}02192\ \ \ \ \ \ \ \ \ \ \ \ \ validation\_fraction=validation\_fraction,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02193}02193\ \ \ \ \ \ \ \ \ \ \ \ \ n\_iter\_no\_change=n\_iter\_no\_change,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02194}02194\ \ \ \ \ \ \ \ \ \ \ \ \ tol=tol,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02195}02195\ \ \ \ \ \ \ \ \ \ \ \ \ verbose=verbose,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02196}02196\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=random\_state,}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02197}02197\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02198}02198\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_aa0eedfb5cdc27ad75585a56d9fd7acf5}{class\_weight}}\ =\ class\_weight}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02199}02199\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02200}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a7765960d3462e6c76193b9aa6588e9d3}{02200}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a7765960d3462e6c76193b9aa6588e9d3}{\_finalize\_sample\_weight}}(self,\ sample\_weight,\ y):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02201}02201\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Adjust\ sample\_weights\ with\ class\_weights."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02202}02202\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_aa0eedfb5cdc27ad75585a56d9fd7acf5}{class\_weight}}\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02203}02203\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ sample\_weight}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02204}02204\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02205}02205\ \ \ \ \ \ \ \ \ expanded\_class\_weight\ =\ compute\_sample\_weight(self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_aa0eedfb5cdc27ad75585a56d9fd7acf5}{class\_weight}},\ y)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02206}02206\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02207}02207\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ sample\_weight\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02208}02208\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ sample\_weight\ *\ expanded\_class\_weight}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02209}02209\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02210}02210\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ expanded\_class\_weight}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02211}02211\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02212}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_ac4c11b235f97f1c62bf28e9e506dc61a}{02212}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_ac4c11b235f97f1c62bf28e9e506dc61a}{predict}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02213}02213\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Predict\ classes\ for\ X.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02214}02214\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02215}02215\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02216}02216\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02217}02217\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like,\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02218}02218\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02219}02219\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02220}02220\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02221}02221\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02222}02222\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ y\ :\ ndarray,\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02223}02223\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ predicted\ classes.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02224}02224\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02225}02225\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ TODO:\ This\ could\ be\ done\ in\ parallel}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02226}02226\ \ \ \ \ \ \ \ \ raw\_predictions\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa4a8356439ef87a220f9ec262a885137}{\_raw\_predict}}(X)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02227}02227\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ raw\_predictions.shape[1]\ ==\ 1:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02228}02228\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ np.argmax([0.5,\ 0.5])\ is\ 0,\ not\ 1.\ Therefore\ "{}>\ 0"{}\ not\ "{}>=\ 0"{}\ to\ be}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02229}02229\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ consistent\ with\ the\ multiclass\ case.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02230}02230\ \ \ \ \ \ \ \ \ \ \ \ \ encoded\_classes\ =\ (raw\_predictions.ravel()\ >\ 0).astype(int)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02231}02231\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02232}02232\ \ \ \ \ \ \ \ \ \ \ \ \ encoded\_classes\ =\ np.argmax(raw\_predictions,\ axis=1)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02233}02233\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_ac4ec38fed5bb8a8d250f0f509bf99941}{classes\_}}[encoded\_classes]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02234}02234\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02235}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a2d14405e39a86c68c79ddc2d9d992f49}{02235}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a2d14405e39a86c68c79ddc2d9d992f49}{staged\_predict}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02236}02236\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Predict\ classes\ at\ each\ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02237}02237\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02238}02238\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ This\ method\ allows\ monitoring\ (i.e.\ determine\ error\ on\ testing\ set)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02239}02239\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ after\ each\ stage.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02240}02240\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02241}02241\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.24}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02242}02242\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02243}02243\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02244}02244\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02245}02245\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02246}02246\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02247}02247\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02248}02248\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Yields}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02249}02249\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02250}02250\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ y\ :\ generator\ of\ ndarray\ of\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02251}02251\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ predicted\ classes\ of\ the\ input\ samples,\ for\ each\ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02252}02252\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02253}02253\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ raw\_predictions\ \textcolor{keywordflow}{in}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57f54f37a2214f8e4a93b3dcf4488cd7}{\_staged\_raw\_predict}}(X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02254}02254\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ raw\_predictions.shape[1]\ ==\ 1:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02255}02255\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ np.argmax([0,\ 0])\ is\ 0,\ not\ 1,\ therefore\ "{}>\ 0"{}\ not\ "{}>=\ 0"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02256}02256\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ encoded\_classes\ =\ (raw\_predictions.ravel()\ >\ 0).astype(int)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02257}02257\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02258}02258\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ encoded\_classes\ =\ np.argmax(raw\_predictions,\ axis=1)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02259}02259\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{yield}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_ac4ec38fed5bb8a8d250f0f509bf99941}{classes\_}}.take(encoded\_classes,\ axis=0)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02260}02260\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02261}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a91fcc49a116cd60614346adcf739fc40}{02261}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a91fcc49a116cd60614346adcf739fc40}{predict\_proba}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02262}02262\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Predict\ class\ probabilities\ for\ X.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02263}02263\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02264}02264\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02265}02265\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02266}02266\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like,\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02267}02267\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02268}02268\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02269}02269\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02270}02270\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02271}02271\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ p\ :\ ndarray,\ shape\ (n\_samples,\ n\_classes)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02272}02272\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ class\ probabilities\ of\ the\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02273}02273\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02274}02274\ \ \ \ \ \ \ \ \ raw\_predictions\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa4a8356439ef87a220f9ec262a885137}{\_raw\_predict}}(X)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02275}02275\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a91fcc49a116cd60614346adcf739fc40}{predict\_proba}}(raw\_predictions)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02276}02276\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02277}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a801989a31f3167ce2194b93144137e98}{02277}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a801989a31f3167ce2194b93144137e98}{staged\_predict\_proba}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02278}02278\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Predict\ class\ probabilities\ at\ each\ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02279}02279\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02280}02280\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ This\ method\ allows\ monitoring\ (i.e.\ determine\ error\ on\ testing\ set)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02281}02281\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ after\ each\ stage.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02282}02282\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02283}02283\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02284}02284\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02285}02285\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02286}02286\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02287}02287\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02288}02288\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Yields}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02289}02289\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02290}02290\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ y\ :\ generator\ of\ ndarray\ of\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02291}02291\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ predicted\ class\ probabilities\ of\ the\ input\ samples,}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02292}02292\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ for\ each\ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02293}02293\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02294}02294\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ raw\_predictions\ \textcolor{keywordflow}{in}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57f54f37a2214f8e4a93b3dcf4488cd7}{\_staged\_raw\_predict}}(X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02295}02295\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{yield}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\_loss}}.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a91fcc49a116cd60614346adcf739fc40}{predict\_proba}}(raw\_predictions)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02296}02296\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02297}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_acdee8643ef0a79a1acb7c72e9238649a}{02297}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_acdee8643ef0a79a1acb7c72e9238649a}{decision\_function}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02298}02298\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Compute\ the\ decision\ function\ of\ \`{}\`{}X\`{}\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02299}02299\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02300}02300\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02301}02301\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02302}02302\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like,\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02303}02303\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02304}02304\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02305}02305\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02306}02306\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02307}02307\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ decision\ :\ ndarray,\ shape\ (n\_samples,)\ or\ \(\backslash\)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02308}02308\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (n\_samples,\ n\_trees\_per\_iteration)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02309}02309\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ raw\ predicted\ values\ (i.e.\ the\ sum\ of\ the\ trees\ leaves)\ for}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02310}02310\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ each\ sample.\ n\_trees\_per\_iteration\ is\ equal\ to\ the\ number\ of}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02311}02311\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ classes\ in\ multiclass\ classification.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02312}02312\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02313}02313\ \ \ \ \ \ \ \ \ decision\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa4a8356439ef87a220f9ec262a885137}{\_raw\_predict}}(X)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02314}02314\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ decision.shape[1]\ ==\ 1:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02315}02315\ \ \ \ \ \ \ \ \ \ \ \ \ decision\ =\ decision.ravel()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02316}02316\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ decision}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02317}02317\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02318}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a25e6f9554cd6168aa7d9c00e7f04deaf}{02318}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a25e6f9554cd6168aa7d9c00e7f04deaf}{staged\_decision\_function}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02319}02319\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Compute\ decision\ function\ of\ \`{}\`{}X\`{}\`{}\ for\ each\ iteration.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02320}02320\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02321}02321\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ This\ method\ allows\ monitoring\ (i.e.\ determine\ error\ on\ testing\ set)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02322}02322\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ after\ each\ stage.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02323}02323\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02324}02324\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02325}02325\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02326}02326\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02327}02327\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ input\ samples.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02328}02328\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02329}02329\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Yields}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02330}02330\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02331}02331\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ decision\ :\ generator\ of\ ndarray\ of\ shape\ (n\_samples,)\ or\ \(\backslash\)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02332}02332\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (n\_samples,\ n\_trees\_per\_iteration)}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02333}02333\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ The\ decision\ function\ of\ the\ input\ samples,\ which\ corresponds\ to}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02334}02334\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ the\ raw\ values\ predicted\ from\ the\ trees\ of\ the\ ensemble\ .\ The}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02335}02335\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ classes\ corresponds\ to\ that\ in\ the\ attribute\ :term:\`{}classes\_\`{}.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02336}02336\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02337}02337\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ staged\_decision\ \textcolor{keywordflow}{in}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57f54f37a2214f8e4a93b3dcf4488cd7}{\_staged\_raw\_predict}}(X):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02338}02338\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ staged\_decision.shape[1]\ ==\ 1:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02339}02339\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ staged\_decision\ =\ staged\_decision.ravel()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02340}02340\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{yield}\ staged\_decision}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02341}02341\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02342}\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a680e4459b0606442238a3dbc44f10a05}{02342}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a680e4459b0606442238a3dbc44f10a05}{\_encode\_y}}(self,\ y):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02343}02343\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Create\ self.\_label\_encoder\ and\ encode\ y\ correspondingly."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02344}02344\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ encode\ classes\ into\ 0\ ...\ n\_classes\ -\/\ 1\ and\ sets\ attributes\ classes\_}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02345}02345\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ and\ n\_trees\_per\_iteration\_}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02346}02346\ \ \ \ \ \ \ \ \ check\_classification\_targets(y)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02347}02347\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02348}02348\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ We\ need\ to\ store\ the\ label\ encoder\ in\ case\ y\_val\ needs\ to\ be\ label\ encoded,}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02349}02349\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ too.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02350}02350\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a4e4e61e8cf495f4d05358d7cb3da3f27}{\_label\_encoder}}\ =\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__label_1_1LabelEncoder}{LabelEncoder}}()}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02351}02351\ \ \ \ \ \ \ \ \ encoded\_y\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a4e4e61e8cf495f4d05358d7cb3da3f27}{\_label\_encoder}}.fit\_transform(y)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02352}02352\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_ac4ec38fed5bb8a8d250f0f509bf99941}{classes\_}}\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a4e4e61e8cf495f4d05358d7cb3da3f27}{\_label\_encoder}}.classes\_}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02353}02353\ \ \ \ \ \ \ \ \ n\_classes\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_ac4ec38fed5bb8a8d250f0f509bf99941}{classes\_}}.shape[0]}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02354}02354\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ only\ 1\ tree\ for\ binary\ classification.\ For\ multiclass\ classification,}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02355}02355\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ we\ build\ 1\ tree\ per\ class.}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02356}02356\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}}\ =\ 1\ \textcolor{keywordflow}{if}\ n\_classes\ <=\ 2\ \textcolor{keywordflow}{else}\ n\_classes}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02357}02357\ \ \ \ \ \ \ \ \ encoded\_y\ =\ encoded\_y.astype(Y\_DTYPE,\ copy=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02358}02358\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ encoded\_y}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02359}02359\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02360}02360\ \ \ \ \ \textcolor{keyword}{def\ }\_encode\_y\_val(self,\ y):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02361}02361\ \ \ \ \ \ \ \ \ encoded\_y\ =\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier_a4e4e61e8cf495f4d05358d7cb3da3f27}{\_label\_encoder}}.transform(y)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02362}02362\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ encoded\_y.astype(Y\_DTYPE,\ copy=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02363}02363\ }
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02364}02364\ \ \ \ \ \textcolor{keyword}{def\ }\_get\_loss(self,\ sample\_weight):}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02365}02365\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ At\ this\ point\ self.loss\ ==\ "{}log\_loss"{}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02366}02366\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}}\ ==\ 1:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02367}02367\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfBinomialLoss}{HalfBinomialLoss}}(sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02368}02368\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02369}02369\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfMultinomialLoss}{HalfMultinomialLoss}}(}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02370}02370\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_weight=sample\_weight,\ n\_classes=self.\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\_trees\_per\_iteration\_}}}
\DoxyCodeLine{\Hypertarget{gradient__boosting_8py_source_l02371}02371\ \ \ \ \ \ \ \ \ \ \ \ \ )}

\end{DoxyCode}
