\doxysection{\+\_\+huber.\+py}
\hypertarget{__huber_8py_source}{}\label{__huber_8py_source}\index{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/linear\_model/\_huber.py@{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/linear\_model/\_huber.py}}

\begin{DoxyCode}{0}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00001}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1__huber}{00001}}\ \textcolor{comment}{\#\ Authors:\ The\ scikit-\/learn\ developers}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00002}00002\ \textcolor{comment}{\#\ SPDX-\/License-\/Identifier:\ BSD-\/3-\/Clause}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00003}00003\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00004}00004\ \textcolor{keyword}{from}\ numbers\ \textcolor{keyword}{import}\ Integral,\ Real}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00005}00005\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00006}00006\ \textcolor{keyword}{import}\ numpy\ \textcolor{keyword}{as}\ np}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00007}00007\ \textcolor{keyword}{from}\ scipy\ \textcolor{keyword}{import}\ optimize}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00008}00008\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00009}00009\ \textcolor{keyword}{from}\ ..base\ \textcolor{keyword}{import}\ BaseEstimator,\ RegressorMixin,\ \_fit\_context}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00010}00010\ \textcolor{keyword}{from}\ ..utils.\_mask\ \textcolor{keyword}{import}\ axis0\_safe\_slice}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00011}00011\ \textcolor{keyword}{from}\ ..utils.\_param\_validation\ \textcolor{keyword}{import}\ Interval}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00012}00012\ \textcolor{keyword}{from}\ ..utils.extmath\ \textcolor{keyword}{import}\ safe\_sparse\_dot}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00013}00013\ \textcolor{keyword}{from}\ ..utils.fixes\ \textcolor{keyword}{import}\ \_get\_additional\_lbfgs\_options\_dict}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00014}00014\ \textcolor{keyword}{from}\ ..utils.optimize\ \textcolor{keyword}{import}\ \_check\_optimize\_result}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00015}00015\ \textcolor{keyword}{from}\ ..utils.validation\ \textcolor{keyword}{import}\ \_check\_sample\_weight,\ validate\_data}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00016}00016\ \textcolor{keyword}{from}\ .\_base\ \textcolor{keyword}{import}\ LinearModel}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00017}00017\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00018}00018\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00019}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1__huber_a5ac2f64944b5884919d526eda8b8202b}{00019}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1__huber_a5ac2f64944b5884919d526eda8b8202b}{\_huber\_loss\_and\_gradient}}(w,\ X,\ y,\ epsilon,\ alpha,\ sample\_weight=None):}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00020}00020\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Returns\ the\ Huber\ loss\ and\ the\ gradient.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00021}00021\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00022}00022\ \textcolor{stringliteral}{\ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00023}00023\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00024}00024\ \textcolor{stringliteral}{\ \ \ \ w\ :\ ndarray,\ shape\ (n\_features\ +\ 1,)\ or\ (n\_features\ +\ 2,)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00025}00025\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Feature\ vector.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00026}00026\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ w[:n\_features]\ gives\ the\ coefficients}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00027}00027\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ w[-\/1]\ gives\ the\ scale\ factor\ and\ if\ the\ intercept\ is\ fit\ w[-\/2]}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00028}00028\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ gives\ the\ intercept\ factor.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00029}00029\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00030}00030\ \textcolor{stringliteral}{\ \ \ \ X\ :\ ndarray\ of\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00031}00031\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Input\ data.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00032}00032\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00033}00033\ \textcolor{stringliteral}{\ \ \ \ y\ :\ ndarray\ of\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00034}00034\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Target\ vector.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00035}00035\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00036}00036\ \textcolor{stringliteral}{\ \ \ \ epsilon\ :\ float}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00037}00037\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Robustness\ of\ the\ Huber\ estimator.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00038}00038\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00039}00039\ \textcolor{stringliteral}{\ \ \ \ alpha\ :\ float}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00040}00040\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Regularization\ parameter.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00041}00041\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00042}00042\ \textcolor{stringliteral}{\ \ \ \ sample\_weight\ :\ ndarray\ of\ shape\ (n\_samples,),\ default=None}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00043}00043\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Weight\ assigned\ to\ each\ sample.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00044}00044\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00045}00045\ \textcolor{stringliteral}{\ \ \ \ Returns}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00046}00046\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00047}00047\ \textcolor{stringliteral}{\ \ \ \ loss\ :\ float}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00048}00048\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Huber\ loss.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00049}00049\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00050}00050\ \textcolor{stringliteral}{\ \ \ \ gradient\ :\ ndarray,\ shape\ (len(w))}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00051}00051\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns\ the\ derivative\ of\ the\ Huber\ loss\ with\ respect\ to\ each}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00052}00052\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ coefficient,\ intercept\ and\ the\ scale\ as\ a\ vector.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00053}00053\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00054}00054\ \ \ \ \ \_,\ n\_features\ =\ X.shape}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00055}00055\ \ \ \ \ fit\_intercept\ =\ n\_features\ +\ 2\ ==\ w.shape[0]}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00056}00056\ \ \ \ \ \textcolor{keywordflow}{if}\ fit\_intercept:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00057}00057\ \ \ \ \ \ \ \ \ intercept\ =\ w[-\/2]}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00058}00058\ \ \ \ \ sigma\ =\ w[-\/1]}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00059}00059\ \ \ \ \ w\ =\ w[:n\_features]}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00060}00060\ \ \ \ \ n\_samples\ =\ np.sum(sample\_weight)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00061}00061\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00062}00062\ \ \ \ \ \textcolor{comment}{\#\ Calculate\ the\ values\ where\ |y\ -\/\ X'w\ -\/c\ /\ sigma|\ >\ epsilon}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00063}00063\ \ \ \ \ \textcolor{comment}{\#\ The\ values\ above\ this\ threshold\ are\ outliers.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00064}00064\ \ \ \ \ linear\_loss\ =\ y\ -\/\ safe\_sparse\_dot(X,\ w)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00065}00065\ \ \ \ \ \textcolor{keywordflow}{if}\ fit\_intercept:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00066}00066\ \ \ \ \ \ \ \ \ linear\_loss\ -\/=\ intercept}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00067}00067\ \ \ \ \ abs\_linear\_loss\ =\ np.abs(linear\_loss)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00068}00068\ \ \ \ \ outliers\_mask\ =\ abs\_linear\_loss\ >\ epsilon\ *\ sigma}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00069}00069\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00070}00070\ \ \ \ \ \textcolor{comment}{\#\ Calculate\ the\ linear\ loss\ due\ to\ the\ outliers.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00071}00071\ \ \ \ \ \textcolor{comment}{\#\ This\ is\ equal\ to\ (2\ *\ M\ *\ |y\ -\/\ X'w\ -\/c\ /\ sigma|\ -\/\ M**2)\ *\ sigma}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00072}00072\ \ \ \ \ outliers\ =\ abs\_linear\_loss[outliers\_mask]}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00073}00073\ \ \ \ \ num\_outliers\ =\ np.count\_nonzero(outliers\_mask)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00074}00074\ \ \ \ \ n\_non\_outliers\ =\ X.shape[0]\ -\/\ num\_outliers}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00075}00075\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00076}00076\ \ \ \ \ \textcolor{comment}{\#\ n\_sq\_outliers\ includes\ the\ weight\ give\ to\ the\ outliers\ while}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00077}00077\ \ \ \ \ \textcolor{comment}{\#\ num\_outliers\ is\ just\ the\ number\ of\ outliers.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00078}00078\ \ \ \ \ outliers\_sw\ =\ sample\_weight[outliers\_mask]}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00079}00079\ \ \ \ \ n\_sw\_outliers\ =\ np.sum(outliers\_sw)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00080}00080\ \ \ \ \ outlier\_loss\ =\ (}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00081}00081\ \ \ \ \ \ \ \ \ 2.0\ *\ epsilon\ *\ np.sum(outliers\_sw\ *\ outliers)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00082}00082\ \ \ \ \ \ \ \ \ -\/\ sigma\ *\ n\_sw\_outliers\ *\ epsilon**2}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00083}00083\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00084}00084\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00085}00085\ \ \ \ \ \textcolor{comment}{\#\ Calculate\ the\ quadratic\ loss\ due\ to\ the\ non-\/outliers.-\/}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00086}00086\ \ \ \ \ \textcolor{comment}{\#\ This\ is\ equal\ to\ |(y\ -\/\ X'w\ -\/\ c)**2\ /\ sigma**2|\ *\ sigma}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00087}00087\ \ \ \ \ non\_outliers\ =\ linear\_loss[\string~outliers\_mask]}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00088}00088\ \ \ \ \ weighted\_non\_outliers\ =\ sample\_weight[\string~outliers\_mask]\ *\ non\_outliers}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00089}00089\ \ \ \ \ weighted\_loss\ =\ np.dot(weighted\_non\_outliers.T,\ non\_outliers)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00090}00090\ \ \ \ \ squared\_loss\ =\ weighted\_loss\ /\ sigma}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00091}00091\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00092}00092\ \ \ \ \ \textcolor{keywordflow}{if}\ fit\_intercept:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00093}00093\ \ \ \ \ \ \ \ \ grad\ =\ np.zeros(n\_features\ +\ 2)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00094}00094\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00095}00095\ \ \ \ \ \ \ \ \ grad\ =\ np.zeros(n\_features\ +\ 1)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00096}00096\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00097}00097\ \ \ \ \ \textcolor{comment}{\#\ Gradient\ due\ to\ the\ squared\ loss.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00098}00098\ \ \ \ \ X\_non\_outliers\ =\ -\/axis0\_safe\_slice(X,\ \string~outliers\_mask,\ n\_non\_outliers)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00099}00099\ \ \ \ \ grad[:n\_features]\ =\ (}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00100}00100\ \ \ \ \ \ \ \ \ 2.0\ /\ sigma\ *\ safe\_sparse\_dot(weighted\_non\_outliers,\ X\_non\_outliers)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00101}00101\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00102}00102\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00103}00103\ \ \ \ \ \textcolor{comment}{\#\ Gradient\ due\ to\ the\ linear\ loss.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00104}00104\ \ \ \ \ signed\_outliers\ =\ np.ones\_like(outliers)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00105}00105\ \ \ \ \ signed\_outliers\_mask\ =\ linear\_loss[outliers\_mask]\ <\ 0}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00106}00106\ \ \ \ \ signed\_outliers[signed\_outliers\_mask]\ =\ -\/1.0}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00107}00107\ \ \ \ \ X\_outliers\ =\ axis0\_safe\_slice(X,\ outliers\_mask,\ num\_outliers)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00108}00108\ \ \ \ \ sw\_outliers\ =\ sample\_weight[outliers\_mask]\ *\ signed\_outliers}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00109}00109\ \ \ \ \ grad[:n\_features]\ -\/=\ 2.0\ *\ epsilon\ *\ (safe\_sparse\_dot(sw\_outliers,\ X\_outliers))}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00110}00110\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00111}00111\ \ \ \ \ \textcolor{comment}{\#\ Gradient\ due\ to\ the\ penalty.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00112}00112\ \ \ \ \ grad[:n\_features]\ +=\ alpha\ *\ 2.0\ *\ w}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00113}00113\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00114}00114\ \ \ \ \ \textcolor{comment}{\#\ Gradient\ due\ to\ sigma.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00115}00115\ \ \ \ \ grad[-\/1]\ =\ n\_samples}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00116}00116\ \ \ \ \ grad[-\/1]\ -\/=\ n\_sw\_outliers\ *\ epsilon**2}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00117}00117\ \ \ \ \ grad[-\/1]\ -\/=\ squared\_loss\ /\ sigma}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00118}00118\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00119}00119\ \ \ \ \ \textcolor{comment}{\#\ Gradient\ due\ to\ the\ intercept.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00120}00120\ \ \ \ \ \textcolor{keywordflow}{if}\ fit\_intercept:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00121}00121\ \ \ \ \ \ \ \ \ grad[-\/2]\ =\ -\/2.0\ *\ np.sum(weighted\_non\_outliers)\ /\ sigma}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00122}00122\ \ \ \ \ \ \ \ \ grad[-\/2]\ -\/=\ 2.0\ *\ epsilon\ *\ np.sum(sw\_outliers)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00123}00123\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00124}00124\ \ \ \ \ loss\ =\ n\_samples\ *\ sigma\ +\ squared\_loss\ +\ outlier\_loss}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00125}00125\ \ \ \ \ loss\ +=\ alpha\ *\ np.dot(w,\ w)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00126}00126\ \ \ \ \ \textcolor{keywordflow}{return}\ loss,\ grad}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00127}00127\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00128}00128\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00129}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor}{00129}}\ \textcolor{keyword}{class\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor}{HuberRegressor}}(\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__base_1_1LinearModel}{LinearModel}},\ \mbox{\hyperlink{classsklearn_1_1base_1_1RegressorMixin}{RegressorMixin}},\ \mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator}{BaseEstimator}}):}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00130}00130\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}L2-\/regularized\ linear\ regression\ model\ that\ is\ robust\ to\ outliers.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00131}00131\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00132}00132\ \textcolor{stringliteral}{\ \ \ \ The\ Huber\ Regressor\ optimizes\ the\ squared\ loss\ for\ the\ samples\ where}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00133}00133\ \textcolor{stringliteral}{\ \ \ \ \`{}\`{}|(y\ -\/\ Xw\ -\/\ c)\ /\ sigma|\ <\ epsilon\`{}\`{}\ and\ the\ absolute\ loss\ for\ the\ samples}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00134}00134\ \textcolor{stringliteral}{\ \ \ \ where\ \`{}\`{}|(y\ -\/\ Xw\ -\/\ c)\ /\ sigma|\ >\ epsilon\`{}\`{},\ where\ the\ model\ coefficients}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00135}00135\ \textcolor{stringliteral}{\ \ \ \ \`{}\`{}w\`{}\`{},\ the\ intercept\ \`{}\`{}c\`{}\`{}\ and\ the\ scale\ \`{}\`{}sigma\`{}\`{}\ are\ parameters}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00136}00136\ \textcolor{stringliteral}{\ \ \ \ to\ be\ optimized.\ The\ parameter\ \`{}sigma\`{}\ makes\ sure\ that\ if\ \`{}y\`{}\ is\ scaled\ up}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00137}00137\ \textcolor{stringliteral}{\ \ \ \ or\ down\ by\ a\ certain\ factor,\ one\ does\ not\ need\ to\ rescale\ \`{}epsilon\`{}\ to}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00138}00138\ \textcolor{stringliteral}{\ \ \ \ achieve\ the\ same\ robustness.\ Note\ that\ this\ does\ not\ take\ into\ account}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00139}00139\ \textcolor{stringliteral}{\ \ \ \ the\ fact\ that\ the\ different\ features\ of\ \`{}X\`{}\ may\ be\ of\ different\ scales.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00140}00140\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00141}00141\ \textcolor{stringliteral}{\ \ \ \ The\ Huber\ loss\ function\ has\ the\ advantage\ of\ not\ being\ heavily\ influenced}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00142}00142\ \textcolor{stringliteral}{\ \ \ \ by\ the\ outliers\ while\ not\ completely\ ignoring\ their\ effect.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00143}00143\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00144}00144\ \textcolor{stringliteral}{\ \ \ \ Read\ more\ in\ the\ :ref:\`{}User\ Guide\ <huber\_regression>\`{}}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00145}00145\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00146}00146\ \textcolor{stringliteral}{\ \ \ \ ..\ versionadded::\ 0.18}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00147}00147\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00148}00148\ \textcolor{stringliteral}{\ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00149}00149\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00150}00150\ \textcolor{stringliteral}{\ \ \ \ epsilon\ :\ float,\ default=1.35}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00151}00151\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ parameter\ epsilon\ controls\ the\ number\ of\ samples\ that\ should\ be}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00152}00152\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ classified\ as\ outliers.\ The\ smaller\ the\ epsilon,\ the\ more\ robust\ it\ is}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00153}00153\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ to\ outliers.\ Epsilon\ must\ be\ in\ the\ range\ \`{}[1,\ inf)\`{}.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00154}00154\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00155}00155\ \textcolor{stringliteral}{\ \ \ \ max\_iter\ :\ int,\ default=100}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00156}00156\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Maximum\ number\ of\ iterations\ that}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00157}00157\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \`{}\`{}scipy.optimize.minimize(method="{}L-\/BFGS-\/B"{})\`{}\`{}\ should\ run\ for.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00158}00158\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00159}00159\ \textcolor{stringliteral}{\ \ \ \ alpha\ :\ float,\ default=0.0001}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00160}00160\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Strength\ of\ the\ squared\ L2\ regularization.\ Note\ that\ the\ penalty\ is}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00161}00161\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ equal\ to\ \`{}\`{}alpha\ *\ ||w||\string^2\`{}\`{}.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00162}00162\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Must\ be\ in\ the\ range\ \`{}[0,\ inf)\`{}.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00163}00163\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00164}00164\ \textcolor{stringliteral}{\ \ \ \ warm\_start\ :\ bool,\ default=False}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00165}00165\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ This\ is\ useful\ if\ the\ stored\ attributes\ of\ a\ previously\ used\ model}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00166}00166\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ has\ to\ be\ reused.\ If\ set\ to\ False,\ then\ the\ coefficients\ will}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00167}00167\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ be\ rewritten\ for\ every\ call\ to\ fit.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00168}00168\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ See\ :term:\`{}the\ Glossary\ <warm\_start>\`{}.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00169}00169\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00170}00170\ \textcolor{stringliteral}{\ \ \ \ fit\_intercept\ :\ bool,\ default=True}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00171}00171\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Whether\ or\ not\ to\ fit\ the\ intercept.\ This\ can\ be\ set\ to\ False}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00172}00172\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ if\ the\ data\ is\ already\ centered\ around\ the\ origin.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00173}00173\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00174}00174\ \textcolor{stringliteral}{\ \ \ \ tol\ :\ float,\ default=1e-\/05}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00175}00175\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ iteration\ will\ stop\ when}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00176}00176\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \`{}\`{}max\{|proj\ g\_i\ |\ i\ =\ 1,\ ...,\ n\}\`{}\`{}\ <=\ \`{}\`{}tol\`{}\`{}}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00177}00177\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ where\ pg\_i\ is\ the\ i-\/th\ component\ of\ the\ projected\ gradient.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00178}00178\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00179}00179\ \textcolor{stringliteral}{\ \ \ \ Attributes}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00180}00180\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00181}00181\ \textcolor{stringliteral}{\ \ \ \ coef\_\ :\ array,\ shape\ (n\_features,)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00182}00182\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Features\ got\ by\ optimizing\ the\ L2-\/regularized\ Huber\ loss.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00183}00183\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00184}00184\ \textcolor{stringliteral}{\ \ \ \ intercept\_\ :\ float}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00185}00185\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Bias.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00186}00186\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00187}00187\ \textcolor{stringliteral}{\ \ \ \ scale\_\ :\ float}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00188}00188\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ The\ value\ by\ which\ \`{}\`{}|y\ -\/\ Xw\ -\/\ c|\`{}\`{}\ is\ scaled\ down.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00189}00189\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00190}00190\ \textcolor{stringliteral}{\ \ \ \ n\_features\_in\_\ :\ int}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00191}00191\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Number\ of\ features\ seen\ during\ :term:\`{}fit\`{}.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00192}00192\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00193}00193\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 0.24}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00194}00194\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00195}00195\ \textcolor{stringliteral}{\ \ \ \ feature\_names\_in\_\ :\ ndarray\ of\ shape\ (\`{}n\_features\_in\_\`{},)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00196}00196\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Names\ of\ features\ seen\ during\ :term:\`{}fit\`{}.\ Defined\ only\ when\ \`{}X\`{}}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00197}00197\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ has\ feature\ names\ that\ are\ all\ strings.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00198}00198\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00199}00199\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionadded::\ 1.0}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00200}00200\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00201}00201\ \textcolor{stringliteral}{\ \ \ \ n\_iter\_\ :\ int}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00202}00202\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Number\ of\ iterations\ that}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00203}00203\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \`{}\`{}scipy.optimize.minimize(method="{}L-\/BFGS-\/B"{})\`{}\`{}\ has\ run\ for.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00204}00204\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00205}00205\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ ..\ versionchanged::\ 0.20}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00206}00206\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00207}00207\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ In\ SciPy\ <=\ 1.0.0\ the\ number\ of\ lbfgs\ iterations\ may\ exceed}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00208}00208\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ \`{}\`{}max\_iter\`{}\`{}.\ \`{}\`{}n\_iter\_\`{}\`{}\ will\ now\ report\ at\ most\ \`{}\`{}max\_iter\`{}\`{}.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00209}00209\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00210}00210\ \textcolor{stringliteral}{\ \ \ \ outliers\_\ :\ array,\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00211}00211\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ A\ boolean\ mask\ which\ is\ set\ to\ True\ where\ the\ samples\ are\ identified}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00212}00212\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ as\ outliers.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00213}00213\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00214}00214\ \textcolor{stringliteral}{\ \ \ \ See\ Also}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00215}00215\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00216}00216\ \textcolor{stringliteral}{\ \ \ \ RANSACRegressor\ :\ RANSAC\ (RANdom\ SAmple\ Consensus)\ algorithm.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00217}00217\ \textcolor{stringliteral}{\ \ \ \ TheilSenRegressor\ :\ Theil-\/Sen\ Estimator\ robust\ multivariate\ regression\ model.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00218}00218\ \textcolor{stringliteral}{\ \ \ \ SGDRegressor\ :\ Fitted\ by\ minimizing\ a\ regularized\ empirical\ loss\ with\ SGD.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00219}00219\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00220}00220\ \textcolor{stringliteral}{\ \ \ \ References}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00221}00221\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00222}00222\ \textcolor{stringliteral}{\ \ \ \ ..\ [1]\ Peter\ J.\ Huber,\ Elvezio\ M.\ Ronchetti,\ Robust\ Statistics}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00223}00223\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ Concomitant\ scale\ estimates,\ p.\ 172}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00224}00224\ \textcolor{stringliteral}{\ \ \ \ ..\ [2]\ Art\ B.\ Owen\ (2006),\ \`{}A\ robust\ hybrid\ of\ lasso\ and\ ridge\ regression.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00225}00225\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ <https://artowen.su.domains/reports/hhu.pdf>\`{}\_}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00226}00226\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00227}00227\ \textcolor{stringliteral}{\ \ \ \ Examples}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00228}00228\ \textcolor{stringliteral}{\ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00229}00229\ \textcolor{stringliteral}{\ \ \ \ >>>\ import\ numpy\ as\ np}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00230}00230\ \textcolor{stringliteral}{\ \ \ \ >>>\ from\ sklearn.linear\_model\ import\ HuberRegressor,\ LinearRegression}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00231}00231\ \textcolor{stringliteral}{\ \ \ \ >>>\ from\ sklearn.datasets\ import\ make\_regression}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00232}00232\ \textcolor{stringliteral}{\ \ \ \ >>>\ rng\ =\ np.random.RandomState(0)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00233}00233\ \textcolor{stringliteral}{\ \ \ \ >>>\ X,\ y,\ coef\ =\ make\_regression(}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00234}00234\ \textcolor{stringliteral}{\ \ \ \ ...\ \ \ \ \ n\_samples=200,\ n\_features=2,\ noise=4.0,\ coef=True,\ random\_state=0)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00235}00235\ \textcolor{stringliteral}{\ \ \ \ >>>\ X[:4]\ =\ rng.uniform(10,\ 20,\ (4,\ 2))}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00236}00236\ \textcolor{stringliteral}{\ \ \ \ >>>\ y[:4]\ =\ rng.uniform(10,\ 20,\ 4)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00237}00237\ \textcolor{stringliteral}{\ \ \ \ >>>\ huber\ =\ HuberRegressor().fit(X,\ y)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00238}00238\ \textcolor{stringliteral}{\ \ \ \ >>>\ huber.score(X,\ y)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00239}00239\ \textcolor{stringliteral}{\ \ \ \ -\/7.284}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00240}00240\ \textcolor{stringliteral}{\ \ \ \ >>>\ huber.predict(X[:1,])}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00241}00241\ \textcolor{stringliteral}{\ \ \ \ array([806.7200])}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00242}00242\ \textcolor{stringliteral}{\ \ \ \ >>>\ linear\ =\ LinearRegression().fit(X,\ y)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00243}00243\ \textcolor{stringliteral}{\ \ \ \ >>>\ print("{}True\ coefficients:"{},\ coef)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00244}00244\ \textcolor{stringliteral}{\ \ \ \ True\ coefficients:\ [20.4923...\ \ 34.1698...]}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00245}00245\ \textcolor{stringliteral}{\ \ \ \ >>>\ print("{}Huber\ coefficients:"{},\ huber.coef\_)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00246}00246\ \textcolor{stringliteral}{\ \ \ \ Huber\ coefficients:\ [17.7906...\ 31.0106...]}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00247}00247\ \textcolor{stringliteral}{\ \ \ \ >>>\ print("{}Linear\ Regression\ coefficients:"{},\ linear.coef\_)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00248}00248\ \textcolor{stringliteral}{\ \ \ \ Linear\ Regression\ coefficients:\ [-\/1.9221...\ \ 7.0226...]}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00249}00249\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00250}00250\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00251}00251\ \ \ \ \ \_parameter\_constraints:\ dict\ =\ \{}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00252}00252\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}epsilon"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Real,\ 1.0,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}})],}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00253}00253\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_iter"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Integral,\ 0,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}})],}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00254}00254\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}alpha"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Real,\ 0,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}})],}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00255}00255\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}warm\_start"{}}:\ [\textcolor{stringliteral}{"{}boolean"{}}],}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00256}00256\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}fit\_intercept"{}}:\ [\textcolor{stringliteral}{"{}boolean"{}}],}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00257}00257\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}tol"{}}:\ [\mbox{\hyperlink{classsklearn_1_1utils_1_1__param__validation_1_1Interval}{Interval}}(Real,\ 0.0,\ \textcolor{keywordtype}{None},\ closed=\textcolor{stringliteral}{"{}left"{}})],}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00258}00258\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00259}00259\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00260}00260\ \ \ \ \ \textcolor{keyword}{def\ }\_\_init\_\_(}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00261}00261\ \ \ \ \ \ \ \ \ self,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00262}00262\ \ \ \ \ \ \ \ \ *,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00263}00263\ \ \ \ \ \ \ \ \ epsilon=1.35,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00264}00264\ \ \ \ \ \ \ \ \ max\_iter=100,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00265}00265\ \ \ \ \ \ \ \ \ alpha=0.0001,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00266}00266\ \ \ \ \ \ \ \ \ warm\_start=False,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00267}00267\ \ \ \ \ \ \ \ \ fit\_intercept=True,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00268}00268\ \ \ \ \ \ \ \ \ tol=1e-\/05,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00269}00269\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00270}00270\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_ac1171caaad6c21dfbe03ac515b096b58}{epsilon}}\ =\ epsilon}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00271}00271\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a7eb559be3b326c0d47d65806f9b37ea6}{max\_iter}}\ =\ max\_iter}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00272}00272\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a6b83fa3ea5965e20bfcf4402c057df98}{alpha}}\ =\ alpha}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00273}00273\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a029643a4457178cfae982a305c00a853}{warm\_start}}\ =\ warm\_start}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00274}00274\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__base_1_1LinearModel_af4afe40bc0c024c58cf3e154f1a5adcd}{fit\_intercept}}\ =\ fit\_intercept}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00275}00275\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a519ab492a31a37edba2876df7a237e1e}{tol}}\ =\ tol}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00276}00276\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00277}00277\ \ \ \ \ \textcolor{preprocessor}{@\_fit\_context(prefer\_skip\_nested\_validation=True)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00278}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_af7e6bc1b81eabe345e543a4991b19ac4}{00278}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_af7e6bc1b81eabe345e543a4991b19ac4}{fit}}(self,\ X,\ y,\ sample\_weight=None):}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00279}00279\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Fit\ the\ model\ according\ to\ the\ given\ training\ data.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00280}00280\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00281}00281\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Parameters}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00282}00282\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00283}00283\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ X\ :\ array-\/like,\ shape\ (n\_samples,\ n\_features)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00284}00284\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Training\ vector,\ where\ \`{}n\_samples\`{}\ is\ the\ number\ of\ samples\ and}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00285}00285\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ \`{}n\_features\`{}\ is\ the\ number\ of\ features.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00286}00286\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00287}00287\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ y\ :\ array-\/like,\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00288}00288\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Target\ vector\ relative\ to\ X.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00289}00289\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00290}00290\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ sample\_weight\ :\ array-\/like,\ shape\ (n\_samples,)}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00291}00291\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Weight\ given\ to\ each\ sample.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00292}00292\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00293}00293\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ Returns}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00294}00294\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ -\/-\/-\/-\/-\/-\/-\/}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00295}00295\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ self\ :\ object}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00296}00296\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ \ \ \ \ Fitted\ \`{}HuberRegressor\`{}\ estimator.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00297}00297\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00298}00298\ \ \ \ \ \ \ \ \ X,\ y\ =\ validate\_data(}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00299}00299\ \ \ \ \ \ \ \ \ \ \ \ \ self,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00300}00300\ \ \ \ \ \ \ \ \ \ \ \ \ X,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00301}00301\ \ \ \ \ \ \ \ \ \ \ \ \ y,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00302}00302\ \ \ \ \ \ \ \ \ \ \ \ \ copy=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00303}00303\ \ \ \ \ \ \ \ \ \ \ \ \ accept\_sparse=[\textcolor{stringliteral}{"{}csr"{}}],}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00304}00304\ \ \ \ \ \ \ \ \ \ \ \ \ y\_numeric=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00305}00305\ \ \ \ \ \ \ \ \ \ \ \ \ dtype=[np.float64,\ np.float32],}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00306}00306\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00307}00307\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00308}00308\ \ \ \ \ \ \ \ \ sample\_weight\ =\ \_check\_sample\_weight(sample\_weight,\ X)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00309}00309\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00310}00310\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a029643a4457178cfae982a305c00a853}{warm\_start}}\ \textcolor{keywordflow}{and}\ hasattr(self,\ \textcolor{stringliteral}{"{}coef\_"{}}):}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00311}00311\ \ \ \ \ \ \ \ \ \ \ \ \ parameters\ =\ np.concatenate((self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a9ec11fc3d7f8b10b84f5c1378ad0b33e}{coef\_}},\ [self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__base_1_1LinearModel_a1732d338f817d6ee68996974a715077e}{intercept\_}},\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a8dc6abe9fdc4c03a0f81682e4a3b6d7d}{scale\_}}]))}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00312}00312\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00313}00313\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__base_1_1LinearModel_af4afe40bc0c024c58cf3e154f1a5adcd}{fit\_intercept}}:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00314}00314\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ parameters\ =\ np.zeros(X.shape[1]\ +\ 2)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00315}00315\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00316}00316\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ parameters\ =\ np.zeros(X.shape[1]\ +\ 1)}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00317}00317\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ to\ initialize\ the\ scale\ parameter\ to\ a\ strictly}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00318}00318\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ positive\ value:}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00319}00319\ \ \ \ \ \ \ \ \ \ \ \ \ parameters[-\/1]\ =\ 1}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00320}00320\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00321}00321\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Sigma\ or\ the\ scale\ factor\ should\ be\ non-\/negative.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00322}00322\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Setting\ it\ to\ be\ zero\ might\ cause\ undefined\ bounds\ hence\ we\ set\ it}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00323}00323\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ to\ a\ value\ close\ to\ zero.}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00324}00324\ \ \ \ \ \ \ \ \ bounds\ =\ np.tile([-\/np.inf,\ np.inf],\ (parameters.shape[0],\ 1))}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00325}00325\ \ \ \ \ \ \ \ \ bounds[-\/1][0]\ =\ np.finfo(np.float64).eps\ *\ 10}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00326}00326\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00327}00327\ \ \ \ \ \ \ \ \ opt\_res\ =\ optimize.minimize(}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00328}00328\ \ \ \ \ \ \ \ \ \ \ \ \ \_huber\_loss\_and\_gradient,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00329}00329\ \ \ \ \ \ \ \ \ \ \ \ \ parameters,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00330}00330\ \ \ \ \ \ \ \ \ \ \ \ \ method=\textcolor{stringliteral}{"{}L-\/BFGS-\/B"{}},}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00331}00331\ \ \ \ \ \ \ \ \ \ \ \ \ jac=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00332}00332\ \ \ \ \ \ \ \ \ \ \ \ \ args=(X,\ y,\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_ac1171caaad6c21dfbe03ac515b096b58}{epsilon}},\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a6b83fa3ea5965e20bfcf4402c057df98}{alpha}},\ sample\_weight),}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00333}00333\ \ \ \ \ \ \ \ \ \ \ \ \ options=\{}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00334}00334\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}maxiter"{}}:\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a7eb559be3b326c0d47d65806f9b37ea6}{max\_iter}},}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00335}00335\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}gtol"{}}:\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a519ab492a31a37edba2876df7a237e1e}{tol}},}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00336}00336\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ **\_get\_additional\_lbfgs\_options\_dict(\textcolor{stringliteral}{"{}iprint"{}},\ -\/1),}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00337}00337\ \ \ \ \ \ \ \ \ \ \ \ \ \},}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00338}00338\ \ \ \ \ \ \ \ \ \ \ \ \ bounds=bounds,}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00339}00339\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00340}00340\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00341}00341\ \ \ \ \ \ \ \ \ parameters\ =\ opt\_res.x}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00342}00342\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00343}00343\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ opt\_res.status\ ==\ 2:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00344}00344\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ \mbox{\hyperlink{classValueError}{ValueError}}(}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00345}00345\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}HuberRegressor\ convergence\ failed:\ l-\/BFGS-\/b\ solver\ terminated\ with\ \%s"{}}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00346}00346\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \%\ opt\_res.message}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00347}00347\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00348}00348\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a914666b2a3e696d4b85b3b971a6212b9}{n\_iter\_}}\ =\ \_check\_optimize\_result(\textcolor{stringliteral}{"{}lbfgs"{}},\ opt\_res,\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a7eb559be3b326c0d47d65806f9b37ea6}{max\_iter}})}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00349}00349\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a8dc6abe9fdc4c03a0f81682e4a3b6d7d}{scale\_}}\ =\ parameters[-\/1]}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00350}00350\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__base_1_1LinearModel_af4afe40bc0c024c58cf3e154f1a5adcd}{fit\_intercept}}:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00351}00351\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__base_1_1LinearModel_a1732d338f817d6ee68996974a715077e}{intercept\_}}\ =\ parameters[-\/2]}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00352}00352\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00353}00353\ \ \ \ \ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__base_1_1LinearModel_a1732d338f817d6ee68996974a715077e}{intercept\_}}\ =\ 0.0}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00354}00354\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a9ec11fc3d7f8b10b84f5c1378ad0b33e}{coef\_}}\ =\ parameters[:\ X.shape[1]]}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00355}00355\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00356}00356\ \ \ \ \ \ \ \ \ residual\ =\ np.abs(y\ -\/\ safe\_sparse\_dot(X,\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a9ec11fc3d7f8b10b84f5c1378ad0b33e}{coef\_}})\ -\/\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__base_1_1LinearModel_a1732d338f817d6ee68996974a715077e}{intercept\_}})}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00357}00357\ \ \ \ \ \ \ \ \ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a46639d92dfc0e03cb337dee0bb7dab31}{outliers\_}}\ =\ residual\ >\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_a8dc6abe9fdc4c03a0f81682e4a3b6d7d}{scale\_}}\ *\ self.\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__huber_1_1HuberRegressor_ac1171caaad6c21dfbe03ac515b096b58}{epsilon}}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00358}00358\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00359}00359\ }
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00360}00360\ \ \ \ \ \textcolor{keyword}{def\ }\_\_sklearn\_tags\_\_(self):}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00361}00361\ \ \ \ \ \ \ \ \ tags\ =\ super().\_\_sklearn\_tags\_\_()}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00362}00362\ \ \ \ \ \ \ \ \ tags.input\_tags.sparse\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{__huber_8py_source_l00363}00363\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ tags}

\end{DoxyCode}
