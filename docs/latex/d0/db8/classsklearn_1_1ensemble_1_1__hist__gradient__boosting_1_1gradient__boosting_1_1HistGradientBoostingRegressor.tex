\doxysection{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Hist\+Gradient\+Boosting\+Regressor Class Reference}
\hypertarget{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{}\label{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}\index{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}}


Inheritance diagram for sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Hist\+Gradient\+Boosting\+Regressor\+:
% FIG 0


Collaboration diagram for sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Hist\+Gradient\+Boosting\+Regressor\+:
% FIG 1
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a63c7f417756134796ae6b5c92cb4a6e0}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, loss="{}squared\+\_\+error"{}, \texorpdfstring{$\ast$}{*}, quantile=None, learning\+\_\+rate=0.\+1, max\+\_\+iter=100, max\+\_\+leaf\+\_\+nodes=31, max\+\_\+depth=None, min\+\_\+samples\+\_\+leaf=20, l2\+\_\+regularization=0.\+0, max\+\_\+features=1.\+0, max\+\_\+bins=255, categorical\+\_\+features="{}from\+\_\+dtype"{}, monotonic\+\_\+cst=None, interaction\+\_\+cst=None, warm\+\_\+start=False, early\+\_\+stopping="{}auto"{}, scoring="{}loss"{}, validation\+\_\+fraction=0.\+1, n\+\_\+iter\+\_\+no\+\_\+change=10, tol=1e-\/7, verbose=0, random\+\_\+state=None)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_af18d3dbc777369d5e7d113f623bc8d03}{predict}} (self, X)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_ae5dcddcfcbc57ebd809a3119405dde94}{staged\+\_\+predict}} (self, X)
\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1base_1_1RegressorMixin}{sklearn.\+base.\+Regressor\+Mixin}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1RegressorMixin_ae29a40b01c8029a8cfb329b0a61dd142}{\+\_\+\+\_\+sklearn\+\_\+tags\+\_\+\+\_\+}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1RegressorMixin_adce4557f75f598bbc92379cd10c43a7d}{score}} (self, X, y, sample\+\_\+weight=None)
\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abe1e5042ac95c5550189b7906ac29617}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, loss, \texorpdfstring{$\ast$}{*}, learning\+\_\+rate, max\+\_\+iter, max\+\_\+leaf\+\_\+nodes, max\+\_\+depth, min\+\_\+samples\+\_\+leaf, l2\+\_\+regularization, max\+\_\+features, max\+\_\+bins, categorical\+\_\+features, monotonic\+\_\+cst, interaction\+\_\+cst, warm\+\_\+start, early\+\_\+stopping, scoring, validation\+\_\+fraction, n\+\_\+iter\+\_\+no\+\_\+change, tol, verbose, random\+\_\+state)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aba1c789013d8236ed9a2c14764603920}{fit}} (self, X, y, sample\+\_\+weight=None, \texorpdfstring{$\ast$}{*}, X\+\_\+val=None, y\+\_\+val=None, sample\+\_\+weight\+\_\+val=None)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a99ea80c5d025b5fdbb88e00dde88f1f0}{\+\_\+\+\_\+sklearn\+\_\+tags\+\_\+\+\_\+}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a712d3651c535805770fe09a201eca9fb}{n\+\_\+iter\+\_\+}} (self)
\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator}{sklearn.\+base.\+Base\+Estimator}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_a5c3e0c802dfacfbaceafb925c411b211}{get\+\_\+params}} (self, deep=\mbox{\hyperlink{classTrue}{True}})
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_af8177e7086e8cbed1fec2bcdae9202c1}{set\+\_\+params}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}params)
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_a64ca38f0e53f358e93f77258e5b593e2}{\+\_\+\+\_\+sklearn\+\_\+clone\+\_\+\+\_\+}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_ad5da47f044a7f6bc188b93722cad7a4c}{\+\_\+\+\_\+repr\+\_\+\+\_\+}} (self, N\+\_\+\+CHAR\+\_\+\+MAX=700)
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_a1f3d56fd989ef4230f70670d6128549e}{\+\_\+\+\_\+getstate\+\_\+\+\_\+}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_a4e30cf35986d0ed01728b435e83bd427}{\+\_\+\+\_\+setstate\+\_\+\+\_\+}} (self, state)
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_a2605517d96ef2f8dd3defe5577308980}{\+\_\+\+\_\+sklearn\+\_\+tags\+\_\+\+\_\+}} (self)
\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester}{sklearn.\+utils.\+\_\+metadata\+\_\+requests.\+\_\+\+Metadata\+Requester}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_ab48a52b9c986ac3af7911258b42b837f}{set\+\_\+fit\+\_\+request}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_ac10696f69266f6da921b6fd002fc2517}{set\+\_\+partial\+\_\+fit\+\_\+request}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_a123374f10967f5cfe493865b2f09981a}{set\+\_\+predict\+\_\+request}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_ade67738aee2fad236732cada081d6dd8}{set\+\_\+predict\+\_\+proba\+\_\+request}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_aaef1e9253988e03aca9832380e54b12b}{set\+\_\+predict\+\_\+log\+\_\+proba\+\_\+request}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_adb770fcea1b60f29850b1f15de2c88eb}{set\+\_\+decision\+\_\+function\+\_\+request}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_a73c0acefc399f1fcc80da0a35b00b47c}{set\+\_\+score\+\_\+request}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_ad077fd9e21ee8b8455bd1dd0c4d77f53}{set\+\_\+split\+\_\+request}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_a40bb65c21fc1d38ead64b14b6ae2e6c5}{set\+\_\+transform\+\_\+request}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_a9824f6478a2a4f04c22fe245eb3f5002}{set\+\_\+inverse\+\_\+transform\+\_\+request}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_a04d90136cfcfe6cabcda6428978d3ae1}{\+\_\+\+\_\+init\+\_\+subclass\+\_\+\+\_\+}} (cls, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_af8f4bba2743f3b0b4422e588f8427d72}{get\+\_\+metadata\+\_\+routing}} (self)
\end{DoxyCompactItemize}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a895ff08edb9ba52ddecd9e40e932f93a}{quantile}} = quantile
\end{DoxyCompactItemize}
\doxysubsection*{Public Attributes inherited from \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1f71d4fd84cefb07d3a4187160d3bf9b}{loss}} = loss
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a65f2e8d6111cc97abb7202708a046962}{learning\+\_\+rate}} = learning\+\_\+rate
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8c4630fd50d86dfd270c7b0afbd636fb}{max\+\_\+iter}} = max\+\_\+iter
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a691ad0349a8339079183cefbae38e1d0}{max\+\_\+leaf\+\_\+nodes}} = max\+\_\+leaf\+\_\+nodes
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abef4a3ea1fbc76cd3d15dceaa39fe0de}{max\+\_\+depth}} = max\+\_\+depth
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab5cbe9de4a5232f8130abbcd2c433605}{min\+\_\+samples\+\_\+leaf}} = min\+\_\+samples\+\_\+leaf
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ac342bd1bcea4f67b50a928cd1e75a915}{l2\+\_\+regularization}} = l2\+\_\+regularization
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa533d0a8ec3767c97c888844491558c2}{max\+\_\+features}} = max\+\_\+features
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a04540760d13c6f706f3fa44a2141f375}{max\+\_\+bins}} = max\+\_\+bins
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad5f1696e1fd74498621f3a2e13cef6f6}{monotonic\+\_\+cst}} = monotonic\+\_\+cst
\item 
str \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a0ce6a6d7576db5ab409ae2f8f1d6b7b7}{interaction\+\_\+cst}} = interaction\+\_\+cst
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_afc1328f9cf64db2c2a6adfa861b83061}{categorical\+\_\+features}} = categorical\+\_\+features
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a396309db1f0dbf7fda8fcafeaa229df3}{warm\+\_\+start}} = warm\+\_\+start
\item 
str \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a7c1bb95883298c852627543f531c89bf}{early\+\_\+stopping}} = early\+\_\+stopping
\item 
str \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a77783dab5cef4f645a5d0ff93e4deb11}{scoring}} = scoring
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa7961cd8f3763607f578eceac4515b18}{validation\+\_\+fraction}} = validation\+\_\+fraction
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a59c410ffee3831ed0c00add4d3a0c6e6}{n\+\_\+iter\+\_\+no\+\_\+change}} = n\+\_\+iter\+\_\+no\+\_\+change
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6fe4dfcee2bff69d971f26f7b0398d93}{tol}} = tol
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a39a3969984cde73a5dc0879387502020}{verbose}} = verbose
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a82a4dbec8808de99c79d689c08e15af0}{random\+\_\+state}} = random\+\_\+state
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4c7b7421627b7fdb5197779d589fabc0}{is\+\_\+categorical\+\_\+}} = self.\+\_\+check\+\_\+categorical\+\_\+features(X)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad5e24fe1ddcb337a0a56660f3c61ba2d}{n\+\_\+features\+\_\+in\+\_\+}} = self.\+\_\+preprocessor.\+n\+\_\+features\+\_\+in\+\_\+
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6d72f6367d82bbff8ce2b056ae5c75ff}{feature\+\_\+names\+\_\+in\+\_\+}} = self.\+\_\+preprocessor.\+feature\+\_\+names\+\_\+in\+\_\+
\item 
int \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa98b01cc7ca7beefda4cec76e10c29ac}{do\+\_\+early\+\_\+stopping\+\_\+}} = n\+\_\+samples $>$ 10\+\_\+000
\item 
list \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfdec8990efb57c060dee4acdc9ee8a1}{train\+\_\+score\+\_\+}} = \mbox{[}$\,$\mbox{]}
\item 
list \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6245d6c8310ec5dca88d25e0316d3ac1}{validation\+\_\+score\+\_\+}} = \mbox{[}$\,$\mbox{]}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a68e87816ed5daf6e6c99c3d59fc22166}{n\+\_\+iter\+\_\+}} = 0
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a8ec9c807b448b6c570ea723f9109d86b}{n\+\_\+trees\+\_\+per\+\_\+iteration\+\_\+}} = hessian
\end{DoxyCompactItemize}
\doxysubsubsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a6758eb2807909116268bd2c94708ba9f}{\+\_\+encode\+\_\+y}} (self, y)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_abf06de34ef094dcf0580ffd6ec8a3648}{\+\_\+encode\+\_\+y\+\_\+val}} (self, y=None)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a2bcc82c63c55c48f0837eb510dac6efc}{\+\_\+get\+\_\+loss}} (self, sample\+\_\+weight)
\end{DoxyCompactItemize}
\doxysubsection*{Protected Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a42806b43b1e86cb64f2366ff04a2d3d6}{\+\_\+validate\+\_\+parameters}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a3c6c73d838fa46ad6f3c0ccfc2ff4cdb}{\+\_\+finalize\+\_\+sample\+\_\+weight}} (self, sample\+\_\+weight, y)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ab6a1278c0901cb920029746815bcd824}{\+\_\+preprocess\+\_\+X}} (self, X, \texorpdfstring{$\ast$}{*}, reset)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a61ed6d93a6abcb0671fd2cc990131a81}{\+\_\+check\+\_\+categories}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a143ca27c8faef910d8263f7daa255392}{\+\_\+check\+\_\+categorical\+\_\+features}} (self, X)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a85388db29ea4b4a6436c756b97b3197e}{\+\_\+check\+\_\+interaction\+\_\+cst}} (self, n\+\_\+features)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a62834f9ffe3a13cbb18586f837d39d5b}{\+\_\+is\+\_\+fitted}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a0792fbcff561bb817840f5214c3d9dd6}{\+\_\+clear\+\_\+state}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1d9017aa611476cd705da844cfa93034}{\+\_\+get\+\_\+small\+\_\+trainset}} (self, X\+\_\+binned\+\_\+train, y\+\_\+train, sample\+\_\+weight\+\_\+train, seed)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ad3e56b83f7d785263ddc43e0acc6342c}{\+\_\+check\+\_\+early\+\_\+stopping\+\_\+scorer}} (self, X\+\_\+binned\+\_\+small\+\_\+train, y\+\_\+small\+\_\+train, sample\+\_\+weight\+\_\+small\+\_\+train, X\+\_\+binned\+\_\+val, y\+\_\+val, sample\+\_\+weight\+\_\+val, raw\+\_\+predictions\+\_\+small\+\_\+train=None, raw\+\_\+predictions\+\_\+val=None)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a564589da451187a1f20a7da1bb4f6bce}{\+\_\+score\+\_\+with\+\_\+raw\+\_\+predictions}} (self, X, y, sample\+\_\+weight, raw\+\_\+predictions=None)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a689244514867e65787fc11c5520170f7}{\+\_\+check\+\_\+early\+\_\+stopping\+\_\+loss}} (self, raw\+\_\+predictions, y\+\_\+train, sample\+\_\+weight\+\_\+train, raw\+\_\+predictions\+\_\+val, y\+\_\+val, sample\+\_\+weight\+\_\+val, n\+\_\+threads=1)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a6a5b038a6b5daf407a725b68c41a1793}{\+\_\+should\+\_\+stop}} (self, scores)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af18b1289a37ebf4c07a0417a040f4a0c}{\+\_\+bin\+\_\+data}} (self, X, is\+\_\+training\+\_\+data)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57679008c858757379aae8e3918370e4}{\+\_\+print\+\_\+iteration\+\_\+stats}} (self, iteration\+\_\+start\+\_\+time)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa4a8356439ef87a220f9ec262a885137}{\+\_\+raw\+\_\+predict}} (self, X, n\+\_\+threads=None)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a25e59afbf20b7b65de0e92a49ea4b54e}{\+\_\+predict\+\_\+iterations}} (self, X, predictors, raw\+\_\+predictions, is\+\_\+binned, n\+\_\+threads)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a57f54f37a2214f8e4a93b3dcf4488cd7}{\+\_\+staged\+\_\+raw\+\_\+predict}} (self, X)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a7e5f2d889b2c799e41f13ed0b65035a6}{\+\_\+compute\+\_\+partial\+\_\+dependence\+\_\+recursion}} (self, grid, target\+\_\+features)
\end{DoxyCompactItemize}
\doxysubsection*{Protected Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator}{sklearn.\+base.\+Base\+Estimator}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_ab7620691376c89dd6b11583a7ec88056}{\+\_\+get\+\_\+param\+\_\+names}} (cls)
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_a27a676eef23827b46d55a1e7f7b4a9e2}{\+\_\+get\+\_\+params\+\_\+html}} (self, deep=\mbox{\hyperlink{classTrue}{True}})
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_aa8f8e87d8b09ffa6ac9a38403510b839}{\+\_\+validate\+\_\+params}} (self)
\end{DoxyCompactItemize}
\doxysubsection*{Protected Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1ReprHTMLMixin}{sklearn.\+utils.\+\_\+repr\+\_\+html.\+base.\+Repr\+HTMLMixin}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1ReprHTMLMixin_abbd2eef8ae74322be3af7013ce3e8f0c}{\+\_\+repr\+\_\+html\+\_\+}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1ReprHTMLMixin_ad59294b4264a87523735326af7f574a9}{\+\_\+repr\+\_\+html\+\_\+inner}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1ReprHTMLMixin_a5664014dad306a232ffb86680456a8d9}{\+\_\+repr\+\_\+mimebundle\+\_\+}} (self, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\end{DoxyCompactItemize}
\doxysubsection*{Protected Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1__HTMLDocumentationLinkMixin}{sklearn.\+utils.\+\_\+repr\+\_\+html.\+base.\+\_\+\+HTMLDocumentation\+Link\+Mixin}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1__HTMLDocumentationLinkMixin_acb437a0bc58240aec5308543d6406d34}{\+\_\+doc\+\_\+link\+\_\+template}} (self)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1__HTMLDocumentationLinkMixin_a4993851a868087080b98a1be5f030695}{\+\_\+doc\+\_\+link\+\_\+template}} (self, value)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1__HTMLDocumentationLinkMixin_a803004d9b2aef68c50bb5286e0f6da8e}{\+\_\+get\+\_\+doc\+\_\+link}} (self)
\end{DoxyCompactItemize}
\doxysubsection*{Protected Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester}{sklearn.\+utils.\+\_\+metadata\+\_\+requests.\+\_\+\+Metadata\+Requester}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_ac589e16dd865334bf56ea21f99f04248}{\+\_\+build\+\_\+request\+\_\+for\+\_\+signature}} (cls, router, method)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_a12d5e13319a406b611d84cfde04a05a1}{\+\_\+get\+\_\+default\+\_\+requests}} (cls)
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__metadata__requests_1_1__MetadataRequester_a2c1c8ad8d5a4ad9075e1329a9bc01aea}{\+\_\+get\+\_\+metadata\+\_\+request}} (self)
\end{DoxyCompactItemize}
\doxysubsubsection*{Additional Inherited Members}
\doxysubsection*{Protected Attributes inherited from \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a4f8b543277b6689cfa98676cf2fe6afd}{\+\_\+preprocessor}} = None
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_acfcab46edcccc4aa05409934159cd588}{\+\_\+is\+\_\+categorical\+\_\+remapped}} = None
\item 
bool \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a3fc3ed969cf9ec1b7e614eae599e1d66}{\+\_\+fitted\+\_\+with\+\_\+sw}} = \mbox{\hyperlink{classTrue}{True}}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a1abec81a6e54982be76ec308ce533dc3}{\+\_\+random\+\_\+seed}} = rng.\+randint(np.\+iinfo(np.\+uint32).max, dtype="{}u8"{})
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_accbd70f6b5b1826c48e1dd38bf5ce355}{\+\_\+feature\+\_\+subsample\+\_\+rng}} = np.\+random.\+default\+\_\+rng(feature\+\_\+subsample\+\_\+seed)
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_abfa366e1408cc8abaf718dbc73586042}{\+\_\+n\+\_\+features}} = X.\+shape
\item 
bool \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a9fe0089caa05ed5692ffbff1b47a119d}{\+\_\+in\+\_\+fit}} = \mbox{\hyperlink{classTrue}{True}}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_ae0895d9339d35c39e46a6f5886f3e866}{\+\_\+loss}} = self.\+\_\+get\+\_\+loss(sample\+\_\+weight=sample\+\_\+weight)
\item 
tuple \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a12bb6a5453b140706a0da21a0d4ab62b}{\+\_\+use\+\_\+validation\+\_\+data}}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_af07b37765017ed0b88be84e4fb9aeedb}{\+\_\+bin\+\_\+mapper}}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_aa8cf30a8c23006d33229e1abf8a1c087}{\+\_\+baseline\+\_\+prediction}}
\item 
list \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a58768b449193e8be95defd6c3ae07215}{\+\_\+predictors}} = \mbox{[}$\,$\mbox{]}
\item 
\mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting_a583f9f75f3267a2610ff33c46cf28474}{\+\_\+scorer}} = None
\end{DoxyCompactItemize}
\doxysubsection*{Protected Attributes inherited from \mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator}{sklearn.\+base.\+Base\+Estimator}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_aa788e7d07aae196ad4045be35ec03ebd}{\+\_\+parameter\+\_\+constraints}}
\end{DoxyCompactItemize}
\doxysubsection*{Static Protected Attributes inherited from \mbox{\hyperlink{classsklearn_1_1base_1_1RegressorMixin}{sklearn.\+base.\+Regressor\+Mixin}}}
\begin{DoxyCompactItemize}
\item 
str \mbox{\hyperlink{classsklearn_1_1base_1_1RegressorMixin_aba1660973f816763e0ab74f0becd1a06}{\+\_\+estimator\+\_\+type}} = "{}regressor"{}
\end{DoxyCompactItemize}
\doxysubsection*{Static Protected Attributes inherited from \mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator}{sklearn.\+base.\+Base\+Estimator}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator_af02234e06f99aa1ff68dad6902b2ba97}{\+\_\+html\+\_\+repr}} = estimator\+\_\+html\+\_\+repr
\end{DoxyCompactItemize}
\doxysubsection*{Static Protected Attributes inherited from \mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1__HTMLDocumentationLinkMixin}{sklearn.\+utils.\+\_\+repr\+\_\+html.\+base.\+\_\+\+HTMLDocumentation\+Link\+Mixin}}}
\begin{DoxyCompactItemize}
\item 
str \mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1__HTMLDocumentationLinkMixin_ad199eadeedafd0b1b1fdd4eb8a375704}{\+\_\+doc\+\_\+link\+\_\+module}} = "{}sklearn"{}
\item 
\mbox{\hyperlink{classsklearn_1_1utils_1_1__repr__html_1_1base_1_1__HTMLDocumentationLinkMixin_a96665f2f2fb0f3331af7c48b409f45f2}{\+\_\+doc\+\_\+link\+\_\+url\+\_\+param\+\_\+generator}} = None
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Histogram-based Gradient Boosting Regression Tree.

This estimator is much faster than
:class:`GradientBoostingRegressor<sklearn.ensemble.GradientBoostingRegressor>`
for big datasets (n_samples >= 10 000).

This estimator has native support for missing values (NaNs). During
training, the tree grower learns at each split point whether samples
with missing values should go to the left or right child, based on the
potential gain. When predicting, samples with missing values are
assigned to the left or right child consequently. If no missing values
were encountered for a given feature during training, then samples with
missing values are mapped to whichever child has the most samples.
See :ref:`sphx_glr_auto_examples_ensemble_plot_hgbt_regression.py` for a
usecase example of this feature.

This implementation is inspired by
`LightGBM <https://github.com/Microsoft/LightGBM>`_.

Read more in the :ref:`User Guide <histogram_based_gradient_boosting>`.

.. versionadded:: 0.21

Parameters
----------
loss : {'squared_error', 'absolute_error', 'gamma', 'poisson', 'quantile'}, \
        default='squared_error'
    The loss function to use in the boosting process. Note that the
    "squared error", "gamma" and "poisson" losses actually implement
    "half least squares loss", "half gamma deviance" and "half poisson
    deviance" to simplify the computation of the gradient. Furthermore,
    "gamma" and "poisson" losses internally use a log-link, "gamma"
    requires ``y > 0`` and "poisson" requires ``y >= 0``.
    "quantile" uses the pinball loss.

    .. versionchanged:: 0.23
       Added option 'poisson'.

    .. versionchanged:: 1.1
       Added option 'quantile'.

    .. versionchanged:: 1.3
       Added option 'gamma'.

quantile : float, default=None
    If loss is "quantile", this parameter specifies which quantile to be estimated
    and must be between 0 and 1.
learning_rate : float, default=0.1
    The learning rate, also known as *shrinkage*. This is used as a
    multiplicative factor for the leaves values. Use ``1`` for no
    shrinkage.
max_iter : int, default=100
    The maximum number of iterations of the boosting process, i.e. the
    maximum number of trees.
max_leaf_nodes : int or None, default=31
    The maximum number of leaves for each tree. Must be strictly greater
    than 1. If None, there is no maximum limit.
max_depth : int or None, default=None
    The maximum depth of each tree. The depth of a tree is the number of
    edges to go from the root to the deepest leaf.
    Depth isn't constrained by default.
min_samples_leaf : int, default=20
    The minimum number of samples per leaf. For small datasets with less
    than a few hundred samples, it is recommended to lower this value
    since only very shallow trees would be built.
l2_regularization : float, default=0
    The L2 regularization parameter penalizing leaves with small hessians.
    Use ``0`` for no regularization (default).
max_features : float, default=1.0
    Proportion of randomly chosen features in each and every node split.
    This is a form of regularization, smaller values make the trees weaker
    learners and might prevent overfitting.
    If interaction constraints from `interaction_cst` are present, only allowed
    features are taken into account for the subsampling.

    .. versionadded:: 1.4

max_bins : int, default=255
    The maximum number of bins to use for non-missing values. Before
    training, each feature of the input array `X` is binned into
    integer-valued bins, which allows for a much faster training stage.
    Features with a small number of unique values may use less than
    ``max_bins`` bins. In addition to the ``max_bins`` bins, one more bin
    is always reserved for missing values. Must be no larger than 255.
categorical_features : array-like of {bool, int, str} of shape (n_features) \
        or shape (n_categorical_features,), default='from_dtype'
    Indicates the categorical features.

    - None : no feature will be considered categorical.
    - boolean array-like : boolean mask indicating categorical features.
    - integer array-like : integer indices indicating categorical
      features.
    - str array-like: names of categorical features (assuming the training
      data has feature names).
    - `"from_dtype"`: dataframe columns with dtype "category" are
      considered to be categorical features. The input must be an object
      exposing a ``__dataframe__`` method such as pandas or polars
      DataFrames to use this feature.

    For each categorical feature, there must be at most `max_bins` unique
    categories. Negative values for categorical features encoded as numeric
    dtypes are treated as missing values. All categorical values are
    converted to floating point numbers. This means that categorical values
    of 1.0 and 1 are treated as the same category.

    Read more in the :ref:`User Guide <categorical_support_gbdt>` and
    :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_categorical.py`.

    .. versionadded:: 0.24

    .. versionchanged:: 1.2
       Added support for feature names.

    .. versionchanged:: 1.4
       Added `"from_dtype"` option.

    .. versionchanged:: 1.6
       The default value changed from `None` to `"from_dtype"`.

monotonic_cst : array-like of int of shape (n_features) or dict, default=None
    Monotonic constraint to enforce on each feature are specified using the
    following integer values:

    - 1: monotonic increase
    - 0: no constraint
    - -1: monotonic decrease

    If a dict with str keys, map feature to monotonic constraints by name.
    If an array, the features are mapped to constraints by position. See
    :ref:`monotonic_cst_features_names` for a usage example.

    Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.

    .. versionadded:: 0.23

    .. versionchanged:: 1.2
       Accept dict of constraints with feature names as keys.

interaction_cst : {"pairwise", "no_interactions"} or sequence of lists/tuples/sets \
        of int, default=None
    Specify interaction constraints, the sets of features which can
    interact with each other in child node splits.

    Each item specifies the set of feature indices that are allowed
    to interact with each other. If there are more features than
    specified in these constraints, they are treated as if they were
    specified as an additional set.

    The strings "pairwise" and "no_interactions" are shorthands for
    allowing only pairwise or no interactions, respectively.

    For instance, with 5 features in total, `interaction_cst=[{0, 1}]`
    is equivalent to `interaction_cst=[{0, 1}, {2, 3, 4}]`,
    and specifies that each branch of a tree will either only split
    on features 0 and 1 or only split on features 2, 3 and 4.

    See :ref:`this example<ice-vs-pdp>` on how to use `interaction_cst`.

    .. versionadded:: 1.2

warm_start : bool, default=False
    When set to ``True``, reuse the solution of the previous call to fit
    and add more estimators to the ensemble. For results to be valid, the
    estimator should be re-trained on the same data only.
    See :term:`the Glossary <warm_start>`.
early_stopping : 'auto' or bool, default='auto'
    If 'auto', early stopping is enabled if the sample size is larger than
    10000 or if `X_val` and `y_val` are passed to `fit`. If True, early stopping
    is enabled, otherwise early stopping is disabled.

    .. versionadded:: 0.23

scoring : str or callable or None, default='loss'
    Scoring method to use for early stopping. Only used if `early_stopping`
    is enabled. Options:

    - str: see :ref:`scoring_string_names` for options.
    - callable: a scorer callable object (e.g., function) with signature
      ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.
    - `None`: the :ref:`coefficient of determination <r2_score>`
      (:math:`R^2`) is used.
    - 'loss': early stopping is checked w.r.t the loss value.

validation_fraction : int or float or None, default=0.1
    Proportion (or absolute size) of training data to set aside as
    validation data for early stopping. If None, early stopping is done on
    the training data.
    The value is ignored if either early stopping is not performed, e.g.
    `early_stopping=False`, or if `X_val` and `y_val` are passed to fit.
n_iter_no_change : int, default=10
    Used to determine when to "early stop". The fitting process is
    stopped when none of the last ``n_iter_no_change`` scores are better
    than the ``n_iter_no_change - 1`` -th-to-last one, up to some
    tolerance. Only used if early stopping is performed.
tol : float, default=1e-7
    The absolute tolerance to use when comparing scores during early
    stopping. The higher the tolerance, the more likely we are to early
    stop: higher tolerance means that it will be harder for subsequent
    iterations to be considered an improvement upon the reference score.
verbose : int, default=0
    The verbosity level. If not zero, print some information about the
    fitting process. ``1`` prints only summary info, ``2`` prints info per
    iteration.
random_state : int, RandomState instance or None, default=None
    Pseudo-random number generator to control the subsampling in the
    binning process, and the train/validation data split if early stopping
    is enabled.
    Pass an int for reproducible output across multiple function calls.
    See :term:`Glossary <random_state>`.

Attributes
----------
do_early_stopping_ : bool
    Indicates whether early stopping is used during training.
n_iter_ : int
    The number of iterations as selected by early stopping, depending on
    the `early_stopping` parameter. Otherwise it corresponds to max_iter.
n_trees_per_iteration_ : int
    The number of tree that are built at each iteration. For regressors,
    this is always 1.
train_score_ : ndarray, shape (n_iter_+1,)
    The scores at each iteration on the training data. The first entry
    is the score of the ensemble before the first iteration. Scores are
    computed according to the ``scoring`` parameter. If ``scoring`` is
    not 'loss', scores are computed on a subset of at most 10 000
    samples. Empty if no early stopping.
validation_score_ : ndarray, shape (n_iter_+1,)
    The scores at each iteration on the held-out validation data. The
    first entry is the score of the ensemble before the first iteration.
    Scores are computed according to the ``scoring`` parameter. Empty if
    no early stopping or if ``validation_fraction`` is None.
is_categorical_ : ndarray, shape (n_features, ) or None
    Boolean mask for the categorical features. ``None`` if there are no
    categorical features.
n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24
feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

See Also
--------
GradientBoostingRegressor : Exact gradient boosting method that does not
    scale as good on datasets with a large number of samples.
sklearn.tree.DecisionTreeRegressor : A decision tree regressor.
RandomForestRegressor : A meta-estimator that fits a number of decision
    tree regressors on various sub-samples of the dataset and uses
    averaging to improve the statistical performance and control
    over-fitting.
AdaBoostRegressor : A meta-estimator that begins by fitting a regressor
    on the original dataset and then fits additional copies of the
    regressor on the same dataset but where the weights of instances are
    adjusted according to the error of the current prediction. As such,
    subsequent regressors focus more on difficult cases.

Examples
--------
>>> from sklearn.ensemble import HistGradientBoostingRegressor
>>> from sklearn.datasets import load_diabetes
>>> X, y = load_diabetes(return_X_y=True)
>>> est = HistGradientBoostingRegressor().fit(X, y)
>>> est.score(X, y)
0.92...
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{gradient__boosting_8py_source_l01470}{1470}} of file \mbox{\hyperlink{gradient__boosting_8py_source}{gradient\+\_\+boosting.\+py}}.



\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a63c7f417756134796ae6b5c92cb4a6e0}\index{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}}
\doxysubsubsection{\texorpdfstring{\_\_init\_\_()}{\_\_init\_\_()}}
{\footnotesize\ttfamily \label{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a63c7f417756134796ae6b5c92cb4a6e0} 
sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Hist\+Gradient\+Boosting\+Regressor.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{loss}{ = {\ttfamily "{}squared\+\_\+error"{}}, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{quantile}{ = {\ttfamily None}, }\item[{}]{learning\+\_\+rate}{ = {\ttfamily 0.1}, }\item[{}]{max\+\_\+iter}{ = {\ttfamily 100}, }\item[{}]{max\+\_\+leaf\+\_\+nodes}{ = {\ttfamily 31}, }\item[{}]{max\+\_\+depth}{ = {\ttfamily None}, }\item[{}]{min\+\_\+samples\+\_\+leaf}{ = {\ttfamily 20}, }\item[{}]{l2\+\_\+regularization}{ = {\ttfamily 0.0}, }\item[{}]{max\+\_\+features}{ = {\ttfamily 1.0}, }\item[{}]{max\+\_\+bins}{ = {\ttfamily 255}, }\item[{}]{categorical\+\_\+features}{ = {\ttfamily "{}from\+\_\+dtype"{}}, }\item[{}]{monotonic\+\_\+cst}{ = {\ttfamily None}, }\item[{}]{interaction\+\_\+cst}{ = {\ttfamily None}, }\item[{}]{warm\+\_\+start}{ = {\ttfamily False}, }\item[{}]{early\+\_\+stopping}{ = {\ttfamily "{}auto"{}}, }\item[{}]{scoring}{ = {\ttfamily "{}loss"{}}, }\item[{}]{validation\+\_\+fraction}{ = {\ttfamily 0.1}, }\item[{}]{n\+\_\+iter\+\_\+no\+\_\+change}{ = {\ttfamily 10}, }\item[{}]{tol}{ = {\ttfamily 1e-\/7}, }\item[{}]{verbose}{ = {\ttfamily 0}, }\item[{}]{random\+\_\+state}{ = {\ttfamily None}}\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{gradient__boosting_8py_source_l01757}{1757}} of file \mbox{\hyperlink{gradient__boosting_8py_source}{gradient\+\_\+boosting.\+py}}.



Referenced by \mbox{\hyperlink{kernels_8py_source_l00178}{sklearn.\+gaussian\+\_\+process.\+kernels.\+Kernel.\+get\+\_\+params()}}.



\doxysubsection{Member Function Documentation}
\Hypertarget{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a6758eb2807909116268bd2c94708ba9f}\index{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}!\_encode\_y@{\_encode\_y}}
\index{\_encode\_y@{\_encode\_y}!sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}}
\doxysubsubsection{\texorpdfstring{\_encode\_y()}{\_encode\_y()}}
{\footnotesize\ttfamily \label{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a6758eb2807909116268bd2c94708ba9f} 
sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Hist\+Gradient\+Boosting\+Regressor.\+\_\+encode\+\_\+y (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{y}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Reimplemented from \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting}}.



Definition at line \mbox{\hyperlink{gradient__boosting_8py_source_l01845}{1845}} of file \mbox{\hyperlink{gradient__boosting_8py_source}{gradient\+\_\+boosting.\+py}}.

\Hypertarget{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_abf06de34ef094dcf0580ffd6ec8a3648}\index{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}!\_encode\_y\_val@{\_encode\_y\_val}}
\index{\_encode\_y\_val@{\_encode\_y\_val}!sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}}
\doxysubsubsection{\texorpdfstring{\_encode\_y\_val()}{\_encode\_y\_val()}}
{\footnotesize\ttfamily \label{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_abf06de34ef094dcf0580ffd6ec8a3648} 
sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Hist\+Gradient\+Boosting\+Regressor.\+\_\+encode\+\_\+y\+\_\+val (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{y}{ = {\ttfamily None}}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Reimplemented from \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting}}.



Definition at line \mbox{\hyperlink{gradient__boosting_8py_source_l01861}{1861}} of file \mbox{\hyperlink{gradient__boosting_8py_source}{gradient\+\_\+boosting.\+py}}.

\Hypertarget{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a2bcc82c63c55c48f0837eb510dac6efc}\index{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}!\_get\_loss@{\_get\_loss}}
\index{\_get\_loss@{\_get\_loss}!sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}}
\doxysubsubsection{\texorpdfstring{\_get\_loss()}{\_get\_loss()}}
{\footnotesize\ttfamily \label{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a2bcc82c63c55c48f0837eb510dac6efc} 
sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Hist\+Gradient\+Boosting\+Regressor.\+\_\+get\+\_\+loss (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{sample\+\_\+weight}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Reimplemented from \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1BaseHistGradientBoosting}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting}}.



Definition at line \mbox{\hyperlink{gradient__boosting_8py_source_l01864}{1864}} of file \mbox{\hyperlink{gradient__boosting_8py_source}{gradient\+\_\+boosting.\+py}}.



Referenced by \mbox{\hyperlink{glm_8py_source_l00172}{sklearn.\+linear\+\_\+model.\+\_\+glm.\+glm.\+\_\+\+Generalized\+Linear\+Regressor.\+fit()}}, and \mbox{\hyperlink{glm_8py_source_l00371}{sklearn.\+linear\+\_\+model.\+\_\+glm.\+glm.\+\_\+\+Generalized\+Linear\+Regressor.\+score()}}.

\Hypertarget{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_af18d3dbc777369d5e7d113f623bc8d03}\index{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}!predict@{predict}}
\index{predict@{predict}!sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}}
\doxysubsubsection{\texorpdfstring{predict()}{predict()}}
{\footnotesize\ttfamily \label{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_af18d3dbc777369d5e7d113f623bc8d03} 
sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Hist\+Gradient\+Boosting\+Regressor.\+predict (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{X}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Predict values for X.

Parameters
----------
X : array-like, shape (n_samples, n_features)
    The input samples.

Returns
-------
y : ndarray, shape (n_samples,)
    The predicted values.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{gradient__boosting_8py_source_l01806}{1806}} of file \mbox{\hyperlink{gradient__boosting_8py_source}{gradient\+\_\+boosting.\+py}}.



References \mbox{\hyperlink{__gb_8py_source_l00442}{sklearn.\+ensemble.\+\_\+gb.\+Base\+Gradient\+Boosting.\+\_\+loss}}, \mbox{\hyperlink{gradient__boosting_8py_source_l00646}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting.\+\_\+loss}}, \mbox{\hyperlink{__gb_8py_source_l00962}{sklearn.\+ensemble.\+\_\+gb.\+Base\+Gradient\+Boosting.\+\_\+raw\+\_\+predict()}}, and \mbox{\hyperlink{gradient__boosting_8py_source_l01291}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting.\+\_\+raw\+\_\+predict()}}.



Referenced by \mbox{\hyperlink{__gpr_8py_source_l00498}{sklearn.\+gaussian\+\_\+process.\+\_\+gpr.\+Gaussian\+Process\+Regressor.\+sample\+\_\+y()}}, and \mbox{\hyperlink{multioutput_8py_source_l00590}{sklearn.\+multioutput.\+Multi\+Output\+Classifier.\+score()}}.

\Hypertarget{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_ae5dcddcfcbc57ebd809a3119405dde94}\index{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}!staged\_predict@{staged\_predict}}
\index{staged\_predict@{staged\_predict}!sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}}
\doxysubsubsection{\texorpdfstring{staged\_predict()}{staged\_predict()}}
{\footnotesize\ttfamily \label{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_ae5dcddcfcbc57ebd809a3119405dde94} 
sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Hist\+Gradient\+Boosting\+Regressor.\+staged\+\_\+predict (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{X}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Predict regression target for each iteration.

This method allows monitoring (i.e. determine error on testing set)
after each stage.

.. versionadded:: 0.24

Parameters
----------
X : array-like of shape (n_samples, n_features)
    The input samples.

Yields
------
y : generator of ndarray of shape (n_samples,)
    The predicted values of the input samples, for each iteration.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{gradient__boosting_8py_source_l01824}{1824}} of file \mbox{\hyperlink{gradient__boosting_8py_source}{gradient\+\_\+boosting.\+py}}.



References \mbox{\hyperlink{__gb_8py_source_l00420}{sklearn.\+ensemble.\+\_\+gb.\+Base\+Gradient\+Boosting.\+\_\+encode\+\_\+y()}}, \mbox{\hyperlink{__gb_8py_source_l01513}{sklearn.\+ensemble.\+\_\+gb.\+Gradient\+Boosting\+Classifier.\+\_\+encode\+\_\+y()}}, \mbox{\hyperlink{__gb_8py_source_l02121}{sklearn.\+ensemble.\+\_\+gb.\+Gradient\+Boosting\+Regressor.\+\_\+encode\+\_\+y()}}, \mbox{\hyperlink{gradient__boosting_8py_source_l01456}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting.\+\_\+encode\+\_\+y()}}, \mbox{\hyperlink{__gb_8py_source_l00442}{sklearn.\+ensemble.\+\_\+gb.\+Base\+Gradient\+Boosting.\+\_\+loss}}, \mbox{\hyperlink{gradient__boosting_8py_source_l00646}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting.\+\_\+loss}}, \mbox{\hyperlink{__gb_8py_source_l00969}{sklearn.\+ensemble.\+\_\+gb.\+Base\+Gradient\+Boosting.\+\_\+staged\+\_\+raw\+\_\+predict()}}, \mbox{\hyperlink{gradient__boosting_8py_source_l01356}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting.\+\_\+staged\+\_\+raw\+\_\+predict()}}, \mbox{\hyperlink{__gb_8py_source_l00399}{sklearn.\+ensemble.\+\_\+gb.\+Base\+Gradient\+Boosting.\+loss}}, \mbox{\hyperlink{__gb_8py_source_l01544}{sklearn.\+ensemble.\+\_\+gb.\+Gradient\+Boosting\+Classifier.\+loss}}, \mbox{\hyperlink{gradient__boosting_8py_source_l00201}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting.\+loss}}, \mbox{\hyperlink{__gb_8py_source_l00465}{sklearn.\+ensemble.\+\_\+gb.\+Base\+Gradient\+Boosting.\+n\+\_\+trees\+\_\+per\+\_\+iteration\+\_\+}}, \mbox{\hyperlink{__gb_8py_source_l01524}{sklearn.\+ensemble.\+\_\+gb.\+Gradient\+Boosting\+Classifier.\+n\+\_\+trees\+\_\+per\+\_\+iteration\+\_\+}}, \mbox{\hyperlink{__gb_8py_source_l02123}{sklearn.\+ensemble.\+\_\+gb.\+Gradient\+Boosting\+Regressor.\+n\+\_\+trees\+\_\+per\+\_\+iteration\+\_\+}}, \mbox{\hyperlink{gradient__boosting_8py_source_l00934}{sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Base\+Hist\+Gradient\+Boosting.\+n\+\_\+trees\+\_\+per\+\_\+iteration\+\_\+}}, \mbox{\hyperlink{loss_8py_source_l00689}{sklearn.\+\_\+loss.\+loss.\+Huber\+Loss.\+quantile}}, \mbox{\hyperlink{dummy_8py_source_l00540}{sklearn.\+dummy.\+Dummy\+Regressor.\+quantile}}, and \mbox{\hyperlink{gradient__boosting_8py_source_l01804}{quantile}}.



\doxysubsection{Member Data Documentation}
\Hypertarget{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a895ff08edb9ba52ddecd9e40e932f93a}\index{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}!quantile@{quantile}}
\index{quantile@{quantile}!sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor@{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting.HistGradientBoostingRegressor}}
\doxysubsubsection{\texorpdfstring{quantile}{quantile}}
{\footnotesize\ttfamily \label{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor_a895ff08edb9ba52ddecd9e40e932f93a} 
sklearn.\+ensemble.\+\_\+hist\+\_\+gradient\+\_\+boosting.\+gradient\+\_\+boosting.\+Hist\+Gradient\+Boosting\+Regressor.\+quantile = quantile}



Definition at line \mbox{\hyperlink{gradient__boosting_8py_source_l01804}{1804}} of file \mbox{\hyperlink{gradient__boosting_8py_source}{gradient\+\_\+boosting.\+py}}.



Referenced by \mbox{\hyperlink{__quantile_8py_source_l00143}{sklearn.\+linear\+\_\+model.\+\_\+quantile.\+Quantile\+Regressor.\+fit()}}, \mbox{\hyperlink{frame_8py_source_l12062}{pandas.\+core.\+frame.\+Data\+Frame.\+quantile()}}, and \mbox{\hyperlink{gradient__boosting_8py_source_l01824}{staged\+\_\+predict()}}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/jam/\+Research/\+IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.\+12/site-\/packages/sklearn/ensemble/\+\_\+hist\+\_\+gradient\+\_\+boosting/gradient\+\_\+boosting.\+py\end{DoxyCompactItemize}
