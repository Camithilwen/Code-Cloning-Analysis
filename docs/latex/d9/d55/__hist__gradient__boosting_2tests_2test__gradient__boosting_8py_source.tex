\doxysection{test\+\_\+gradient\+\_\+boosting.\+py}
\hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source}{}\label{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source}\index{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/ensemble/\_hist\_gradient\_boosting/tests/test\_gradient\_boosting.py@{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/ensemble/\_hist\_gradient\_boosting/tests/test\_gradient\_boosting.py}}

\begin{DoxyCode}{0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00001}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting}{00001}}\ \textcolor{keyword}{import}\ copyreg}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00002}00002\ \textcolor{keyword}{import}\ io}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00003}00003\ \textcolor{keyword}{import}\ pickle}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00004}00004\ \textcolor{keyword}{import}\ re}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00005}00005\ \textcolor{keyword}{import}\ warnings}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00006}00006\ \textcolor{keyword}{from}\ unittest.mock\ \textcolor{keyword}{import}\ Mock}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00007}00007\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00008}00008\ \textcolor{keyword}{import}\ joblib}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00009}00009\ \textcolor{keyword}{import}\ numpy\ \textcolor{keyword}{as}\ np}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00010}00010\ \textcolor{keyword}{import}\ pytest}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00011}00011\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacejoblib_1_1numpy__pickle}{joblib.numpy\_pickle}}\ \textcolor{keyword}{import}\ NumpyPickler}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00012}00012\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacenumpy_1_1testing}{numpy.testing}}\ \textcolor{keyword}{import}\ assert\_allclose,\ assert\_array\_equal}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00013}00013\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00014}00014\ \textcolor{keyword}{import}\ sklearn}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00015}00015\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1__loss_1_1loss}{sklearn.\_loss.loss}}\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00016}00016\ \ \ \ \ AbsoluteError,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00017}00017\ \ \ \ \ HalfBinomialLoss,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00018}00018\ \ \ \ \ HalfSquaredError,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00019}00019\ \ \ \ \ PinballLoss,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00020}00020\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00021}00021\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1base}{sklearn.base}}\ \textcolor{keyword}{import}\ BaseEstimator,\ TransformerMixin,\ clone,\ is\_regressor}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00022}00022\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1compose}{sklearn.compose}}\ \textcolor{keyword}{import}\ make\_column\_transformer}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00023}00023\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1datasets}{sklearn.datasets}}\ \textcolor{keyword}{import}\ make\_classification,\ make\_low\_rank\_matrix,\ make\_regression}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00024}00024\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1dummy}{sklearn.dummy}}\ \textcolor{keyword}{import}\ DummyRegressor}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00025}00025\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1ensemble}{sklearn.ensemble}}\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00026}00026\ \ \ \ \ HistGradientBoostingClassifier,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00027}00027\ \ \ \ \ HistGradientBoostingRegressor,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00028}00028\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00029}00029\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1binning}{sklearn.ensemble.\_hist\_gradient\_boosting.binning}}\ \textcolor{keyword}{import}\ \_BinMapper}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00030}00030\ \textcolor{keyword}{from}\ sklearn.ensemble.\_hist\_gradient\_boosting.common\ \textcolor{keyword}{import}\ G\_H\_DTYPE}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00031}00031\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1grower}{sklearn.ensemble.\_hist\_gradient\_boosting.grower}}\ \textcolor{keyword}{import}\ TreeGrower}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00032}00032\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1predictor}{sklearn.ensemble.\_hist\_gradient\_boosting.predictor}}\ \textcolor{keyword}{import}\ TreePredictor}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00033}00033\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1exceptions}{sklearn.exceptions}}\ \textcolor{keyword}{import}\ NotFittedError}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00034}00034\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1metrics}{sklearn.metrics}}\ \textcolor{keyword}{import}\ get\_scorer,\ mean\_gamma\_deviance,\ mean\_poisson\_deviance}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00035}00035\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1model__selection}{sklearn.model\_selection}}\ \textcolor{keyword}{import}\ cross\_val\_score,\ train\_test\_split}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00036}00036\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1pipeline}{sklearn.pipeline}}\ \textcolor{keyword}{import}\ make\_pipeline}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00037}00037\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1preprocessing}{sklearn.preprocessing}}\ \textcolor{keyword}{import}\ KBinsDiscretizer,\ MinMaxScaler,\ OneHotEncoder}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00038}00038\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils}{sklearn.utils}}\ \textcolor{keyword}{import}\ check\_random\_state,\ shuffle}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00039}00039\ \textcolor{keyword}{from}\ sklearn.utils.\_openmp\_helpers\ \textcolor{keyword}{import}\ \_openmp\_effective\_n\_threads}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00040}00040\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils_1_1__testing}{sklearn.utils.\_testing}}\ \textcolor{keyword}{import}\ \_convert\_container}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00041}00041\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils_1_1fixes}{sklearn.utils.fixes}}\ \textcolor{keyword}{import}\ \_IS\_32BIT}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00042}00042\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00043}00043\ n\_threads\ =\ \_openmp\_effective\_n\_threads()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00044}00044\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00045}00045\ X\_classification,\ y\_classification\ =\ make\_classification(random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00046}00046\ X\_regression,\ y\_regression\ =\ make\_regression(random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00047}00047\ X\_multi\_classification,\ y\_multi\_classification\ =\ make\_classification(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00048}00048\ \ \ \ \ n\_classes=3,\ n\_informative=3,\ random\_state=0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00049}00049\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00050}00050\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00051}00051\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00052}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a3cb0417328a4806f2391c495dd0a1d7d}{00052}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a3cb0417328a4806f2391c495dd0a1d7d}{\_make\_dumb\_dataset}}(n\_samples):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00053}00053\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Make\ a\ dumb\ dataset\ to\ test\ early\ stopping."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00054}00054\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00055}00055\ \ \ \ \ X\_dumb\ =\ rng.randn(n\_samples,\ 1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00056}00056\ \ \ \ \ y\_dumb\ =\ (X\_dumb[:,\ 0]\ >\ 0).astype(\textcolor{stringliteral}{"{}int64"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00057}00057\ \ \ \ \ \textcolor{keywordflow}{return}\ X\_dumb,\ y\_dumb}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00058}00058\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00059}00059\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00060}00060\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00061}00061\ \ \ \ \ \textcolor{stringliteral}{"{}GradientBoosting,\ X,\ y"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00062}00062\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00063}00063\ \ \ \ \ \ \ \ \ (HistGradientBoostingClassifier,\ X\_classification,\ y\_classification),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00064}00064\ \ \ \ \ \ \ \ \ (HistGradientBoostingRegressor,\ X\_regression,\ y\_regression),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00065}00065\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00066}00066\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00067}00067\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00068}00068\ \ \ \ \ \textcolor{stringliteral}{"{}params,\ err\_msg"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00069}00069\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00070}00070\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00071}00071\ \ \ \ \ \ \ \ \ \ \ \ \ \{\textcolor{stringliteral}{"{}interaction\_cst"{}}:\ [0,\ 1]\},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00072}00072\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Interaction\ constraints\ must\ be\ a\ sequence\ of\ tuples\ or\ lists"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00073}00073\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00074}00074\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00075}00075\ \ \ \ \ \ \ \ \ \ \ \ \ \{\textcolor{stringliteral}{"{}interaction\_cst"{}}:\ [\{0,\ 9999\}]\},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00076}00076\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}Interaction\ constraints\ must\ consist\ of\ integer\ indices\ in\ \(\backslash\)[0,"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00077}00077\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}\ n\_features\ -\/\ 1\(\backslash\)]\ =\ \(\backslash\)[.*\(\backslash\)],\ specifying\ the\ position\ of\ features,"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00078}00078\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00079}00079\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00080}00080\ \ \ \ \ \ \ \ \ \ \ \ \ \{\textcolor{stringliteral}{"{}interaction\_cst"{}}:\ [\{-\/1,\ 0\}]\},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00081}00081\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}Interaction\ constraints\ must\ consist\ of\ integer\ indices\ in\ \(\backslash\)[0,"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00082}00082\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}\ n\_features\ -\/\ 1\(\backslash\)]\ =\ \(\backslash\)[.*\(\backslash\)],\ specifying\ the\ position\ of\ features,"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00083}00083\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00084}00084\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00085}00085\ \ \ \ \ \ \ \ \ \ \ \ \ \{\textcolor{stringliteral}{"{}interaction\_cst"{}}:\ [\{0.5\}]\},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00086}00086\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}Interaction\ constraints\ must\ consist\ of\ integer\ indices\ in\ \(\backslash\)[0,"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00087}00087\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}\ n\_features\ -\/\ 1\(\backslash\)]\ =\ \(\backslash\)[.*\(\backslash\)],\ specifying\ the\ position\ of\ features,"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00088}00088\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00089}00089\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00090}00090\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00091}00091\ \textcolor{keyword}{def\ }test\_init\_parameters\_validation(GradientBoosting,\ X,\ y,\ params,\ err\_msg):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00092}00092\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=err\_msg):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00093}00093\ \ \ \ \ \ \ \ \ GradientBoosting(**params).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00094}00094\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00095}00095\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00096}00096\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00097}00097\ \ \ \ \ \textcolor{stringliteral}{"{}scoring,\ validation\_fraction,\ early\_stopping,\ n\_iter\_no\_change,\ tol"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00098}00098\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00099}00099\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}neg\_mean\_squared\_error"{}},\ 0.1,\ \textcolor{keyword}{True},\ 5,\ 1e-\/7),\ \ \textcolor{comment}{\#\ use\ scorer}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00100}00100\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}neg\_mean\_squared\_error"{}},\ \textcolor{keywordtype}{None},\ \textcolor{keyword}{True},\ 5,\ 1e-\/1),\ \ \textcolor{comment}{\#\ use\ scorer\ on\ train}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00101}00101\ \ \ \ \ \ \ \ \ (\textcolor{keywordtype}{None},\ 0.1,\ \textcolor{keyword}{True},\ 5,\ 1e-\/7),\ \ \textcolor{comment}{\#\ same\ with\ default\ scorer}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00102}00102\ \ \ \ \ \ \ \ \ (\textcolor{keywordtype}{None},\ \textcolor{keywordtype}{None},\ \textcolor{keyword}{True},\ 5,\ 1e-\/1),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00103}00103\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}loss"{}},\ 0.1,\ \textcolor{keyword}{True},\ 5,\ 1e-\/7),\ \ \textcolor{comment}{\#\ use\ loss}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00104}00104\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}loss"{}},\ \textcolor{keywordtype}{None},\ \textcolor{keyword}{True},\ 5,\ 1e-\/1),\ \ \textcolor{comment}{\#\ use\ loss\ on\ training\ data}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00105}00105\ \ \ \ \ \ \ \ \ (\textcolor{keywordtype}{None},\ \textcolor{keywordtype}{None},\ \textcolor{keyword}{False},\ 5,\ 0.0),\ \ \textcolor{comment}{\#\ no\ early\ stopping}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00106}00106\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00107}00107\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00108}00108\ \textcolor{keyword}{def\ }test\_early\_stopping\_regression(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00109}00109\ \ \ \ \ scoring,\ validation\_fraction,\ early\_stopping,\ n\_iter\_no\_change,\ tol}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00110}00110\ ):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00111}00111\ \ \ \ \ max\_iter\ =\ 200}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00112}00112\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00113}00113\ \ \ \ \ X,\ y\ =\ make\_regression(n\_samples=50,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00114}00114\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00115}00115\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00116}00116\ \ \ \ \ \ \ \ \ verbose=1,\ \ \textcolor{comment}{\#\ just\ for\ coverage}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00117}00117\ \ \ \ \ \ \ \ \ min\_samples\_leaf=5,\ \ \textcolor{comment}{\#\ easier\ to\ overfit\ fast}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00118}00118\ \ \ \ \ \ \ \ \ scoring=scoring,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00119}00119\ \ \ \ \ \ \ \ \ tol=tol,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00120}00120\ \ \ \ \ \ \ \ \ early\_stopping=early\_stopping,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00121}00121\ \ \ \ \ \ \ \ \ validation\_fraction=validation\_fraction,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00122}00122\ \ \ \ \ \ \ \ \ max\_iter=max\_iter,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00123}00123\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=n\_iter\_no\_change,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00124}00124\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00125}00125\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00126}00126\ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00127}00127\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00128}00128\ \ \ \ \ \textcolor{keywordflow}{if}\ early\_stopping:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00129}00129\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ n\_iter\_no\_change\ <=\ gb.n\_iter\_\ <\ max\_iter}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00130}00130\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00131}00131\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ gb.n\_iter\_\ ==\ max\_iter}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00132}00132\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00133}00133\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00134}00134\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00135}00135\ \ \ \ \ \textcolor{stringliteral}{"{}data"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00136}00136\ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00137}00137\ \ \ \ \ \ \ \ \ make\_classification(n\_samples=30,\ random\_state=0),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00138}00138\ \ \ \ \ \ \ \ \ make\_classification(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00139}00139\ \ \ \ \ \ \ \ \ \ \ \ \ n\_samples=30,\ n\_classes=3,\ n\_clusters\_per\_class=1,\ random\_state=0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00140}00140\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00141}00141\ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00142}00142\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00143}00143\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00144}00144\ \ \ \ \ \textcolor{stringliteral}{"{}scoring,\ validation\_fraction,\ early\_stopping,\ n\_iter\_no\_change,\ tol"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00145}00145\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00146}00146\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}accuracy"{}},\ 0.1,\ \textcolor{keyword}{True},\ 5,\ 1e-\/7),\ \ \textcolor{comment}{\#\ use\ scorer}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00147}00147\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}accuracy"{}},\ \textcolor{keywordtype}{None},\ \textcolor{keyword}{True},\ 5,\ 1e-\/1),\ \ \textcolor{comment}{\#\ use\ scorer\ on\ training\ data}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00148}00148\ \ \ \ \ \ \ \ \ (\textcolor{keywordtype}{None},\ 0.1,\ \textcolor{keyword}{True},\ 5,\ 1e-\/7),\ \ \textcolor{comment}{\#\ same\ with\ default\ scorer}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00149}00149\ \ \ \ \ \ \ \ \ (\textcolor{keywordtype}{None},\ \textcolor{keywordtype}{None},\ \textcolor{keyword}{True},\ 5,\ 1e-\/1),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00150}00150\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}loss"{}},\ 0.1,\ \textcolor{keyword}{True},\ 5,\ 1e-\/7),\ \ \textcolor{comment}{\#\ use\ loss}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00151}00151\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}loss"{}},\ \textcolor{keywordtype}{None},\ \textcolor{keyword}{True},\ 5,\ 1e-\/1),\ \ \textcolor{comment}{\#\ use\ loss\ on\ training\ data}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00152}00152\ \ \ \ \ \ \ \ \ (\textcolor{keywordtype}{None},\ \textcolor{keywordtype}{None},\ \textcolor{keyword}{False},\ 5,\ 0.0),\ \ \textcolor{comment}{\#\ no\ early\ stopping}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00153}00153\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00154}00154\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00155}00155\ \textcolor{keyword}{def\ }test\_early\_stopping\_classification(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00156}00156\ \ \ \ \ data,\ scoring,\ validation\_fraction,\ early\_stopping,\ n\_iter\_no\_change,\ tol}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00157}00157\ ):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00158}00158\ \ \ \ \ max\_iter\ =\ 50}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00159}00159\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00160}00160\ \ \ \ \ X,\ y\ =\ data}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00161}00161\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00162}00162\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00163}00163\ \ \ \ \ \ \ \ \ verbose=2,\ \ \textcolor{comment}{\#\ just\ for\ coverage}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00164}00164\ \ \ \ \ \ \ \ \ min\_samples\_leaf=5,\ \ \textcolor{comment}{\#\ easier\ to\ overfit\ fast}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00165}00165\ \ \ \ \ \ \ \ \ scoring=scoring,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00166}00166\ \ \ \ \ \ \ \ \ tol=tol,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00167}00167\ \ \ \ \ \ \ \ \ early\_stopping=early\_stopping,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00168}00168\ \ \ \ \ \ \ \ \ validation\_fraction=validation\_fraction,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00169}00169\ \ \ \ \ \ \ \ \ max\_iter=max\_iter,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00170}00170\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=n\_iter\_no\_change,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00171}00171\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00172}00172\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00173}00173\ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00174}00174\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00175}00175\ \ \ \ \ \textcolor{keywordflow}{if}\ early\_stopping\ \textcolor{keywordflow}{is}\ \textcolor{keyword}{True}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00176}00176\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ n\_iter\_no\_change\ <=\ gb.n\_iter\_\ <\ max\_iter}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00177}00177\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00178}00178\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ gb.n\_iter\_\ ==\ max\_iter}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00179}00179\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00180}00180\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00181}00181\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00182}00182\ \ \ \ \ \textcolor{stringliteral}{"{}GradientBoosting,\ X,\ y"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00183}00183\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00184}00184\ \ \ \ \ \ \ \ \ (HistGradientBoostingClassifier,\ *\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a3cb0417328a4806f2391c495dd0a1d7d}{\_make\_dumb\_dataset}}(10000)),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00185}00185\ \ \ \ \ \ \ \ \ (HistGradientBoostingClassifier,\ *\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a3cb0417328a4806f2391c495dd0a1d7d}{\_make\_dumb\_dataset}}(10001)),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00186}00186\ \ \ \ \ \ \ \ \ (HistGradientBoostingRegressor,\ *\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a3cb0417328a4806f2391c495dd0a1d7d}{\_make\_dumb\_dataset}}(10000)),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00187}00187\ \ \ \ \ \ \ \ \ (HistGradientBoostingRegressor,\ *\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a3cb0417328a4806f2391c495dd0a1d7d}{\_make\_dumb\_dataset}}(10001)),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00188}00188\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00189}00189\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00190}00190\ \textcolor{keyword}{def\ }test\_early\_stopping\_default(GradientBoosting,\ X,\ y):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00191}00191\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ early\ stopping\ is\ enabled\ by\ default\ if\ and\ only\ if\ there}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00192}00192\ \ \ \ \ \textcolor{comment}{\#\ are\ more\ than\ 10000\ samples}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00193}00193\ \ \ \ \ gb\ =\ GradientBoosting(max\_iter=10,\ n\_iter\_no\_change=2,\ tol=1e-\/1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00194}00194\ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00195}00195\ \ \ \ \ \textcolor{keywordflow}{if}\ X.shape[0]\ >\ 10000:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00196}00196\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ gb.n\_iter\_\ <\ gb.max\_iter}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00197}00197\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00198}00198\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ gb.n\_iter\_\ ==\ gb.max\_iter}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00199}00199\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00200}00200\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00201}00201\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00202}00202\ \ \ \ \ \textcolor{stringliteral}{"{}scores,\ n\_iter\_no\_change,\ tol,\ stopping"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00203}00203\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00204}00204\ \ \ \ \ \ \ \ \ ([],\ 1,\ 0.001,\ \textcolor{keyword}{False}),\ \ \textcolor{comment}{\#\ not\ enough\ iterations}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00205}00205\ \ \ \ \ \ \ \ \ ([1,\ 1,\ 1],\ 5,\ 0.001,\ \textcolor{keyword}{False}),\ \ \textcolor{comment}{\#\ not\ enough\ iterations}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00206}00206\ \ \ \ \ \ \ \ \ ([1,\ 1,\ 1,\ 1,\ 1],\ 5,\ 0.001,\ \textcolor{keyword}{False}),\ \ \textcolor{comment}{\#\ not\ enough\ iterations}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00207}00207\ \ \ \ \ \ \ \ \ ([1,\ 2,\ 3,\ 4,\ 5,\ 6],\ 5,\ 0.001,\ \textcolor{keyword}{False}),\ \ \textcolor{comment}{\#\ significant\ improvement}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00208}00208\ \ \ \ \ \ \ \ \ ([1,\ 2,\ 3,\ 4,\ 5,\ 6],\ 5,\ 0.0,\ \textcolor{keyword}{False}),\ \ \textcolor{comment}{\#\ significant\ improvement}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00209}00209\ \ \ \ \ \ \ \ \ ([1,\ 2,\ 3,\ 4,\ 5,\ 6],\ 5,\ 0.999,\ \textcolor{keyword}{False}),\ \ \textcolor{comment}{\#\ significant\ improvement}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00210}00210\ \ \ \ \ \ \ \ \ ([1,\ 2,\ 3,\ 4,\ 5,\ 6],\ 5,\ 5\ -\/\ 1e-\/5,\ \textcolor{keyword}{False}),\ \ \textcolor{comment}{\#\ significant\ improvement}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00211}00211\ \ \ \ \ \ \ \ \ ([1]\ *\ 6,\ 5,\ 0.0,\ \textcolor{keyword}{True}),\ \ \textcolor{comment}{\#\ no\ significant\ improvement}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00212}00212\ \ \ \ \ \ \ \ \ ([1]\ *\ 6,\ 5,\ 0.001,\ \textcolor{keyword}{True}),\ \ \textcolor{comment}{\#\ no\ significant\ improvement}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00213}00213\ \ \ \ \ \ \ \ \ ([1]\ *\ 6,\ 5,\ 5,\ \textcolor{keyword}{True}),\ \ \textcolor{comment}{\#\ no\ significant\ improvement}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00214}00214\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00215}00215\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00216}00216\ \textcolor{keyword}{def\ }test\_should\_stop(scores,\ n\_iter\_no\_change,\ tol,\ stopping):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00217}00217\ \ \ \ \ gbdt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(n\_iter\_no\_change=n\_iter\_no\_change,\ tol=tol)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00218}00218\ \ \ \ \ \textcolor{keyword}{assert}\ gbdt.\_should\_stop(scores)\ ==\ stopping}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00219}00219\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00220}00220\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00221}00221\ \textcolor{keyword}{def\ }test\_absolute\_error():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00222}00222\ \ \ \ \ \textcolor{comment}{\#\ For\ coverage\ only.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00223}00223\ \ \ \ \ X,\ y\ =\ make\_regression(n\_samples=500,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00224}00224\ \ \ \ \ gbdt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}absolute\_error"{}},\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00225}00225\ \ \ \ \ gbdt.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00226}00226\ \ \ \ \ \textcolor{keyword}{assert}\ gbdt.score(X,\ y)\ >\ 0.9}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00227}00227\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00228}00228\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00229}00229\ \textcolor{keyword}{def\ }test\_absolute\_error\_sample\_weight():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00230}00230\ \ \ \ \ \textcolor{comment}{\#\ non\ regression\ test\ for\ issue\ \#19400}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00231}00231\ \ \ \ \ \textcolor{comment}{\#\ make\ sure\ no\ error\ is\ thrown\ during\ fit\ of}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00232}00232\ \ \ \ \ \textcolor{comment}{\#\ HistGradientBoostingRegressor\ with\ absolute\_error\ loss\ function}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00233}00233\ \ \ \ \ \textcolor{comment}{\#\ and\ passing\ sample\_weight}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00234}00234\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00235}00235\ \ \ \ \ n\_samples\ =\ 100}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00236}00236\ \ \ \ \ X\ =\ rng.uniform(-\/1,\ 1,\ size=(n\_samples,\ 2))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00237}00237\ \ \ \ \ y\ =\ rng.uniform(-\/1,\ 1,\ size=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00238}00238\ \ \ \ \ sample\_weight\ =\ rng.uniform(0,\ 1,\ size=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00239}00239\ \ \ \ \ gbdt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}absolute\_error"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00240}00240\ \ \ \ \ gbdt.fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00241}00241\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00242}00242\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00243}00243\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}y"{},\ [([1.0,\ -\/2.0,\ 0.0])},\ ([0.0,\ 1.0,\ 2.0])])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00244}00244\ \textcolor{keyword}{def\ }test\_gamma\_y\_positive(y):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00245}00245\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ ValueError\ is\ raised\ if\ any\ y\_i\ <=\ 0.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00246}00246\ \ \ \ \ err\_msg\ =\ \textcolor{stringliteral}{r"{}loss='gamma'\ requires\ strictly\ positive\ y."{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00247}00247\ \ \ \ \ gbdt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}gamma"{}},\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00248}00248\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=err\_msg):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00249}00249\ \ \ \ \ \ \ \ \ gbdt.fit(np.zeros(shape=(len(y),\ 1)),\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00250}00250\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00251}00251\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00252}00252\ \textcolor{keyword}{def\ }test\_gamma():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00253}00253\ \ \ \ \ \textcolor{comment}{\#\ For\ a\ Gamma\ distributed\ target,\ we\ expect\ an\ HGBT\ trained\ with\ the\ Gamma\ deviance}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00254}00254\ \ \ \ \ \textcolor{comment}{\#\ (loss)\ to\ give\ better\ results\ than\ an\ HGBT\ with\ any\ other\ loss\ function,\ measured}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00255}00255\ \ \ \ \ \textcolor{comment}{\#\ in\ out-\/of-\/sample\ Gamma\ deviance\ as\ metric/score.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00256}00256\ \ \ \ \ \textcolor{comment}{\#\ Note\ that\ squared\ error\ could\ potentially\ predict\ negative\ values\ which\ is}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00257}00257\ \ \ \ \ \textcolor{comment}{\#\ invalid\ (np.inf)\ for\ the\ Gamma\ deviance.\ A\ Poisson\ HGBT\ (having\ a\ log\ link)}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00258}00258\ \ \ \ \ \textcolor{comment}{\#\ does\ not\ have\ that\ defect.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00259}00259\ \ \ \ \ \textcolor{comment}{\#\ Important\ note:\ It\ seems\ that\ a\ Poisson\ HGBT\ almost\ always\ has\ better}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00260}00260\ \ \ \ \ \textcolor{comment}{\#\ out-\/of-\/sample\ performance\ than\ the\ Gamma\ HGBT,\ measured\ in\ Gamma\ deviance.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00261}00261\ \ \ \ \ \textcolor{comment}{\#\ LightGBM\ shows\ the\ same\ behaviour.\ Hence,\ we\ only\ compare\ to\ a\ squared\ error}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00262}00262\ \ \ \ \ \textcolor{comment}{\#\ HGBT,\ but\ not\ to\ a\ Poisson\ deviance\ HGBT.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00263}00263\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00264}00264\ \ \ \ \ n\_train,\ n\_test,\ n\_features\ =\ 500,\ 100,\ 20}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00265}00265\ \ \ \ \ X\ =\ make\_low\_rank\_matrix(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00266}00266\ \ \ \ \ \ \ \ \ n\_samples=n\_train\ +\ n\_test,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00267}00267\ \ \ \ \ \ \ \ \ n\_features=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00268}00268\ \ \ \ \ \ \ \ \ random\_state=rng,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00269}00269\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00270}00270\ \ \ \ \ \textcolor{comment}{\#\ We\ create\ a\ log-\/linear\ Gamma\ model.\ This\ gives\ y.min\ \string~\ 1e-\/2,\ y.max\ \string~\ 1e2}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00271}00271\ \ \ \ \ coef\ =\ rng.uniform(low=-\/10,\ high=20,\ size=n\_features)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00272}00272\ \ \ \ \ \textcolor{comment}{\#\ Numpy\ parametrizes\ gamma(shape=k,\ scale=theta)\ with\ mean\ =\ k\ *\ theta\ and}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00273}00273\ \ \ \ \ \textcolor{comment}{\#\ variance\ =\ k\ *\ theta\string^2.\ We\ parametrize\ it\ instead\ with\ mean\ =\ exp(X\ @\ coef)}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00274}00274\ \ \ \ \ \textcolor{comment}{\#\ and\ variance\ =\ dispersion\ *\ mean\string^2\ by\ setting\ k\ =\ 1\ /\ dispersion,}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00275}00275\ \ \ \ \ \textcolor{comment}{\#\ theta\ =\ \ dispersion\ *\ mean.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00276}00276\ \ \ \ \ dispersion\ =\ 0.5}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00277}00277\ \ \ \ \ y\ =\ rng.gamma(shape=1\ /\ dispersion,\ scale=dispersion\ *\ np.exp(X\ @\ coef))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00278}00278\ \ \ \ \ X\_train,\ X\_test,\ y\_train,\ y\_test\ =\ train\_test\_split(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00279}00279\ \ \ \ \ \ \ \ \ X,\ y,\ test\_size=n\_test,\ random\_state=rng}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00280}00280\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00281}00281\ \ \ \ \ gbdt\_gamma\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}gamma"{}},\ random\_state=123)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00282}00282\ \ \ \ \ gbdt\_mse\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}squared\_error"{}},\ random\_state=123)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00283}00283\ \ \ \ \ dummy\ =\ \mbox{\hyperlink{classsklearn_1_1dummy_1_1DummyRegressor}{DummyRegressor}}(strategy=\textcolor{stringliteral}{"{}mean"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00284}00284\ \ \ \ \ \textcolor{keywordflow}{for}\ model\ \textcolor{keywordflow}{in}\ (gbdt\_gamma,\ gbdt\_mse,\ dummy):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00285}00285\ \ \ \ \ \ \ \ \ model.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00286}00286\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00287}00287\ \ \ \ \ \textcolor{keywordflow}{for}\ X,\ y\ \textcolor{keywordflow}{in}\ [(X\_train,\ y\_train),\ (X\_test,\ y\_test)]:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00288}00288\ \ \ \ \ \ \ \ \ loss\_gbdt\_gamma\ =\ mean\_gamma\_deviance(y,\ gbdt\_gamma.predict(X))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00289}00289\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ We\ restrict\ the\ squared\ error\ HGBT\ to\ predict\ at\ least\ the\ minimum\ seen\ y\ at}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00290}00290\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ train\ time\ to\ make\ it\ strictly\ positive.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00291}00291\ \ \ \ \ \ \ \ \ loss\_gbdt\_mse\ =\ mean\_gamma\_deviance(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00292}00292\ \ \ \ \ \ \ \ \ \ \ \ \ y,\ np.maximum(np.min(y\_train),\ gbdt\_mse.predict(X))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00293}00293\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00294}00294\ \ \ \ \ \ \ \ \ loss\_dummy\ =\ mean\_gamma\_deviance(y,\ dummy.predict(X))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00295}00295\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ loss\_gbdt\_gamma\ <\ loss\_dummy}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00296}00296\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ loss\_gbdt\_gamma\ <\ loss\_gbdt\_mse}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00297}00297\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00298}00298\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00299}00299\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}quantile"{},\ [0.2,\ 0.5,\ 0.8])}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00300}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_af3b530d2aac41e4b441974cd56c02041}{00300}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_af3b530d2aac41e4b441974cd56c02041}{test\_quantile\_asymmetric\_error}}(quantile):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00301}00301\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ quantile\ regression\ for\ asymmetric\ distributed\ targets."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00302}00302\ \ \ \ \ n\_samples\ =\ 10\_000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00303}00303\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00304}00304\ \ \ \ \ \textcolor{comment}{\#\ take\ care\ that\ X\ @\ coef\ +\ intercept\ >\ 0}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00305}00305\ \ \ \ \ X\ =\ np.concatenate(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00306}00306\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00307}00307\ \ \ \ \ \ \ \ \ \ \ \ \ np.abs(rng.randn(n\_samples)[:,\ \textcolor{keywordtype}{None}]),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00308}00308\ \ \ \ \ \ \ \ \ \ \ \ \ -\/rng.randint(2,\ size=(n\_samples,\ 1)),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00309}00309\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00310}00310\ \ \ \ \ \ \ \ \ axis=1,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00311}00311\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00312}00312\ \ \ \ \ intercept\ =\ 1.23}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00313}00313\ \ \ \ \ coef\ =\ np.array([0.5,\ -\/2])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00314}00314\ \ \ \ \ \textcolor{comment}{\#\ For\ an\ exponential\ distribution\ with\ rate\ lambda,\ e.g.\ exp(-\/lambda\ *\ x),}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00315}00315\ \ \ \ \ \textcolor{comment}{\#\ the\ quantile\ at\ level\ q\ is:}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00316}00316\ \ \ \ \ \textcolor{comment}{\#\ \ \ quantile(q)\ =\ -\/\ log(1\ -\/\ q)\ /\ lambda}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00317}00317\ \ \ \ \ \textcolor{comment}{\#\ \ \ scale\ =\ 1/lambda\ =\ -\/quantile(q)\ /\ log(1-\/q)}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00318}00318\ \ \ \ \ y\ =\ rng.exponential(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00319}00319\ \ \ \ \ \ \ \ \ scale=-\/(X\ @\ coef\ +\ intercept)\ /\ np.log(1\ -\/\ quantile),\ size=n\_samples}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00320}00320\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00321}00321\ \ \ \ \ model\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00322}00322\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}quantile"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00323}00323\ \ \ \ \ \ \ \ \ quantile=quantile,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00324}00324\ \ \ \ \ \ \ \ \ max\_iter=25,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00325}00325\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00326}00326\ \ \ \ \ \ \ \ \ max\_leaf\_nodes=10,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00327}00327\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00328}00328\ \ \ \ \ assert\_allclose(np.mean(model.predict(X)\ >\ y),\ quantile,\ rtol=1e-\/2)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00329}00329\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00330}00330\ \ \ \ \ pinball\_loss\ =\ \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1PinballLoss}{PinballLoss}}(quantile=quantile)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00331}00331\ \ \ \ \ loss\_true\_quantile\ =\ pinball\_loss(y,\ X\ @\ coef\ +\ intercept)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00332}00332\ \ \ \ \ loss\_pred\_quantile\ =\ pinball\_loss(y,\ model.predict(X))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00333}00333\ \ \ \ \ \textcolor{comment}{\#\ we\ are\ overfitting}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00334}00334\ \ \ \ \ \textcolor{keyword}{assert}\ loss\_pred\_quantile\ <=\ loss\_true\_quantile}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00335}00335\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00336}00336\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00337}00337\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}y"{},\ [([1.0,\ -\/2.0,\ 0.0])},\ ([0.0,\ 0.0,\ 0.0])])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00338}00338\ \textcolor{keyword}{def\ }test\_poisson\_y\_positive(y):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00339}00339\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ ValueError\ is\ raised\ if\ either\ one\ y\_i\ <\ 0\ or\ sum(y\_i)\ <=\ 0.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00340}00340\ \ \ \ \ err\_msg\ =\ \textcolor{stringliteral}{r"{}loss='poisson'\ requires\ non-\/negative\ y\ and\ sum\(\backslash\)(y\(\backslash\))\ >\ 0."{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00341}00341\ \ \ \ \ gbdt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}poisson"{}},\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00342}00342\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=err\_msg):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00343}00343\ \ \ \ \ \ \ \ \ gbdt.fit(np.zeros(shape=(len(y),\ 1)),\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00344}00344\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00345}00345\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00346}00346\ \textcolor{keyword}{def\ }test\_poisson():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00347}00347\ \ \ \ \ \textcolor{comment}{\#\ For\ Poisson\ distributed\ target,\ Poisson\ loss\ should\ give\ better\ results}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00348}00348\ \ \ \ \ \textcolor{comment}{\#\ than\ least\ squares\ measured\ in\ Poisson\ deviance\ as\ metric.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00349}00349\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00350}00350\ \ \ \ \ n\_train,\ n\_test,\ n\_features\ =\ 500,\ 100,\ 100}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00351}00351\ \ \ \ \ X\ =\ make\_low\_rank\_matrix(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00352}00352\ \ \ \ \ \ \ \ \ n\_samples=n\_train\ +\ n\_test,\ n\_features=n\_features,\ random\_state=rng}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00353}00353\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00354}00354\ \ \ \ \ \textcolor{comment}{\#\ We\ create\ a\ log-\/linear\ Poisson\ model\ and\ downscale\ coef\ as\ it\ will\ get}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00355}00355\ \ \ \ \ \textcolor{comment}{\#\ exponentiated.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00356}00356\ \ \ \ \ coef\ =\ rng.uniform(low=-\/2,\ high=2,\ size=n\_features)\ /\ np.max(X,\ axis=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00357}00357\ \ \ \ \ y\ =\ rng.poisson(lam=np.exp(X\ @\ coef))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00358}00358\ \ \ \ \ X\_train,\ X\_test,\ y\_train,\ y\_test\ =\ train\_test\_split(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00359}00359\ \ \ \ \ \ \ \ \ X,\ y,\ test\_size=n\_test,\ random\_state=rng}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00360}00360\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00361}00361\ \ \ \ \ gbdt\_pois\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}poisson"{}},\ random\_state=rng)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00362}00362\ \ \ \ \ gbdt\_ls\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}squared\_error"{}},\ random\_state=rng)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00363}00363\ \ \ \ \ gbdt\_pois.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00364}00364\ \ \ \ \ gbdt\_ls.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00365}00365\ \ \ \ \ dummy\ =\ \mbox{\hyperlink{classsklearn_1_1dummy_1_1DummyRegressor}{DummyRegressor}}(strategy=\textcolor{stringliteral}{"{}mean"{}}).fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00366}00366\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00367}00367\ \ \ \ \ \textcolor{keywordflow}{for}\ X,\ y\ \textcolor{keywordflow}{in}\ [(X\_train,\ y\_train),\ (X\_test,\ y\_test)]:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00368}00368\ \ \ \ \ \ \ \ \ metric\_pois\ =\ mean\_poisson\_deviance(y,\ gbdt\_pois.predict(X))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00369}00369\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ squared\_error\ might\ produce\ non-\/positive\ predictions\ =>\ clip}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00370}00370\ \ \ \ \ \ \ \ \ metric\_ls\ =\ mean\_poisson\_deviance(y,\ np.clip(gbdt\_ls.predict(X),\ 1e-\/15,\ \textcolor{keywordtype}{None}))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00371}00371\ \ \ \ \ \ \ \ \ metric\_dummy\ =\ mean\_poisson\_deviance(y,\ dummy.predict(X))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00372}00372\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ metric\_pois\ <\ metric\_ls}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00373}00373\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ metric\_pois\ <\ metric\_dummy}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00374}00374\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00375}00375\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00376}00376\ \textcolor{keyword}{def\ }test\_binning\_train\_validation\_are\_separated():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00377}00377\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ training\ and\ validation\ data\ are\ binned\ separately.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00378}00378\ \ \ \ \ \textcolor{comment}{\#\ See\ issue\ 13926}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00379}00379\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00380}00380\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00381}00381\ \ \ \ \ validation\_fraction\ =\ 0.2}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00382}00382\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00383}00383\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},\ validation\_fraction=validation\_fraction,\ random\_state=rng}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00384}00384\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00385}00385\ \ \ \ \ gb.fit(X\_classification,\ y\_classification)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00386}00386\ \ \ \ \ mapper\_training\_data\ =\ gb.\_bin\_mapper}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00387}00387\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00388}00388\ \ \ \ \ \textcolor{comment}{\#\ Note\ that\ since\ the\ data\ is\ small\ there\ is\ no\ subsampling\ and\ the}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00389}00389\ \ \ \ \ \textcolor{comment}{\#\ random\_state\ doesn't\ matter}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00390}00390\ \ \ \ \ mapper\_whole\_data\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1binning_1_1__BinMapper}{\_BinMapper}}(random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00391}00391\ \ \ \ \ mapper\_whole\_data.fit(X\_classification)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00392}00392\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00393}00393\ \ \ \ \ n\_samples\ =\ X\_classification.shape[0]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00394}00394\ \ \ \ \ \textcolor{keyword}{assert}\ np.all(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00395}00395\ \ \ \ \ \ \ \ \ mapper\_training\_data.n\_bins\_non\_missing\_}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00396}00396\ \ \ \ \ \ \ \ \ ==\ int((1\ -\/\ validation\_fraction)\ *\ n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00397}00397\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00398}00398\ \ \ \ \ \textcolor{keyword}{assert}\ np.all(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00399}00399\ \ \ \ \ \ \ \ \ mapper\_training\_data.n\_bins\_non\_missing\_}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00400}00400\ \ \ \ \ \ \ \ \ !=\ mapper\_whole\_data.n\_bins\_non\_missing\_}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00401}00401\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00402}00402\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00403}00403\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00404}00404\ \textcolor{keyword}{def\ }test\_missing\_values\_trivial():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00405}00405\ \ \ \ \ \textcolor{comment}{\#\ sanity\ check\ for\ missing\ values\ support.\ With\ only\ one\ feature\ and}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00406}00406\ \ \ \ \ \textcolor{comment}{\#\ y\ ==\ isnan(X),\ the\ gbdt\ is\ supposed\ to\ reach\ perfect\ accuracy\ on\ the}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00407}00407\ \ \ \ \ \textcolor{comment}{\#\ training\ set.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00408}00408\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00409}00409\ \ \ \ \ n\_samples\ =\ 100}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00410}00410\ \ \ \ \ n\_features\ =\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00411}00411\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00412}00412\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00413}00413\ \ \ \ \ X\ =\ rng.normal(size=(n\_samples,\ n\_features))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00414}00414\ \ \ \ \ mask\ =\ rng.binomial(1,\ 0.5,\ size=X.shape).astype(bool)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00415}00415\ \ \ \ \ X[mask]\ =\ np.nan}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00416}00416\ \ \ \ \ y\ =\ mask.ravel()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00417}00417\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00418}00418\ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00419}00419\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00420}00420\ \ \ \ \ \textcolor{keyword}{assert}\ gb.score(X,\ y)\ ==\ pytest.approx(1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00421}00421\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00422}00422\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00423}00423\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}problem"{},\ ("{}classification"{},\ "{}regression"{})})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00424}00424\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00425}00425\ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00426}00426\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}missing\_proportion,\ expected\_min\_score\_classification,\ "{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00427}00427\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}expected\_min\_score\_regression"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00428}00428\ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00429}00429\ \ \ \ \ [(0.1,\ 0.97,\ 0.89),\ (0.2,\ 0.93,\ 0.81),\ (0.5,\ 0.79,\ 0.52)],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00430}00430\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00431}00431\ \textcolor{keyword}{def\ }test\_missing\_values\_resilience(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00432}00432\ \ \ \ \ problem,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00433}00433\ \ \ \ \ missing\_proportion,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00434}00434\ \ \ \ \ expected\_min\_score\_classification,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00435}00435\ \ \ \ \ expected\_min\_score\_regression,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00436}00436\ ):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00437}00437\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ the\ estimators\ can\ deal\ with\ missing\ values\ and\ still\ yield}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00438}00438\ \ \ \ \ \textcolor{comment}{\#\ decent\ predictions}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00439}00439\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00440}00440\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00441}00441\ \ \ \ \ n\_samples\ =\ 1000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00442}00442\ \ \ \ \ n\_features\ =\ 2}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00443}00443\ \ \ \ \ \textcolor{keywordflow}{if}\ problem\ ==\ \textcolor{stringliteral}{"{}regression"{}}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00444}00444\ \ \ \ \ \ \ \ \ X,\ y\ =\ make\_regression(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00445}00445\ \ \ \ \ \ \ \ \ \ \ \ \ n\_samples=n\_samples,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00446}00446\ \ \ \ \ \ \ \ \ \ \ \ \ n\_features=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00447}00447\ \ \ \ \ \ \ \ \ \ \ \ \ n\_informative=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00448}00448\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=rng,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00449}00449\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00450}00450\ \ \ \ \ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00451}00451\ \ \ \ \ \ \ \ \ expected\_min\_score\ =\ expected\_min\_score\_regression}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00452}00452\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00453}00453\ \ \ \ \ \ \ \ \ X,\ y\ =\ make\_classification(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00454}00454\ \ \ \ \ \ \ \ \ \ \ \ \ n\_samples=n\_samples,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00455}00455\ \ \ \ \ \ \ \ \ \ \ \ \ n\_features=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00456}00456\ \ \ \ \ \ \ \ \ \ \ \ \ n\_informative=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00457}00457\ \ \ \ \ \ \ \ \ \ \ \ \ n\_redundant=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00458}00458\ \ \ \ \ \ \ \ \ \ \ \ \ n\_repeated=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00459}00459\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=rng,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00460}00460\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00461}00461\ \ \ \ \ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00462}00462\ \ \ \ \ \ \ \ \ expected\_min\_score\ =\ expected\_min\_score\_classification}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00463}00463\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00464}00464\ \ \ \ \ mask\ =\ rng.binomial(1,\ missing\_proportion,\ size=X.shape).astype(bool)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00465}00465\ \ \ \ \ X[mask]\ =\ np.nan}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00466}00466\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00467}00467\ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00468}00468\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00469}00469\ \ \ \ \ \textcolor{keyword}{assert}\ gb.score(X,\ y)\ >\ expected\_min\_score}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00470}00470\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00471}00471\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00472}00472\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00473}00473\ \ \ \ \ \textcolor{stringliteral}{"{}data"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00474}00474\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00475}00475\ \ \ \ \ \ \ \ \ make\_classification(random\_state=0,\ n\_classes=2),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00476}00476\ \ \ \ \ \ \ \ \ make\_classification(random\_state=0,\ n\_classes=3,\ n\_informative=3),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00477}00477\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00478}00478\ \ \ \ \ ids=[\textcolor{stringliteral}{"{}binary\_log\_loss"{}},\ \textcolor{stringliteral}{"{}multiclass\_log\_loss"{}}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00479}00479\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00480}00480\ \textcolor{keyword}{def\ }test\_zero\_division\_hessians(data):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00481}00481\ \ \ \ \ \textcolor{comment}{\#\ non\ regression\ test\ for\ issue\ \#14018}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00482}00482\ \ \ \ \ \textcolor{comment}{\#\ make\ sure\ we\ avoid\ zero\ division\ errors\ when\ computing\ the\ leaves\ values.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00483}00483\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00484}00484\ \ \ \ \ \textcolor{comment}{\#\ If\ the\ learning\ rate\ is\ too\ high,\ the\ raw\ predictions\ are\ bad\ and\ will}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00485}00485\ \ \ \ \ \textcolor{comment}{\#\ saturate\ the\ softmax\ (or\ sigmoid\ in\ binary\ classif).\ This\ leads\ to}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00486}00486\ \ \ \ \ \textcolor{comment}{\#\ probabilities\ being\ exactly\ 0\ or\ 1,\ gradients\ being\ constant,\ and}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00487}00487\ \ \ \ \ \textcolor{comment}{\#\ hessians\ being\ zero.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00488}00488\ \ \ \ \ X,\ y\ =\ data}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00489}00489\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(learning\_rate=100,\ max\_iter=10)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00490}00490\ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00491}00491\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00492}00492\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00493}00493\ \textcolor{keyword}{def\ }test\_small\_trainset():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00494}00494\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ that\ the\ small\ trainset\ is\ stratified\ and\ has\ the\ expected}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00495}00495\ \ \ \ \ \textcolor{comment}{\#\ length\ (10k\ samples)}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00496}00496\ \ \ \ \ n\_samples\ =\ 20000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00497}00497\ \ \ \ \ original\_distrib\ =\ \{0:\ 0.1,\ 1:\ 0.2,\ 2:\ 0.3,\ 3:\ 0.4\}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00498}00498\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00499}00499\ \ \ \ \ X\ =\ rng.randn(n\_samples).reshape(n\_samples,\ 1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00500}00500\ \ \ \ \ y\ =\ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00501}00501\ \ \ \ \ \ \ \ \ [class\_]\ *\ int(prop\ *\ n\_samples)\ \textcolor{keywordflow}{for}\ (class\_,\ prop)\ \textcolor{keywordflow}{in}\ original\_distrib.items()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00502}00502\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00503}00503\ \ \ \ \ y\ =\ shuffle(np.concatenate(y))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00504}00504\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00505}00505\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00506}00506\ \ \ \ \ \textcolor{comment}{\#\ Compute\ the\ small\ training\ set}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00507}00507\ \ \ \ \ X\_small,\ y\_small,\ *\_\ =\ gb.\_get\_small\_trainset(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00508}00508\ \ \ \ \ \ \ \ \ X,\ y,\ seed=42,\ sample\_weight\_train=\textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00509}00509\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00510}00510\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00511}00511\ \ \ \ \ \textcolor{comment}{\#\ Compute\ the\ class\ distribution\ in\ the\ small\ training\ set}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00512}00512\ \ \ \ \ unique,\ counts\ =\ np.unique(y\_small,\ return\_counts=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00513}00513\ \ \ \ \ small\_distrib\ =\ \{class\_:\ count\ /\ 10000\ \textcolor{keywordflow}{for}\ (class\_,\ count)\ \textcolor{keywordflow}{in}\ zip(unique,\ counts)\}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00514}00514\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00515}00515\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ the\ small\ training\ set\ has\ the\ expected\ length}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00516}00516\ \ \ \ \ \textcolor{keyword}{assert}\ X\_small.shape[0]\ ==\ 10000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00517}00517\ \ \ \ \ \textcolor{keyword}{assert}\ y\_small.shape[0]\ ==\ 10000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00518}00518\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00519}00519\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ the\ class\ distributions\ in\ the\ whole\ dataset\ and\ in\ the\ small}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00520}00520\ \ \ \ \ \textcolor{comment}{\#\ training\ set\ are\ identical}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00521}00521\ \ \ \ \ \textcolor{keyword}{assert}\ small\_distrib\ ==\ pytest.approx(original\_distrib)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00522}00522\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00523}00523\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00524}00524\ \textcolor{keyword}{def\ }test\_missing\_values\_minmax\_imputation():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00525}00525\ \ \ \ \ \textcolor{comment}{\#\ Compare\ the\ buit-\/in\ missing\ value\ handling\ of\ Histogram\ GBC\ with\ an}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00526}00526\ \ \ \ \ \textcolor{comment}{\#\ a-\/priori\ missing\ value\ imputation\ strategy\ that\ should\ yield\ the\ same}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00527}00527\ \ \ \ \ \textcolor{comment}{\#\ results\ in\ terms\ of\ decision\ function.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00528}00528\ \ \ \ \ \textcolor{comment}{\#}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00529}00529\ \ \ \ \ \textcolor{comment}{\#\ Each\ feature\ (containing\ NaNs)\ is\ replaced\ by\ 2\ features:}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00530}00530\ \ \ \ \ \textcolor{comment}{\#\ -\/\ one\ where\ the\ nans\ are\ replaced\ by\ min(feature)\ -\/\ 1}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00531}00531\ \ \ \ \ \textcolor{comment}{\#\ -\/\ one\ where\ the\ nans\ are\ replaced\ by\ max(feature)\ +\ 1}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00532}00532\ \ \ \ \ \textcolor{comment}{\#\ A\ split\ where\ nans\ go\ to\ the\ left\ has\ an\ equivalent\ split\ in\ the}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00533}00533\ \ \ \ \ \textcolor{comment}{\#\ first\ (min)\ feature,\ and\ a\ split\ where\ nans\ go\ to\ the\ right\ has\ an}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00534}00534\ \ \ \ \ \textcolor{comment}{\#\ equivalent\ split\ in\ the\ second\ (max)\ feature.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00535}00535\ \ \ \ \ \textcolor{comment}{\#}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00536}00536\ \ \ \ \ \textcolor{comment}{\#\ Assuming\ the\ data\ is\ such\ that\ there\ is\ never\ a\ tie\ to\ select\ the\ best}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00537}00537\ \ \ \ \ \textcolor{comment}{\#\ feature\ to\ split\ on\ during\ training,\ the\ learned\ decision\ trees\ should\ be}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00538}00538\ \ \ \ \ \textcolor{comment}{\#\ strictly\ equivalent\ (learn\ a\ sequence\ of\ splits\ that\ encode\ the\ same}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00539}00539\ \ \ \ \ \textcolor{comment}{\#\ decision\ function).}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00540}00540\ \ \ \ \ \textcolor{comment}{\#}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00541}00541\ \ \ \ \ \textcolor{comment}{\#\ The\ MinMaxImputer\ transformer\ is\ meant\ to\ be\ a\ toy\ implementation\ of\ the}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00542}00542\ \ \ \ \ \textcolor{comment}{\#\ "{}Missing\ In\ Attributes"{}\ (MIA)\ missing\ value\ handling\ for\ decision\ trees}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00543}00543\ \ \ \ \ \textcolor{comment}{\#\ https://www.sciencedirect.com/science/article/abs/pii/S0167865508000305}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00544}00544\ \ \ \ \ \textcolor{comment}{\#\ The\ implementation\ of\ MIA\ as\ an\ imputation\ transformer\ was\ suggested\ by}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00545}00545\ \ \ \ \ \textcolor{comment}{\#\ "{}Remark\ 3"{}\ in\ :arxiv:'<1902.06931>`}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00546}00546\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00547}00547\ \ \ \ \ \textcolor{keyword}{class\ }MinMaxImputer(\mbox{\hyperlink{classsklearn_1_1base_1_1TransformerMixin}{TransformerMixin}},\ \mbox{\hyperlink{classsklearn_1_1base_1_1BaseEstimator}{BaseEstimator}}):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00548}00548\ \ \ \ \ \ \ \ \ \textcolor{keyword}{def\ }fit(self,\ X,\ y=None):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00549}00549\ \ \ \ \ \ \ \ \ \ \ \ \ mm\ =\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__data_1_1MinMaxScaler}{MinMaxScaler}}().fit(X)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00550}00550\ \ \ \ \ \ \ \ \ \ \ \ \ self.data\_min\_\ =\ mm.data\_min\_}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00551}00551\ \ \ \ \ \ \ \ \ \ \ \ \ self.data\_max\_\ =\ mm.data\_max\_}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00552}00552\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00553}00553\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00554}00554\ \ \ \ \ \ \ \ \ \textcolor{keyword}{def\ }transform(self,\ X):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00555}00555\ \ \ \ \ \ \ \ \ \ \ \ \ X\_min,\ X\_max\ =\ X.copy(),\ X.copy()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00556}00556\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00557}00557\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ feature\_idx\ \textcolor{keywordflow}{in}\ range(X.shape[1]):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00558}00558\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ nan\_mask\ =\ np.isnan(X[:,\ feature\_idx])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00559}00559\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_min[nan\_mask,\ feature\_idx]\ =\ self.data\_min\_[feature\_idx]\ -\/\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00560}00560\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ X\_max[nan\_mask,\ feature\_idx]\ =\ self.data\_max\_[feature\_idx]\ +\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00561}00561\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00562}00562\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ np.concatenate([X\_min,\ X\_max],\ axis=1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00563}00563\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00564}00564\ \ \ \ \ \textcolor{keyword}{def\ }make\_missing\_value\_data(n\_samples=int(1e4),\ seed=0):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00565}00565\ \ \ \ \ \ \ \ \ rng\ =\ np.random.RandomState(seed)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00566}00566\ \ \ \ \ \ \ \ \ X,\ y\ =\ make\_regression(n\_samples=n\_samples,\ n\_features=4,\ random\_state=rng)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00567}00567\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00568}00568\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Pre-\/bin\ the\ data\ to\ ensure\ a\ deterministic\ handling\ by\ the\ 2}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00569}00569\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ strategies\ and\ also\ make\ it\ easier\ to\ insert\ np.nan\ in\ a\ structured}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00570}00570\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ way:}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00571}00571\ \ \ \ \ \ \ \ \ X\ =\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__discretization_1_1KBinsDiscretizer}{KBinsDiscretizer}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00572}00572\ \ \ \ \ \ \ \ \ \ \ \ \ n\_bins=42,\ encode=\textcolor{stringliteral}{"{}ordinal"{}},\ quantile\_method=\textcolor{stringliteral}{"{}averaged\_inverted\_cdf"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00573}00573\ \ \ \ \ \ \ \ \ ).fit\_transform(X)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00574}00574\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00575}00575\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ First\ feature\ has\ missing\ values\ completely\ at\ random:}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00576}00576\ \ \ \ \ \ \ \ \ rnd\_mask\ =\ rng.rand(X.shape[0])\ >\ 0.9}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00577}00577\ \ \ \ \ \ \ \ \ X[rnd\_mask,\ 0]\ =\ np.nan}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00578}00578\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00579}00579\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Second\ and\ third\ features\ have\ missing\ values\ for\ extreme\ values}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00580}00580\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ (censoring\ missingness):}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00581}00581\ \ \ \ \ \ \ \ \ low\_mask\ =\ X[:,\ 1]\ ==\ 0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00582}00582\ \ \ \ \ \ \ \ \ X[low\_mask,\ 1]\ =\ np.nan}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00583}00583\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00584}00584\ \ \ \ \ \ \ \ \ high\_mask\ =\ X[:,\ 2]\ ==\ X[:,\ 2].max()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00585}00585\ \ \ \ \ \ \ \ \ X[high\_mask,\ 2]\ =\ np.nan}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00586}00586\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00587}00587\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Make\ the\ last\ feature\ nan\ pattern\ very\ informative:}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00588}00588\ \ \ \ \ \ \ \ \ y\_max\ =\ np.percentile(y,\ 70)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00589}00589\ \ \ \ \ \ \ \ \ y\_max\_mask\ =\ y\ >=\ y\_max}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00590}00590\ \ \ \ \ \ \ \ \ y[y\_max\_mask]\ =\ y\_max}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00591}00591\ \ \ \ \ \ \ \ \ X[y\_max\_mask,\ 3]\ =\ np.nan}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00592}00592\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00593}00593\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ there\ is\ at\ least\ one\ missing\ value\ in\ each\ feature:}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00594}00594\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ feature\_idx\ \textcolor{keywordflow}{in}\ range(X.shape[1]):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00595}00595\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ any(np.isnan(X[:,\ feature\_idx]))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00596}00596\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00597}00597\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Let's\ use\ a\ test\ set\ to\ check\ that\ the\ learned\ decision\ function\ is}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00598}00598\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ the\ same\ as\ evaluated\ on\ unseen\ data.\ Otherwise\ it\ could\ just\ be\ the}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00599}00599\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ case\ that\ we\ find\ two\ independent\ ways\ to\ overfit\ the\ training\ set.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00600}00600\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ train\_test\_split(X,\ y,\ random\_state=rng)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00601}00601\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00602}00602\ \ \ \ \ \textcolor{comment}{\#\ n\_samples\ need\ to\ be\ large\ enough\ to\ minimize\ the\ likelihood\ of\ having}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00603}00603\ \ \ \ \ \textcolor{comment}{\#\ several\ candidate\ splits\ with\ the\ same\ gain\ value\ in\ a\ given\ tree.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00604}00604\ \ \ \ \ X\_train,\ X\_test,\ y\_train,\ y\_test\ =\ make\_missing\_value\_data(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00605}00605\ \ \ \ \ \ \ \ \ n\_samples=int(1e4),\ seed=0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00606}00606\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00607}00607\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00608}00608\ \ \ \ \ \textcolor{comment}{\#\ Use\ a\ small\ number\ of\ leaf\ nodes\ and\ iterations\ so\ as\ to\ keep}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00609}00609\ \ \ \ \ \textcolor{comment}{\#\ under-\/fitting\ models\ to\ minimize\ the\ likelihood\ of\ ties\ when\ training\ the}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00610}00610\ \ \ \ \ \textcolor{comment}{\#\ model.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00611}00611\ \ \ \ \ gbm1\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(max\_iter=100,\ max\_leaf\_nodes=5,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00612}00612\ \ \ \ \ gbm1.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00613}00613\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00614}00614\ \ \ \ \ gbm2\ =\ make\_pipeline(MinMaxImputer(),\ clone(gbm1))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00615}00615\ \ \ \ \ gbm2.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00616}00616\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00617}00617\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ the\ model\ reach\ the\ same\ score:}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00618}00618\ \ \ \ \ \textcolor{keyword}{assert}\ gbm1.score(X\_train,\ y\_train)\ ==\ pytest.approx(gbm2.score(X\_train,\ y\_train))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00619}00619\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00620}00620\ \ \ \ \ \textcolor{keyword}{assert}\ gbm1.score(X\_test,\ y\_test)\ ==\ pytest.approx(gbm2.score(X\_test,\ y\_test))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00621}00621\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00622}00622\ \ \ \ \ \textcolor{comment}{\#\ Check\ the\ individual\ prediction\ match\ as\ a\ finer\ grained}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00623}00623\ \ \ \ \ \textcolor{comment}{\#\ decision\ function\ check.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00624}00624\ \ \ \ \ assert\_allclose(gbm1.predict(X\_train),\ gbm2.predict(X\_train))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00625}00625\ \ \ \ \ assert\_allclose(gbm1.predict(X\_test),\ gbm2.predict(X\_test))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00626}00626\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00627}00627\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00628}00628\ \textcolor{keyword}{def\ }test\_infinite\_values():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00629}00629\ \ \ \ \ \textcolor{comment}{\#\ Basic\ test\ for\ infinite\ values}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00630}00630\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00631}00631\ \ \ \ \ X\ =\ np.array([-\/np.inf,\ 0,\ 1,\ np.inf]).reshape(-\/1,\ 1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00632}00632\ \ \ \ \ y\ =\ np.array([0,\ 0,\ 1,\ 1])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00633}00633\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00634}00634\ \ \ \ \ gbdt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(min\_samples\_leaf=1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00635}00635\ \ \ \ \ gbdt.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00636}00636\ \ \ \ \ np.testing.assert\_allclose(gbdt.predict(X),\ y,\ atol=1e-\/4)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00637}00637\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00638}00638\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00639}00639\ \textcolor{keyword}{def\ }test\_consistent\_lengths():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00640}00640\ \ \ \ \ X\ =\ np.array([-\/np.inf,\ 0,\ 1,\ np.inf]).reshape(-\/1,\ 1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00641}00641\ \ \ \ \ y\ =\ np.array([0,\ 0,\ 1,\ 1])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00642}00642\ \ \ \ \ sample\_weight\ =\ np.array([0.1,\ 0.3,\ 0.1])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00643}00643\ \ \ \ \ gbdt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00644}00644\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=\textcolor{stringliteral}{r"{}sample\_weight.shape\ ==\ \(\backslash\)(3,\(\backslash\)),\ expected"{}}):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00645}00645\ \ \ \ \ \ \ \ \ gbdt.fit(X,\ y,\ sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00646}00646\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00647}00647\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00648}00648\ \ \ \ \ \ \ \ \ ValueError,\ match=\textcolor{stringliteral}{"{}Found\ input\ variables\ with\ inconsistent\ number"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00649}00649\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00650}00650\ \ \ \ \ \ \ \ \ gbdt.fit(X,\ y[1:])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00651}00651\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00652}00652\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00653}00653\ \textcolor{keyword}{def\ }test\_infinite\_values\_missing\_values():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00654}00654\ \ \ \ \ \textcolor{comment}{\#\ High\ level\ test\ making\ sure\ that\ inf\ and\ nan\ values\ are\ properly\ handled}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00655}00655\ \ \ \ \ \textcolor{comment}{\#\ when\ both\ are\ present.\ This\ is\ similar\ to}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00656}00656\ \ \ \ \ \textcolor{comment}{\#\ test\_split\_on\_nan\_with\_infinite\_values()\ in\ test\_grower.py,\ though\ we}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00657}00657\ \ \ \ \ \textcolor{comment}{\#\ cannot\ check\ the\ predictions\ for\ binned\ values\ here.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00658}00658\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00659}00659\ \ \ \ \ X\ =\ np.asarray([-\/np.inf,\ 0,\ 1,\ np.inf,\ np.nan]).reshape(-\/1,\ 1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00660}00660\ \ \ \ \ y\_isnan\ =\ np.isnan(X.ravel())}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00661}00661\ \ \ \ \ y\_isinf\ =\ X.ravel()\ ==\ np.inf}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00662}00662\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00663}00663\ \ \ \ \ stump\_clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00664}00664\ \ \ \ \ \ \ \ \ min\_samples\_leaf=1,\ max\_iter=1,\ learning\_rate=1,\ max\_depth=2}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00665}00665\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00666}00666\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00667}00667\ \ \ \ \ \textcolor{keyword}{assert}\ stump\_clf.fit(X,\ y\_isinf).score(X,\ y\_isinf)\ ==\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00668}00668\ \ \ \ \ \textcolor{keyword}{assert}\ stump\_clf.fit(X,\ y\_isnan).score(X,\ y\_isnan)\ ==\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00669}00669\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00670}00670\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00671}00671\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}scoring"{},\ [None,\ "{}loss"{}])}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00672}00672\ \textcolor{keyword}{def\ }test\_string\_target\_early\_stopping(scoring):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00673}00673\ \ \ \ \ \textcolor{comment}{\#\ Regression\ tests\ for\ \#14709\ where\ the\ targets\ need\ to\ be\ encoded\ before}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00674}00674\ \ \ \ \ \textcolor{comment}{\#\ to\ compute\ the\ score}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00675}00675\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00676}00676\ \ \ \ \ X\ =\ rng.randn(100,\ 10)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00677}00677\ \ \ \ \ y\ =\ np.array([\textcolor{stringliteral}{"{}x"{}}]\ *\ 50\ +\ [\textcolor{stringliteral}{"{}y"{}}]\ *\ 50,\ dtype=object)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00678}00678\ \ \ \ \ gbrt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(n\_iter\_no\_change=10,\ scoring=scoring)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00679}00679\ \ \ \ \ gbrt.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00680}00680\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00681}00681\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00682}00682\ \textcolor{keyword}{def\ }test\_zero\_sample\_weights\_regression():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00683}00683\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ setting\ a\ SW\ to\ zero\ amounts\ to\ ignoring\ the\ corresponding}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00684}00684\ \ \ \ \ \textcolor{comment}{\#\ sample}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00685}00685\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00686}00686\ \ \ \ \ X\ =\ [[1,\ 0],\ [1,\ 0],\ [1,\ 0],\ [0,\ 1]]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00687}00687\ \ \ \ \ y\ =\ [0,\ 0,\ 1,\ 0]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00688}00688\ \ \ \ \ \textcolor{comment}{\#\ ignore\ the\ first\ 2\ training\ samples\ by\ setting\ their\ weight\ to\ 0}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00689}00689\ \ \ \ \ sample\_weight\ =\ [0,\ 0,\ 1,\ 1]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00690}00690\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(min\_samples\_leaf=1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00691}00691\ \ \ \ \ gb.fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00692}00692\ \ \ \ \ \textcolor{keyword}{assert}\ gb.predict([[1,\ 0]])[0]\ >\ 0.5}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00693}00693\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00694}00694\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00695}00695\ \textcolor{keyword}{def\ }test\_zero\_sample\_weights\_classification():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00696}00696\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ setting\ a\ SW\ to\ zero\ amounts\ to\ ignoring\ the\ corresponding}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00697}00697\ \ \ \ \ \textcolor{comment}{\#\ sample}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00698}00698\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00699}00699\ \ \ \ \ X\ =\ [[1,\ 0],\ [1,\ 0],\ [1,\ 0],\ [0,\ 1]]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00700}00700\ \ \ \ \ y\ =\ [0,\ 0,\ 1,\ 0]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00701}00701\ \ \ \ \ \textcolor{comment}{\#\ ignore\ the\ first\ 2\ training\ samples\ by\ setting\ their\ weight\ to\ 0}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00702}00702\ \ \ \ \ sample\_weight\ =\ [0,\ 0,\ 1,\ 1]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00703}00703\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(loss=\textcolor{stringliteral}{"{}log\_loss"{}},\ min\_samples\_leaf=1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00704}00704\ \ \ \ \ gb.fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00705}00705\ \ \ \ \ assert\_array\_equal(gb.predict([[1,\ 0]]),\ [1])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00706}00706\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00707}00707\ \ \ \ \ X\ =\ [[1,\ 0],\ [1,\ 0],\ [1,\ 0],\ [0,\ 1],\ [1,\ 1]]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00708}00708\ \ \ \ \ y\ =\ [0,\ 0,\ 1,\ 0,\ 2]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00709}00709\ \ \ \ \ \textcolor{comment}{\#\ ignore\ the\ first\ 2\ training\ samples\ by\ setting\ their\ weight\ to\ 0}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00710}00710\ \ \ \ \ sample\_weight\ =\ [0,\ 0,\ 1,\ 1,\ 1]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00711}00711\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(loss=\textcolor{stringliteral}{"{}log\_loss"{}},\ min\_samples\_leaf=1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00712}00712\ \ \ \ \ gb.fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00713}00713\ \ \ \ \ assert\_array\_equal(gb.predict([[1,\ 0]]),\ [1])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00714}00714\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00715}00715\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00716}00716\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00717}00717\ \ \ \ \ \textcolor{stringliteral}{"{}problem"{}},\ (\textcolor{stringliteral}{"{}regression"{}},\ \textcolor{stringliteral}{"{}binary\_classification"{}},\ \textcolor{stringliteral}{"{}multiclass\_classification"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00718}00718\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00719}00719\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}duplication"{},\ ("{}half"{},\ "{}all"{})})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00720}00720\ \textcolor{keyword}{def\ }test\_sample\_weight\_effect(problem,\ duplication):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00721}00721\ \ \ \ \ \textcolor{comment}{\#\ High\ level\ test\ to\ make\ sure\ that\ duplicating\ a\ sample\ is\ equivalent\ to}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00722}00722\ \ \ \ \ \textcolor{comment}{\#\ giving\ it\ weight\ of\ 2.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00723}00723\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00724}00724\ \ \ \ \ \textcolor{comment}{\#\ fails\ for\ n\_samples\ >\ 255\ because\ binning\ does\ not\ take\ sample\ weights}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00725}00725\ \ \ \ \ \textcolor{comment}{\#\ into\ account.\ Keeping\ n\_samples\ <=\ 255\ makes}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00726}00726\ \ \ \ \ \textcolor{comment}{\#\ sure\ only\ unique\ values\ are\ used\ so\ SW\ have\ no\ effect\ on\ binning.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00727}00727\ \ \ \ \ n\_samples\ =\ 255}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00728}00728\ \ \ \ \ n\_features\ =\ 2}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00729}00729\ \ \ \ \ \textcolor{keywordflow}{if}\ problem\ ==\ \textcolor{stringliteral}{"{}regression"{}}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00730}00730\ \ \ \ \ \ \ \ \ X,\ y\ =\ make\_regression(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00731}00731\ \ \ \ \ \ \ \ \ \ \ \ \ n\_samples=n\_samples,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00732}00732\ \ \ \ \ \ \ \ \ \ \ \ \ n\_features=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00733}00733\ \ \ \ \ \ \ \ \ \ \ \ \ n\_informative=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00734}00734\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00735}00735\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00736}00736\ \ \ \ \ \ \ \ \ Klass\ =\ HistGradientBoostingRegressor}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00737}00737\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00738}00738\ \ \ \ \ \ \ \ \ n\_classes\ =\ 2\ \textcolor{keywordflow}{if}\ problem\ ==\ \textcolor{stringliteral}{"{}binary\_classification"{}}\ \textcolor{keywordflow}{else}\ 3}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00739}00739\ \ \ \ \ \ \ \ \ X,\ y\ =\ make\_classification(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00740}00740\ \ \ \ \ \ \ \ \ \ \ \ \ n\_samples=n\_samples,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00741}00741\ \ \ \ \ \ \ \ \ \ \ \ \ n\_features=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00742}00742\ \ \ \ \ \ \ \ \ \ \ \ \ n\_informative=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00743}00743\ \ \ \ \ \ \ \ \ \ \ \ \ n\_redundant=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00744}00744\ \ \ \ \ \ \ \ \ \ \ \ \ n\_clusters\_per\_class=1,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00745}00745\ \ \ \ \ \ \ \ \ \ \ \ \ n\_classes=n\_classes,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00746}00746\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00747}00747\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00748}00748\ \ \ \ \ \ \ \ \ Klass\ =\ HistGradientBoostingClassifier}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00749}00749\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00750}00750\ \ \ \ \ \textcolor{comment}{\#\ This\ test\ can't\ pass\ if\ min\_samples\_leaf\ >\ 1\ because\ that\ would\ force\ 2}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00751}00751\ \ \ \ \ \textcolor{comment}{\#\ samples\ to\ be\ in\ the\ same\ node\ in\ est\_sw,\ while\ these\ samples\ would\ be}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00752}00752\ \ \ \ \ \textcolor{comment}{\#\ free\ to\ be\ separate\ in\ est\_dup:\ est\_dup\ would\ just\ group\ together\ the}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00753}00753\ \ \ \ \ \textcolor{comment}{\#\ duplicated\ samples.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00754}00754\ \ \ \ \ est\ =\ Klass(min\_samples\_leaf=1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00755}00755\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00756}00756\ \ \ \ \ \textcolor{comment}{\#\ Create\ dataset\ with\ duplicate\ and\ corresponding\ sample\ weights}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00757}00757\ \ \ \ \ \textcolor{keywordflow}{if}\ duplication\ ==\ \textcolor{stringliteral}{"{}half"{}}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00758}00758\ \ \ \ \ \ \ \ \ lim\ =\ n\_samples\ //\ 2}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00759}00759\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00760}00760\ \ \ \ \ \ \ \ \ lim\ =\ n\_samples}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00761}00761\ \ \ \ \ X\_dup\ =\ np.r\_[X,\ X[:lim]]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00762}00762\ \ \ \ \ y\_dup\ =\ np.r\_[y,\ y[:lim]]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00763}00763\ \ \ \ \ sample\_weight\ =\ np.ones(shape=(n\_samples))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00764}00764\ \ \ \ \ sample\_weight[:lim]\ =\ 2}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00765}00765\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00766}00766\ \ \ \ \ est\_sw\ =\ clone(est).fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00767}00767\ \ \ \ \ est\_dup\ =\ clone(est).fit(X\_dup,\ y\_dup)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00768}00768\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00769}00769\ \ \ \ \ \textcolor{comment}{\#\ checking\ raw\_predict\ is\ stricter\ than\ just\ predict\ for\ classification}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00770}00770\ \ \ \ \ \textcolor{keyword}{assert}\ np.allclose(est\_sw.\_raw\_predict(X\_dup),\ est\_dup.\_raw\_predict(X\_dup))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00771}00771\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00772}00772\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00773}00773\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Loss"{},\ (HalfSquaredError,\ AbsoluteError)})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00774}00774\ \textcolor{keyword}{def\ }test\_sum\_hessians\_are\_sample\_weight(Loss):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00775}00775\ \ \ \ \ \textcolor{comment}{\#\ For\ losses\ with\ constant\ hessians,\ the\ sum\_hessians\ field\ of\ the}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00776}00776\ \ \ \ \ \textcolor{comment}{\#\ histograms\ must\ be\ equal\ to\ the\ sum\ of\ the\ sample\ weight\ of\ samples\ at}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00777}00777\ \ \ \ \ \textcolor{comment}{\#\ the\ corresponding\ bin.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00778}00778\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00779}00779\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00780}00780\ \ \ \ \ n\_samples\ =\ 1000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00781}00781\ \ \ \ \ n\_features\ =\ 2}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00782}00782\ \ \ \ \ X,\ y\ =\ make\_regression(n\_samples=n\_samples,\ n\_features=n\_features,\ random\_state=rng)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00783}00783\ \ \ \ \ bin\_mapper\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1binning_1_1__BinMapper}{\_BinMapper}}()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00784}00784\ \ \ \ \ X\_binned\ =\ bin\_mapper.fit\_transform(X)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00785}00785\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00786}00786\ \ \ \ \ \textcolor{comment}{\#\ While\ sample\ weights\ are\ supposed\ to\ be\ positive,\ this\ still\ works.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00787}00787\ \ \ \ \ sample\_weight\ =\ rng.normal(size=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00788}00788\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00789}00789\ \ \ \ \ loss\ =\ Loss(sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00790}00790\ \ \ \ \ gradients,\ hessians\ =\ loss.init\_gradient\_and\_hessian(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00791}00791\ \ \ \ \ \ \ \ \ n\_samples=n\_samples,\ dtype=G\_H\_DTYPE}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00792}00792\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00793}00793\ \ \ \ \ gradients,\ hessians\ =\ gradients.reshape((-\/1,\ 1)),\ hessians.reshape((-\/1,\ 1))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00794}00794\ \ \ \ \ raw\_predictions\ =\ rng.normal(size=(n\_samples,\ 1))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00795}00795\ \ \ \ \ loss.gradient\_hessian(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00796}00796\ \ \ \ \ \ \ \ \ y\_true=y,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00797}00797\ \ \ \ \ \ \ \ \ raw\_prediction=raw\_predictions,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00798}00798\ \ \ \ \ \ \ \ \ sample\_weight=sample\_weight,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00799}00799\ \ \ \ \ \ \ \ \ gradient\_out=gradients,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00800}00800\ \ \ \ \ \ \ \ \ hessian\_out=hessians,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00801}00801\ \ \ \ \ \ \ \ \ n\_threads=n\_threads,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00802}00802\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00803}00803\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00804}00804\ \ \ \ \ \textcolor{comment}{\#\ build\ sum\_sample\_weight\ which\ contains\ the\ sum\ of\ the\ sample\ weights\ at}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00805}00805\ \ \ \ \ \textcolor{comment}{\#\ each\ bin\ (for\ each\ feature).\ This\ must\ be\ equal\ to\ the\ sum\_hessians}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00806}00806\ \ \ \ \ \textcolor{comment}{\#\ field\ of\ the\ corresponding\ histogram}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00807}00807\ \ \ \ \ sum\_sw\ =\ np.zeros(shape=(n\_features,\ bin\_mapper.n\_bins))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00808}00808\ \ \ \ \ \textcolor{keywordflow}{for}\ feature\_idx\ \textcolor{keywordflow}{in}\ range(n\_features):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00809}00809\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ sample\_idx\ \textcolor{keywordflow}{in}\ range(n\_samples):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00810}00810\ \ \ \ \ \ \ \ \ \ \ \ \ sum\_sw[feature\_idx,\ X\_binned[sample\_idx,\ feature\_idx]]\ +=\ sample\_weight[}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00811}00811\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ sample\_idx}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00812}00812\ \ \ \ \ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00813}00813\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00814}00814\ \ \ \ \ \textcolor{comment}{\#\ Build\ histogram}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00815}00815\ \ \ \ \ grower\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1grower_1_1TreeGrower}{TreeGrower}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00816}00816\ \ \ \ \ \ \ \ \ X\_binned,\ gradients[:,\ 0],\ hessians[:,\ 0],\ n\_bins=bin\_mapper.n\_bins}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00817}00817\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00818}00818\ \ \ \ \ histograms\ =\ grower.histogram\_builder.compute\_histograms\_brute(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00819}00819\ \ \ \ \ \ \ \ \ grower.root.sample\_indices}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00820}00820\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00821}00821\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00822}00822\ \ \ \ \ \textcolor{keywordflow}{for}\ feature\_idx\ \textcolor{keywordflow}{in}\ range(n\_features):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00823}00823\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ bin\_idx\ \textcolor{keywordflow}{in}\ range(bin\_mapper.n\_bins):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00824}00824\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ histograms[feature\_idx,\ bin\_idx][\textcolor{stringliteral}{"{}sum\_hessians"{}}]\ ==\ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00825}00825\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ pytest.approx(sum\_sw[feature\_idx,\ bin\_idx],\ rel=1e-\/5)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00826}00826\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00827}00827\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00828}00828\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00829}00829\ \textcolor{keyword}{def\ }test\_max\_depth\_max\_leaf\_nodes():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00830}00830\ \ \ \ \ \textcolor{comment}{\#\ Non\ regression\ test\ for}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00831}00831\ \ \ \ \ \textcolor{comment}{\#\ https://github.com/scikit-\/learn/scikit-\/learn/issues/16179}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00832}00832\ \ \ \ \ \textcolor{comment}{\#\ there\ was\ a\ bug\ when\ the\ max\_depth\ and\ the\ max\_leaf\_nodes\ criteria\ were}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00833}00833\ \ \ \ \ \textcolor{comment}{\#\ met\ at\ the\ same\ time,\ which\ would\ lead\ to\ max\_leaf\_nodes\ not\ being}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00834}00834\ \ \ \ \ \textcolor{comment}{\#\ respected.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00835}00835\ \ \ \ \ X,\ y\ =\ make\_classification(random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00836}00836\ \ \ \ \ est\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(max\_depth=2,\ max\_leaf\_nodes=3,\ max\_iter=1).fit(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00837}00837\ \ \ \ \ \ \ \ \ X,\ y}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00838}00838\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00839}00839\ \ \ \ \ tree\ =\ est.\_predictors[0][0]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00840}00840\ \ \ \ \ \textcolor{keyword}{assert}\ tree.get\_max\_depth()\ ==\ 2}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00841}00841\ \ \ \ \ \textcolor{keyword}{assert}\ tree.get\_n\_leaf\_nodes()\ ==\ 3\ \ \textcolor{comment}{\#\ would\ be\ 4\ prior\ to\ bug\ fix}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00842}00842\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00843}00843\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00844}00844\ \textcolor{keyword}{def\ }test\_early\_stopping\_on\_test\_set\_with\_warm\_start():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00845}00845\ \ \ \ \ \textcolor{comment}{\#\ Non\ regression\ test\ for\ \#16661\ where\ second\ fit\ fails\ with}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00846}00846\ \ \ \ \ \textcolor{comment}{\#\ warm\_start=True,\ early\_stopping\ is\ on,\ and\ no\ validation\ set}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00847}00847\ \ \ \ \ X,\ y\ =\ make\_classification(random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00848}00848\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00849}00849\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00850}00850\ \ \ \ \ \ \ \ \ scoring=\textcolor{stringliteral}{"{}loss"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00851}00851\ \ \ \ \ \ \ \ \ warm\_start=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00852}00852\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00853}00853\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=1,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00854}00854\ \ \ \ \ \ \ \ \ validation\_fraction=\textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00855}00855\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00856}00856\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00857}00857\ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00858}00858\ \ \ \ \ \textcolor{comment}{\#\ does\ not\ raise\ on\ second\ call}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00859}00859\ \ \ \ \ gb.set\_params(max\_iter=2)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00860}00860\ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00861}00861\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00862}00862\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00863}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_af305778a4e3914ed337663d08307bc46}{00863}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_af305778a4e3914ed337663d08307bc46}{test\_early\_stopping\_with\_sample\_weights}}(monkeypatch):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00864}00864\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ sample\ weights\ is\ passed\ in\ to\ the\ scorer\ and\ \_raw\_predict\ is\ not}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00865}00865\ \textcolor{stringliteral}{\ \ \ \ called."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00866}00866\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00867}00867\ \ \ \ \ mock\_scorer\ =\ Mock(side\_effect=get\_scorer(\textcolor{stringliteral}{"{}neg\_median\_absolute\_error"{}}))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00868}00868\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00869}00869\ \ \ \ \ \textcolor{keyword}{def\ }mock\_check\_scoring(estimator,\ scoring):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00870}00870\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ scoring\ ==\ \textcolor{stringliteral}{"{}neg\_median\_absolute\_error"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00871}00871\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ mock\_scorer}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00872}00872\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00873}00873\ \ \ \ \ monkeypatch.setattr(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00874}00874\ \ \ \ \ \ \ \ \ \mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting}{sklearn.ensemble.\_hist\_gradient\_boosting.gradient\_boosting}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00875}00875\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}check\_scoring"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00876}00876\ \ \ \ \ \ \ \ \ mock\_check\_scoring,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00877}00877\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00878}00878\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00879}00879\ \ \ \ \ X,\ y\ =\ make\_regression(random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00880}00880\ \ \ \ \ sample\_weight\ =\ np.ones\_like(y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00881}00881\ \ \ \ \ hist\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00882}00882\ \ \ \ \ \ \ \ \ max\_iter=2,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00883}00883\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00884}00884\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00885}00885\ \ \ \ \ \ \ \ \ scoring=\textcolor{stringliteral}{"{}neg\_median\_absolute\_error"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00886}00886\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00887}00887\ \ \ \ \ mock\_raw\_predict\ =\ Mock(side\_effect=hist.\_raw\_predict)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00888}00888\ \ \ \ \ hist.\_raw\_predict\ =\ mock\_raw\_predict}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00889}00889\ \ \ \ \ hist.fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00890}00890\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00891}00891\ \ \ \ \ \textcolor{comment}{\#\ \_raw\_predict\ should\ never\ be\ called\ with\ scoring\ as\ a\ string}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00892}00892\ \ \ \ \ \textcolor{keyword}{assert}\ mock\_raw\_predict.call\_count\ ==\ 0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00893}00893\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00894}00894\ \ \ \ \ \textcolor{comment}{\#\ For\ scorer\ is\ called\ twice\ (train\ and\ val)\ for\ the\ baseline\ score,\ and\ twice}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00895}00895\ \ \ \ \ \textcolor{comment}{\#\ per\ iteration\ (train\ and\ val)\ after\ that.\ So\ 6\ times\ in\ total\ for\ \`{}max\_iter=2`.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00896}00896\ \ \ \ \ \textcolor{keyword}{assert}\ mock\_scorer.call\_count\ ==\ 6}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00897}00897\ \ \ \ \ \textcolor{keywordflow}{for}\ arg\_list\ \textcolor{keywordflow}{in}\ mock\_scorer.call\_args\_list:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00898}00898\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{stringliteral}{"{}sample\_weight"{}}\ \textcolor{keywordflow}{in}\ arg\_list[1]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00899}00899\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00900}00900\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00901}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a643873101ad86dc8d72d85446a63898d}{00901}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a643873101ad86dc8d72d85446a63898d}{test\_raw\_predict\_is\_called\_with\_custom\_scorer}}():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00902}00902\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Custom\ scorer\ will\ still\ call\ \_raw\_predict."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00903}00903\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00904}00904\ \ \ \ \ mock\_scorer\ =\ Mock(side\_effect=get\_scorer(\textcolor{stringliteral}{"{}neg\_median\_absolute\_error"{}}))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00905}00905\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00906}00906\ \ \ \ \ X,\ y\ =\ make\_regression(random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00907}00907\ \ \ \ \ hist\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00908}00908\ \ \ \ \ \ \ \ \ max\_iter=2,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00909}00909\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00910}00910\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00911}00911\ \ \ \ \ \ \ \ \ scoring=mock\_scorer,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00912}00912\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00913}00913\ \ \ \ \ mock\_raw\_predict\ =\ Mock(side\_effect=hist.\_raw\_predict)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00914}00914\ \ \ \ \ hist.\_raw\_predict\ =\ mock\_raw\_predict}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00915}00915\ \ \ \ \ hist.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00916}00916\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00917}00917\ \ \ \ \ \textcolor{comment}{\#\ \`{}\_raw\_predict`\ and\ scorer\ is\ called\ twice\ (train\ and\ val)\ for\ the\ baseline\ score,}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00918}00918\ \ \ \ \ \textcolor{comment}{\#\ and\ twice\ per\ iteration\ (train\ and\ val)\ after\ that.\ So\ 6\ times\ in\ total\ for}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00919}00919\ \ \ \ \ \textcolor{comment}{\#\ \`{}max\_iter=2`.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00920}00920\ \ \ \ \ \textcolor{keyword}{assert}\ mock\_raw\_predict.call\_count\ ==\ 6}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00921}00921\ \ \ \ \ \textcolor{keyword}{assert}\ mock\_scorer.call\_count\ ==\ 6}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00922}00922\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00923}00923\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00924}00924\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00925}00925\ \ \ \ \ \textcolor{stringliteral}{"{}Est"{}},\ (HistGradientBoostingClassifier,\ HistGradientBoostingRegressor)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00926}00926\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00927}00927\ \textcolor{keyword}{def\ }test\_single\_node\_trees(Est):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00928}00928\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ it's\ still\ possible\ to\ build\ single-\/node\ trees.\ In\ that\ case}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00929}00929\ \ \ \ \ \textcolor{comment}{\#\ the\ value\ of\ the\ root\ is\ set\ to\ 0.\ That's\ a\ correct\ value:\ if\ the\ tree\ is}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00930}00930\ \ \ \ \ \textcolor{comment}{\#\ single-\/node\ that's\ because\ min\_gain\_to\_split\ is\ not\ respected\ right\ from}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00931}00931\ \ \ \ \ \textcolor{comment}{\#\ the\ root,\ so\ we\ don't\ want\ the\ tree\ to\ have\ any\ impact\ on\ the}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00932}00932\ \ \ \ \ \textcolor{comment}{\#\ predictions.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00933}00933\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00934}00934\ \ \ \ \ X,\ y\ =\ make\_classification(random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00935}00935\ \ \ \ \ y[:]\ =\ 1\ \ \textcolor{comment}{\#\ constant\ target\ will\ lead\ to\ a\ single\ root\ node}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00936}00936\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00937}00937\ \ \ \ \ est\ =\ Est(max\_iter=20)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00938}00938\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00939}00939\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00940}00940\ \ \ \ \ \textcolor{keyword}{assert}\ all(len(predictor[0].nodes)\ ==\ 1\ \textcolor{keywordflow}{for}\ predictor\ \textcolor{keywordflow}{in}\ est.\_predictors)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00941}00941\ \ \ \ \ \textcolor{keyword}{assert}\ all(predictor[0].nodes[0][\textcolor{stringliteral}{"{}value"{}}]\ ==\ 0\ \textcolor{keywordflow}{for}\ predictor\ \textcolor{keywordflow}{in}\ est.\_predictors)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00942}00942\ \ \ \ \ \textcolor{comment}{\#\ Still\ gives\ correct\ predictions\ thanks\ to\ the\ baseline\ prediction}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00943}00943\ \ \ \ \ assert\_allclose(est.predict(X),\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00944}00944\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00945}00945\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00946}00946\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00947}00947\ \ \ \ \ \textcolor{stringliteral}{"{}Est,\ loss,\ X,\ y"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00948}00948\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00949}00949\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00950}00950\ \ \ \ \ \ \ \ \ \ \ \ \ HistGradientBoostingClassifier,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00951}00951\ \ \ \ \ \ \ \ \ \ \ \ \ \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfBinomialLoss}{HalfBinomialLoss}}(sample\_weight=\textcolor{keywordtype}{None}),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00952}00952\ \ \ \ \ \ \ \ \ \ \ \ \ X\_classification,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00953}00953\ \ \ \ \ \ \ \ \ \ \ \ \ y\_classification,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00954}00954\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00955}00955\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00956}00956\ \ \ \ \ \ \ \ \ \ \ \ \ HistGradientBoostingRegressor,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00957}00957\ \ \ \ \ \ \ \ \ \ \ \ \ \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfSquaredError}{HalfSquaredError}}(sample\_weight=\textcolor{keywordtype}{None}),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00958}00958\ \ \ \ \ \ \ \ \ \ \ \ \ X\_regression,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00959}00959\ \ \ \ \ \ \ \ \ \ \ \ \ y\_regression,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00960}00960\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00961}00961\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00962}00962\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00963}00963\ \textcolor{keyword}{def\ }test\_custom\_loss(Est,\ loss,\ X,\ y):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00964}00964\ \ \ \ \ est\ =\ Est(loss=loss,\ max\_iter=20)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00965}00965\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00966}00966\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00967}00967\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00968}00968\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00969}00969\ \ \ \ \ \textcolor{stringliteral}{"{}HistGradientBoosting,\ X,\ y"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00970}00970\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00971}00971\ \ \ \ \ \ \ \ \ (HistGradientBoostingClassifier,\ X\_classification,\ y\_classification),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00972}00972\ \ \ \ \ \ \ \ \ (HistGradientBoostingRegressor,\ X\_regression,\ y\_regression),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00973}00973\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00974}00974\ \ \ \ \ \ \ \ \ \ \ \ \ HistGradientBoostingClassifier,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00975}00975\ \ \ \ \ \ \ \ \ \ \ \ \ X\_multi\_classification,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00976}00976\ \ \ \ \ \ \ \ \ \ \ \ \ y\_multi\_classification,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00977}00977\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00978}00978\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00979}00979\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00980}00980\ \textcolor{keyword}{def\ }test\_staged\_predict(HistGradientBoosting,\ X,\ y):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00981}00981\ \ \ \ \ \textcolor{comment}{\#\ Test\ whether\ staged\ predictor\ eventually\ gives}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00982}00982\ \ \ \ \ \textcolor{comment}{\#\ the\ same\ prediction.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00983}00983\ \ \ \ \ X\_train,\ X\_test,\ y\_train,\ y\_test\ =\ train\_test\_split(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00984}00984\ \ \ \ \ \ \ \ \ X,\ y,\ test\_size=0.5,\ random\_state=0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00985}00985\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00986}00986\ \ \ \ \ gb\ =\ HistGradientBoosting(max\_iter=10)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00987}00987\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00988}00988\ \ \ \ \ \textcolor{comment}{\#\ test\ raise\ NotFittedError\ if\ not\ fitted}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00989}00989\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(NotFittedError):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00990}00990\ \ \ \ \ \ \ \ \ next(gb.staged\_predict(X\_test))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00991}00991\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00992}00992\ \ \ \ \ gb.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00993}00993\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00994}00994\ \ \ \ \ \textcolor{comment}{\#\ test\ if\ the\ staged\ predictions\ of\ each\ iteration}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00995}00995\ \ \ \ \ \textcolor{comment}{\#\ are\ equal\ to\ the\ corresponding\ predictions\ of\ the\ same\ estimator}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00996}00996\ \ \ \ \ \textcolor{comment}{\#\ trained\ from\ scratch.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00997}00997\ \ \ \ \ \textcolor{comment}{\#\ this\ also\ test\ limit\ case\ when\ max\_iter\ =\ 1}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00998}00998\ \ \ \ \ method\_names\ =\ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l00999}00999\ \ \ \ \ \ \ \ \ [\textcolor{stringliteral}{"{}predict"{}}]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01000}01000\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ is\_regressor(gb)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01001}01001\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}\ [\textcolor{stringliteral}{"{}predict"{}},\ \textcolor{stringliteral}{"{}predict\_proba"{}},\ \textcolor{stringliteral}{"{}decision\_function"{}}]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01002}01002\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01003}01003\ \ \ \ \ \textcolor{keywordflow}{for}\ method\_name\ \textcolor{keywordflow}{in}\ method\_names:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01004}01004\ \ \ \ \ \ \ \ \ staged\_method\ =\ getattr(gb,\ \textcolor{stringliteral}{"{}staged\_"{}}\ +\ method\_name)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01005}01005\ \ \ \ \ \ \ \ \ staged\_predictions\ =\ list(staged\_method(X\_test))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01006}01006\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ len(staged\_predictions)\ ==\ gb.n\_iter\_}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01007}01007\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ n\_iter,\ staged\_predictions\ \textcolor{keywordflow}{in}\ enumerate(staged\_method(X\_test),\ 1):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01008}01008\ \ \ \ \ \ \ \ \ \ \ \ \ aux\ =\ HistGradientBoosting(max\_iter=n\_iter)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01009}01009\ \ \ \ \ \ \ \ \ \ \ \ \ aux.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01010}01010\ \ \ \ \ \ \ \ \ \ \ \ \ pred\_aux\ =\ getattr(aux,\ method\_name)(X\_test)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01011}01011\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01012}01012\ \ \ \ \ \ \ \ \ \ \ \ \ assert\_allclose(staged\_predictions,\ pred\_aux)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01013}01013\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ staged\_predictions.shape\ ==\ pred\_aux.shape}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01014}01014\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01015}01015\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01016}01016\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}insert\_missing"{},\ [False,\ True])}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01017}01017\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01018}01018\ \ \ \ \ \textcolor{stringliteral}{"{}Est"{}},\ (HistGradientBoostingRegressor,\ HistGradientBoostingClassifier)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01019}01019\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01020}01020\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}bool\_categorical\_parameter"{},\ [True,\ False])}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01021}01021\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}missing\_value"{},\ [np.nan,\ -\/1])}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01022}01022\ \textcolor{keyword}{def\ }test\_unknown\_categories\_nan(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01023}01023\ \ \ \ \ insert\_missing,\ Est,\ bool\_categorical\_parameter,\ missing\_value}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01024}01024\ ):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01025}01025\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ no\ error\ is\ raised\ at\ predict\ if\ a\ category\ wasn't\ seen\ during}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01026}01026\ \ \ \ \ \textcolor{comment}{\#\ fit.\ We\ also\ make\ sure\ they're\ treated\ as\ nans.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01027}01027\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01028}01028\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01029}01029\ \ \ \ \ n\_samples\ =\ 1000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01030}01030\ \ \ \ \ f1\ =\ rng.rand(n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01031}01031\ \ \ \ \ f2\ =\ rng.randint(4,\ size=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01032}01032\ \ \ \ \ X\ =\ np.c\_[f1,\ f2]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01033}01033\ \ \ \ \ y\ =\ np.zeros(shape=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01034}01034\ \ \ \ \ y[X[:,\ 1]\ \%\ 2\ ==\ 0]\ =\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01035}01035\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01036}01036\ \ \ \ \ \textcolor{keywordflow}{if}\ bool\_categorical\_parameter:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01037}01037\ \ \ \ \ \ \ \ \ categorical\_features\ =\ [\textcolor{keyword}{False},\ \textcolor{keyword}{True}]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01038}01038\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01039}01039\ \ \ \ \ \ \ \ \ categorical\_features\ =\ [1]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01040}01040\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01041}01041\ \ \ \ \ \textcolor{keywordflow}{if}\ insert\_missing:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01042}01042\ \ \ \ \ \ \ \ \ mask\ =\ rng.binomial(1,\ 0.01,\ size=X.shape).astype(bool)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01043}01043\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ mask.sum()\ >\ 0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01044}01044\ \ \ \ \ \ \ \ \ X[mask]\ =\ missing\_value}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01045}01045\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01046}01046\ \ \ \ \ est\ =\ Est(max\_iter=20,\ categorical\_features=categorical\_features).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01047}01047\ \ \ \ \ assert\_array\_equal(est.is\_categorical\_,\ [\textcolor{keyword}{False},\ \textcolor{keyword}{True}])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01048}01048\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01049}01049\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ no\ error\ is\ raised\ on\ unknown\ categories\ and\ nans}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01050}01050\ \ \ \ \ \textcolor{comment}{\#\ unknown\ categories\ will\ be\ treated\ as\ nans}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01051}01051\ \ \ \ \ X\_test\ =\ np.zeros((10,\ X.shape[1]),\ dtype=float)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01052}01052\ \ \ \ \ X\_test[:5,\ 1]\ =\ 30}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01053}01053\ \ \ \ \ X\_test[5:,\ 1]\ =\ missing\_value}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01054}01054\ \ \ \ \ \textcolor{keyword}{assert}\ len(np.unique(est.predict(X\_test)))\ ==\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01055}01055\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01056}01056\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01057}01057\ \textcolor{keyword}{def\ }test\_categorical\_encoding\_strategies():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01058}01058\ \ \ \ \ \textcolor{comment}{\#\ Check\ native\ categorical\ handling\ vs\ different\ encoding\ strategies.\ We}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01059}01059\ \ \ \ \ \textcolor{comment}{\#\ make\ sure\ that\ native\ encoding\ needs\ only\ 1\ split\ to\ achieve\ a\ perfect}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01060}01060\ \ \ \ \ \textcolor{comment}{\#\ prediction\ on\ a\ simple\ dataset.\ In\ contrast,\ OneHotEncoded\ data\ needs}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01061}01061\ \ \ \ \ \textcolor{comment}{\#\ more\ depth\ /\ splits,\ and\ treating\ categories\ as\ ordered\ (just\ using}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01062}01062\ \ \ \ \ \textcolor{comment}{\#\ OrdinalEncoder)\ requires\ even\ more\ depth.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01063}01063\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01064}01064\ \ \ \ \ \textcolor{comment}{\#\ dataset\ with\ one\ random\ continuous\ feature,\ and\ one\ categorical\ feature}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01065}01065\ \ \ \ \ \textcolor{comment}{\#\ with\ values\ in\ [0,\ 5],\ e.g.\ from\ an\ OrdinalEncoder.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01066}01066\ \ \ \ \ \textcolor{comment}{\#\ class\ ==\ 1\ iff\ categorical\ value\ in\ \{0,\ 2,\ 4\}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01067}01067\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01068}01068\ \ \ \ \ n\_samples\ =\ 10\_000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01069}01069\ \ \ \ \ f1\ =\ rng.rand(n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01070}01070\ \ \ \ \ f2\ =\ rng.randint(6,\ size=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01071}01071\ \ \ \ \ X\ =\ np.c\_[f1,\ f2]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01072}01072\ \ \ \ \ y\ =\ np.zeros(shape=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01073}01073\ \ \ \ \ y[X[:,\ 1]\ \%\ 2\ ==\ 0]\ =\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01074}01074\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01075}01075\ \ \ \ \ \textcolor{comment}{\#\ make\ sure\ dataset\ is\ balanced\ so\ that\ the\ baseline\_prediction\ doesn't}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01076}01076\ \ \ \ \ \textcolor{comment}{\#\ influence\ predictions\ too\ much\ with\ max\_iter\ =\ 1}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01077}01077\ \ \ \ \ \textcolor{keyword}{assert}\ 0.49\ <\ y.mean()\ <\ 0.51}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01078}01078\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01079}01079\ \ \ \ \ native\_cat\_specs\ =\ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01080}01080\ \ \ \ \ \ \ \ \ [\textcolor{keyword}{False},\ \textcolor{keyword}{True}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01081}01081\ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01082}01082\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01083}01083\ \ \ \ \ \textcolor{keywordflow}{try}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01084}01084\ \ \ \ \ \ \ \ \ \textcolor{keyword}{import}\ pandas\ \textcolor{keyword}{as}\ pd}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01085}01085\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01086}01086\ \ \ \ \ \ \ \ \ X\ =\ pd.DataFrame(X,\ columns=[\textcolor{stringliteral}{"{}f\_0"{}},\ \textcolor{stringliteral}{"{}f\_1"{}}])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01087}01087\ \ \ \ \ \ \ \ \ native\_cat\_specs.append([\textcolor{stringliteral}{"{}f\_1"{}}])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01088}01088\ \ \ \ \ \textcolor{keywordflow}{except}\ ImportError:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01089}01089\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{pass}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01090}01090\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01091}01091\ \ \ \ \ \textcolor{keywordflow}{for}\ native\_cat\_spec\ \textcolor{keywordflow}{in}\ native\_cat\_specs:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01092}01092\ \ \ \ \ \ \ \ \ clf\_cat\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01093}01093\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=1,\ max\_depth=1,\ categorical\_features=native\_cat\_spec}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01094}01094\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01095}01095\ \ \ \ \ \ \ \ \ clf\_cat.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01096}01096\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01097}01097\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Using\ native\ categorical\ encoding,\ we\ get\ perfect\ predictions\ with\ just}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01098}01098\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ one\ split}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01099}01099\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ cross\_val\_score(clf\_cat,\ X,\ y).mean()\ ==\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01100}01100\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01101}01101\ \ \ \ \ \textcolor{comment}{\#\ quick\ sanity\ check\ for\ the\ bitset:\ 0,\ 2,\ 4\ =\ 2**0\ +\ 2**2\ +\ 2**4\ =\ 21}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01102}01102\ \ \ \ \ expected\_left\_bitset\ =\ [21,\ 0,\ 0,\ 0,\ 0,\ 0,\ 0,\ 0]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01103}01103\ \ \ \ \ left\_bitset\ =\ clf\_cat.fit(X,\ y).\_predictors[0][0].raw\_left\_cat\_bitsets[0]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01104}01104\ \ \ \ \ assert\_array\_equal(left\_bitset,\ expected\_left\_bitset)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01105}01105\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01106}01106\ \ \ \ \ \textcolor{comment}{\#\ Treating\ categories\ as\ ordered,\ we\ need\ more\ depth\ /\ more\ splits\ to\ get}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01107}01107\ \ \ \ \ \textcolor{comment}{\#\ the\ same\ predictions}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01108}01108\ \ \ \ \ clf\_no\_cat\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01109}01109\ \ \ \ \ \ \ \ \ max\_iter=1,\ max\_depth=4,\ categorical\_features=\textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01110}01110\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01111}01111\ \ \ \ \ \textcolor{keyword}{assert}\ cross\_val\_score(clf\_no\_cat,\ X,\ y).mean()\ <\ 0.9}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01112}01112\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01113}01113\ \ \ \ \ clf\_no\_cat.set\_params(max\_depth=5)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01114}01114\ \ \ \ \ \textcolor{keyword}{assert}\ cross\_val\_score(clf\_no\_cat,\ X,\ y).mean()\ ==\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01115}01115\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01116}01116\ \ \ \ \ \textcolor{comment}{\#\ Using\ OHEd\ data,\ we\ need\ less\ splits\ than\ with\ pure\ OEd\ data,\ but\ we}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01117}01117\ \ \ \ \ \textcolor{comment}{\#\ still\ need\ more\ splits\ than\ with\ the\ native\ categorical\ splits}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01118}01118\ \ \ \ \ ct\ =\ make\_column\_transformer(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01119}01119\ \ \ \ \ \ \ \ \ (\mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__encoders_1_1OneHotEncoder}{OneHotEncoder}}(sparse\_output=\textcolor{keyword}{False}),\ [1]),\ remainder=\textcolor{stringliteral}{"{}passthrough"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01120}01120\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01121}01121\ \ \ \ \ X\_ohe\ =\ ct.fit\_transform(X)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01122}01122\ \ \ \ \ clf\_no\_cat.set\_params(max\_depth=2)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01123}01123\ \ \ \ \ \textcolor{keyword}{assert}\ cross\_val\_score(clf\_no\_cat,\ X\_ohe,\ y).mean()\ <\ 0.9}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01124}01124\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01125}01125\ \ \ \ \ clf\_no\_cat.set\_params(max\_depth=3)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01126}01126\ \ \ \ \ \textcolor{keyword}{assert}\ cross\_val\_score(clf\_no\_cat,\ X\_ohe,\ y).mean()\ ==\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01127}01127\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01128}01128\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01129}01129\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01130}01130\ \ \ \ \ \textcolor{stringliteral}{"{}Est"{}},\ (HistGradientBoostingClassifier,\ HistGradientBoostingRegressor)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01131}01131\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01132}01132\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01133}01133\ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features,\ monotonic\_cst,\ expected\_msg"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01134}01134\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01135}01135\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01136}01136\ \ \ \ \ \ \ \ \ \ \ \ \ [b\textcolor{stringliteral}{"{}hello"{}},\ b\textcolor{stringliteral}{"{}world"{}}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01137}01137\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01138}01138\ \ \ \ \ \ \ \ \ \ \ \ \ re.escape(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01139}01139\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ must\ be\ an\ array-\/like\ of\ bool,\ int\ or\ str,\ "{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01140}01140\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}got:\ bytes40."{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01141}01141\ \ \ \ \ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01142}01142\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01143}01143\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01144}01144\ \ \ \ \ \ \ \ \ \ \ \ \ np.array([b\textcolor{stringliteral}{"{}hello"{}},\ 1.3],\ dtype=object),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01145}01145\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01146}01146\ \ \ \ \ \ \ \ \ \ \ \ \ re.escape(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01147}01147\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ must\ be\ an\ array-\/like\ of\ bool,\ int\ or\ str,\ "{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01148}01148\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}got:\ bytes,\ float."{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01149}01149\ \ \ \ \ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01150}01150\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01151}01151\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01152}01152\ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ -\/1],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01153}01153\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01154}01154\ \ \ \ \ \ \ \ \ \ \ \ \ re.escape(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01155}01155\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ set\ as\ integer\ indices\ must\ be\ in\ "{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01156}01156\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}[0,\ n\_features\ -\/\ 1]"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01157}01157\ \ \ \ \ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01158}01158\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01159}01159\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01160}01160\ \ \ \ \ \ \ \ \ \ \ \ \ [\textcolor{keyword}{True},\ \textcolor{keyword}{True},\ \textcolor{keyword}{False},\ \textcolor{keyword}{False},\ \textcolor{keyword}{True}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01161}01161\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01162}01162\ \ \ \ \ \ \ \ \ \ \ \ \ re.escape(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01163}01163\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ set\ as\ a\ boolean\ mask\ must\ have\ shape\ "{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01164}01164\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}(n\_features,)"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01165}01165\ \ \ \ \ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01166}01166\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01167}01167\ \ \ \ \ \ \ \ \ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01168}01168\ \ \ \ \ \ \ \ \ \ \ \ \ [\textcolor{keyword}{True},\ \textcolor{keyword}{True},\ \textcolor{keyword}{False},\ \textcolor{keyword}{False}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01169}01169\ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ -\/1,\ 0,\ 1],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01170}01170\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Categorical\ features\ cannot\ have\ monotonic\ constraints"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01171}01171\ \ \ \ \ \ \ \ \ ),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01172}01172\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01173}01173\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01174}01174\ \textcolor{keyword}{def\ }test\_categorical\_spec\_errors(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01175}01175\ \ \ \ \ Est,\ categorical\_features,\ monotonic\_cst,\ expected\_msg}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01176}01176\ ):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01177}01177\ \ \ \ \ \textcolor{comment}{\#\ Test\ errors\ when\ categories\ are\ specified\ incorrectly}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01178}01178\ \ \ \ \ n\_samples\ =\ 100}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01179}01179\ \ \ \ \ X,\ y\ =\ make\_classification(random\_state=0,\ n\_features=4,\ n\_samples=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01180}01180\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01181}01181\ \ \ \ \ X[:,\ 0]\ =\ rng.randint(0,\ 10,\ size=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01182}01182\ \ \ \ \ X[:,\ 1]\ =\ rng.randint(0,\ 10,\ size=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01183}01183\ \ \ \ \ est\ =\ Est(categorical\_features=categorical\_features,\ monotonic\_cst=monotonic\_cst)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01184}01184\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01185}01185\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=expected\_msg):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01186}01186\ \ \ \ \ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01187}01187\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01188}01188\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01189}01189\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01190}01190\ \ \ \ \ \textcolor{stringliteral}{"{}Est"{}},\ (HistGradientBoostingClassifier,\ HistGradientBoostingRegressor)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01191}01191\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01192}01192\ \textcolor{keyword}{def\ }test\_categorical\_spec\_errors\_with\_feature\_names(Est):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01193}01193\ \ \ \ \ pd\ =\ pytest.importorskip(\textcolor{stringliteral}{"{}pandas"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01194}01194\ \ \ \ \ n\_samples\ =\ 10}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01195}01195\ \ \ \ \ X\ =\ pd.DataFrame(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01196}01196\ \ \ \ \ \ \ \ \ \{}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01197}01197\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}f0"{}}:\ range(n\_samples),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01198}01198\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}f1"{}}:\ range(n\_samples),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01199}01199\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}f2"{}}:\ [1.0]\ *\ n\_samples,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01200}01200\ \ \ \ \ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01201}01201\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01202}01202\ \ \ \ \ y\ =\ [0,\ 1]\ *\ (n\_samples\ //\ 2)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01203}01203\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01204}01204\ \ \ \ \ est\ =\ Est(categorical\_features=[\textcolor{stringliteral}{"{}f0"{}},\ \textcolor{stringliteral}{"{}f1"{}},\ \textcolor{stringliteral}{"{}f3"{}}])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01205}01205\ \ \ \ \ expected\_msg\ =\ re.escape(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01206}01206\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ has\ a\ item\ value\ 'f3'\ which\ is\ not\ a\ valid\ "{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01207}01207\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}feature\ name\ of\ the\ training\ data."{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01208}01208\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01209}01209\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=expected\_msg):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01210}01210\ \ \ \ \ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01211}01211\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01212}01212\ \ \ \ \ est\ =\ Est(categorical\_features=[\textcolor{stringliteral}{"{}f0"{}},\ \textcolor{stringliteral}{"{}f1"{}}])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01213}01213\ \ \ \ \ expected\_msg\ =\ re.escape(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01214}01214\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}categorical\_features\ should\ be\ passed\ as\ an\ array\ of\ integers\ or\ "{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01215}01215\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}as\ a\ boolean\ mask\ when\ the\ model\ is\ fitted\ on\ data\ without\ feature\ "{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01216}01216\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}names."{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01217}01217\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01218}01218\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=expected\_msg):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01219}01219\ \ \ \ \ \ \ \ \ est.fit(X.to\_numpy(),\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01220}01220\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01221}01221\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01222}01222\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01223}01223\ \ \ \ \ \textcolor{stringliteral}{"{}Est"{}},\ (HistGradientBoostingClassifier,\ HistGradientBoostingRegressor)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01224}01224\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01225}01225\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}categorical\_features"{},\ ([False,\ False],\ [])})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01226}01226\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}as\_array"{},\ (True,\ False)})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01227}01227\ \textcolor{keyword}{def\ }test\_categorical\_spec\_no\_categories(Est,\ categorical\_features,\ as\_array):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01228}01228\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ we\ can\ properly\ detect\ that\ no\ categorical\ features\ are\ present}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01229}01229\ \ \ \ \ \textcolor{comment}{\#\ even\ if\ the\ categorical\_features\ parameter\ is\ not\ None}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01230}01230\ \ \ \ \ X\ =\ np.arange(10).reshape(5,\ 2)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01231}01231\ \ \ \ \ y\ =\ np.arange(5)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01232}01232\ \ \ \ \ \textcolor{keywordflow}{if}\ as\_array:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01233}01233\ \ \ \ \ \ \ \ \ categorical\_features\ =\ np.asarray(categorical\_features)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01234}01234\ \ \ \ \ est\ =\ Est(categorical\_features=categorical\_features).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01235}01235\ \ \ \ \ \textcolor{keyword}{assert}\ est.is\_categorical\_\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01236}01236\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01237}01237\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01238}01238\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01239}01239\ \ \ \ \ \textcolor{stringliteral}{"{}Est"{}},\ (HistGradientBoostingClassifier,\ HistGradientBoostingRegressor)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01240}01240\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01241}01241\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01242}01242\ \ \ \ \ \textcolor{stringliteral}{"{}use\_pandas,\ feature\_name"{}},\ [(\textcolor{keyword}{False},\ \textcolor{stringliteral}{"{}at\ index\ 0"{}}),\ (\textcolor{keyword}{True},\ \textcolor{stringliteral}{"{}'f0'"{}})]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01243}01243\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01244}01244\ \textcolor{keyword}{def\ }test\_categorical\_bad\_encoding\_errors(Est,\ use\_pandas,\ feature\_name):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01245}01245\ \ \ \ \ \textcolor{comment}{\#\ Test\ errors\ when\ categories\ are\ encoded\ incorrectly}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01246}01246\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01247}01247\ \ \ \ \ gb\ =\ Est(categorical\_features=[\textcolor{keyword}{True}],\ max\_bins=2)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01248}01248\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01249}01249\ \ \ \ \ \textcolor{keywordflow}{if}\ use\_pandas:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01250}01250\ \ \ \ \ \ \ \ \ pd\ =\ pytest.importorskip(\textcolor{stringliteral}{"{}pandas"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01251}01251\ \ \ \ \ \ \ \ \ X\ =\ pd.DataFrame(\{\textcolor{stringliteral}{"{}f0"{}}:\ [0,\ 1,\ 2]\})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01252}01252\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01253}01253\ \ \ \ \ \ \ \ \ X\ =\ np.array([[0,\ 1,\ 2]]).T}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01254}01254\ \ \ \ \ y\ =\ np.arange(3)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01255}01255\ \ \ \ \ msg\ =\ (}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01256}01256\ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}Categorical\ feature\ \{feature\_name\}\ is\ expected\ to\ have\ a\ "{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01257}01257\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}cardinality\ <=\ 2\ but\ actually\ has\ a\ cardinality\ of\ 3."{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01258}01258\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01259}01259\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=msg):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01260}01260\ \ \ \ \ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01261}01261\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01262}01262\ \ \ \ \ \textcolor{comment}{\#\ nans\ are\ ignored\ in\ the\ counts}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01263}01263\ \ \ \ \ X\ =\ np.array([[0,\ 1,\ np.nan]]).T}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01264}01264\ \ \ \ \ y\ =\ np.arange(3)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01265}01265\ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01266}01266\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01267}01267\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01268}01268\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01269}01269\ \ \ \ \ \textcolor{stringliteral}{"{}Est"{}},\ (HistGradientBoostingClassifier,\ HistGradientBoostingRegressor)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01270}01270\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01271}01271\ \textcolor{keyword}{def\ }test\_uint8\_predict(Est):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01272}01272\ \ \ \ \ \textcolor{comment}{\#\ Non\ regression\ test\ for}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01273}01273\ \ \ \ \ \textcolor{comment}{\#\ https://github.com/scikit-\/learn/scikit-\/learn/issues/18408}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01274}01274\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ X\ can\ be\ of\ dtype\ uint8\ (i.e.\ X\_BINNED\_DTYPE)\ in\ predict.\ It}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01275}01275\ \ \ \ \ \textcolor{comment}{\#\ will\ be\ converted\ to\ X\_DTYPE.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01276}01276\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01277}01277\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01278}01278\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01279}01279\ \ \ \ \ X\ =\ rng.randint(0,\ 100,\ size=(10,\ 2)).astype(np.uint8)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01280}01280\ \ \ \ \ y\ =\ rng.randint(0,\ 2,\ size=10).astype(np.uint8)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01281}01281\ \ \ \ \ est\ =\ Est()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01282}01282\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01283}01283\ \ \ \ \ est.predict(X)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01284}01284\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01285}01285\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01286}01286\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01287}01287\ \ \ \ \ \textcolor{stringliteral}{"{}interaction\_cst,\ n\_features,\ result"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01288}01288\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01289}01289\ \ \ \ \ \ \ \ \ (\textcolor{keywordtype}{None},\ 931,\ \textcolor{keywordtype}{None}),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01290}01290\ \ \ \ \ \ \ \ \ ([\{0,\ 1\}],\ 2,\ [\{0,\ 1\}]),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01291}01291\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}pairwise"{}},\ 2,\ [\{0,\ 1\}]),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01292}01292\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}pairwise"{}},\ 4,\ [\{0,\ 1\},\ \{0,\ 2\},\ \{0,\ 3\},\ \{1,\ 2\},\ \{1,\ 3\},\ \{2,\ 3\}]),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01293}01293\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}no\_interactions"{}},\ 2,\ [\{0\},\ \{1\}]),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01294}01294\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}no\_interactions"{}},\ 4,\ [\{0\},\ \{1\},\ \{2\},\ \{3\}]),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01295}01295\ \ \ \ \ \ \ \ \ ([(1,\ 0),\ [5,\ 1]],\ 6,\ [\{0,\ 1\},\ \{1,\ 5\},\ \{2,\ 3,\ 4\}]),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01296}01296\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01297}01297\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01298}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a6899a98ba2ca7069b673af35aa91d40d}{01298}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a6899a98ba2ca7069b673af35aa91d40d}{test\_check\_interaction\_cst}}(interaction\_cst,\ n\_features,\ result):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01299}01299\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ \_check\_interaction\_cst\ returns\ the\ expected\ list\ of\ sets"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01300}01300\ \ \ \ \ est\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01301}01301\ \ \ \ \ est.set\_params(interaction\_cst=interaction\_cst)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01302}01302\ \ \ \ \ \textcolor{keyword}{assert}\ est.\_check\_interaction\_cst(n\_features)\ ==\ result}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01303}01303\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01304}01304\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01305}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a7d5029f1dcb1cd33faf267a057ef3e82}{01305}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a7d5029f1dcb1cd33faf267a057ef3e82}{test\_interaction\_cst\_numerically}}():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01306}01306\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ interaction\ constraints\ have\ no\ forbidden\ interactions."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01307}01307\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01308}01308\ \ \ \ \ n\_samples\ =\ 1000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01309}01309\ \ \ \ \ X\ =\ rng.uniform(size=(n\_samples,\ 2))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01310}01310\ \ \ \ \ \textcolor{comment}{\#\ Construct\ y\ with\ a\ strong\ interaction\ term}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01311}01311\ \ \ \ \ \textcolor{comment}{\#\ y\ =\ x0\ +\ x1\ +\ 5\ *\ x0\ *\ x1}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01312}01312\ \ \ \ \ y\ =\ np.hstack((X,\ 5\ *\ X[:,\ [0]]\ *\ X[:,\ [1]])).sum(axis=1)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01313}01313\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01314}01314\ \ \ \ \ est\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(random\_state=42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01315}01315\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01316}01316\ \ \ \ \ est\_no\_interactions\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01317}01317\ \ \ \ \ \ \ \ \ interaction\_cst=[\{0\},\ \{1\}],\ random\_state=42}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01318}01318\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01319}01319\ \ \ \ \ est\_no\_interactions.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01320}01320\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01321}01321\ \ \ \ \ delta\ =\ 0.25}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01322}01322\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ we\ do\ not\ extrapolate\ out\ of\ the\ training\ set\ as\ tree-\/based\ estimators}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01323}01323\ \ \ \ \ \textcolor{comment}{\#\ are\ very\ bad\ in\ doing\ so.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01324}01324\ \ \ \ \ X\_test\ =\ X[(X[:,\ 0]\ <\ 1\ -\/\ delta)\ \&\ (X[:,\ 1]\ <\ 1\ -\/\ delta)]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01325}01325\ \ \ \ \ X\_delta\_d\_0\ =\ X\_test\ +\ [delta,\ 0]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01326}01326\ \ \ \ \ X\_delta\_0\_d\ =\ X\_test\ +\ [0,\ delta]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01327}01327\ \ \ \ \ X\_delta\_d\_d\ =\ X\_test\ +\ [delta,\ delta]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01328}01328\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01329}01329\ \ \ \ \ \textcolor{comment}{\#\ Note:\ For\ the\ y\ from\ above\ as\ a\ function\ of\ x0\ and\ x1,\ we\ have}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01330}01330\ \ \ \ \ \textcolor{comment}{\#\ y(x0+d,\ x1+d)\ =\ y(x0,\ x1)\ +\ 5\ *\ d\ *\ (2/5\ +\ x0\ +\ x1)\ +\ 5\ *\ d**2}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01331}01331\ \ \ \ \ \textcolor{comment}{\#\ y(x0+d,\ x1)\ \ \ =\ y(x0,\ x1)\ +\ 5\ *\ d\ *\ (1/5\ +\ x1)}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01332}01332\ \ \ \ \ \textcolor{comment}{\#\ y(x0,\ \ \ x1+d)\ =\ y(x0,\ x1)\ +\ 5\ *\ d\ *\ (1/5\ +\ x0)}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01333}01333\ \ \ \ \ \textcolor{comment}{\#\ Without\ interaction\ constraints,\ we\ would\ expect\ a\ result\ of\ 5\ *\ d**2\ for\ the}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01334}01334\ \ \ \ \ \textcolor{comment}{\#\ following\ expression,\ but\ zero\ with\ constraints\ in\ place.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01335}01335\ \ \ \ \ assert\_allclose(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01336}01336\ \ \ \ \ \ \ \ \ est\_no\_interactions.predict(X\_delta\_d\_d)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01337}01337\ \ \ \ \ \ \ \ \ +\ est\_no\_interactions.predict(X\_test)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01338}01338\ \ \ \ \ \ \ \ \ -\/\ est\_no\_interactions.predict(X\_delta\_d\_0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01339}01339\ \ \ \ \ \ \ \ \ -\/\ est\_no\_interactions.predict(X\_delta\_0\_d),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01340}01340\ \ \ \ \ \ \ \ \ 0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01341}01341\ \ \ \ \ \ \ \ \ atol=1e-\/12,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01342}01342\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01343}01343\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01344}01344\ \ \ \ \ \textcolor{comment}{\#\ Correct\ result\ of\ the\ expressions\ is\ 5\ *\ delta**2.\ But\ this\ is\ hard\ to\ achieve\ by}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01345}01345\ \ \ \ \ \textcolor{comment}{\#\ a\ fitted\ tree-\/based\ model.\ However,\ with\ 100\ iterations\ the\ expression\ should}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01346}01346\ \ \ \ \ \textcolor{comment}{\#\ at\ least\ be\ positive!}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01347}01347\ \ \ \ \ \textcolor{keyword}{assert}\ np.all(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01348}01348\ \ \ \ \ \ \ \ \ est.predict(X\_delta\_d\_d)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01349}01349\ \ \ \ \ \ \ \ \ +\ est.predict(X\_test)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01350}01350\ \ \ \ \ \ \ \ \ -\/\ est.predict(X\_delta\_d\_0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01351}01351\ \ \ \ \ \ \ \ \ -\/\ est.predict(X\_delta\_0\_d)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01352}01352\ \ \ \ \ \ \ \ \ >\ 0.01}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01353}01353\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01354}01354\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01355}01355\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01356}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a962466734911480f7433bcd355c21ae4}{01356}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a962466734911480f7433bcd355c21ae4}{test\_no\_user\_warning\_with\_scoring}}():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01357}01357\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ no\ UserWarning\ is\ raised\ when\ scoring\ is\ set.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01358}01358\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01359}01359\ \textcolor{stringliteral}{\ \ \ \ Non-\/regression\ test\ for\ \#22907.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01360}01360\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01361}01361\ \ \ \ \ pd\ =\ pytest.importorskip(\textcolor{stringliteral}{"{}pandas"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01362}01362\ \ \ \ \ X,\ y\ =\ make\_regression(n\_samples=50,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01363}01363\ \ \ \ \ X\_df\ =\ pd.DataFrame(X,\ columns=[f\textcolor{stringliteral}{"{}col\{i\}"{}}\ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(X.shape[1])])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01364}01364\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01365}01365\ \ \ \ \ est\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01366}01366\ \ \ \ \ \ \ \ \ random\_state=0,\ scoring=\textcolor{stringliteral}{"{}neg\_mean\_absolute\_error"{}},\ early\_stopping=\textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01367}01367\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01368}01368\ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01369}01369\ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}error"{}},\ UserWarning)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01370}01370\ \ \ \ \ \ \ \ \ est.fit(X\_df,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01371}01371\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01372}01372\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01373}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a124b83ee297d5edcadfa012d71d1d826}{01373}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a124b83ee297d5edcadfa012d71d1d826}{test\_class\_weights}}():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01374}01374\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}High\ level\ test\ to\ check\ class\_weights."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01375}01375\ \ \ \ \ n\_samples\ =\ 255}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01376}01376\ \ \ \ \ n\_features\ =\ 2}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01377}01377\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01378}01378\ \ \ \ \ X,\ y\ =\ make\_classification(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01379}01379\ \ \ \ \ \ \ \ \ n\_samples=n\_samples,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01380}01380\ \ \ \ \ \ \ \ \ n\_features=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01381}01381\ \ \ \ \ \ \ \ \ n\_informative=n\_features,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01382}01382\ \ \ \ \ \ \ \ \ n\_redundant=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01383}01383\ \ \ \ \ \ \ \ \ n\_clusters\_per\_class=1,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01384}01384\ \ \ \ \ \ \ \ \ n\_classes=2,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01385}01385\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01386}01386\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01387}01387\ \ \ \ \ y\_is\_1\ =\ y\ ==\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01388}01388\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01389}01389\ \ \ \ \ \textcolor{comment}{\#\ class\_weight\ is\ the\ same\ as\ sample\ weights\ with\ the\ corresponding\ class}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01390}01390\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01391}01391\ \ \ \ \ \ \ \ \ min\_samples\_leaf=2,\ random\_state=0,\ max\_depth=2}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01392}01392\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01393}01393\ \ \ \ \ sample\_weight\ =\ np.ones(shape=(n\_samples))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01394}01394\ \ \ \ \ sample\_weight[y\_is\_1]\ =\ 3.0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01395}01395\ \ \ \ \ clf.fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01396}01396\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01397}01397\ \ \ \ \ class\_weight\ =\ \{0:\ 1.0,\ 1:\ 3.0\}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01398}01398\ \ \ \ \ clf\_class\_weighted\ =\ clone(clf).set\_params(class\_weight=class\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01399}01399\ \ \ \ \ clf\_class\_weighted.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01400}01400\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01401}01401\ \ \ \ \ assert\_allclose(clf.decision\_function(X),\ clf\_class\_weighted.decision\_function(X))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01402}01402\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01403}01403\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ sample\_weight\ and\ class\_weight\ are\ multiplicative}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01404}01404\ \ \ \ \ clf.fit(X,\ y,\ sample\_weight=sample\_weight**2)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01405}01405\ \ \ \ \ clf\_class\_weighted.fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01406}01406\ \ \ \ \ assert\_allclose(clf.decision\_function(X),\ clf\_class\_weighted.decision\_function(X))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01407}01407\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01408}01408\ \ \ \ \ \textcolor{comment}{\#\ Make\ imbalanced\ dataset}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01409}01409\ \ \ \ \ X\_imb\ =\ np.concatenate((X[\string~y\_is\_1],\ X[y\_is\_1][:10]))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01410}01410\ \ \ \ \ y\_imb\ =\ np.concatenate((y[\string~y\_is\_1],\ y[y\_is\_1][:10]))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01411}01411\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01412}01412\ \ \ \ \ \textcolor{comment}{\#\ class\_weight="{}balanced"{}\ is\ the\ same\ as\ sample\_weights\ to\ be}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01413}01413\ \ \ \ \ \textcolor{comment}{\#\ inversely\ proportional\ to\ n\_samples\ /\ (n\_classes\ *\ np.bincount(y))}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01414}01414\ \ \ \ \ clf\_balanced\ =\ clone(clf).set\_params(class\_weight=\textcolor{stringliteral}{"{}balanced"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01415}01415\ \ \ \ \ clf\_balanced.fit(X\_imb,\ y\_imb)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01416}01416\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01417}01417\ \ \ \ \ class\_weight\ =\ y\_imb.shape[0]\ /\ (2\ *\ np.bincount(y\_imb))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01418}01418\ \ \ \ \ sample\_weight\ =\ class\_weight[y\_imb]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01419}01419\ \ \ \ \ clf\_sample\_weight\ =\ clone(clf).set\_params(class\_weight=\textcolor{keywordtype}{None})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01420}01420\ \ \ \ \ clf\_sample\_weight.fit(X\_imb,\ y\_imb,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01421}01421\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01422}01422\ \ \ \ \ assert\_allclose(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01423}01423\ \ \ \ \ \ \ \ \ clf\_balanced.decision\_function(X\_imb),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01424}01424\ \ \ \ \ \ \ \ \ clf\_sample\_weight.decision\_function(X\_imb),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01425}01425\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01426}01426\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01427}01427\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01428}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a021d57b8ad64db46dc18a12ca277d99b}{01428}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a021d57b8ad64db46dc18a12ca277d99b}{test\_unknown\_category\_that\_are\_negative}}():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01429}01429\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ unknown\ categories\ that\ are\ negative\ does\ not\ error.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01430}01430\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01431}01431\ \textcolor{stringliteral}{\ \ \ \ Non-\/regression\ test\ for\ \#24274.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01432}01432\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01433}01433\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01434}01434\ \ \ \ \ n\_samples\ =\ 1000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01435}01435\ \ \ \ \ X\ =\ np.c\_[rng.rand(n\_samples),\ rng.randint(4,\ size=n\_samples)]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01436}01436\ \ \ \ \ y\ =\ np.zeros(shape=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01437}01437\ \ \ \ \ y[X[:,\ 1]\ \%\ 2\ ==\ 0]\ =\ 1}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01438}01438\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01439}01439\ \ \ \ \ hist\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01440}01440\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01441}01441\ \ \ \ \ \ \ \ \ categorical\_features=[\textcolor{keyword}{False},\ \textcolor{keyword}{True}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01442}01442\ \ \ \ \ \ \ \ \ max\_iter=10,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01443}01443\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01444}01444\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01445}01445\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ negative\ values\ from\ the\ second\ column\ are\ treated\ like\ a}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01446}01446\ \ \ \ \ \textcolor{comment}{\#\ missing\ category}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01447}01447\ \ \ \ \ X\_test\_neg\ =\ np.asarray([[1,\ -\/2],\ [3,\ -\/4]])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01448}01448\ \ \ \ \ X\_test\_nan\ =\ np.asarray([[1,\ np.nan],\ [3,\ np.nan]])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01449}01449\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01450}01450\ \ \ \ \ assert\_allclose(hist.predict(X\_test\_neg),\ hist.predict(X\_test\_nan))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01451}01451\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01452}01452\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01453}01453\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01454}01454\ \ \ \ \ (\textcolor{stringliteral}{"{}GradientBoosting"{}},\ \textcolor{stringliteral}{"{}make\_X\_y"{}}),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01455}01455\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01456}01456\ \ \ \ \ \ \ \ \ (HistGradientBoostingClassifier,\ make\_classification),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01457}01457\ \ \ \ \ \ \ \ \ (HistGradientBoostingRegressor,\ make\_regression),}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01458}01458\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01459}01459\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01460}01460\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}sample\_weight"{},\ [False,\ True])}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01461}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a12ddca707adcc026b207c7fc28b996af}{01461}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a12ddca707adcc026b207c7fc28b996af}{test\_X\_val\_in\_fit}}(GradientBoosting,\ make\_X\_y,\ sample\_weight,\ global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01462}01462\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ that\ passing\ X\_val,\ y\_val\ in\ fit\ is\ same\ as\ validation\ fraction."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01463}01463\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01464}01464\ \ \ \ \ n\_samples\ =\ 100}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01465}01465\ \ \ \ \ X,\ y\ =\ make\_X\_y(n\_samples=n\_samples,\ random\_state=rng)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01466}01466\ \ \ \ \ \textcolor{keywordflow}{if}\ sample\_weight:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01467}01467\ \ \ \ \ \ \ \ \ sample\_weight\ =\ np.abs(rng.normal(size=n\_samples))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01468}01468\ \ \ \ \ \ \ \ \ data\ =\ (X,\ y,\ sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01469}01469\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01470}01470\ \ \ \ \ \ \ \ \ sample\_weight\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01471}01471\ \ \ \ \ \ \ \ \ data\ =\ (X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01472}01472\ \ \ \ \ rng\_seed\ =\ global\_random\_seed}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01473}01473\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01474}01474\ \ \ \ \ \textcolor{comment}{\#\ Fit\ with\ validation\ fraction\ and\ early\ stopping.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01475}01475\ \ \ \ \ m1\ =\ GradientBoosting(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01476}01476\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01477}01477\ \ \ \ \ \ \ \ \ validation\_fraction=0.5,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01478}01478\ \ \ \ \ \ \ \ \ random\_state=rng\_seed,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01479}01479\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01480}01480\ \ \ \ \ m1.fit(X,\ y,\ sample\_weight)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01481}01481\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01482}01482\ \ \ \ \ \textcolor{comment}{\#\ Do\ train-\/test\ split\ ourselves.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01483}01483\ \ \ \ \ rng\ =\ check\_random\_state(rng\_seed)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01484}01484\ \ \ \ \ \textcolor{comment}{\#\ We\ do\ the\ same\ as\ in\ the\ fit\ method.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01485}01485\ \ \ \ \ stratify\ =\ y\ \textcolor{keywordflow}{if}\ isinstance(m1,\ HistGradientBoostingClassifier)\ \textcolor{keywordflow}{else}\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01486}01486\ \ \ \ \ random\_seed\ =\ rng.randint(np.iinfo(np.uint32).max,\ dtype=\textcolor{stringliteral}{"{}u8"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01487}01487\ \ \ \ \ X\_train,\ X\_val,\ y\_train,\ y\_val,\ *sw\ =\ train\_test\_split(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01488}01488\ \ \ \ \ \ \ \ \ *data,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01489}01489\ \ \ \ \ \ \ \ \ test\_size=0.5,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01490}01490\ \ \ \ \ \ \ \ \ stratify=stratify,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01491}01491\ \ \ \ \ \ \ \ \ random\_state=random\_seed,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01492}01492\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01493}01493\ \ \ \ \ \textcolor{keywordflow}{if}\ sample\_weight\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01494}01494\ \ \ \ \ \ \ \ \ sample\_weight\_train\ =\ sw[0]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01495}01495\ \ \ \ \ \ \ \ \ sample\_weight\_val\ =\ sw[1]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01496}01496\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01497}01497\ \ \ \ \ \ \ \ \ sample\_weight\_train\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01498}01498\ \ \ \ \ \ \ \ \ sample\_weight\_val\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01499}01499\ \ \ \ \ m2\ =\ GradientBoosting(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01500}01500\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01501}01501\ \ \ \ \ \ \ \ \ random\_state=rng\_seed,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01502}01502\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01503}01503\ \ \ \ \ m2.fit(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01504}01504\ \ \ \ \ \ \ \ \ X\_train,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01505}01505\ \ \ \ \ \ \ \ \ y\_train,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01506}01506\ \ \ \ \ \ \ \ \ sample\_weight=sample\_weight\_train,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01507}01507\ \ \ \ \ \ \ \ \ X\_val=X\_val,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01508}01508\ \ \ \ \ \ \ \ \ y\_val=y\_val,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01509}01509\ \ \ \ \ \ \ \ \ sample\_weight\_val=sample\_weight\_val,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01510}01510\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01511}01511\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01512}01512\ \ \ \ \ assert\_allclose(m2.n\_iter\_,\ m1.n\_iter\_)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01513}01513\ \ \ \ \ assert\_allclose(m2.predict(X),\ m1.predict(X))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01514}01514\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01515}01515\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01516}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a03fb5cc18b04e3730d162148929a4f63}{01516}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a03fb5cc18b04e3730d162148929a4f63}{test\_X\_val\_raises\_missing\_y\_val}}():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01517}01517\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ that\ an\ error\ is\ raised\ if\ X\_val\ given\ but\ y\_val\ None."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01518}01518\ \ \ \ \ X,\ y\ =\ make\_classification(n\_samples=4)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01519}01519\ \ \ \ \ X,\ X\_val\ =\ X[:2],\ X[2:]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01520}01520\ \ \ \ \ y,\ y\_val\ =\ y[:2],\ y[2:]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01521}01521\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01522}01522\ \ \ \ \ \ \ \ \ ValueError,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01523}01523\ \ \ \ \ \ \ \ \ match=\textcolor{stringliteral}{"{}X\_val\ is\ provided,\ but\ y\_val\ was\ not\ provided"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01524}01524\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01525}01525\ \ \ \ \ \ \ \ \ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}().fit(X,\ y,\ X\_val=X\_val)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01526}01526\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01527}01527\ \ \ \ \ \ \ \ \ ValueError,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01528}01528\ \ \ \ \ \ \ \ \ match=\textcolor{stringliteral}{"{}y\_val\ is\ provided,\ but\ X\_val\ was\ not\ provided"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01529}01529\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01530}01530\ \ \ \ \ \ \ \ \ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}().fit(X,\ y,\ y\_val=y\_val)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01531}01531\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01532}01532\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01533}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_af781d90466c1cbcc843fd0a35aed3a1d}{01533}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_af781d90466c1cbcc843fd0a35aed3a1d}{test\_X\_val\_raises\_with\_early\_stopping\_false}}():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01534}01534\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ that\ an\ error\ is\ raised\ if\ X\_val\ given\ but\ early\_stopping\ is\ False."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01535}01535\ \ \ \ \ X,\ y\ =\ make\_regression(n\_samples=4)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01536}01536\ \ \ \ \ X,\ X\_val\ =\ X[:2],\ X[2:]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01537}01537\ \ \ \ \ y,\ y\_val\ =\ y[:2],\ y[2:]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01538}01538\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01539}01539\ \ \ \ \ \ \ \ \ ValueError,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01540}01540\ \ \ \ \ \ \ \ \ match=\textcolor{stringliteral}{"{}X\_val\ and\ y\_val\ are\ passed\ to\ fit\ while\ at\ the\ same\ time"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01541}01541\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01542}01542\ \ \ \ \ \ \ \ \ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingRegressor}{HistGradientBoostingRegressor}}(early\_stopping=\textcolor{keyword}{False}).fit(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01543}01543\ \ \ \ \ \ \ \ \ \ \ \ \ X,\ y,\ X\_val=X\_val,\ y\_val=y\_val}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01544}01544\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01545}01545\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01546}01546\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01547}01547\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}dataframe\_lib"{},\ ["{}pandas"{},\ "{}polars"{}])}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01548}01548\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01549}01549\ \ \ \ \ \textcolor{stringliteral}{"{}HistGradientBoosting"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01550}01550\ \ \ \ \ [HistGradientBoostingClassifier,\ HistGradientBoostingRegressor],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01551}01551\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01552}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a79f7a2af997edd7e3e79ac4421afc324}{01552}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a79f7a2af997edd7e3e79ac4421afc324}{test\_dataframe\_categorical\_results\_same\_as\_ndarray}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01553}01553\ \ \ \ \ dataframe\_lib,\ HistGradientBoosting}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01554}01554\ ):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01555}01555\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ pandas\ categorical\ give\ the\ same\ results\ as\ ndarray."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01556}01556\ \ \ \ \ pytest.importorskip(dataframe\_lib)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01557}01557\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01558}01558\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01559}01559\ \ \ \ \ n\_samples\ =\ 5\_000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01560}01560\ \ \ \ \ n\_cardinality\ =\ 50}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01561}01561\ \ \ \ \ max\_bins\ =\ 100}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01562}01562\ \ \ \ \ f\_num\ =\ rng.rand(n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01563}01563\ \ \ \ \ f\_cat\ =\ rng.randint(n\_cardinality,\ size=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01564}01564\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01565}01565\ \ \ \ \ \textcolor{comment}{\#\ Make\ f\_cat\ an\ informative\ feature}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01566}01566\ \ \ \ \ y\ =\ (f\_cat\ \%\ 3\ ==\ 0)\ \&\ (f\_num\ >\ 0.2)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01567}01567\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01568}01568\ \ \ \ \ X\ =\ np.c\_[f\_num,\ f\_cat]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01569}01569\ \ \ \ \ f\_cat\ =\ [f\textcolor{stringliteral}{"{}cat\{c:0>3\}"{}}\ \textcolor{keywordflow}{for}\ c\ \textcolor{keywordflow}{in}\ f\_cat]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01570}01570\ \ \ \ \ X\_df\ =\ \_convert\_container(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01571}01571\ \ \ \ \ \ \ \ \ np.asarray([f\_num,\ f\_cat]).T,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01572}01572\ \ \ \ \ \ \ \ \ dataframe\_lib,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01573}01573\ \ \ \ \ \ \ \ \ [\textcolor{stringliteral}{"{}f\_num"{}},\ \textcolor{stringliteral}{"{}f\_cat"{}}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01574}01574\ \ \ \ \ \ \ \ \ categorical\_feature\_names=[\textcolor{stringliteral}{"{}f\_cat"{}}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01575}01575\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01576}01576\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01577}01577\ \ \ \ \ X\_train,\ X\_test,\ X\_train\_df,\ X\_test\_df,\ y\_train,\ y\_test\ =\ train\_test\_split(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01578}01578\ \ \ \ \ \ \ \ \ X,\ X\_df,\ y,\ random\_state=0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01579}01579\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01580}01580\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01581}01581\ \ \ \ \ hist\_kwargs\ =\ dict(max\_iter=10,\ max\_bins=max\_bins,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01582}01582\ \ \ \ \ hist\_np\ =\ HistGradientBoosting(categorical\_features=[\textcolor{keyword}{False},\ \textcolor{keyword}{True}],\ **hist\_kwargs)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01583}01583\ \ \ \ \ hist\_np.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01584}01584\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01585}01585\ \ \ \ \ hist\_pd\ =\ HistGradientBoosting(categorical\_features=\textcolor{stringliteral}{"{}from\_dtype"{}},\ **hist\_kwargs)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01586}01586\ \ \ \ \ hist\_pd.fit(X\_train\_df,\ y\_train)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01587}01587\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01588}01588\ \ \ \ \ \textcolor{comment}{\#\ Check\ categories\ are\ correct\ and\ sorted}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01589}01589\ \ \ \ \ categories\ =\ hist\_pd.\_preprocessor.named\_transformers\_[\textcolor{stringliteral}{"{}encoder"{}}].categories\_[0]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01590}01590\ \ \ \ \ assert\_array\_equal(categories,\ np.unique(f\_cat))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01591}01591\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01592}01592\ \ \ \ \ \textcolor{keyword}{assert}\ len(hist\_np.\_predictors)\ ==\ len(hist\_pd.\_predictors)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01593}01593\ \ \ \ \ \textcolor{keywordflow}{for}\ predictor\_1,\ predictor\_2\ \textcolor{keywordflow}{in}\ zip(hist\_np.\_predictors,\ hist\_pd.\_predictors):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01594}01594\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ len(predictor\_1[0].nodes)\ ==\ len(predictor\_2[0].nodes)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01595}01595\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01596}01596\ \ \ \ \ score\_np\ =\ hist\_np.score(X\_test,\ y\_test)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01597}01597\ \ \ \ \ score\_pd\ =\ hist\_pd.score(X\_test\_df,\ y\_test)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01598}01598\ \ \ \ \ \textcolor{keyword}{assert}\ score\_np\ ==\ pytest.approx(score\_pd)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01599}01599\ \ \ \ \ assert\_allclose(hist\_np.predict(X\_test),\ hist\_pd.predict(X\_test\_df))}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01600}01600\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01601}01601\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01602}01602\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}dataframe\_lib"{},\ ["{}pandas"{},\ "{}polars"{}])}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01603}01603\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01604}01604\ \ \ \ \ \textcolor{stringliteral}{"{}HistGradientBoosting"{}},}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01605}01605\ \ \ \ \ [HistGradientBoostingClassifier,\ HistGradientBoostingRegressor],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01606}01606\ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01607}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a8e7d2855f3eedc058c9f9d4a69a26b3e}{01607}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_a8e7d2855f3eedc058c9f9d4a69a26b3e}{test\_dataframe\_categorical\_errors}}(dataframe\_lib,\ HistGradientBoosting):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01608}01608\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ error\ cases\ for\ pandas\ categorical\ feature."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01609}01609\ \ \ \ \ pytest.importorskip(dataframe\_lib)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01610}01610\ \ \ \ \ msg\ =\ \textcolor{stringliteral}{"{}Categorical\ feature\ 'f\_cat'\ is\ expected\ to\ have\ a\ cardinality\ <=\ 16"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01611}01611\ \ \ \ \ hist\ =\ HistGradientBoosting(categorical\_features=\textcolor{stringliteral}{"{}from\_dtype"{}},\ max\_bins=16)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01612}01612\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01613}01613\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01614}01614\ \ \ \ \ f\_cat\ =\ rng.randint(0,\ high=100,\ size=100).astype(str)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01615}01615\ \ \ \ \ X\_df\ =\ \_convert\_container(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01616}01616\ \ \ \ \ \ \ \ \ f\_cat[:,\ \textcolor{keywordtype}{None}],\ dataframe\_lib,\ [\textcolor{stringliteral}{"{}f\_cat"{}}],\ categorical\_feature\_names=[\textcolor{stringliteral}{"{}f\_cat"{}}]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01617}01617\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01618}01618\ \ \ \ \ y\ =\ rng.randint(0,\ high=2,\ size=100)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01619}01619\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01620}01620\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=msg):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01621}01621\ \ \ \ \ \ \ \ \ hist.fit(X\_df,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01622}01622\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01623}01623\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01624}01624\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}dataframe\_lib"{},\ ["{}pandas"{},\ "{}polars"{}])}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01625}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_ae3e26b71393f9535caaf6aed1075ee3d}{01625}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1tests_1_1test__gradient__boosting_ae3e26b71393f9535caaf6aed1075ee3d}{test\_categorical\_different\_order\_same\_model}}(dataframe\_lib):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01626}01626\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ the\ order\ of\ the\ categorical\ gives\ same\ model."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01627}01627\ \ \ \ \ pytest.importorskip(dataframe\_lib)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01628}01628\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01629}01629\ \ \ \ \ n\_samples\ =\ 1\_000}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01630}01630\ \ \ \ \ f\_ints\ =\ rng.randint(low=0,\ high=2,\ size=n\_samples)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01631}01631\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01632}01632\ \ \ \ \ \textcolor{comment}{\#\ Construct\ a\ target\ with\ some\ noise}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01633}01633\ \ \ \ \ y\ =\ f\_ints.copy()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01634}01634\ \ \ \ \ flipped\ =\ rng.choice([\textcolor{keyword}{True},\ \textcolor{keyword}{False}],\ size=n\_samples,\ p=[0.1,\ 0.9])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01635}01635\ \ \ \ \ y[flipped]\ =\ 1\ -\/\ y[flipped]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01636}01636\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01637}01637\ \ \ \ \ \textcolor{comment}{\#\ Construct\ categorical\ where\ 0\ -\/>\ A\ and\ 1\ -\/>\ B\ and\ 1\ -\/>\ A\ and\ 0\ -\/>\ B}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01638}01638\ \ \ \ \ f\_cat\_a\_b\ =\ np.asarray([\textcolor{stringliteral}{"{}A"{}},\ \textcolor{stringliteral}{"{}B"{}}])[f\_ints]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01639}01639\ \ \ \ \ f\_cat\_b\_a\ =\ np.asarray([\textcolor{stringliteral}{"{}B"{}},\ \textcolor{stringliteral}{"{}A"{}}])[f\_ints]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01640}01640\ \ \ \ \ df\_a\_b\ =\ \_convert\_container(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01641}01641\ \ \ \ \ \ \ \ \ f\_cat\_a\_b[:,\ \textcolor{keywordtype}{None}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01642}01642\ \ \ \ \ \ \ \ \ dataframe\_lib,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01643}01643\ \ \ \ \ \ \ \ \ [\textcolor{stringliteral}{"{}f\_cat"{}}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01644}01644\ \ \ \ \ \ \ \ \ categorical\_feature\_names=[\textcolor{stringliteral}{"{}f\_cat"{}}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01645}01645\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01646}01646\ \ \ \ \ df\_b\_a\ =\ \_convert\_container(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01647}01647\ \ \ \ \ \ \ \ \ f\_cat\_b\_a[:,\ \textcolor{keywordtype}{None}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01648}01648\ \ \ \ \ \ \ \ \ dataframe\_lib,}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01649}01649\ \ \ \ \ \ \ \ \ [\textcolor{stringliteral}{"{}f\_cat"{}}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01650}01650\ \ \ \ \ \ \ \ \ categorical\_feature\_names=[\textcolor{stringliteral}{"{}f\_cat"{}}],}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01651}01651\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01652}01652\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01653}01653\ \ \ \ \ hist\_a\_b\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01654}01654\ \ \ \ \ \ \ \ \ categorical\_features=\textcolor{stringliteral}{"{}from\_dtype"{}},\ random\_state=0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01655}01655\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01656}01656\ \ \ \ \ hist\_b\_a\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01657}01657\ \ \ \ \ \ \ \ \ categorical\_features=\textcolor{stringliteral}{"{}from\_dtype"{}},\ random\_state=0}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01658}01658\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01659}01659\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01660}01660\ \ \ \ \ hist\_a\_b.fit(df\_a\_b,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01661}01661\ \ \ \ \ hist\_b\_a.fit(df\_b\_a,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01662}01662\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01663}01663\ \ \ \ \ \textcolor{keyword}{assert}\ len(hist\_a\_b.\_predictors)\ ==\ len(hist\_b\_a.\_predictors)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01664}01664\ \ \ \ \ \textcolor{keywordflow}{for}\ predictor\_1,\ predictor\_2\ \textcolor{keywordflow}{in}\ zip(hist\_a\_b.\_predictors,\ hist\_b\_a.\_predictors):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01665}01665\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ len(predictor\_1[0].nodes)\ ==\ len(predictor\_2[0].nodes)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01666}01666\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01667}01667\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01668}01668\ \textcolor{keyword}{def\ }get\_different\_bitness\_node\_ndarray(node\_ndarray):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01669}01669\ \ \ \ \ new\_dtype\_for\_indexing\_fields\ =\ np.int64\ \textcolor{keywordflow}{if}\ \_IS\_32BIT\ \textcolor{keywordflow}{else}\ np.int32}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01670}01670\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01671}01671\ \ \ \ \ \textcolor{comment}{\#\ field\ names\ in\ Node\ struct\ with\ np.intp\ types\ (see}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01672}01672\ \ \ \ \ \textcolor{comment}{\#\ sklearn/ensemble/\_hist\_gradient\_boosting/common.pyx)}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01673}01673\ \ \ \ \ indexing\_field\_names\ =\ [\textcolor{stringliteral}{"{}feature\_idx"{}}]}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01674}01674\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01675}01675\ \ \ \ \ new\_dtype\_dict\ =\ \{}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01676}01676\ \ \ \ \ \ \ \ \ name:\ dtype\ \textcolor{keywordflow}{for}\ name,\ (dtype,\ \_)\ \textcolor{keywordflow}{in}\ node\_ndarray.dtype.fields.items()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01677}01677\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01678}01678\ \ \ \ \ \textcolor{keywordflow}{for}\ name\ \textcolor{keywordflow}{in}\ indexing\_field\_names:}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01679}01679\ \ \ \ \ \ \ \ \ new\_dtype\_dict[name]\ =\ new\_dtype\_for\_indexing\_fields}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01680}01680\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01681}01681\ \ \ \ \ new\_dtype\ =\ np.dtype(}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01682}01682\ \ \ \ \ \ \ \ \ \{\textcolor{stringliteral}{"{}names"{}}:\ list(new\_dtype\_dict.keys()),\ \textcolor{stringliteral}{"{}formats"{}}:\ list(new\_dtype\_dict.values())\}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01683}01683\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01684}01684\ \ \ \ \ \textcolor{keywordflow}{return}\ node\_ndarray.astype(new\_dtype,\ casting=\textcolor{stringliteral}{"{}same\_kind"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01685}01685\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01686}01686\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01687}01687\ \textcolor{keyword}{def\ }reduce\_predictor\_with\_different\_bitness(predictor):}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01688}01688\ \ \ \ \ cls,\ args,\ state\ =\ predictor.\_\_reduce\_\_()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01689}01689\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01690}01690\ \ \ \ \ new\_state\ =\ state.copy()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01691}01691\ \ \ \ \ new\_state[\textcolor{stringliteral}{"{}nodes"{}}]\ =\ get\_different\_bitness\_node\_ndarray(new\_state[\textcolor{stringliteral}{"{}nodes"{}}])}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01692}01692\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01693}01693\ \ \ \ \ \textcolor{keywordflow}{return}\ (cls,\ args,\ new\_state)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01694}01694\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01695}01695\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01696}01696\ \textcolor{keyword}{def\ }test\_different\_bitness\_pickle():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01697}01697\ \ \ \ \ X,\ y\ =\ make\_classification(random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01698}01698\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01699}01699\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(random\_state=0,\ max\_depth=3)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01700}01700\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01701}01701\ \ \ \ \ score\ =\ clf.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01702}01702\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01703}01703\ \ \ \ \ \textcolor{keyword}{def\ }pickle\_dump\_with\_different\_bitness():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01704}01704\ \ \ \ \ \ \ \ \ f\ =\ io.BytesIO()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01705}01705\ \ \ \ \ \ \ \ \ p\ =\ pickle.Pickler(f)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01706}01706\ \ \ \ \ \ \ \ \ p.dispatch\_table\ =\ copyreg.dispatch\_table.copy()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01707}01707\ \ \ \ \ \ \ \ \ p.dispatch\_table[TreePredictor]\ =\ reduce\_predictor\_with\_different\_bitness}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01708}01708\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01709}01709\ \ \ \ \ \ \ \ \ p.dump(clf)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01710}01710\ \ \ \ \ \ \ \ \ f.seek(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01711}01711\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ f}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01712}01712\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01713}01713\ \ \ \ \ \textcolor{comment}{\#\ Simulate\ loading\ a\ pickle\ of\ the\ same\ model\ trained\ on\ a\ platform\ with\ different}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01714}01714\ \ \ \ \ \textcolor{comment}{\#\ bitness\ that\ than\ the\ platform\ it\ will\ be\ used\ to\ make\ predictions\ on:}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01715}01715\ \ \ \ \ new\_clf\ =\ pickle.load(pickle\_dump\_with\_different\_bitness())}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01716}01716\ \ \ \ \ new\_score\ =\ new\_clf.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01717}01717\ \ \ \ \ \textcolor{keyword}{assert}\ score\ ==\ pytest.approx(new\_score)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01718}01718\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01719}01719\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01720}01720\ \textcolor{keyword}{def\ }test\_different\_bitness\_joblib\_pickle():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01721}01721\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ that\ a\ platform\ specific\ pickle\ generated\ on\ a\ 64\ bit}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01722}01722\ \ \ \ \ \textcolor{comment}{\#\ platform\ can\ be\ converted\ at\ pickle\ load\ time\ into\ an\ estimator}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01723}01723\ \ \ \ \ \textcolor{comment}{\#\ with\ Cython\ code\ that\ works\ with\ the\ host's\ native\ integer\ precision}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01724}01724\ \ \ \ \ \textcolor{comment}{\#\ to\ index\ nodes\ in\ the\ tree\ data\ structure\ when\ the\ host\ is\ a\ 32\ bit}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01725}01725\ \ \ \ \ \textcolor{comment}{\#\ platform\ (and\ vice\ versa).}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01726}01726\ \ \ \ \ \textcolor{comment}{\#}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01727}01727\ \ \ \ \ \textcolor{comment}{\#\ This\ is\ in\ particular\ useful\ to\ be\ able\ to\ train\ a\ model\ on\ a\ 64\ bit\ Linux}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01728}01728\ \ \ \ \ \textcolor{comment}{\#\ server\ and\ deploy\ the\ model\ as\ part\ of\ a\ (32\ bit)\ WASM\ in-\/browser}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01729}01729\ \ \ \ \ \textcolor{comment}{\#\ application\ using\ pyodide.}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01730}01730\ \ \ \ \ X,\ y\ =\ make\_classification(random\_state=0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01731}01731\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01732}01732\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}(random\_state=0,\ max\_depth=3)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01733}01733\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01734}01734\ \ \ \ \ score\ =\ clf.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01735}01735\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01736}01736\ \ \ \ \ \textcolor{keyword}{def\ }joblib\_dump\_with\_different\_bitness():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01737}01737\ \ \ \ \ \ \ \ \ f\ =\ io.BytesIO()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01738}01738\ \ \ \ \ \ \ \ \ p\ =\ \mbox{\hyperlink{classjoblib_1_1numpy__pickle_1_1NumpyPickler}{NumpyPickler}}(f)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01739}01739\ \ \ \ \ \ \ \ \ p.dispatch\_table\ =\ copyreg.dispatch\_table.copy()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01740}01740\ \ \ \ \ \ \ \ \ p.dispatch\_table[TreePredictor]\ =\ reduce\_predictor\_with\_different\_bitness}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01741}01741\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01742}01742\ \ \ \ \ \ \ \ \ p.dump(clf)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01743}01743\ \ \ \ \ \ \ \ \ f.seek(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01744}01744\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ f}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01745}01745\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01746}01746\ \ \ \ \ new\_clf\ =\ joblib.load(joblib\_dump\_with\_different\_bitness())}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01747}01747\ \ \ \ \ new\_score\ =\ new\_clf.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01748}01748\ \ \ \ \ \textcolor{keyword}{assert}\ score\ ==\ pytest.approx(new\_score)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01749}01749\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01750}01750\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01751}01751\ \textcolor{keyword}{def\ }test\_pandas\_nullable\_dtype():}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01752}01752\ \ \ \ \ \textcolor{comment}{\#\ Non\ regression\ test\ for\ https://github.com/scikit-\/learn/scikit-\/learn/issues/28317}}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01753}01753\ \ \ \ \ pd\ =\ pytest.importorskip(\textcolor{stringliteral}{"{}pandas"{}})}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01754}01754\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01755}01755\ \ \ \ \ rng\ =\ np.random.default\_rng(0)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01756}01756\ \ \ \ \ X\ =\ pd.DataFrame(\{\textcolor{stringliteral}{"{}a"{}}:\ rng.integers(10,\ size=100)\}).astype(pd.Int64Dtype())}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01757}01757\ \ \ \ \ y\ =\ rng.integers(2,\ size=100)}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01758}01758\ }
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01759}01759\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__hist__gradient__boosting_1_1gradient__boosting_1_1HistGradientBoostingClassifier}{HistGradientBoostingClassifier}}()}
\DoxyCodeLine{\Hypertarget{__hist__gradient__boosting_2tests_2test__gradient__boosting_8py_source_l01760}01760\ \ \ \ \ clf.fit(X,\ y)}

\end{DoxyCode}
