\doxysection{test\+\_\+gradient\+\_\+boosting.\+py}
\hypertarget{tests_2test__gradient__boosting_8py_source}{}\label{tests_2test__gradient__boosting_8py_source}\index{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/ensemble/tests/test\_gradient\_boosting.py@{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/ensemble/tests/test\_gradient\_boosting.py}}

\begin{DoxyCode}{0}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00001}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting}{00001}}\ \textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00002}00002\ \textcolor{stringliteral}{Testing\ for\ the\ gradient\ boosting\ module\ (sklearn.ensemble.gradient\_boosting).}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00003}00003\ \textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00004}00004\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00005}00005\ \textcolor{keyword}{import}\ re}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00006}00006\ \textcolor{keyword}{import}\ warnings}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00007}00007\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00008}00008\ \textcolor{keyword}{import}\ numpy\ \textcolor{keyword}{as}\ np}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00009}00009\ \textcolor{keyword}{import}\ pytest}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00010}00010\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacenumpy_1_1testing}{numpy.testing}}\ \textcolor{keyword}{import}\ assert\_allclose}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00011}00011\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00012}00012\ \textcolor{keyword}{from}\ sklearn\ \textcolor{keyword}{import}\ datasets}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00013}00013\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1base}{sklearn.base}}\ \textcolor{keyword}{import}\ clone}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00014}00014\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1datasets}{sklearn.datasets}}\ \textcolor{keyword}{import}\ make\_classification,\ make\_regression}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00015}00015\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1dummy}{sklearn.dummy}}\ \textcolor{keyword}{import}\ DummyClassifier,\ DummyRegressor}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00016}00016\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1ensemble}{sklearn.ensemble}}\ \textcolor{keyword}{import}\ GradientBoostingClassifier,\ GradientBoostingRegressor}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00017}00017\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1__gb}{sklearn.ensemble.\_gb}}\ \textcolor{keyword}{import}\ \_safe\_divide}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00018}00018\ \textcolor{keyword}{from}\ sklearn.ensemble.\_gradient\_boosting\ \textcolor{keyword}{import}\ predict\_stages}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00019}00019\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1exceptions}{sklearn.exceptions}}\ \textcolor{keyword}{import}\ DataConversionWarning,\ NotFittedError}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00020}00020\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1linear__model}{sklearn.linear\_model}}\ \textcolor{keyword}{import}\ LinearRegression}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00021}00021\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1metrics}{sklearn.metrics}}\ \textcolor{keyword}{import}\ mean\_squared\_error}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00022}00022\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1model__selection}{sklearn.model\_selection}}\ \textcolor{keyword}{import}\ train\_test\_split}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00023}00023\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1pipeline}{sklearn.pipeline}}\ \textcolor{keyword}{import}\ make\_pipeline}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00024}00024\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1preprocessing}{sklearn.preprocessing}}\ \textcolor{keyword}{import}\ scale}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00025}00025\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1svm}{sklearn.svm}}\ \textcolor{keyword}{import}\ NuSVR}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00026}00026\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils}{sklearn.utils}}\ \textcolor{keyword}{import}\ check\_random\_state}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00027}00027\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils_1_1__mocking}{sklearn.utils.\_mocking}}\ \textcolor{keyword}{import}\ NoSampleWeightWrapper}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00028}00028\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils_1_1__param__validation}{sklearn.utils.\_param\_validation}}\ \textcolor{keyword}{import}\ InvalidParameterError}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00029}00029\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils_1_1__testing}{sklearn.utils.\_testing}}\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00030}00030\ \ \ \ \ assert\_array\_almost\_equal,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00031}00031\ \ \ \ \ assert\_array\_equal,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00032}00032\ \ \ \ \ skip\_if\_32bit,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00033}00033\ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00034}00034\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils_1_1fixes}{sklearn.utils.fixes}}\ \textcolor{keyword}{import}\ COO\_CONTAINERS,\ CSC\_CONTAINERS,\ CSR\_CONTAINERS}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00035}00035\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00036}00036\ GRADIENT\_BOOSTING\_ESTIMATORS\ =\ [GradientBoostingClassifier,\ GradientBoostingRegressor]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00037}00037\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00038}00038\ \textcolor{comment}{\#\ toy\ sample}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00039}00039\ X\ =\ [[-\/2,\ -\/1],\ [-\/1,\ -\/1],\ [-\/1,\ -\/2],\ [1,\ 1],\ [1,\ 2],\ [2,\ 1]]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00040}00040\ y\ =\ [-\/1,\ -\/1,\ -\/1,\ 1,\ 1,\ 1]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00041}00041\ T\ =\ [[-\/1,\ -\/1],\ [2,\ 2],\ [3,\ 2]]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00042}00042\ true\_result\ =\ [-\/1,\ 1,\ 1]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00043}00043\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00044}00044\ \textcolor{comment}{\#\ also\ make\ regression\ dataset}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00045}00045\ X\_reg,\ y\_reg\ =\ make\_regression(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00046}00046\ \ \ \ \ n\_samples=100,\ n\_features=4,\ n\_informative=8,\ noise=10,\ random\_state=7}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00047}00047\ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00048}00048\ y\_reg\ =\ scale(y\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00049}00049\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00050}00050\ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00051}00051\ \textcolor{comment}{\#\ also\ load\ the\ iris\ dataset}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00052}00052\ \textcolor{comment}{\#\ and\ randomly\ permute\ it}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00053}00053\ iris\ =\ datasets.load\_iris()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00054}00054\ perm\ =\ rng.permutation(iris.target.size)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00055}00055\ iris.data\ =\ iris.data[perm]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00056}00056\ iris.target\ =\ iris.target[perm]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00057}00057\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00058}00058\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00059}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a74116472415b4c5855c7441294dfda17}{00059}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a74116472415b4c5855c7441294dfda17}{test\_exponential\_n\_classes\_gt\_2}}():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00060}00060\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ exponential\ loss\ raises\ for\ n\_classes\ >\ 2."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00061}00061\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(loss=\textcolor{stringliteral}{"{}exponential"{}})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00062}00062\ \ \ \ \ msg\ =\ \textcolor{stringliteral}{"{}loss='exponential'\ is\ only\ suitable\ for\ a\ binary\ classification"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00063}00063\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=msg):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00064}00064\ \ \ \ \ \ \ \ \ clf.fit(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00065}00065\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00066}00066\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00067}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a76ef92c4589e93498655101b3999ad45}{00067}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a76ef92c4589e93498655101b3999ad45}{test\_raise\_if\_init\_has\_no\_predict\_proba}}():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00068}00068\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ raise\ if\ init\_\ has\ no\ predict\_proba\ method."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00069}00069\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(init=GradientBoostingRegressor)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00070}00070\ \ \ \ \ msg\ =\ (}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00071}00071\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}The\ 'init'\ parameter\ of\ GradientBoostingClassifier\ must\ be\ a\ str\ among\ "{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00072}00072\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\{'zero'\},\ None\ or\ an\ object\ implementing\ 'fit'\ and\ 'predict\_proba'."{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00073}00073\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00074}00074\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=msg):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00075}00075\ \ \ \ \ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00076}00076\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00077}00077\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00078}00078\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}loss"{},\ ("{}log\_loss"{},\ "{}exponential"{})})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00079}00079\ \textcolor{keyword}{def\ }test\_classification\_toy(loss,\ global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00080}00080\ \ \ \ \ \textcolor{comment}{\#\ Check\ classification\ on\ a\ toy\ dataset.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00081}00081\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00082}00082\ \ \ \ \ \ \ \ \ loss=loss,\ n\_estimators=10,\ random\_state=global\_random\_seed}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00083}00083\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00084}00084\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00085}00085\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00086}00086\ \ \ \ \ \ \ \ \ clf.predict(T)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00087}00087\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00088}00088\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00089}00089\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ true\_result)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00090}00090\ \ \ \ \ \textcolor{keyword}{assert}\ 10\ ==\ len(clf.estimators\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00091}00091\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00092}00092\ \ \ \ \ log\_loss\_decrease\ =\ clf.train\_score\_[:-\/1]\ -\/\ clf.train\_score\_[1:]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00093}00093\ \ \ \ \ \textcolor{keyword}{assert}\ np.any(log\_loss\_decrease\ >=\ 0.0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00094}00094\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00095}00095\ \ \ \ \ leaves\ =\ clf.apply(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00096}00096\ \ \ \ \ \textcolor{keyword}{assert}\ leaves.shape\ ==\ (6,\ 10,\ 1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00097}00097\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00098}00098\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00099}00099\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}loss"{},\ ("{}log\_loss"{},\ "{}exponential"{})})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00100}00100\ \textcolor{keyword}{def\ }test\_classification\_synthetic(loss,\ global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00101}00101\ \ \ \ \ \textcolor{comment}{\#\ Test\ GradientBoostingClassifier\ on\ synthetic\ dataset\ used\ by}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00102}00102\ \ \ \ \ \textcolor{comment}{\#\ Hastie\ et\ al.\ in\ ESLII\ -\/\ Figure\ 10.9}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00103}00103\ \ \ \ \ \textcolor{comment}{\#\ Note\ that\ Figure\ 10.9\ reuses\ the\ dataset\ generated\ for\ figure\ 10.2}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00104}00104\ \ \ \ \ \textcolor{comment}{\#\ and\ should\ have\ 2\_000\ train\ data\ points\ and\ 10\_000\ test\ data\ points.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00105}00105\ \ \ \ \ \textcolor{comment}{\#\ Here\ we\ intentionally\ use\ a\ smaller\ variant\ to\ make\ the\ test\ run\ faster,}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00106}00106\ \ \ \ \ \textcolor{comment}{\#\ but\ the\ conclusions\ are\ still\ the\ same,\ despite\ the\ smaller\ datasets.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00107}00107\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=2000,\ random\_state=global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00108}00108\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00109}00109\ \ \ \ \ split\_idx\ =\ 500}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00110}00110\ \ \ \ \ X\_train,\ X\_test\ =\ X[:split\_idx],\ X[split\_idx:]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00111}00111\ \ \ \ \ y\_train,\ y\_test\ =\ y[:split\_idx],\ y[split\_idx:]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00112}00112\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00113}00113\ \ \ \ \ \textcolor{comment}{\#\ Increasing\ the\ number\ of\ trees\ should\ decrease\ the\ test\ error}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00114}00114\ \ \ \ \ common\_params\ =\ \{}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00115}00115\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_depth"{}}:\ 1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00116}00116\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}learning\_rate"{}}:\ 1.0,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00117}00117\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}loss"{}}:\ loss,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00118}00118\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}random\_state"{}}:\ global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00119}00119\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00120}00120\ \ \ \ \ gbrt\_10\_stumps\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=10,\ **common\_params)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00121}00121\ \ \ \ \ gbrt\_10\_stumps.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00122}00122\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00123}00123\ \ \ \ \ gbrt\_50\_stumps\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=50,\ **common\_params)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00124}00124\ \ \ \ \ gbrt\_50\_stumps.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00125}00125\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00126}00126\ \ \ \ \ \textcolor{keyword}{assert}\ gbrt\_10\_stumps.score(X\_test,\ y\_test)\ <\ gbrt\_50\_stumps.score(X\_test,\ y\_test)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00127}00127\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00128}00128\ \ \ \ \ \textcolor{comment}{\#\ Decision\ stumps\ are\ better\ suited\ for\ this\ dataset\ with\ a\ large\ number\ of}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00129}00129\ \ \ \ \ \textcolor{comment}{\#\ estimators.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00130}00130\ \ \ \ \ common\_params\ =\ \{}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00131}00131\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}n\_estimators"{}}:\ 200,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00132}00132\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}learning\_rate"{}}:\ 1.0,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00133}00133\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}loss"{}}:\ loss,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00134}00134\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}random\_state"{}}:\ global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00135}00135\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00136}00136\ \ \ \ \ gbrt\_stumps\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(max\_depth=1,\ **common\_params)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00137}00137\ \ \ \ \ gbrt\_stumps.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00138}00138\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00139}00139\ \ \ \ \ gbrt\_10\_nodes\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(max\_leaf\_nodes=10,\ **common\_params)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00140}00140\ \ \ \ \ gbrt\_10\_nodes.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00141}00141\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00142}00142\ \ \ \ \ \textcolor{keyword}{assert}\ gbrt\_stumps.score(X\_test,\ y\_test)\ >\ gbrt\_10\_nodes.score(X\_test,\ y\_test)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00143}00143\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00144}00144\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00145}00145\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}loss"{},\ ("{}squared\_error"{},\ "{}absolute\_error"{},\ "{}huber"{})})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00146}00146\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}subsample"{},\ (1.0,\ 0.5)})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00147}00147\ \textcolor{keyword}{def\ }test\_regression\_dataset(loss,\ subsample,\ global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00148}00148\ \ \ \ \ \textcolor{comment}{\#\ Check\ consistency\ on\ regression\ dataset\ with\ least\ squares}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00149}00149\ \ \ \ \ \textcolor{comment}{\#\ and\ least\ absolute\ deviation.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00150}00150\ \ \ \ \ ones\ =\ np.ones(len(y\_reg))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00151}00151\ \ \ \ \ last\_y\_pred\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00152}00152\ \ \ \ \ \textcolor{keywordflow}{for}\ sample\_weight\ \textcolor{keywordflow}{in}\ [\textcolor{keywordtype}{None},\ ones,\ 2\ *\ ones]:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00153}00153\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ learning\_rate,\ max\_depth\ and\ n\_estimators\ were\ adjusted\ to\ get\ a\ mode}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00154}00154\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ that\ is\ accurate\ enough\ to\ reach\ a\ low\ MSE\ on\ the\ training\ set\ while}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00155}00155\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ keeping\ the\ resource\ used\ to\ execute\ this\ test\ low\ enough.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00156}00156\ \ \ \ \ \ \ \ \ reg\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00157}00157\ \ \ \ \ \ \ \ \ \ \ \ \ n\_estimators=30,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00158}00158\ \ \ \ \ \ \ \ \ \ \ \ \ loss=loss,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00159}00159\ \ \ \ \ \ \ \ \ \ \ \ \ max\_depth=4,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00160}00160\ \ \ \ \ \ \ \ \ \ \ \ \ subsample=subsample,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00161}00161\ \ \ \ \ \ \ \ \ \ \ \ \ min\_samples\_split=2,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00162}00162\ \ \ \ \ \ \ \ \ \ \ \ \ random\_state=global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00163}00163\ \ \ \ \ \ \ \ \ \ \ \ \ learning\_rate=0.5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00164}00164\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00165}00165\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00166}00166\ \ \ \ \ \ \ \ \ reg.fit(X\_reg,\ y\_reg,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00167}00167\ \ \ \ \ \ \ \ \ leaves\ =\ reg.apply(X\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00168}00168\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ leaves.shape\ ==\ (100,\ 30)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00169}00169\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00170}00170\ \ \ \ \ \ \ \ \ y\_pred\ =\ reg.predict(X\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00171}00171\ \ \ \ \ \ \ \ \ mse\ =\ mean\_squared\_error(y\_reg,\ y\_pred)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00172}00172\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ mse\ <\ 0.05}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00173}00173\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00174}00174\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ last\_y\_pred\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00175}00175\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ FIXME:\ We\ temporarily\ bypass\ this\ test.\ This\ is\ due\ to\ the\ fact}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00176}00176\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ that\ GBRT\ with\ and\ without\ \`{}sample\_weight`\ do\ not\ use\ the\ same}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00177}00177\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ implementation\ of\ the\ median\ during\ the\ initialization\ with\ the}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00178}00178\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ \`{}DummyRegressor`.\ In\ the\ future,\ we\ should\ make\ sure\ that\ both}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00179}00179\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ implementations\ should\ be\ the\ same.\ See\ PR\ \#17377\ for\ more.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00180}00180\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ assert\_allclose(last\_y\_pred,\ y\_pred)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00181}00181\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{pass}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00182}00182\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00183}00183\ \ \ \ \ \ \ \ \ last\_y\_pred\ =\ y\_pred}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00184}00184\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00185}00185\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00186}00186\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}subsample"{},\ (1.0,\ 0.5)})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00187}00187\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}sample\_weight"{},\ (None,\ 1)})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00188}00188\ \textcolor{keyword}{def\ }test\_iris(subsample,\ sample\_weight,\ global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00189}00189\ \ \ \ \ \textcolor{keywordflow}{if}\ sample\_weight\ ==\ 1:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00190}00190\ \ \ \ \ \ \ \ \ sample\_weight\ =\ np.ones(len(iris.target))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00191}00191\ \ \ \ \ \textcolor{comment}{\#\ Check\ consistency\ on\ dataset\ iris.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00192}00192\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00193}00193\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00194}00194\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}log\_loss"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00195}00195\ \ \ \ \ \ \ \ \ random\_state=global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00196}00196\ \ \ \ \ \ \ \ \ subsample=subsample,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00197}00197\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00198}00198\ \ \ \ \ clf.fit(iris.data,\ iris.target,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00199}00199\ \ \ \ \ score\ =\ clf.score(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00200}00200\ \ \ \ \ \textcolor{keyword}{assert}\ score\ >\ 0.9}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00201}00201\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00202}00202\ \ \ \ \ leaves\ =\ clf.apply(iris.data)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00203}00203\ \ \ \ \ \textcolor{keyword}{assert}\ leaves.shape\ ==\ (150,\ 100,\ 3)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00204}00204\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00205}00205\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00206}00206\ \textcolor{keyword}{def\ }test\_regression\_synthetic(global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00207}00207\ \ \ \ \ \textcolor{comment}{\#\ Test\ on\ synthetic\ regression\ datasets\ used\ in\ Leo\ Breiman,}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00208}00208\ \ \ \ \ \textcolor{comment}{\#\ \`{}Bagging\ Predictors?.\ Machine\ Learning\ 24(2):\ 123-\/140\ (1996).}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00209}00209\ \ \ \ \ random\_state\ =\ check\_random\_state(global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00210}00210\ \ \ \ \ regression\_params\ =\ \{}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00211}00211\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}n\_estimators"{}}:\ 100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00212}00212\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_depth"{}}:\ 4,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00213}00213\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}min\_samples\_split"{}}:\ 2,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00214}00214\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}learning\_rate"{}}:\ 0.1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00215}00215\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}loss"{}}:\ \textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00216}00216\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}random\_state"{}}:\ global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00217}00217\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00218}00218\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00219}00219\ \ \ \ \ \textcolor{comment}{\#\ Friedman1}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00220}00220\ \ \ \ \ X,\ y\ =\ datasets.make\_friedman1(n\_samples=1200,\ random\_state=random\_state,\ noise=1.0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00221}00221\ \ \ \ \ X\_train,\ y\_train\ =\ X[:200],\ y[:200]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00222}00222\ \ \ \ \ X\_test,\ y\_test\ =\ X[200:],\ y[200:]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00223}00223\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00224}00224\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(**regression\_params)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00225}00225\ \ \ \ \ clf.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00226}00226\ \ \ \ \ mse\ =\ mean\_squared\_error(y\_test,\ clf.predict(X\_test))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00227}00227\ \ \ \ \ \textcolor{keyword}{assert}\ mse\ <\ 6.5}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00228}00228\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00229}00229\ \ \ \ \ \textcolor{comment}{\#\ Friedman2}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00230}00230\ \ \ \ \ X,\ y\ =\ datasets.make\_friedman2(n\_samples=1200,\ random\_state=random\_state)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00231}00231\ \ \ \ \ X\_train,\ y\_train\ =\ X[:200],\ y[:200]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00232}00232\ \ \ \ \ X\_test,\ y\_test\ =\ X[200:],\ y[200:]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00233}00233\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00234}00234\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(**regression\_params)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00235}00235\ \ \ \ \ clf.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00236}00236\ \ \ \ \ mse\ =\ mean\_squared\_error(y\_test,\ clf.predict(X\_test))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00237}00237\ \ \ \ \ \textcolor{keyword}{assert}\ mse\ <\ 2500.0}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00238}00238\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00239}00239\ \ \ \ \ \textcolor{comment}{\#\ Friedman3}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00240}00240\ \ \ \ \ X,\ y\ =\ datasets.make\_friedman3(n\_samples=1200,\ random\_state=random\_state)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00241}00241\ \ \ \ \ X\_train,\ y\_train\ =\ X[:200],\ y[:200]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00242}00242\ \ \ \ \ X\_test,\ y\_test\ =\ X[200:],\ y[200:]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00243}00243\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00244}00244\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(**regression\_params)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00245}00245\ \ \ \ \ clf.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00246}00246\ \ \ \ \ mse\ =\ mean\_squared\_error(y\_test,\ clf.predict(X\_test))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00247}00247\ \ \ \ \ \textcolor{keyword}{assert}\ mse\ <\ 0.025}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00248}00248\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00249}00249\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00250}00250\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00251}00251\ \ \ \ \ \textcolor{stringliteral}{"{}GradientBoosting,\ X,\ y"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00252}00252\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00253}00253\ \ \ \ \ \ \ \ \ (GradientBoostingRegressor,\ X\_reg,\ y\_reg),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00254}00254\ \ \ \ \ \ \ \ \ (GradientBoostingClassifier,\ iris.data,\ iris.target),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00255}00255\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00256}00256\ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00257}00257\ \textcolor{keyword}{def\ }test\_feature\_importances(GradientBoosting,\ X,\ y):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00258}00258\ \ \ \ \ \textcolor{comment}{\#\ smoke\ test\ to\ check\ that\ the\ gradient\ boosting\ expose\ an\ attribute}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00259}00259\ \ \ \ \ \textcolor{comment}{\#\ feature\_importances\_}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00260}00260\ \ \ \ \ gbdt\ =\ GradientBoosting()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00261}00261\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ hasattr(gbdt,\ \textcolor{stringliteral}{"{}feature\_importances\_"{}})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00262}00262\ \ \ \ \ gbdt.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00263}00263\ \ \ \ \ \textcolor{keyword}{assert}\ hasattr(gbdt,\ \textcolor{stringliteral}{"{}feature\_importances\_"{}})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00264}00264\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00265}00265\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00266}00266\ \textcolor{keyword}{def\ }test\_probability\_log(global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00267}00267\ \ \ \ \ \textcolor{comment}{\#\ Predict\ probabilities.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00268}00268\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00269}00269\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00270}00270\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00271}00271\ \ \ \ \ \ \ \ \ clf.predict\_proba(T)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00272}00272\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00273}00273\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00274}00274\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ true\_result)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00275}00275\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00276}00276\ \ \ \ \ \textcolor{comment}{\#\ check\ if\ probabilities\ are\ in\ [0,\ 1].}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00277}00277\ \ \ \ \ y\_proba\ =\ clf.predict\_proba(T)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00278}00278\ \ \ \ \ \textcolor{keyword}{assert}\ np.all(y\_proba\ >=\ 0.0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00279}00279\ \ \ \ \ \textcolor{keyword}{assert}\ np.all(y\_proba\ <=\ 1.0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00280}00280\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00281}00281\ \ \ \ \ \textcolor{comment}{\#\ derive\ predictions\ from\ probabilities}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00282}00282\ \ \ \ \ y\_pred\ =\ clf.classes\_.take(y\_proba.argmax(axis=1),\ axis=0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00283}00283\ \ \ \ \ assert\_array\_equal(y\_pred,\ true\_result)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00284}00284\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00285}00285\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00286}00286\ \textcolor{keyword}{def\ }test\_single\_class\_with\_sample\_weight():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00287}00287\ \ \ \ \ sample\_weight\ =\ [0,\ 0,\ 0,\ 1,\ 1,\ 1]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00288}00288\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00289}00289\ \ \ \ \ msg\ =\ (}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00290}00290\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}y\ contains\ 1\ class\ after\ sample\_weight\ trimmed\ classes\ with\ "{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00291}00291\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}zero\ weights,\ while\ a\ minimum\ of\ 2\ classes\ are\ required."{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00292}00292\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00293}00293\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=msg):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00294}00294\ \ \ \ \ \ \ \ \ clf.fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00295}00295\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00296}00296\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00297}00297\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}csc\_container"{},\ CSC\_CONTAINERS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00298}00298\ \textcolor{keyword}{def\ }test\_check\_inputs\_predict\_stages(csc\_container):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00299}00299\ \ \ \ \ \textcolor{comment}{\#\ check\ that\ predict\_stages\ through\ an\ error\ if\ the\ type\ of\ X\ is\ not}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00300}00300\ \ \ \ \ \textcolor{comment}{\#\ supported}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00301}00301\ \ \ \ \ x,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00302}00302\ \ \ \ \ x\_sparse\_csc\ =\ csc\_container(x)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00303}00303\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00304}00304\ \ \ \ \ clf.fit(x,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00305}00305\ \ \ \ \ score\ =\ np.zeros((y.shape)).reshape(-\/1,\ 1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00306}00306\ \ \ \ \ err\_msg\ =\ \textcolor{stringliteral}{"{}When\ X\ is\ a\ sparse\ matrix,\ a\ CSR\ format\ is\ expected"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00307}00307\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=err\_msg):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00308}00308\ \ \ \ \ \ \ \ \ predict\_stages(clf.estimators\_,\ x\_sparse\_csc,\ clf.learning\_rate,\ score)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00309}00309\ \ \ \ \ x\_fortran\ =\ np.asfortranarray(x)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00310}00310\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=\textcolor{stringliteral}{"{}X\ should\ be\ C-\/ordered\ np.ndarray"{}}):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00311}00311\ \ \ \ \ \ \ \ \ predict\_stages(clf.estimators\_,\ x\_fortran,\ clf.learning\_rate,\ score)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00312}00312\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00313}00313\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00314}00314\ \textcolor{keyword}{def\ }test\_max\_feature\_regression(global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00315}00315\ \ \ \ \ \textcolor{comment}{\#\ Test\ to\ make\ sure\ random\ state\ is\ set\ properly.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00316}00316\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=12000,\ random\_state=global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00317}00317\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00318}00318\ \ \ \ \ X\_train,\ X\_test\ =\ X[:2000],\ X[2000:]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00319}00319\ \ \ \ \ y\_train,\ y\_test\ =\ y[:2000],\ y[2000:]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00320}00320\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00321}00321\ \ \ \ \ gbrt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00322}00322\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00323}00323\ \ \ \ \ \ \ \ \ min\_samples\_split=5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00324}00324\ \ \ \ \ \ \ \ \ max\_depth=2,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00325}00325\ \ \ \ \ \ \ \ \ learning\_rate=0.1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00326}00326\ \ \ \ \ \ \ \ \ max\_features=2,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00327}00327\ \ \ \ \ \ \ \ \ random\_state=global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00328}00328\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00329}00329\ \ \ \ \ gbrt.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00330}00330\ \ \ \ \ log\_loss\ =\ gbrt.\_loss(y\_test,\ gbrt.decision\_function(X\_test))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00331}00331\ \ \ \ \ \textcolor{keyword}{assert}\ log\_loss\ <\ 0.5,\ \textcolor{stringliteral}{"{}GB\ failed\ with\ deviance\ \%.4f"{}}\ \%\ log\_loss}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00332}00332\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00333}00333\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00334}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_ab4f6d3b7ef62338e906bea5ef558851c}{00334}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_ab4f6d3b7ef62338e906bea5ef558851c}{test\_feature\_importance\_regression}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00335}00335\ \ \ \ \ fetch\_california\_housing\_fxt,\ global\_random\_seed}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00336}00336\ ):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00337}00337\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ that\ Gini\ importance\ is\ calculated\ correctly.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00338}00338\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00339}00339\ \textcolor{stringliteral}{\ \ \ \ This\ test\ follows\ the\ example\ from\ [1]\_\ (pg.\ 373).}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00340}00340\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00341}00341\ \textcolor{stringliteral}{\ \ \ \ ..\ [1]\ Friedman,\ J.,\ Hastie,\ T.,\ \&\ Tibshirani,\ R.\ (2001).\ The\ elements}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00342}00342\ \textcolor{stringliteral}{\ \ \ \ \ \ \ of\ statistical\ learning.\ New\ York:\ Springer\ series\ in\ statistics.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00343}00343\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00344}00344\ \ \ \ \ california\ =\ fetch\_california\_housing\_fxt()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00345}00345\ \ \ \ \ X,\ y\ =\ california.data,\ california.target}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00346}00346\ \ \ \ \ X\_train,\ X\_test,\ y\_train,\ y\_test\ =\ train\_test\_split(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00347}00347\ \ \ \ \ \ \ \ \ X,\ y,\ random\_state=global\_random\_seed}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00348}00348\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00349}00349\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00350}00350\ \ \ \ \ reg\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00351}00351\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}huber"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00352}00352\ \ \ \ \ \ \ \ \ learning\_rate=0.1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00353}00353\ \ \ \ \ \ \ \ \ max\_leaf\_nodes=6,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00354}00354\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00355}00355\ \ \ \ \ \ \ \ \ random\_state=global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00356}00356\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00357}00357\ \ \ \ \ reg.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00358}00358\ \ \ \ \ sorted\_idx\ =\ np.argsort(reg.feature\_importances\_)[::-\/1]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00359}00359\ \ \ \ \ sorted\_features\ =\ [california.feature\_names[s]\ \textcolor{keywordflow}{for}\ s\ \textcolor{keywordflow}{in}\ sorted\_idx]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00360}00360\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00361}00361\ \ \ \ \ \textcolor{comment}{\#\ The\ most\ important\ feature\ is\ the\ median\ income\ by\ far.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00362}00362\ \ \ \ \ \textcolor{keyword}{assert}\ sorted\_features[0]\ ==\ \textcolor{stringliteral}{"{}MedInc"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00363}00363\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00364}00364\ \ \ \ \ \textcolor{comment}{\#\ The\ three\ subsequent\ features\ are\ the\ following.\ Their\ relative\ ordering}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00365}00365\ \ \ \ \ \textcolor{comment}{\#\ might\ change\ a\ bit\ depending\ on\ the\ randomness\ of\ the\ trees\ and\ the}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00366}00366\ \ \ \ \ \textcolor{comment}{\#\ train\ /\ test\ split.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00367}00367\ \ \ \ \ \textcolor{keyword}{assert}\ set(sorted\_features[1:4])\ ==\ \{\textcolor{stringliteral}{"{}Longitude"{}},\ \textcolor{stringliteral}{"{}AveOccup"{}},\ \textcolor{stringliteral}{"{}Latitude"{}}\}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00368}00368\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00369}00369\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00370}00370\ \textcolor{keyword}{def\ }test\_max\_features():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00371}00371\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ max\ features\ is\ set\ properly\ for\ floats\ and\ str.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00372}00372\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=12000,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00373}00373\ \ \ \ \ \_,\ n\_features\ =\ X.shape}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00374}00374\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00375}00375\ \ \ \ \ X\_train\ =\ X[:2000]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00376}00376\ \ \ \ \ y\_train\ =\ y[:2000]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00377}00377\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00378}00378\ \ \ \ \ gbrt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=1,\ max\_features=\textcolor{keywordtype}{None})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00379}00379\ \ \ \ \ gbrt.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00380}00380\ \ \ \ \ \textcolor{keyword}{assert}\ gbrt.max\_features\_\ ==\ n\_features}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00381}00381\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00382}00382\ \ \ \ \ gbrt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(n\_estimators=1,\ max\_features=\textcolor{keywordtype}{None})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00383}00383\ \ \ \ \ gbrt.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00384}00384\ \ \ \ \ \textcolor{keyword}{assert}\ gbrt.max\_features\_\ ==\ n\_features}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00385}00385\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00386}00386\ \ \ \ \ gbrt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(n\_estimators=1,\ max\_features=0.3)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00387}00387\ \ \ \ \ gbrt.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00388}00388\ \ \ \ \ \textcolor{keyword}{assert}\ gbrt.max\_features\_\ ==\ int(n\_features\ *\ 0.3)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00389}00389\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00390}00390\ \ \ \ \ gbrt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(n\_estimators=1,\ max\_features=\textcolor{stringliteral}{"{}sqrt"{}})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00391}00391\ \ \ \ \ gbrt.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00392}00392\ \ \ \ \ \textcolor{keyword}{assert}\ gbrt.max\_features\_\ ==\ int(np.sqrt(n\_features))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00393}00393\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00394}00394\ \ \ \ \ gbrt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(n\_estimators=1,\ max\_features=\textcolor{stringliteral}{"{}log2"{}})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00395}00395\ \ \ \ \ gbrt.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00396}00396\ \ \ \ \ \textcolor{keyword}{assert}\ gbrt.max\_features\_\ ==\ int(np.log2(n\_features))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00397}00397\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00398}00398\ \ \ \ \ gbrt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(n\_estimators=1,\ max\_features=0.01\ /\ X.shape[1])}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00399}00399\ \ \ \ \ gbrt.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00400}00400\ \ \ \ \ \textcolor{keyword}{assert}\ gbrt.max\_features\_\ ==\ 1}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00401}00401\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00402}00402\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00403}00403\ \textcolor{keyword}{def\ }test\_staged\_predict():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00404}00404\ \ \ \ \ \textcolor{comment}{\#\ Test\ whether\ staged\ decision\ function\ eventually\ gives}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00405}00405\ \ \ \ \ \textcolor{comment}{\#\ the\ same\ prediction.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00406}00406\ \ \ \ \ X,\ y\ =\ datasets.make\_friedman1(n\_samples=1200,\ random\_state=1,\ noise=1.0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00407}00407\ \ \ \ \ X\_train,\ y\_train\ =\ X[:200],\ y[:200]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00408}00408\ \ \ \ \ X\_test\ =\ X[200:]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00409}00409\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00410}00410\ \ \ \ \ \textcolor{comment}{\#\ test\ raise\ ValueError\ if\ not\ fitted}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00411}00411\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00412}00412\ \ \ \ \ \ \ \ \ np.fromiter(clf.staged\_predict(X\_test),\ dtype=np.float64)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00413}00413\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00414}00414\ \ \ \ \ clf.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00415}00415\ \ \ \ \ y\_pred\ =\ clf.predict(X\_test)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00416}00416\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00417}00417\ \ \ \ \ \textcolor{comment}{\#\ test\ if\ prediction\ for\ last\ stage\ equals\ \`{}\`{}predict``}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00418}00418\ \ \ \ \ \textcolor{keywordflow}{for}\ y\ \textcolor{keywordflow}{in}\ clf.staged\_predict(X\_test):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00419}00419\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ y.shape\ ==\ y\_pred.shape}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00420}00420\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00421}00421\ \ \ \ \ assert\_array\_almost\_equal(y\_pred,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00422}00422\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00423}00423\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00424}00424\ \textcolor{keyword}{def\ }test\_staged\_predict\_proba():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00425}00425\ \ \ \ \ \textcolor{comment}{\#\ Test\ whether\ staged\ predict\ proba\ eventually\ gives}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00426}00426\ \ \ \ \ \textcolor{comment}{\#\ the\ same\ prediction.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00427}00427\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=1200,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00428}00428\ \ \ \ \ X\_train,\ y\_train\ =\ X[:200],\ y[:200]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00429}00429\ \ \ \ \ X\_test,\ y\_test\ =\ X[200:],\ y[200:]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00430}00430\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=20)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00431}00431\ \ \ \ \ \textcolor{comment}{\#\ test\ raise\ NotFittedError\ if\ not}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00432}00432\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(NotFittedError):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00433}00433\ \ \ \ \ \ \ \ \ np.fromiter(clf.staged\_predict\_proba(X\_test),\ dtype=np.float64)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00434}00434\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00435}00435\ \ \ \ \ clf.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00436}00436\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00437}00437\ \ \ \ \ \textcolor{comment}{\#\ test\ if\ prediction\ for\ last\ stage\ equals\ \`{}\`{}predict``}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00438}00438\ \ \ \ \ \textcolor{keywordflow}{for}\ y\_pred\ \textcolor{keywordflow}{in}\ clf.staged\_predict(X\_test):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00439}00439\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ y\_test.shape\ ==\ y\_pred.shape}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00440}00440\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00441}00441\ \ \ \ \ assert\_array\_equal(clf.predict(X\_test),\ y\_pred)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00442}00442\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00443}00443\ \ \ \ \ \textcolor{comment}{\#\ test\ if\ prediction\ for\ last\ stage\ equals\ \`{}\`{}predict\_proba``}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00444}00444\ \ \ \ \ \textcolor{keywordflow}{for}\ staged\_proba\ \textcolor{keywordflow}{in}\ clf.staged\_predict\_proba(X\_test):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00445}00445\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ y\_test.shape[0]\ ==\ staged\_proba.shape[0]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00446}00446\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ 2\ ==\ staged\_proba.shape[1]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00447}00447\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00448}00448\ \ \ \ \ assert\_array\_almost\_equal(clf.predict\_proba(X\_test),\ staged\_proba)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00449}00449\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00450}00450\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00451}00451\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Estimator"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00452}00452\ \textcolor{keyword}{def\ }test\_staged\_functions\_defensive(Estimator,\ global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00453}00453\ \ \ \ \ \textcolor{comment}{\#\ test\ that\ staged\_functions\ make\ defensive\ copies}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00454}00454\ \ \ \ \ rng\ =\ np.random.RandomState(global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00455}00455\ \ \ \ \ X\ =\ rng.uniform(size=(10,\ 3))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00456}00456\ \ \ \ \ y\ =\ (4\ *\ X[:,\ 0]).astype(int)\ +\ 1\ \ \textcolor{comment}{\#\ don't\ predict\ zeros}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00457}00457\ \ \ \ \ estimator\ =\ Estimator()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00458}00458\ \ \ \ \ estimator.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00459}00459\ \ \ \ \ \textcolor{keywordflow}{for}\ func\ \textcolor{keywordflow}{in}\ [\textcolor{stringliteral}{"{}predict"{}},\ \textcolor{stringliteral}{"{}decision\_function"{}},\ \textcolor{stringliteral}{"{}predict\_proba"{}}]:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00460}00460\ \ \ \ \ \ \ \ \ staged\_func\ =\ getattr(estimator,\ \textcolor{stringliteral}{"{}staged\_"{}}\ +\ func,\ \textcolor{keywordtype}{None})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00461}00461\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ staged\_func\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00462}00462\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ regressor\ has\ no\ staged\_predict\_proba}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00463}00463\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{continue}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00464}00464\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings(record=\textcolor{keyword}{True}):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00465}00465\ \ \ \ \ \ \ \ \ \ \ \ \ staged\_result\ =\ list(staged\_func(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00466}00466\ \ \ \ \ \ \ \ \ staged\_result[1][:]\ =\ 0}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00467}00467\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ np.all(staged\_result[0]\ !=\ 0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00468}00468\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00469}00469\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00470}00470\ \textcolor{keyword}{def\ }test\_serialization():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00471}00471\ \ \ \ \ \textcolor{comment}{\#\ Check\ model\ serialization.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00472}00472\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00473}00473\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00474}00474\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00475}00475\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ true\_result)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00476}00476\ \ \ \ \ \textcolor{keyword}{assert}\ 100\ ==\ len(clf.estimators\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00477}00477\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00478}00478\ \ \ \ \ \textcolor{keywordflow}{try}:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00479}00479\ \ \ \ \ \ \ \ \ \textcolor{keyword}{import}\ cPickle\ \textcolor{keyword}{as}\ pickle}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00480}00480\ \ \ \ \ \textcolor{keywordflow}{except}\ ImportError:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00481}00481\ \ \ \ \ \ \ \ \ \textcolor{keyword}{import}\ pickle}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00482}00482\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00483}00483\ \ \ \ \ serialized\_clf\ =\ pickle.dumps(clf,\ protocol=pickle.HIGHEST\_PROTOCOL)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00484}00484\ \ \ \ \ clf\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00485}00485\ \ \ \ \ clf\ =\ pickle.loads(serialized\_clf)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00486}00486\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ true\_result)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00487}00487\ \ \ \ \ \textcolor{keyword}{assert}\ 100\ ==\ len(clf.estimators\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00488}00488\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00489}00489\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00490}00490\ \textcolor{keyword}{def\ }test\_degenerate\_targets():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00491}00491\ \ \ \ \ \textcolor{comment}{\#\ Check\ if\ we\ can\ fit\ even\ though\ all\ targets\ are\ equal.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00492}00492\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00493}00493\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00494}00494\ \ \ \ \ \textcolor{comment}{\#\ classifier\ should\ raise\ exception}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00495}00495\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00496}00496\ \ \ \ \ \ \ \ \ clf.fit(X,\ np.ones(len(X)))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00497}00497\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00498}00498\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00499}00499\ \ \ \ \ clf.fit(X,\ np.ones(len(X)))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00500}00500\ \ \ \ \ clf.predict([rng.rand(2)])}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00501}00501\ \ \ \ \ assert\_array\_equal(np.ones((1,),\ dtype=np.float64),\ clf.predict([rng.rand(2)]))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00502}00502\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00503}00503\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00504}00504\ \textcolor{keyword}{def\ }test\_quantile\_loss(global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00505}00505\ \ \ \ \ \textcolor{comment}{\#\ Check\ if\ quantile\ loss\ with\ alpha=0.5\ equals\ absolute\_error.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00506}00506\ \ \ \ \ clf\_quantile\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00507}00507\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00508}00508\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}quantile"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00509}00509\ \ \ \ \ \ \ \ \ max\_depth=4,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00510}00510\ \ \ \ \ \ \ \ \ alpha=0.5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00511}00511\ \ \ \ \ \ \ \ \ random\_state=global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00512}00512\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00513}00513\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00514}00514\ \ \ \ \ clf\_quantile.fit(X\_reg,\ y\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00515}00515\ \ \ \ \ y\_quantile\ =\ clf\_quantile.predict(X\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00516}00516\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00517}00517\ \ \ \ \ clf\_ae\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00518}00518\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00519}00519\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}absolute\_error"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00520}00520\ \ \ \ \ \ \ \ \ max\_depth=4,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00521}00521\ \ \ \ \ \ \ \ \ random\_state=global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00522}00522\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00523}00523\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00524}00524\ \ \ \ \ clf\_ae.fit(X\_reg,\ y\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00525}00525\ \ \ \ \ y\_ae\ =\ clf\_ae.predict(X\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00526}00526\ \ \ \ \ assert\_allclose(y\_quantile,\ y\_ae)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00527}00527\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00528}00528\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00529}00529\ \textcolor{keyword}{def\ }test\_symbol\_labels():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00530}00530\ \ \ \ \ \textcolor{comment}{\#\ Test\ with\ non-\/integer\ class\ labels.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00531}00531\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00532}00532\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00533}00533\ \ \ \ \ symbol\_y\ =\ list(map(str,\ y))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00534}00534\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00535}00535\ \ \ \ \ clf.fit(X,\ symbol\_y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00536}00536\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ list(map(str,\ true\_result)))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00537}00537\ \ \ \ \ \textcolor{keyword}{assert}\ 100\ ==\ len(clf.estimators\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00538}00538\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00539}00539\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00540}00540\ \textcolor{keyword}{def\ }test\_float\_class\_labels():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00541}00541\ \ \ \ \ \textcolor{comment}{\#\ Test\ with\ float\ class\ labels.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00542}00542\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00543}00543\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00544}00544\ \ \ \ \ float\_y\ =\ np.asarray(y,\ dtype=np.float32)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00545}00545\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00546}00546\ \ \ \ \ clf.fit(X,\ float\_y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00547}00547\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ np.asarray(true\_result,\ dtype=np.float32))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00548}00548\ \ \ \ \ \textcolor{keyword}{assert}\ 100\ ==\ len(clf.estimators\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00549}00549\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00550}00550\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00551}00551\ \textcolor{keyword}{def\ }test\_shape\_y():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00552}00552\ \ \ \ \ \textcolor{comment}{\#\ Test\ with\ float\ class\ labels.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00553}00553\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00554}00554\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00555}00555\ \ \ \ \ y\_\ =\ np.asarray(y,\ dtype=np.int32)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00556}00556\ \ \ \ \ y\_\ =\ y\_[:,\ np.newaxis]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00557}00557\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00558}00558\ \ \ \ \ \textcolor{comment}{\#\ This\ will\ raise\ a\ DataConversionWarning\ that\ we\ want\ to}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00559}00559\ \ \ \ \ \textcolor{comment}{\#\ "{}always"{}\ raise,\ elsewhere\ the\ warnings\ gets\ ignored\ in\ the}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00560}00560\ \ \ \ \ \textcolor{comment}{\#\ later\ tests,\ and\ the\ tests\ that\ check\ for\ this\ warning\ fail}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00561}00561\ \ \ \ \ warn\_msg\ =\ (}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00562}00562\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}A\ column-\/vector\ y\ was\ passed\ when\ a\ 1d\ array\ was\ expected.\ "{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00563}00563\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Please\ change\ the\ shape\ of\ y\ to\ \(\backslash\)\(\backslash\)(n\_samples,\ \(\backslash\)\(\backslash\)),\ for\ "{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00564}00564\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}example\ using\ ravel()."{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00565}00565\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00566}00566\ \ \ \ \ \textcolor{keyword}{with}\ pytest.warns(DataConversionWarning,\ match=warn\_msg):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00567}00567\ \ \ \ \ \ \ \ \ clf.fit(X,\ y\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00568}00568\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ true\_result)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00569}00569\ \ \ \ \ \textcolor{keyword}{assert}\ 100\ ==\ len(clf.estimators\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00570}00570\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00571}00571\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00572}00572\ \textcolor{keyword}{def\ }test\_mem\_layout():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00573}00573\ \ \ \ \ \textcolor{comment}{\#\ Test\ with\ different\ memory\ layouts\ of\ X\ and\ y}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00574}00574\ \ \ \ \ X\_\ =\ np.asfortranarray(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00575}00575\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00576}00576\ \ \ \ \ clf.fit(X\_,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00577}00577\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ true\_result)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00578}00578\ \ \ \ \ \textcolor{keyword}{assert}\ 100\ ==\ len(clf.estimators\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00579}00579\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00580}00580\ \ \ \ \ X\_\ =\ np.ascontiguousarray(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00581}00581\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00582}00582\ \ \ \ \ clf.fit(X\_,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00583}00583\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ true\_result)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00584}00584\ \ \ \ \ \textcolor{keyword}{assert}\ 100\ ==\ len(clf.estimators\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00585}00585\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00586}00586\ \ \ \ \ y\_\ =\ np.asarray(y,\ dtype=np.int32)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00587}00587\ \ \ \ \ y\_\ =\ np.ascontiguousarray(y\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00588}00588\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00589}00589\ \ \ \ \ clf.fit(X,\ y\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00590}00590\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ true\_result)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00591}00591\ \ \ \ \ \textcolor{keyword}{assert}\ 100\ ==\ len(clf.estimators\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00592}00592\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00593}00593\ \ \ \ \ y\_\ =\ np.asarray(y,\ dtype=np.int32)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00594}00594\ \ \ \ \ y\_\ =\ np.asfortranarray(y\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00595}00595\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00596}00596\ \ \ \ \ clf.fit(X,\ y\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00597}00597\ \ \ \ \ assert\_array\_equal(clf.predict(T),\ true\_result)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00598}00598\ \ \ \ \ \textcolor{keyword}{assert}\ 100\ ==\ len(clf.estimators\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00599}00599\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00600}00600\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00601}00601\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}GradientBoostingEstimator"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00602}00602\ \textcolor{keyword}{def\ }test\_oob\_improvement(GradientBoostingEstimator):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00603}00603\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ oob\ improvement\ has\ correct\ shape\ and\ regression\ test.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00604}00604\ \ \ \ \ estimator\ =\ GradientBoostingEstimator(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00605}00605\ \ \ \ \ \ \ \ \ n\_estimators=100,\ random\_state=1,\ subsample=0.5}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00606}00606\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00607}00607\ \ \ \ \ estimator.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00608}00608\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_improvement\_.shape[0]\ ==\ 100}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00609}00609\ \ \ \ \ \textcolor{comment}{\#\ hard-\/coded\ regression\ test\ -\/\ change\ if\ modification\ in\ OOB\ computation}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00610}00610\ \ \ \ \ assert\_array\_almost\_equal(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00611}00611\ \ \ \ \ \ \ \ \ estimator.oob\_improvement\_[:5],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00612}00612\ \ \ \ \ \ \ \ \ np.array([0.19,\ 0.15,\ 0.12,\ -\/0.11,\ 0.11]),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00613}00613\ \ \ \ \ \ \ \ \ decimal=2,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00614}00614\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00615}00615\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00616}00616\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00617}00617\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}GradientBoostingEstimator"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00618}00618\ \textcolor{keyword}{def\ }test\_oob\_scores(GradientBoostingEstimator):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00619}00619\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ oob\ scores\ has\ correct\ shape\ and\ regression\ test.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00620}00620\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00621}00621\ \ \ \ \ estimator\ =\ GradientBoostingEstimator(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00622}00622\ \ \ \ \ \ \ \ \ n\_estimators=100,\ random\_state=1,\ subsample=0.5}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00623}00623\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00624}00624\ \ \ \ \ estimator.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00625}00625\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_scores\_.shape[0]\ ==\ 100}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00626}00626\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_scores\_[-\/1]\ ==\ pytest.approx(estimator.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00627}00627\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00628}00628\ \ \ \ \ estimator\ =\ GradientBoostingEstimator(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00629}00629\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00630}00630\ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00631}00631\ \ \ \ \ \ \ \ \ subsample=0.5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00632}00632\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00633}00633\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00634}00634\ \ \ \ \ estimator.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00635}00635\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_scores\_.shape[0]\ <\ 100}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00636}00636\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_scores\_[-\/1]\ ==\ pytest.approx(estimator.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00637}00637\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00638}00638\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00639}00639\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00640}00640\ \ \ \ \ \textcolor{stringliteral}{"{}GradientBoostingEstimator,\ oob\_attribute"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00641}00641\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00642}00642\ \ \ \ \ \ \ \ \ (GradientBoostingClassifier,\ \textcolor{stringliteral}{"{}oob\_improvement\_"{}}),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00643}00643\ \ \ \ \ \ \ \ \ (GradientBoostingClassifier,\ \textcolor{stringliteral}{"{}oob\_scores\_"{}}),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00644}00644\ \ \ \ \ \ \ \ \ (GradientBoostingClassifier,\ \textcolor{stringliteral}{"{}oob\_score\_"{}}),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00645}00645\ \ \ \ \ \ \ \ \ (GradientBoostingRegressor,\ \textcolor{stringliteral}{"{}oob\_improvement\_"{}}),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00646}00646\ \ \ \ \ \ \ \ \ (GradientBoostingRegressor,\ \textcolor{stringliteral}{"{}oob\_scores\_"{}}),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00647}00647\ \ \ \ \ \ \ \ \ (GradientBoostingRegressor,\ \textcolor{stringliteral}{"{}oob\_score\_"{}}),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00648}00648\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00649}00649\ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00650}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a1ad6554b8427b9e81dd8035fd518726d}{00650}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a1ad6554b8427b9e81dd8035fd518726d}{test\_oob\_attributes\_error}}(GradientBoostingEstimator,\ oob\_attribute):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00651}00651\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00652}00652\ \textcolor{stringliteral}{\ \ \ \ Check\ that\ we\ raise\ an\ AttributeError\ when\ the\ OOB\ statistics\ were\ not\ computed.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00653}00653\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00654}00654\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00655}00655\ \ \ \ \ estimator\ =\ GradientBoostingEstimator(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00656}00656\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00657}00657\ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00658}00658\ \ \ \ \ \ \ \ \ subsample=1.0,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00659}00659\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00660}00660\ \ \ \ \ estimator.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00661}00661\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(AttributeError):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00662}00662\ \ \ \ \ \ \ \ \ estimator.oob\_attribute}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00663}00663\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00664}00664\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00665}00665\ \textcolor{keyword}{def\ }test\_oob\_multilcass\_iris():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00666}00666\ \ \ \ \ \textcolor{comment}{\#\ Check\ OOB\ improvement\ on\ multi-\/class\ dataset.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00667}00667\ \ \ \ \ estimator\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00668}00668\ \ \ \ \ \ \ \ \ n\_estimators=100,\ loss=\textcolor{stringliteral}{"{}log\_loss"{}},\ random\_state=1,\ subsample=0.5}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00669}00669\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00670}00670\ \ \ \ \ estimator.fit(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00671}00671\ \ \ \ \ score\ =\ estimator.score(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00672}00672\ \ \ \ \ \textcolor{keyword}{assert}\ score\ >\ 0.9}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00673}00673\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_improvement\_.shape[0]\ ==\ estimator.n\_estimators}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00674}00674\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_scores\_.shape[0]\ ==\ estimator.n\_estimators}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00675}00675\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_scores\_[-\/1]\ ==\ pytest.approx(estimator.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00676}00676\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00677}00677\ \ \ \ \ estimator\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00678}00678\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00679}00679\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}log\_loss"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00680}00680\ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00681}00681\ \ \ \ \ \ \ \ \ subsample=0.5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00682}00682\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00683}00683\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00684}00684\ \ \ \ \ estimator.fit(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00685}00685\ \ \ \ \ score\ =\ estimator.score(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00686}00686\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_improvement\_.shape[0]\ <\ estimator.n\_estimators}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00687}00687\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_scores\_.shape[0]\ <\ estimator.n\_estimators}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00688}00688\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_scores\_[-\/1]\ ==\ pytest.approx(estimator.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00689}00689\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00690}00690\ \ \ \ \ \textcolor{comment}{\#\ hard-\/coded\ regression\ test\ -\/\ change\ if\ modification\ in\ OOB\ computation}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00691}00691\ \ \ \ \ \textcolor{comment}{\#\ FIXME:\ the\ following\ snippet\ does\ not\ yield\ the\ same\ results\ on\ 32\ bits}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00692}00692\ \ \ \ \ \textcolor{comment}{\#\ assert\_array\_almost\_equal(estimator.oob\_improvement\_[:5],}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00693}00693\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ np.array([12.68,\ 10.45,\ 8.18,\ 6.43,\ 5.13]),}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00694}00694\ \ \ \ \ \textcolor{comment}{\#\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ decimal=2)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00695}00695\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00696}00696\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00697}00697\ \textcolor{keyword}{def\ }test\_verbose\_output():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00698}00698\ \ \ \ \ \textcolor{comment}{\#\ Check\ verbose=1\ does\ not\ cause\ error.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00699}00699\ \ \ \ \ \textcolor{keyword}{import}\ sys}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00700}00700\ \ \ \ \ \textcolor{keyword}{from}\ io\ \textcolor{keyword}{import}\ StringIO}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00701}00701\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00702}00702\ \ \ \ \ old\_stdout\ =\ sys.stdout}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00703}00703\ \ \ \ \ sys.stdout\ =\ \mbox{\hyperlink{classStringIO}{StringIO}}()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00704}00704\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00705}00705\ \ \ \ \ \ \ \ \ n\_estimators=100,\ random\_state=1,\ verbose=1,\ subsample=0.8}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00706}00706\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00707}00707\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00708}00708\ \ \ \ \ verbose\_output\ =\ sys.stdout}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00709}00709\ \ \ \ \ sys.stdout\ =\ old\_stdout}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00710}00710\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00711}00711\ \ \ \ \ \textcolor{comment}{\#\ check\ output}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00712}00712\ \ \ \ \ verbose\_output.seek(0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00713}00713\ \ \ \ \ header\ =\ verbose\_output.readline().rstrip()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00714}00714\ \ \ \ \ \textcolor{comment}{\#\ with\ OOB}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00715}00715\ \ \ \ \ true\_header\ =\ \textcolor{stringliteral}{"{}\ "{}}.join([\textcolor{stringliteral}{"{}\%10s"{}}]\ +\ [\textcolor{stringliteral}{"{}\%16s"{}}]\ *\ 3)\ \%\ (}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00716}00716\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Iter"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00717}00717\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Train\ Loss"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00718}00718\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}OOB\ Improve"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00719}00719\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Remaining\ Time"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00720}00720\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00721}00721\ \ \ \ \ \textcolor{keyword}{assert}\ true\_header\ ==\ header}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00722}00722\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00723}00723\ \ \ \ \ n\_lines\ =\ sum(1\ \textcolor{keywordflow}{for}\ l\ \textcolor{keywordflow}{in}\ verbose\_output.readlines())}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00724}00724\ \ \ \ \ \textcolor{comment}{\#\ one\ for\ 1-\/10\ and\ then\ 9\ for\ 20-\/100}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00725}00725\ \ \ \ \ \textcolor{keyword}{assert}\ 10\ +\ 9\ ==\ n\_lines}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00726}00726\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00727}00727\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00728}00728\ \textcolor{keyword}{def\ }test\_more\_verbose\_output():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00729}00729\ \ \ \ \ \textcolor{comment}{\#\ Check\ verbose=2\ does\ not\ cause\ error.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00730}00730\ \ \ \ \ \textcolor{keyword}{import}\ sys}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00731}00731\ \ \ \ \ \textcolor{keyword}{from}\ io\ \textcolor{keyword}{import}\ StringIO}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00732}00732\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00733}00733\ \ \ \ \ old\_stdout\ =\ sys.stdout}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00734}00734\ \ \ \ \ sys.stdout\ =\ \mbox{\hyperlink{classStringIO}{StringIO}}()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00735}00735\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=100,\ random\_state=1,\ verbose=2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00736}00736\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00737}00737\ \ \ \ \ verbose\_output\ =\ sys.stdout}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00738}00738\ \ \ \ \ sys.stdout\ =\ old\_stdout}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00739}00739\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00740}00740\ \ \ \ \ \textcolor{comment}{\#\ check\ output}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00741}00741\ \ \ \ \ verbose\_output.seek(0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00742}00742\ \ \ \ \ header\ =\ verbose\_output.readline().rstrip()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00743}00743\ \ \ \ \ \textcolor{comment}{\#\ no\ OOB}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00744}00744\ \ \ \ \ true\_header\ =\ \textcolor{stringliteral}{"{}\ "{}}.join([\textcolor{stringliteral}{"{}\%10s"{}}]\ +\ [\textcolor{stringliteral}{"{}\%16s"{}}]\ *\ 2)\ \%\ (}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00745}00745\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Iter"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00746}00746\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Train\ Loss"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00747}00747\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Remaining\ Time"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00748}00748\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00749}00749\ \ \ \ \ \textcolor{keyword}{assert}\ true\_header\ ==\ header}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00750}00750\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00751}00751\ \ \ \ \ n\_lines\ =\ sum(1\ \textcolor{keywordflow}{for}\ l\ \textcolor{keywordflow}{in}\ verbose\_output.readlines())}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00752}00752\ \ \ \ \ \textcolor{comment}{\#\ 100\ lines\ for\ n\_estimators==100}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00753}00753\ \ \ \ \ \textcolor{keyword}{assert}\ 100\ ==\ n\_lines}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00754}00754\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00755}00755\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00756}00756\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00757}00757\ \textcolor{keyword}{def\ }test\_warm\_start(Cls,\ global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00758}00758\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ warm\ start\ equals\ fit.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00759}00759\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00760}00760\ \ \ \ \ est\ =\ Cls(n\_estimators=200,\ max\_depth=1,\ random\_state=global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00761}00761\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00762}00762\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00763}00763\ \ \ \ \ est\_ws\ =\ Cls(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00764}00764\ \ \ \ \ \ \ \ \ n\_estimators=100,\ max\_depth=1,\ warm\_start=\textcolor{keyword}{True},\ random\_state=global\_random\_seed}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00765}00765\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00766}00766\ \ \ \ \ est\_ws.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00767}00767\ \ \ \ \ est\_ws.set\_params(n\_estimators=200)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00768}00768\ \ \ \ \ est\_ws.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00769}00769\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00770}00770\ \ \ \ \ \textcolor{keywordflow}{if}\ Cls\ \textcolor{keywordflow}{is}\ GradientBoostingRegressor:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00771}00771\ \ \ \ \ \ \ \ \ assert\_allclose(est\_ws.predict(X),\ est.predict(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00772}00772\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00773}00773\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Random\ state\ is\ preserved\ and\ hence\ predict\_proba\ must\ also\ be}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00774}00774\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ same}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00775}00775\ \ \ \ \ \ \ \ \ assert\_array\_equal(est\_ws.predict(X),\ est.predict(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00776}00776\ \ \ \ \ \ \ \ \ assert\_allclose(est\_ws.predict\_proba(X),\ est.predict\_proba(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00777}00777\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00778}00778\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00779}00779\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00780}00780\ \textcolor{keyword}{def\ }test\_warm\_start\_n\_estimators(Cls,\ global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00781}00781\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ warm\ start\ equals\ fit\ -\/\ set\ n\_estimators.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00782}00782\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00783}00783\ \ \ \ \ est\ =\ Cls(n\_estimators=300,\ max\_depth=1,\ random\_state=global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00784}00784\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00785}00785\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00786}00786\ \ \ \ \ est\_ws\ =\ Cls(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00787}00787\ \ \ \ \ \ \ \ \ n\_estimators=100,\ max\_depth=1,\ warm\_start=\textcolor{keyword}{True},\ random\_state=global\_random\_seed}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00788}00788\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00789}00789\ \ \ \ \ est\_ws.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00790}00790\ \ \ \ \ est\_ws.set\_params(n\_estimators=300)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00791}00791\ \ \ \ \ est\_ws.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00792}00792\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00793}00793\ \ \ \ \ assert\_allclose(est\_ws.predict(X),\ est.predict(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00794}00794\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00795}00795\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00796}00796\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00797}00797\ \textcolor{keyword}{def\ }test\_warm\_start\_max\_depth(Cls):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00798}00798\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ possible\ to\ fit\ trees\ of\ different\ depth\ in\ ensemble.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00799}00799\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00800}00800\ \ \ \ \ est\ =\ Cls(n\_estimators=100,\ max\_depth=1,\ warm\_start=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00801}00801\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00802}00802\ \ \ \ \ est.set\_params(n\_estimators=110,\ max\_depth=2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00803}00803\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00804}00804\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00805}00805\ \ \ \ \ \textcolor{comment}{\#\ last\ 10\ trees\ have\ different\ depth}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00806}00806\ \ \ \ \ \textcolor{keyword}{assert}\ est.estimators\_[0,\ 0].max\_depth\ ==\ 1}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00807}00807\ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(1,\ 11):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00808}00808\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ est.estimators\_[-\/i,\ 0].max\_depth\ ==\ 2}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00809}00809\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00810}00810\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00811}00811\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00812}00812\ \textcolor{keyword}{def\ }test\_warm\_start\_clear(Cls):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00813}00813\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ fit\ clears\ state.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00814}00814\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00815}00815\ \ \ \ \ est\ =\ Cls(n\_estimators=100,\ max\_depth=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00816}00816\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00817}00817\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00818}00818\ \ \ \ \ est\_2\ =\ Cls(n\_estimators=100,\ max\_depth=1,\ warm\_start=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00819}00819\ \ \ \ \ est\_2.fit(X,\ y)\ \ \textcolor{comment}{\#\ inits\ state}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00820}00820\ \ \ \ \ est\_2.set\_params(warm\_start=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00821}00821\ \ \ \ \ est\_2.fit(X,\ y)\ \ \textcolor{comment}{\#\ clears\ old\ state\ and\ equals\ est}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00822}00822\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00823}00823\ \ \ \ \ assert\_array\_almost\_equal(est\_2.predict(X),\ est.predict(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00824}00824\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00825}00825\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00826}00826\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}GradientBoosting"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00827}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a531c06ba7d9e2d0b51f5809156fd7735}{00827}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a531c06ba7d9e2d0b51f5809156fd7735}{test\_warm\_start\_state\_oob\_scores}}(GradientBoosting):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00828}00828\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00829}00829\ \textcolor{stringliteral}{\ \ \ \ Check\ that\ the\ states\ of\ the\ OOB\ scores\ are\ cleared\ when\ used\ with\ \`{}warm\_start\`{}.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00830}00830\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00831}00831\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00832}00832\ \ \ \ \ n\_estimators\ =\ 100}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00833}00833\ \ \ \ \ estimator\ =\ GradientBoosting(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00834}00834\ \ \ \ \ \ \ \ \ n\_estimators=n\_estimators,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00835}00835\ \ \ \ \ \ \ \ \ max\_depth=1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00836}00836\ \ \ \ \ \ \ \ \ subsample=0.5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00837}00837\ \ \ \ \ \ \ \ \ warm\_start=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00838}00838\ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00839}00839\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00840}00840\ \ \ \ \ estimator.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00841}00841\ \ \ \ \ oob\_scores,\ oob\_score\ =\ estimator.oob\_scores\_,\ estimator.oob\_score\_}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00842}00842\ \ \ \ \ \textcolor{keyword}{assert}\ len(oob\_scores)\ ==\ n\_estimators}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00843}00843\ \ \ \ \ \textcolor{keyword}{assert}\ oob\_scores[-\/1]\ ==\ pytest.approx(oob\_score)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00844}00844\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00845}00845\ \ \ \ \ n\_more\_estimators\ =\ 200}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00846}00846\ \ \ \ \ estimator.set\_params(n\_estimators=n\_more\_estimators).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00847}00847\ \ \ \ \ \textcolor{keyword}{assert}\ len(estimator.oob\_scores\_)\ ==\ n\_more\_estimators}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00848}00848\ \ \ \ \ assert\_allclose(estimator.oob\_scores\_[:n\_estimators],\ oob\_scores)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00849}00849\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00850}00850\ \ \ \ \ estimator.set\_params(n\_estimators=n\_estimators,\ warm\_start=\textcolor{keyword}{False}).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00851}00851\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_scores\_\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ oob\_scores}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00852}00852\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_score\_\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ oob\_score}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00853}00853\ \ \ \ \ assert\_allclose(estimator.oob\_scores\_,\ oob\_scores)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00854}00854\ \ \ \ \ \textcolor{keyword}{assert}\ estimator.oob\_score\_\ ==\ pytest.approx(oob\_score)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00855}00855\ \ \ \ \ \textcolor{keyword}{assert}\ oob\_scores[-\/1]\ ==\ pytest.approx(oob\_score)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00856}00856\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00857}00857\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00858}00858\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00859}00859\ \textcolor{keyword}{def\ }test\_warm\_start\_smaller\_n\_estimators(Cls):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00860}00860\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ warm\ start\ with\ smaller\ n\_estimators\ raises\ error}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00861}00861\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00862}00862\ \ \ \ \ est\ =\ Cls(n\_estimators=100,\ max\_depth=1,\ warm\_start=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00863}00863\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00864}00864\ \ \ \ \ est.set\_params(n\_estimators=99)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00865}00865\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00866}00866\ \ \ \ \ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00867}00867\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00868}00868\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00869}00869\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00870}00870\ \textcolor{keyword}{def\ }test\_warm\_start\_equal\_n\_estimators(Cls):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00871}00871\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ warm\ start\ with\ equal\ n\_estimators\ does\ nothing}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00872}00872\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00873}00873\ \ \ \ \ est\ =\ Cls(n\_estimators=100,\ max\_depth=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00874}00874\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00875}00875\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00876}00876\ \ \ \ \ est2\ =\ clone(est)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00877}00877\ \ \ \ \ est2.set\_params(n\_estimators=est.n\_estimators,\ warm\_start=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00878}00878\ \ \ \ \ est2.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00879}00879\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00880}00880\ \ \ \ \ assert\_array\_almost\_equal(est2.predict(X),\ est.predict(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00881}00881\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00882}00882\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00883}00883\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00884}00884\ \textcolor{keyword}{def\ }test\_warm\_start\_oob\_switch(Cls):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00885}00885\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ oob\ can\ be\ turned\ on\ during\ warm\ start.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00886}00886\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00887}00887\ \ \ \ \ est\ =\ Cls(n\_estimators=100,\ max\_depth=1,\ warm\_start=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00888}00888\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00889}00889\ \ \ \ \ est.set\_params(n\_estimators=110,\ subsample=0.5)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00890}00890\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00891}00891\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00892}00892\ \ \ \ \ assert\_array\_equal(est.oob\_improvement\_[:100],\ np.zeros(100))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00893}00893\ \ \ \ \ assert\_array\_equal(est.oob\_scores\_[:100],\ np.zeros(100))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00894}00894\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00895}00895\ \ \ \ \ \textcolor{comment}{\#\ the\ last\ 10\ are\ not\ zeros}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00896}00896\ \ \ \ \ \textcolor{keyword}{assert}\ (est.oob\_improvement\_[-\/10:]\ !=\ 0.0).all()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00897}00897\ \ \ \ \ \textcolor{keyword}{assert}\ (est.oob\_scores\_[-\/10:]\ !=\ 0.0).all()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00898}00898\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00899}00899\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_scores\_[-\/1]\ ==\ pytest.approx(est.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00900}00900\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00901}00901\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00902}00902\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00903}00903\ \textcolor{keyword}{def\ }test\_warm\_start\_oob(Cls):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00904}00904\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ warm\ start\ OOB\ equals\ fit.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00905}00905\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00906}00906\ \ \ \ \ est\ =\ Cls(n\_estimators=200,\ max\_depth=1,\ subsample=0.5,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00907}00907\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00908}00908\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00909}00909\ \ \ \ \ est\_ws\ =\ Cls(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00910}00910\ \ \ \ \ \ \ \ \ n\_estimators=100,\ max\_depth=1,\ subsample=0.5,\ random\_state=1,\ warm\_start=\textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00911}00911\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00912}00912\ \ \ \ \ est\_ws.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00913}00913\ \ \ \ \ est\_ws.set\_params(n\_estimators=200)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00914}00914\ \ \ \ \ est\_ws.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00915}00915\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00916}00916\ \ \ \ \ assert\_array\_almost\_equal(est\_ws.oob\_improvement\_[:100],\ est.oob\_improvement\_[:100])}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00917}00917\ \ \ \ \ assert\_array\_almost\_equal(est\_ws.oob\_scores\_[:100],\ est.oob\_scores\_[:100])}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00918}00918\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_scores\_[-\/1]\ ==\ pytest.approx(est.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00919}00919\ \ \ \ \ \textcolor{keyword}{assert}\ est\_ws.oob\_scores\_[-\/1]\ ==\ pytest.approx(est\_ws.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00920}00920\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00921}00921\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00922}00922\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00923}00923\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00924}00924\ \ \ \ \ \textcolor{stringliteral}{"{}sparse\_container"{}},\ COO\_CONTAINERS\ +\ CSC\_CONTAINERS\ +\ CSR\_CONTAINERS}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00925}00925\ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00926}00926\ \textcolor{keyword}{def\ }test\_warm\_start\_sparse(Cls,\ sparse\_container):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00927}00927\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ all\ sparse\ matrix\ types\ are\ supported}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00928}00928\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00929}00929\ \ \ \ \ est\_dense\ =\ Cls(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00930}00930\ \ \ \ \ \ \ \ \ n\_estimators=100,\ max\_depth=1,\ subsample=0.5,\ random\_state=1,\ warm\_start=\textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00931}00931\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00932}00932\ \ \ \ \ est\_dense.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00933}00933\ \ \ \ \ est\_dense.predict(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00934}00934\ \ \ \ \ est\_dense.set\_params(n\_estimators=200)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00935}00935\ \ \ \ \ est\_dense.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00936}00936\ \ \ \ \ y\_pred\_dense\ =\ est\_dense.predict(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00937}00937\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00938}00938\ \ \ \ \ X\_sparse\ =\ sparse\_container(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00939}00939\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00940}00940\ \ \ \ \ est\_sparse\ =\ Cls(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00941}00941\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00942}00942\ \ \ \ \ \ \ \ \ max\_depth=1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00943}00943\ \ \ \ \ \ \ \ \ subsample=0.5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00944}00944\ \ \ \ \ \ \ \ \ random\_state=1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00945}00945\ \ \ \ \ \ \ \ \ warm\_start=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00946}00946\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00947}00947\ \ \ \ \ est\_sparse.fit(X\_sparse,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00948}00948\ \ \ \ \ est\_sparse.predict(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00949}00949\ \ \ \ \ est\_sparse.set\_params(n\_estimators=200)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00950}00950\ \ \ \ \ est\_sparse.fit(X\_sparse,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00951}00951\ \ \ \ \ y\_pred\_sparse\ =\ est\_sparse.predict(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00952}00952\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00953}00953\ \ \ \ \ assert\_array\_almost\_equal(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00954}00954\ \ \ \ \ \ \ \ \ est\_dense.oob\_improvement\_[:100],\ est\_sparse.oob\_improvement\_[:100]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00955}00955\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00956}00956\ \ \ \ \ \textcolor{keyword}{assert}\ est\_dense.oob\_scores\_[-\/1]\ ==\ pytest.approx(est\_dense.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00957}00957\ \ \ \ \ assert\_array\_almost\_equal(est\_dense.oob\_scores\_[:100],\ est\_sparse.oob\_scores\_[:100])}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00958}00958\ \ \ \ \ \textcolor{keyword}{assert}\ est\_sparse.oob\_scores\_[-\/1]\ ==\ pytest.approx(est\_sparse.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00959}00959\ \ \ \ \ assert\_array\_almost\_equal(y\_pred\_dense,\ y\_pred\_sparse)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00960}00960\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00961}00961\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00962}00962\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00963}00963\ \textcolor{keyword}{def\ }test\_warm\_start\_fortran(Cls,\ global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00964}00964\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ feeding\ a\ X\ in\ Fortran-\/ordered\ is\ giving\ the\ same\ results\ as}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00965}00965\ \ \ \ \ \textcolor{comment}{\#\ in\ C-\/ordered}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00966}00966\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00967}00967\ \ \ \ \ est\_c\ =\ Cls(n\_estimators=1,\ random\_state=global\_random\_seed,\ warm\_start=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00968}00968\ \ \ \ \ est\_fortran\ =\ Cls(n\_estimators=1,\ random\_state=global\_random\_seed,\ warm\_start=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00969}00969\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00970}00970\ \ \ \ \ est\_c.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00971}00971\ \ \ \ \ est\_c.set\_params(n\_estimators=11)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00972}00972\ \ \ \ \ est\_c.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00973}00973\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00974}00974\ \ \ \ \ X\_fortran\ =\ np.asfortranarray(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00975}00975\ \ \ \ \ est\_fortran.fit(X\_fortran,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00976}00976\ \ \ \ \ est\_fortran.set\_params(n\_estimators=11)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00977}00977\ \ \ \ \ est\_fortran.fit(X\_fortran,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00978}00978\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00979}00979\ \ \ \ \ assert\_allclose(est\_c.predict(X),\ est\_fortran.predict(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00980}00980\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00981}00981\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00982}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_af9c412d7450aba8c3de5fc37e90fc2bc}{00982}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_af9c412d7450aba8c3de5fc37e90fc2bc}{early\_stopping\_monitor}}(i,\ est,\ locals):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00983}00983\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Returns\ True\ on\ the\ 10th\ iteration."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00984}00984\ \ \ \ \ \textcolor{keywordflow}{if}\ i\ ==\ 9:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00985}00985\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00986}00986\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00987}00987\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{keyword}{False}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00988}00988\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00989}00989\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00990}00990\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Cls"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00991}00991\ \textcolor{keyword}{def\ }test\_monitor\_early\_stopping(Cls):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00992}00992\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ monitor\ return\ value\ works.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00993}00993\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00994}00994\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00995}00995\ \ \ \ \ est\ =\ Cls(n\_estimators=20,\ max\_depth=1,\ random\_state=1,\ subsample=0.5)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00996}00996\ \ \ \ \ est.fit(X,\ y,\ monitor=early\_stopping\_monitor)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00997}00997\ \ \ \ \ \textcolor{keyword}{assert}\ est.n\_estimators\ ==\ 20\ \ \textcolor{comment}{\#\ this\ is\ not\ altered}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00998}00998\ \ \ \ \ \textcolor{keyword}{assert}\ est.estimators\_.shape[0]\ ==\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l00999}00999\ \ \ \ \ \textcolor{keyword}{assert}\ est.train\_score\_.shape[0]\ ==\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01000}01000\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_improvement\_.shape[0]\ ==\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01001}01001\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_scores\_.shape[0]\ ==\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01002}01002\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_scores\_[-\/1]\ ==\ pytest.approx(est.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01003}01003\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01004}01004\ \ \ \ \ \textcolor{comment}{\#\ try\ refit}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01005}01005\ \ \ \ \ est.set\_params(n\_estimators=30)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01006}01006\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01007}01007\ \ \ \ \ \textcolor{keyword}{assert}\ est.n\_estimators\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01008}01008\ \ \ \ \ \textcolor{keyword}{assert}\ est.estimators\_.shape[0]\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01009}01009\ \ \ \ \ \textcolor{keyword}{assert}\ est.train\_score\_.shape[0]\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01010}01010\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_improvement\_.shape[0]\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01011}01011\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_scores\_.shape[0]\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01012}01012\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_scores\_[-\/1]\ ==\ pytest.approx(est.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01013}01013\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01014}01014\ \ \ \ \ est\ =\ Cls(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01015}01015\ \ \ \ \ \ \ \ \ n\_estimators=20,\ max\_depth=1,\ random\_state=1,\ subsample=0.5,\ warm\_start=\textcolor{keyword}{True}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01016}01016\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01017}01017\ \ \ \ \ est.fit(X,\ y,\ monitor=early\_stopping\_monitor)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01018}01018\ \ \ \ \ \textcolor{keyword}{assert}\ est.n\_estimators\ ==\ 20}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01019}01019\ \ \ \ \ \textcolor{keyword}{assert}\ est.estimators\_.shape[0]\ ==\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01020}01020\ \ \ \ \ \textcolor{keyword}{assert}\ est.train\_score\_.shape[0]\ ==\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01021}01021\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_improvement\_.shape[0]\ ==\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01022}01022\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_scores\_.shape[0]\ ==\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01023}01023\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_scores\_[-\/1]\ ==\ pytest.approx(est.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01024}01024\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01025}01025\ \ \ \ \ \textcolor{comment}{\#\ try\ refit}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01026}01026\ \ \ \ \ est.set\_params(n\_estimators=30,\ warm\_start=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01027}01027\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01028}01028\ \ \ \ \ \textcolor{keyword}{assert}\ est.n\_estimators\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01029}01029\ \ \ \ \ \textcolor{keyword}{assert}\ est.train\_score\_.shape[0]\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01030}01030\ \ \ \ \ \textcolor{keyword}{assert}\ est.estimators\_.shape[0]\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01031}01031\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_improvement\_.shape[0]\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01032}01032\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_scores\_.shape[0]\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01033}01033\ \ \ \ \ \textcolor{keyword}{assert}\ est.oob\_scores\_[-\/1]\ ==\ pytest.approx(est.oob\_score\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01034}01034\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01035}01035\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01036}01036\ \textcolor{keyword}{def\ }test\_complete\_classification():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01037}01037\ \ \ \ \ \textcolor{comment}{\#\ Test\ greedy\ trees\ with\ max\_depth\ +\ 1\ leafs.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01038}01038\ \ \ \ \ \textcolor{keyword}{from}\ sklearn.tree.\_tree\ \textcolor{keyword}{import}\ TREE\_LEAF}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01039}01039\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01040}01040\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01041}01041\ \ \ \ \ k\ =\ 4}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01042}01042\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01043}01043\ \ \ \ \ est\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01044}01044\ \ \ \ \ \ \ \ \ n\_estimators=20,\ max\_depth=\textcolor{keywordtype}{None},\ random\_state=1,\ max\_leaf\_nodes=k\ +\ 1}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01045}01045\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01046}01046\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01047}01047\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01048}01048\ \ \ \ \ tree\ =\ est.estimators\_[0,\ 0].tree\_}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01049}01049\ \ \ \ \ \textcolor{keyword}{assert}\ tree.max\_depth\ ==\ k}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01050}01050\ \ \ \ \ \textcolor{keyword}{assert}\ tree.children\_left[tree.children\_left\ ==\ TREE\_LEAF].shape[0]\ ==\ k\ +\ 1}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01051}01051\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01052}01052\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01053}01053\ \textcolor{keyword}{def\ }test\_complete\_regression():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01054}01054\ \ \ \ \ \textcolor{comment}{\#\ Test\ greedy\ trees\ with\ max\_depth\ +\ 1\ leafs.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01055}01055\ \ \ \ \ \textcolor{keyword}{from}\ sklearn.tree.\_tree\ \textcolor{keyword}{import}\ TREE\_LEAF}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01056}01056\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01057}01057\ \ \ \ \ k\ =\ 4}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01058}01058\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01059}01059\ \ \ \ \ est\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01060}01060\ \ \ \ \ \ \ \ \ n\_estimators=20,\ max\_depth=\textcolor{keywordtype}{None},\ random\_state=1,\ max\_leaf\_nodes=k\ +\ 1}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01061}01061\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01062}01062\ \ \ \ \ est.fit(X\_reg,\ y\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01063}01063\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01064}01064\ \ \ \ \ tree\ =\ est.estimators\_[-\/1,\ 0].tree\_}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01065}01065\ \ \ \ \ \textcolor{keyword}{assert}\ tree.children\_left[tree.children\_left\ ==\ TREE\_LEAF].shape[0]\ ==\ k\ +\ 1}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01066}01066\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01067}01067\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01068}01068\ \textcolor{keyword}{def\ }test\_zero\_estimator\_reg(global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01069}01069\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ init='zero'\ works\ for\ regression\ by\ checking\ that\ it\ is\ better}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01070}01070\ \ \ \ \ \textcolor{comment}{\#\ than\ a\ simple\ baseline.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01071}01071\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01072}01072\ \ \ \ \ baseline\ =\ \mbox{\hyperlink{classsklearn_1_1dummy_1_1DummyRegressor}{DummyRegressor}}(strategy=\textcolor{stringliteral}{"{}mean"{}}).fit(X\_reg,\ y\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01073}01073\ \ \ \ \ mse\_baseline\ =\ mean\_squared\_error(baseline.predict(X\_reg),\ y\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01074}01074\ \ \ \ \ est\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01075}01075\ \ \ \ \ \ \ \ \ n\_estimators=5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01076}01076\ \ \ \ \ \ \ \ \ max\_depth=1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01077}01077\ \ \ \ \ \ \ \ \ random\_state=global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01078}01078\ \ \ \ \ \ \ \ \ init=\textcolor{stringliteral}{"{}zero"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01079}01079\ \ \ \ \ \ \ \ \ learning\_rate=0.5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01080}01080\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01081}01081\ \ \ \ \ est.fit(X\_reg,\ y\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01082}01082\ \ \ \ \ y\_pred\ =\ est.predict(X\_reg)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01083}01083\ \ \ \ \ mse\_gbdt\ =\ mean\_squared\_error(y\_reg,\ y\_pred)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01084}01084\ \ \ \ \ \textcolor{keyword}{assert}\ mse\_gbdt\ <\ mse\_baseline}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01085}01085\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01086}01086\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01087}01087\ \textcolor{keyword}{def\ }test\_zero\_estimator\_clf(global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01088}01088\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ init='zero'\ works\ for\ classification.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01089}01089\ \ \ \ \ X\ =\ iris.data}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01090}01090\ \ \ \ \ y\ =\ np.array(iris.target)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01091}01091\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01092}01092\ \ \ \ \ est\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01093}01093\ \ \ \ \ \ \ \ \ n\_estimators=20,\ max\_depth=1,\ random\_state=global\_random\_seed,\ init=\textcolor{stringliteral}{"{}zero"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01094}01094\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01095}01095\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01096}01096\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01097}01097\ \ \ \ \ \textcolor{keyword}{assert}\ est.score(X,\ y)\ >\ 0.96}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01098}01098\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01099}01099\ \ \ \ \ \textcolor{comment}{\#\ binary\ clf}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01100}01100\ \ \ \ \ mask\ =\ y\ !=\ 0}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01101}01101\ \ \ \ \ y[mask]\ =\ 1}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01102}01102\ \ \ \ \ y[\string~mask]\ =\ 0}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01103}01103\ \ \ \ \ est\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01104}01104\ \ \ \ \ \ \ \ \ n\_estimators=20,\ max\_depth=1,\ random\_state=global\_random\_seed,\ init=\textcolor{stringliteral}{"{}zero"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01105}01105\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01106}01106\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01107}01107\ \ \ \ \ \textcolor{keyword}{assert}\ est.score(X,\ y)\ >\ 0.96}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01108}01108\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01109}01109\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01110}01110\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}GBEstimator"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01111}01111\ \textcolor{keyword}{def\ }test\_max\_leaf\_nodes\_max\_depth(GBEstimator):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01112}01112\ \ \ \ \ \textcolor{comment}{\#\ Test\ precedence\ of\ max\_leaf\_nodes\ over\ max\_depth.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01113}01113\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01114}01114\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01115}01115\ \ \ \ \ k\ =\ 4}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01116}01116\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01117}01117\ \ \ \ \ est\ =\ GBEstimator(max\_depth=1,\ max\_leaf\_nodes=k).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01118}01118\ \ \ \ \ tree\ =\ est.estimators\_[0,\ 0].tree\_}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01119}01119\ \ \ \ \ \textcolor{keyword}{assert}\ tree.max\_depth\ ==\ 1}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01120}01120\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01121}01121\ \ \ \ \ est\ =\ GBEstimator(max\_depth=1).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01122}01122\ \ \ \ \ tree\ =\ est.estimators\_[0,\ 0].tree\_}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01123}01123\ \ \ \ \ \textcolor{keyword}{assert}\ tree.max\_depth\ ==\ 1}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01124}01124\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01125}01125\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01126}01126\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}GBEstimator"{},\ GRADIENT\_BOOSTING\_ESTIMATORS)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01127}01127\ \textcolor{keyword}{def\ }test\_min\_impurity\_decrease(GBEstimator):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01128}01128\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01129}01129\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01130}01130\ \ \ \ \ est\ =\ GBEstimator(min\_impurity\_decrease=0.1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01131}01131\ \ \ \ \ est.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01132}01132\ \ \ \ \ \textcolor{keywordflow}{for}\ tree\ \textcolor{keywordflow}{in}\ est.estimators\_.flat:}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01133}01133\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Simply\ check\ if\ the\ parameter\ is\ passed\ on\ correctly.\ Tree\ tests}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01134}01134\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ will\ suffice\ for\ the\ actual\ working\ of\ this\ param}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01135}01135\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ tree.min\_impurity\_decrease\ ==\ 0.1}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01136}01136\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01137}01137\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01138}01138\ \textcolor{keyword}{def\ }test\_warm\_start\_wo\_nestimators\_change():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01139}01139\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ warm\_start\ does\ nothing\ if\ n\_estimators\ is\ not\ changed.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01140}01140\ \ \ \ \ \textcolor{comment}{\#\ Regression\ test\ for\ \#3513.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01141}01141\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=10,\ warm\_start=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01142}01142\ \ \ \ \ clf.fit([[0,\ 1],\ [2,\ 3]],\ [0,\ 1])}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01143}01143\ \ \ \ \ \textcolor{keyword}{assert}\ clf.estimators\_.shape[0]\ ==\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01144}01144\ \ \ \ \ clf.fit([[0,\ 1],\ [2,\ 3]],\ [0,\ 1])}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01145}01145\ \ \ \ \ \textcolor{keyword}{assert}\ clf.estimators\_.shape[0]\ ==\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01146}01146\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01147}01147\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01148}01148\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01149}01149\ \ \ \ \ (\textcolor{stringliteral}{"{}loss"{}},\ \textcolor{stringliteral}{"{}value"{}}),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01150}01150\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01151}01151\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}squared\_error"{}},\ 0.5),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01152}01152\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}absolute\_error"{}},\ 0.0),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01153}01153\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}huber"{}},\ 0.5),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01154}01154\ \ \ \ \ \ \ \ \ (\textcolor{stringliteral}{"{}quantile"{}},\ 0.5),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01155}01155\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01156}01156\ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01157}01157\ \textcolor{keyword}{def\ }test\_non\_uniform\_weights\_toy\_edge\_case\_reg(loss,\ value):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01158}01158\ \ \ \ \ X\ =\ [[1,\ 0],\ [1,\ 0],\ [1,\ 0],\ [0,\ 1]]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01159}01159\ \ \ \ \ y\ =\ [0,\ 0,\ 1,\ 0]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01160}01160\ \ \ \ \ \textcolor{comment}{\#\ ignore\ the\ first\ 2\ training\ samples\ by\ setting\ their\ weight\ to\ 0}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01161}01161\ \ \ \ \ sample\_weight\ =\ [0,\ 0,\ 1,\ 1]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01162}01162\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(learning\_rate=1.0,\ n\_estimators=2,\ loss=loss)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01163}01163\ \ \ \ \ gb.fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01164}01164\ \ \ \ \ \textcolor{keyword}{assert}\ gb.predict([[1,\ 0]])[0]\ >=\ value}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01165}01165\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01166}01166\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01167}01167\ \textcolor{keyword}{def\ }test\_non\_uniform\_weights\_toy\_edge\_case\_clf():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01168}01168\ \ \ \ \ X\ =\ [[1,\ 0],\ [1,\ 0],\ [1,\ 0],\ [0,\ 1]]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01169}01169\ \ \ \ \ y\ =\ [0,\ 0,\ 1,\ 0]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01170}01170\ \ \ \ \ \textcolor{comment}{\#\ ignore\ the\ first\ 2\ training\ samples\ by\ setting\ their\ weight\ to\ 0}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01171}01171\ \ \ \ \ sample\_weight\ =\ [0,\ 0,\ 1,\ 1]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01172}01172\ \ \ \ \ \textcolor{keywordflow}{for}\ loss\ \textcolor{keywordflow}{in}\ (\textcolor{stringliteral}{"{}log\_loss"{}},\ \textcolor{stringliteral}{"{}exponential"{}}):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01173}01173\ \ \ \ \ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_estimators=5,\ loss=loss)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01174}01174\ \ \ \ \ \ \ \ \ gb.fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01175}01175\ \ \ \ \ \ \ \ \ assert\_array\_equal(gb.predict([[1,\ 0]]),\ [1])}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01176}01176\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01177}01177\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01178}01178\ \textcolor{preprocessor}{@skip\_if\_32bit}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01179}01179\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01180}01180\ \ \ \ \ \textcolor{stringliteral}{"{}EstimatorClass"{}},\ (GradientBoostingClassifier,\ GradientBoostingRegressor)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01181}01181\ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01182}01182\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01183}01183\ \ \ \ \ \textcolor{stringliteral}{"{}sparse\_container"{}},\ COO\_CONTAINERS\ +\ CSC\_CONTAINERS\ +\ CSR\_CONTAINERS}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01184}01184\ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01185}01185\ \textcolor{keyword}{def\ }test\_sparse\_input(EstimatorClass,\ sparse\_container):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01186}01186\ \ \ \ \ y,\ X\ =\ datasets.make\_multilabel\_classification(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01187}01187\ \ \ \ \ \ \ \ \ random\_state=0,\ n\_samples=50,\ n\_features=1,\ n\_classes=20}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01188}01188\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01189}01189\ \ \ \ \ y\ =\ y[:,\ 0]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01190}01190\ \ \ \ \ X\_sparse\ =\ sparse\_container(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01191}01191\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01192}01192\ \ \ \ \ dense\ =\ EstimatorClass(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01193}01193\ \ \ \ \ \ \ \ \ n\_estimators=10,\ random\_state=0,\ max\_depth=2,\ min\_impurity\_decrease=1e-\/7}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01194}01194\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01195}01195\ \ \ \ \ sparse\ =\ EstimatorClass(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01196}01196\ \ \ \ \ \ \ \ \ n\_estimators=10,\ random\_state=0,\ max\_depth=2,\ min\_impurity\_decrease=1e-\/7}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01197}01197\ \ \ \ \ ).fit(X\_sparse,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01198}01198\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01199}01199\ \ \ \ \ assert\_array\_almost\_equal(sparse.apply(X),\ dense.apply(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01200}01200\ \ \ \ \ assert\_array\_almost\_equal(sparse.predict(X),\ dense.predict(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01201}01201\ \ \ \ \ assert\_array\_almost\_equal(sparse.feature\_importances\_,\ dense.feature\_importances\_)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01202}01202\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01203}01203\ \ \ \ \ assert\_array\_almost\_equal(sparse.predict(X\_sparse),\ dense.predict(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01204}01204\ \ \ \ \ assert\_array\_almost\_equal(dense.predict(X\_sparse),\ sparse.predict(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01205}01205\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01206}01206\ \ \ \ \ \textcolor{keywordflow}{if}\ issubclass(EstimatorClass,\ GradientBoostingClassifier):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01207}01207\ \ \ \ \ \ \ \ \ assert\_array\_almost\_equal(sparse.predict\_proba(X),\ dense.predict\_proba(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01208}01208\ \ \ \ \ \ \ \ \ assert\_array\_almost\_equal(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01209}01209\ \ \ \ \ \ \ \ \ \ \ \ \ sparse.predict\_log\_proba(X),\ dense.predict\_log\_proba(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01210}01210\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01211}01211\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01212}01212\ \ \ \ \ \ \ \ \ assert\_array\_almost\_equal(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01213}01213\ \ \ \ \ \ \ \ \ \ \ \ \ sparse.decision\_function(X\_sparse),\ sparse.decision\_function(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01214}01214\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01215}01215\ \ \ \ \ \ \ \ \ assert\_array\_almost\_equal(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01216}01216\ \ \ \ \ \ \ \ \ \ \ \ \ dense.decision\_function(X\_sparse),\ sparse.decision\_function(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01217}01217\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01218}01218\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ res\_sparse,\ res\ \textcolor{keywordflow}{in}\ zip(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01219}01219\ \ \ \ \ \ \ \ \ \ \ \ \ sparse.staged\_decision\_function(X\_sparse),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01220}01220\ \ \ \ \ \ \ \ \ \ \ \ \ sparse.staged\_decision\_function(X),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01221}01221\ \ \ \ \ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01222}01222\ \ \ \ \ \ \ \ \ \ \ \ \ assert\_array\_almost\_equal(res\_sparse,\ res)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01223}01223\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01224}01224\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01225}01225\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01226}01226\ \ \ \ \ \textcolor{stringliteral}{"{}GradientBoostingEstimator"{}},\ [GradientBoostingClassifier,\ GradientBoostingRegressor]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01227}01227\ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01228}01228\ \textcolor{keyword}{def\ }test\_gradient\_boosting\_early\_stopping(GradientBoostingEstimator):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01229}01229\ \ \ \ \ \textcolor{comment}{\#\ Check\ if\ early\ stopping\ works\ as\ expected,\ that\ is\ empirically\ check\ that\ the}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01230}01230\ \ \ \ \ \textcolor{comment}{\#\ number\ of\ trained\ estimators\ is\ increasing\ when\ the\ tolerance\ decreases.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01231}01231\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01232}01232\ \ \ \ \ X,\ y\ =\ make\_classification(n\_samples=1000,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01233}01233\ \ \ \ \ n\_estimators\ =\ 1000}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01234}01234\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01235}01235\ \ \ \ \ gb\_large\_tol\ =\ GradientBoostingEstimator(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01236}01236\ \ \ \ \ \ \ \ \ n\_estimators=n\_estimators,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01237}01237\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=10,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01238}01238\ \ \ \ \ \ \ \ \ learning\_rate=0.1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01239}01239\ \ \ \ \ \ \ \ \ max\_depth=3,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01240}01240\ \ \ \ \ \ \ \ \ random\_state=42,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01241}01241\ \ \ \ \ \ \ \ \ tol=1e-\/1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01242}01242\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01243}01243\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01244}01244\ \ \ \ \ gb\_small\_tol\ =\ GradientBoostingEstimator(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01245}01245\ \ \ \ \ \ \ \ \ n\_estimators=n\_estimators,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01246}01246\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=10,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01247}01247\ \ \ \ \ \ \ \ \ learning\_rate=0.1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01248}01248\ \ \ \ \ \ \ \ \ max\_depth=3,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01249}01249\ \ \ \ \ \ \ \ \ random\_state=42,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01250}01250\ \ \ \ \ \ \ \ \ tol=1e-\/3,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01251}01251\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01252}01252\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01253}01253\ \ \ \ \ X\_train,\ X\_test,\ y\_train,\ y\_test\ =\ train\_test\_split(X,\ y,\ random\_state=42)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01254}01254\ \ \ \ \ gb\_large\_tol.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01255}01255\ \ \ \ \ gb\_small\_tol.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01256}01256\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01257}01257\ \ \ \ \ \textcolor{keyword}{assert}\ gb\_large\_tol.n\_estimators\_\ <\ gb\_small\_tol.n\_estimators\_\ <\ n\_estimators}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01258}01258\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01259}01259\ \ \ \ \ \textcolor{keyword}{assert}\ gb\_large\_tol.score(X\_test,\ y\_test)\ >\ 0.7}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01260}01260\ \ \ \ \ \textcolor{keyword}{assert}\ gb\_small\_tol.score(X\_test,\ y\_test)\ >\ 0.7}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01261}01261\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01262}01262\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01263}01263\ \textcolor{keyword}{def\ }test\_gradient\_boosting\_without\_early\_stopping():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01264}01264\ \ \ \ \ \textcolor{comment}{\#\ When\ early\ stopping\ is\ not\ used,\ the\ number\ of\ trained\ estimators}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01265}01265\ \ \ \ \ \textcolor{comment}{\#\ must\ be\ the\ one\ specified.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01266}01266\ \ \ \ \ X,\ y\ =\ make\_classification(n\_samples=1000,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01267}01267\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01268}01268\ \ \ \ \ gbc\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01269}01269\ \ \ \ \ \ \ \ \ n\_estimators=50,\ learning\_rate=0.1,\ max\_depth=3,\ random\_state=42}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01270}01270\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01271}01271\ \ \ \ \ gbc.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01272}01272\ \ \ \ \ gbr\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01273}01273\ \ \ \ \ \ \ \ \ n\_estimators=30,\ learning\_rate=0.1,\ max\_depth=3,\ random\_state=42}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01274}01274\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01275}01275\ \ \ \ \ gbr.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01276}01276\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01277}01277\ \ \ \ \ \textcolor{comment}{\#\ The\ number\ of\ trained\ estimators\ must\ be\ the\ one\ specified.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01278}01278\ \ \ \ \ \textcolor{keyword}{assert}\ gbc.n\_estimators\_\ ==\ 50}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01279}01279\ \ \ \ \ \textcolor{keyword}{assert}\ gbr.n\_estimators\_\ ==\ 30}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01280}01280\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01281}01281\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01282}01282\ \textcolor{keyword}{def\ }test\_gradient\_boosting\_validation\_fraction():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01283}01283\ \ \ \ \ X,\ y\ =\ make\_classification(n\_samples=1000,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01284}01284\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01285}01285\ \ \ \ \ gbc\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01286}01286\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01287}01287\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=10,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01288}01288\ \ \ \ \ \ \ \ \ validation\_fraction=0.1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01289}01289\ \ \ \ \ \ \ \ \ learning\_rate=0.1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01290}01290\ \ \ \ \ \ \ \ \ max\_depth=3,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01291}01291\ \ \ \ \ \ \ \ \ random\_state=42,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01292}01292\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01293}01293\ \ \ \ \ gbc2\ =\ clone(gbc).set\_params(validation\_fraction=0.3)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01294}01294\ \ \ \ \ gbc3\ =\ clone(gbc).set\_params(n\_iter\_no\_change=20)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01295}01295\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01296}01296\ \ \ \ \ gbr\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01297}01297\ \ \ \ \ \ \ \ \ n\_estimators=100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01298}01298\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=10,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01299}01299\ \ \ \ \ \ \ \ \ learning\_rate=0.1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01300}01300\ \ \ \ \ \ \ \ \ max\_depth=3,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01301}01301\ \ \ \ \ \ \ \ \ validation\_fraction=0.1,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01302}01302\ \ \ \ \ \ \ \ \ random\_state=42,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01303}01303\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01304}01304\ \ \ \ \ gbr2\ =\ clone(gbr).set\_params(validation\_fraction=0.3)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01305}01305\ \ \ \ \ gbr3\ =\ clone(gbr).set\_params(n\_iter\_no\_change=20)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01306}01306\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01307}01307\ \ \ \ \ X\_train,\ X\_test,\ y\_train,\ y\_test\ =\ train\_test\_split(X,\ y,\ random\_state=42)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01308}01308\ \ \ \ \ \textcolor{comment}{\#\ Check\ if\ validation\_fraction\ has\ an\ effect}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01309}01309\ \ \ \ \ gbc.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01310}01310\ \ \ \ \ gbc2.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01311}01311\ \ \ \ \ \textcolor{keyword}{assert}\ gbc.n\_estimators\_\ !=\ gbc2.n\_estimators\_}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01312}01312\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01313}01313\ \ \ \ \ gbr.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01314}01314\ \ \ \ \ gbr2.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01315}01315\ \ \ \ \ \textcolor{keyword}{assert}\ gbr.n\_estimators\_\ !=\ gbr2.n\_estimators\_}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01316}01316\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01317}01317\ \ \ \ \ \textcolor{comment}{\#\ Check\ if\ n\_estimators\_\ increase\ monotonically\ with\ n\_iter\_no\_change}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01318}01318\ \ \ \ \ \textcolor{comment}{\#\ Set\ validation}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01319}01319\ \ \ \ \ gbc3.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01320}01320\ \ \ \ \ gbr3.fit(X\_train,\ y\_train)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01321}01321\ \ \ \ \ \textcolor{keyword}{assert}\ gbr.n\_estimators\_\ <\ gbr3.n\_estimators\_}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01322}01322\ \ \ \ \ \textcolor{keyword}{assert}\ gbc.n\_estimators\_\ <\ gbc3.n\_estimators\_}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01323}01323\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01324}01324\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01325}01325\ \textcolor{keyword}{def\ }test\_early\_stopping\_stratified():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01326}01326\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ data\ splitting\ for\ early\ stopping\ is\ stratified}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01327}01327\ \ \ \ \ X\ =\ [[1,\ 2],\ [2,\ 3],\ [3,\ 4],\ [4,\ 5]]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01328}01328\ \ \ \ \ y\ =\ [0,\ 0,\ 0,\ 1]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01329}01329\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01330}01330\ \ \ \ \ gbc\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(n\_iter\_no\_change=5)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01331}01331\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01332}01332\ \ \ \ \ \ \ \ \ ValueError,\ match=\textcolor{stringliteral}{"{}The\ least\ populated\ class\ in\ y\ has\ only\ 1\ member"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01333}01333\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01334}01334\ \ \ \ \ \ \ \ \ gbc.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01335}01335\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01336}01336\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01337}01337\ \textcolor{keyword}{def\ }\_make\_multiclass():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01338}01338\ \ \ \ \ \textcolor{keywordflow}{return}\ make\_classification(n\_classes=3,\ n\_clusters\_per\_class=1)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01339}01339\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01340}01340\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01341}01341\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01342}01342\ \ \ \ \ \textcolor{stringliteral}{"{}gb,\ dataset\_maker,\ init\_estimator"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01343}01343\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01344}01344\ \ \ \ \ \ \ \ \ (GradientBoostingClassifier,\ make\_classification,\ DummyClassifier),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01345}01345\ \ \ \ \ \ \ \ \ (GradientBoostingClassifier,\ \_make\_multiclass,\ DummyClassifier),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01346}01346\ \ \ \ \ \ \ \ \ (GradientBoostingRegressor,\ make\_regression,\ DummyRegressor),}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01347}01347\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01348}01348\ \ \ \ \ ids=[\textcolor{stringliteral}{"{}binary\ classification"{}},\ \textcolor{stringliteral}{"{}multiclass\ classification"{}},\ \textcolor{stringliteral}{"{}regression"{}}],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01349}01349\ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01350}01350\ \textcolor{keyword}{def\ }test\_gradient\_boosting\_with\_init(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01351}01351\ \ \ \ \ gb,\ dataset\_maker,\ init\_estimator,\ global\_random\_seed}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01352}01352\ ):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01353}01353\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ GradientBoostingRegressor\ works\ when\ init\ is\ a\ sklearn}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01354}01354\ \ \ \ \ \textcolor{comment}{\#\ estimator.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01355}01355\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ an\ error\ is\ raised\ if\ trying\ to\ fit\ with\ sample\ weight\ but}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01356}01356\ \ \ \ \ \textcolor{comment}{\#\ initial\ estimator\ does\ not\ support\ sample\ weight}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01357}01357\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01358}01358\ \ \ \ \ X,\ y\ =\ dataset\_maker()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01359}01359\ \ \ \ \ sample\_weight\ =\ np.random.RandomState(global\_random\_seed).rand(100)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01360}01360\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01361}01361\ \ \ \ \ \textcolor{comment}{\#\ init\ supports\ sample\ weights}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01362}01362\ \ \ \ \ init\_est\ =\ init\_estimator()}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01363}01363\ \ \ \ \ gb(init=init\_est).fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01364}01364\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01365}01365\ \ \ \ \ \textcolor{comment}{\#\ init\ does\ not\ support\ sample\ weights}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01366}01366\ \ \ \ \ init\_est\ =\ \mbox{\hyperlink{classsklearn_1_1utils_1_1__mocking_1_1NoSampleWeightWrapper}{NoSampleWeightWrapper}}(init\_estimator())}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01367}01367\ \ \ \ \ gb(init=init\_est).fit(X,\ y)\ \ \textcolor{comment}{\#\ ok\ no\ sample\ weights}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01368}01368\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=\textcolor{stringliteral}{"{}estimator.*does\ not\ support\ sample\ weights"{}}):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01369}01369\ \ \ \ \ \ \ \ \ gb(init=init\_est).fit(X,\ y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01370}01370\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01371}01371\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01372}01372\ \textcolor{keyword}{def\ }test\_gradient\_boosting\_with\_init\_pipeline():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01373}01373\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ the\ init\ estimator\ can\ be\ a\ pipeline\ (see\ issue\ \#13466)}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01374}01374\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01375}01375\ \ \ \ \ X,\ y\ =\ make\_regression(random\_state=0)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01376}01376\ \ \ \ \ init\ =\ make\_pipeline(\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__base_1_1LinearRegression}{LinearRegression}}())}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01377}01377\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(init=init)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01378}01378\ \ \ \ \ gb.fit(X,\ y)\ \ \textcolor{comment}{\#\ pipeline\ without\ sample\_weight\ works\ fine}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01379}01379\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01380}01380\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01381}01381\ \ \ \ \ \ \ \ \ ValueError,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01382}01382\ \ \ \ \ \ \ \ \ match=\textcolor{stringliteral}{"{}The\ initial\ estimator\ Pipeline\ does\ not\ support\ sample\ weights"{}},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01383}01383\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01384}01384\ \ \ \ \ \ \ \ \ gb.fit(X,\ y,\ sample\_weight=np.ones(X.shape[0]))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01385}01385\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01386}01386\ \ \ \ \ \textcolor{comment}{\#\ Passing\ sample\_weight\ to\ a\ pipeline\ raises\ a\ ValueError.\ This\ test\ makes}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01387}01387\ \ \ \ \ \textcolor{comment}{\#\ sure\ we\ make\ the\ distinction\ between\ ValueError\ raised\ by\ a\ pipeline\ that}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01388}01388\ \ \ \ \ \textcolor{comment}{\#\ was\ passed\ sample\_weight,\ and\ a\ InvalidParameterError\ raised\ by\ a\ regular}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01389}01389\ \ \ \ \ \textcolor{comment}{\#\ estimator\ whose\ input\ checking\ failed.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01390}01390\ \ \ \ \ invalid\_nu\ =\ 1.5}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01391}01391\ \ \ \ \ err\_msg\ =\ (}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01392}01392\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}The\ 'nu'\ parameter\ of\ NuSVR\ must\ be\ a\ float\ in\ the"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01393}01393\ \ \ \ \ \ \ \ \ f\textcolor{stringliteral}{"{}\ range\ (0.0,\ 1.0].\ Got\ \{invalid\_nu\}\ instead."{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01394}01394\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01395}01395\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(InvalidParameterError,\ match=re.escape(err\_msg)):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01396}01396\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Note\ that\ NuSVR\ properly\ supports\ sample\_weight}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01397}01397\ \ \ \ \ \ \ \ \ init\ =\ \mbox{\hyperlink{classsklearn_1_1svm_1_1__classes_1_1NuSVR}{NuSVR}}(gamma=\textcolor{stringliteral}{"{}auto"{}},\ nu=invalid\_nu)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01398}01398\ \ \ \ \ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(init=init)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01399}01399\ \ \ \ \ \ \ \ \ gb.fit(X,\ y,\ sample\_weight=np.ones(X.shape[0]))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01400}01400\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01401}01401\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01402}01402\ \textcolor{keyword}{def\ }test\_early\_stopping\_n\_classes():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01403}01403\ \ \ \ \ \textcolor{comment}{\#\ when\ doing\ early\ stopping\ (\_,\ ,\ y\_train,\ \_\ =\ train\_test\_split(X,\ y))}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01404}01404\ \ \ \ \ \textcolor{comment}{\#\ there\ might\ be\ classes\ in\ y\ that\ are\ missing\ in\ y\_train.\ As\ the\ init}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01405}01405\ \ \ \ \ \textcolor{comment}{\#\ estimator\ will\ be\ trained\ on\ y\_train,\ we\ need\ to\ raise\ an\ error\ if\ this}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01406}01406\ \ \ \ \ \textcolor{comment}{\#\ happens.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01407}01407\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01408}01408\ \ \ \ \ X\ =\ [[1]]\ *\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01409}01409\ \ \ \ \ y\ =\ [0,\ 0]\ +\ [1]\ *\ 8\ \ \textcolor{comment}{\#\ only\ 2\ negative\ class\ over\ 10\ samples}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01410}01410\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01411}01411\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=5,\ random\_state=0,\ validation\_fraction=0.8}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01412}01412\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01413}01413\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01414}01414\ \ \ \ \ \ \ \ \ ValueError,\ match=\textcolor{stringliteral}{"{}The\ training\ data\ after\ the\ early\ stopping\ split"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01415}01415\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01416}01416\ \ \ \ \ \ \ \ \ gb.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01417}01417\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01418}01418\ \ \ \ \ \textcolor{comment}{\#\ No\ error\ if\ we\ let\ training\ data\ be\ big\ enough}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01419}01419\ \ \ \ \ gb\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01420}01420\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=5,\ random\_state=0,\ validation\_fraction=0.4}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01421}01421\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01422}01422\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01423}01423\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01424}01424\ \textcolor{keyword}{def\ }test\_gbr\_degenerate\_feature\_importances():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01425}01425\ \ \ \ \ \textcolor{comment}{\#\ growing\ an\ ensemble\ of\ single\ node\ trees.\ See\ \#13620}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01426}01426\ \ \ \ \ X\ =\ np.zeros((10,\ 10))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01427}01427\ \ \ \ \ y\ =\ np.ones((10,))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01428}01428\ \ \ \ \ gbr\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}().fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01429}01429\ \ \ \ \ assert\_array\_equal(gbr.feature\_importances\_,\ np.zeros(10,\ dtype=np.float64))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01430}01430\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01431}01431\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01432}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a761fae0982a1666d7bd2d409ce8fbf55}{01432}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a761fae0982a1666d7bd2d409ce8fbf55}{test\_huber\_vs\_mean\_and\_median}}():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01433}01433\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ huber\ lies\ between\ absolute\ and\ squared\ error."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01434}01434\ \ \ \ \ n\_rep\ =\ 100}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01435}01435\ \ \ \ \ n\_samples\ =\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01436}01436\ \ \ \ \ y\ =\ np.tile(np.arange(n\_samples),\ n\_rep)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01437}01437\ \ \ \ \ x1\ =\ np.minimum(y,\ n\_samples\ /\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01438}01438\ \ \ \ \ x2\ =\ np.minimum(-\/y,\ -\/n\_samples\ /\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01439}01439\ \ \ \ \ X\ =\ np.c\_[x1,\ x2]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01440}01440\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01441}01441\ \ \ \ \ rng\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01442}01442\ \ \ \ \ \textcolor{comment}{\#\ We\ want\ an\ asymmetric\ distribution.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01443}01443\ \ \ \ \ y\ =\ y\ +\ rng.exponential(scale=1,\ size=y.shape)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01444}01444\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01445}01445\ \ \ \ \ gbt\_absolute\_error\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}absolute\_error"{}}).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01446}01446\ \ \ \ \ gbt\_huber\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}huber"{}}).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01447}01447\ \ \ \ \ gbt\_squared\_error\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}().fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01448}01448\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01449}01449\ \ \ \ \ gbt\_huber\_predictions\ =\ gbt\_huber.predict(X)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01450}01450\ \ \ \ \ \textcolor{keyword}{assert}\ np.all(gbt\_absolute\_error.predict(X)\ <=\ gbt\_huber\_predictions)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01451}01451\ \ \ \ \ \textcolor{keyword}{assert}\ np.all(gbt\_huber\_predictions\ <=\ gbt\_squared\_error.predict(X))}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01452}01452\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01453}01453\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01454}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a15519e545e4a1371a8639e6902b75e2c}{01454}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a15519e545e4a1371a8639e6902b75e2c}{test\_safe\_divide}}():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01455}01455\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ that\ \_safe\_divide\ handles\ division\ by\ zero."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01456}01456\ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01457}01457\ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}error"{}})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01458}01458\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ \_safe\_divide(np.float64(1e300),\ 0)\ ==\ 0}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01459}01459\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ \_safe\_divide(np.float64(0.0),\ np.float64(0.0))\ ==\ 0}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01460}01460\ \ \ \ \ \textcolor{keyword}{with}\ pytest.warns(RuntimeWarning,\ match=\textcolor{stringliteral}{"{}overflow"{}}):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01461}01461\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ np.finfo(float).max\ =\ 1.7976931348623157e+308}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01462}01462\ \ \ \ \ \ \ \ \ \_safe\_divide(np.float64(1e300),\ 1e-\/10)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01463}01463\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01464}01464\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01465}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_abb0bea035009ade3564359c2251f0add}{01465}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_abb0bea035009ade3564359c2251f0add}{test\_squared\_error\_exact\_backward\_compat}}():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01466}01466\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ squared\ error\ GBT\ backward\ compat\ on\ a\ simple\ dataset.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01467}01467\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01468}01468\ \textcolor{stringliteral}{\ \ \ \ The\ results\ to\ compare\ against\ are\ taken\ from\ scikit-\/learn\ v1.2.0.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01469}01469\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01470}01470\ \ \ \ \ n\_samples\ =\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01471}01471\ \ \ \ \ y\ =\ np.arange(n\_samples)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01472}01472\ \ \ \ \ x1\ =\ np.minimum(y,\ n\_samples\ /\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01473}01473\ \ \ \ \ x2\ =\ np.minimum(-\/y,\ -\/n\_samples\ /\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01474}01474\ \ \ \ \ X\ =\ np.c\_[x1,\ x2]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01475}01475\ \ \ \ \ gbt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}squared\_error"{}},\ n\_estimators=100).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01476}01476\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01477}01477\ \ \ \ \ pred\_result\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01478}01478\ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01479}01479\ \ \ \ \ \ \ \ \ \ \ \ \ 1.39245726e-\/04,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01480}01480\ \ \ \ \ \ \ \ \ \ \ \ \ 1.00010468e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01481}01481\ \ \ \ \ \ \ \ \ \ \ \ \ 2.00007043e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01482}01482\ \ \ \ \ \ \ \ \ \ \ \ \ 3.00004051e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01483}01483\ \ \ \ \ \ \ \ \ \ \ \ \ 4.00000802e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01484}01484\ \ \ \ \ \ \ \ \ \ \ \ \ 4.99998972e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01485}01485\ \ \ \ \ \ \ \ \ \ \ \ \ 5.99996312e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01486}01486\ \ \ \ \ \ \ \ \ \ \ \ \ 6.99993395e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01487}01487\ \ \ \ \ \ \ \ \ \ \ \ \ 7.99989372e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01488}01488\ \ \ \ \ \ \ \ \ \ \ \ \ 8.99985660e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01489}01489\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01490}01490\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01491}01491\ \ \ \ \ assert\_allclose(gbt.predict(X),\ pred\_result,\ rtol=1e-\/8)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01492}01492\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01493}01493\ \ \ \ \ train\_score\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01494}01494\ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01495}01495\ \ \ \ \ \ \ \ \ \ \ \ \ 4.87246390e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01496}01496\ \ \ \ \ \ \ \ \ \ \ \ \ 3.95590036e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01497}01497\ \ \ \ \ \ \ \ \ \ \ \ \ 3.21267865e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01498}01498\ \ \ \ \ \ \ \ \ \ \ \ \ 2.60970300e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01499}01499\ \ \ \ \ \ \ \ \ \ \ \ \ 2.11820178e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01500}01500\ \ \ \ \ \ \ \ \ \ \ \ \ 1.71995782e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01501}01501\ \ \ \ \ \ \ \ \ \ \ \ \ 1.39695549e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01502}01502\ \ \ \ \ \ \ \ \ \ \ \ \ 1.13391770e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01503}01503\ \ \ \ \ \ \ \ \ \ \ \ \ 9.19931587e-\/09,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01504}01504\ \ \ \ \ \ \ \ \ \ \ \ \ 7.47000575e-\/09,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01505}01505\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01506}01506\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01507}01507\ \ \ \ \ assert\_allclose(gbt.train\_score\_[-\/10:],\ train\_score,\ rtol=1e-\/8)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01508}01508\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01509}01509\ \ \ \ \ \textcolor{comment}{\#\ Same\ but\ with\ sample\_weights}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01510}01510\ \ \ \ \ sample\_weights\ =\ np.tile([1,\ 10],\ n\_samples\ //\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01511}01511\ \ \ \ \ gbt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}squared\_error"{}},\ n\_estimators=100).fit(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01512}01512\ \ \ \ \ \ \ \ \ X,\ y,\ sample\_weight=sample\_weights}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01513}01513\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01514}01514\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01515}01515\ \ \ \ \ pred\_result\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01516}01516\ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01517}01517\ \ \ \ \ \ \ \ \ \ \ \ \ 1.52391462e-\/04,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01518}01518\ \ \ \ \ \ \ \ \ \ \ \ \ 1.00011168e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01519}01519\ \ \ \ \ \ \ \ \ \ \ \ \ 2.00007724e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01520}01520\ \ \ \ \ \ \ \ \ \ \ \ \ 3.00004638e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01521}01521\ \ \ \ \ \ \ \ \ \ \ \ \ 4.00001302e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01522}01522\ \ \ \ \ \ \ \ \ \ \ \ \ 4.99999873e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01523}01523\ \ \ \ \ \ \ \ \ \ \ \ \ 5.99997093e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01524}01524\ \ \ \ \ \ \ \ \ \ \ \ \ 6.99994329e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01525}01525\ \ \ \ \ \ \ \ \ \ \ \ \ 7.99991290e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01526}01526\ \ \ \ \ \ \ \ \ \ \ \ \ 8.99988727e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01527}01527\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01528}01528\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01529}01529\ \ \ \ \ assert\_allclose(gbt.predict(X),\ pred\_result,\ rtol=1e-\/6,\ atol=1e-\/5)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01530}01530\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01531}01531\ \ \ \ \ train\_score\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01532}01532\ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01533}01533\ \ \ \ \ \ \ \ \ \ \ \ \ 4.12445296e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01534}01534\ \ \ \ \ \ \ \ \ \ \ \ \ 3.34418322e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01535}01535\ \ \ \ \ \ \ \ \ \ \ \ \ 2.71151383e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01536}01536\ \ \ \ \ \ \ \ \ \ \ \ \ 2.19782469e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01537}01537\ \ \ \ \ \ \ \ \ \ \ \ \ 1.78173649e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01538}01538\ \ \ \ \ \ \ \ \ \ \ \ \ 1.44461976e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01539}01539\ \ \ \ \ \ \ \ \ \ \ \ \ 1.17120123e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01540}01540\ \ \ \ \ \ \ \ \ \ \ \ \ 9.49485678e-\/09,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01541}01541\ \ \ \ \ \ \ \ \ \ \ \ \ 7.69772505e-\/09,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01542}01542\ \ \ \ \ \ \ \ \ \ \ \ \ 6.24155316e-\/09,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01543}01543\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01544}01544\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01545}01545\ \ \ \ \ assert\_allclose(gbt.train\_score\_[-\/10:],\ train\_score,\ rtol=1e-\/3,\ atol=1e-\/11)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01546}01546\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01547}01547\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01548}01548\ \textcolor{preprocessor}{@skip\_if\_32bit}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01549}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a723c9435fcfb3c97a927350efb8c4064}{01549}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a723c9435fcfb3c97a927350efb8c4064}{test\_huber\_exact\_backward\_compat}}():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01550}01550\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ huber\ GBT\ backward\ compat\ on\ a\ simple\ dataset.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01551}01551\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01552}01552\ \textcolor{stringliteral}{\ \ \ \ The\ results\ to\ compare\ against\ are\ taken\ from\ scikit-\/learn\ v1.2.0.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01553}01553\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01554}01554\ \ \ \ \ n\_samples\ =\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01555}01555\ \ \ \ \ y\ =\ np.arange(n\_samples)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01556}01556\ \ \ \ \ x1\ =\ np.minimum(y,\ n\_samples\ /\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01557}01557\ \ \ \ \ x2\ =\ np.minimum(-\/y,\ -\/n\_samples\ /\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01558}01558\ \ \ \ \ X\ =\ np.c\_[x1,\ x2]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01559}01559\ \ \ \ \ gbt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingRegressor}{GradientBoostingRegressor}}(loss=\textcolor{stringliteral}{"{}huber"{}},\ n\_estimators=100,\ alpha=0.8).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01560}01560\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01561}01561\ \ \ \ \ assert\_allclose(gbt.\_loss.closs.delta,\ 0.0001655688041282133)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01562}01562\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01563}01563\ \ \ \ \ pred\_result\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01564}01564\ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01565}01565\ \ \ \ \ \ \ \ \ \ \ \ \ 1.48120765e-\/04,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01566}01566\ \ \ \ \ \ \ \ \ \ \ \ \ 9.99949174e-\/01,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01567}01567\ \ \ \ \ \ \ \ \ \ \ \ \ 2.00116957e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01568}01568\ \ \ \ \ \ \ \ \ \ \ \ \ 2.99986716e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01569}01569\ \ \ \ \ \ \ \ \ \ \ \ \ 4.00012064e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01570}01570\ \ \ \ \ \ \ \ \ \ \ \ \ 5.00002462e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01571}01571\ \ \ \ \ \ \ \ \ \ \ \ \ 5.99998898e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01572}01572\ \ \ \ \ \ \ \ \ \ \ \ \ 6.99692549e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01573}01573\ \ \ \ \ \ \ \ \ \ \ \ \ 8.00006356e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01574}01574\ \ \ \ \ \ \ \ \ \ \ \ \ 8.99985099e00,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01575}01575\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01576}01576\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01577}01577\ \ \ \ \ assert\_allclose(gbt.predict(X),\ pred\_result,\ rtol=1e-\/8)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01578}01578\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01579}01579\ \ \ \ \ train\_score\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01580}01580\ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01581}01581\ \ \ \ \ \ \ \ \ \ \ \ \ 2.59484709e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01582}01582\ \ \ \ \ \ \ \ \ \ \ \ \ 2.19165900e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01583}01583\ \ \ \ \ \ \ \ \ \ \ \ \ 1.89644782e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01584}01584\ \ \ \ \ \ \ \ \ \ \ \ \ 1.64556454e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01585}01585\ \ \ \ \ \ \ \ \ \ \ \ \ 1.38705110e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01586}01586\ \ \ \ \ \ \ \ \ \ \ \ \ 1.20373736e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01587}01587\ \ \ \ \ \ \ \ \ \ \ \ \ 1.04746082e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01588}01588\ \ \ \ \ \ \ \ \ \ \ \ \ 9.13835687e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01589}01589\ \ \ \ \ \ \ \ \ \ \ \ \ 8.20245756e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01590}01590\ \ \ \ \ \ \ \ \ \ \ \ \ 7.17122188e-\/08,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01591}01591\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01592}01592\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01593}01593\ \ \ \ \ assert\_allclose(gbt.train\_score\_[-\/10:],\ train\_score,\ rtol=1e-\/8)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01594}01594\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01595}01595\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01596}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a0b05ce4b841af8f356f6cc9f40f050cb}{01596}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a0b05ce4b841af8f356f6cc9f40f050cb}{test\_binomial\_error\_exact\_backward\_compat}}():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01597}01597\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ binary\ log\_loss\ GBT\ backward\ compat\ on\ a\ simple\ dataset.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01598}01598\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01599}01599\ \textcolor{stringliteral}{\ \ \ \ The\ results\ to\ compare\ against\ are\ taken\ from\ scikit-\/learn\ v1.2.0.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01600}01600\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01601}01601\ \ \ \ \ n\_samples\ =\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01602}01602\ \ \ \ \ y\ =\ np.arange(n\_samples)\ \%\ 2}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01603}01603\ \ \ \ \ x1\ =\ np.minimum(y,\ n\_samples\ /\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01604}01604\ \ \ \ \ x2\ =\ np.minimum(-\/y,\ -\/n\_samples\ /\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01605}01605\ \ \ \ \ X\ =\ np.c\_[x1,\ x2]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01606}01606\ \ \ \ \ gbt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(loss=\textcolor{stringliteral}{"{}log\_loss"{}},\ n\_estimators=100).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01607}01607\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01608}01608\ \ \ \ \ pred\_result\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01609}01609\ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01610}01610\ \ \ \ \ \ \ \ \ \ \ \ \ [9.99978098e-\/01,\ 2.19017313e-\/05],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01611}01611\ \ \ \ \ \ \ \ \ \ \ \ \ [2.19017313e-\/05,\ 9.99978098e-\/01],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01612}01612\ \ \ \ \ \ \ \ \ \ \ \ \ [9.99978098e-\/01,\ 2.19017313e-\/05],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01613}01613\ \ \ \ \ \ \ \ \ \ \ \ \ [2.19017313e-\/05,\ 9.99978098e-\/01],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01614}01614\ \ \ \ \ \ \ \ \ \ \ \ \ [9.99978098e-\/01,\ 2.19017313e-\/05],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01615}01615\ \ \ \ \ \ \ \ \ \ \ \ \ [2.19017313e-\/05,\ 9.99978098e-\/01],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01616}01616\ \ \ \ \ \ \ \ \ \ \ \ \ [9.99978098e-\/01,\ 2.19017313e-\/05],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01617}01617\ \ \ \ \ \ \ \ \ \ \ \ \ [2.19017313e-\/05,\ 9.99978098e-\/01],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01618}01618\ \ \ \ \ \ \ \ \ \ \ \ \ [9.99978098e-\/01,\ 2.19017313e-\/05],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01619}01619\ \ \ \ \ \ \ \ \ \ \ \ \ [2.19017313e-\/05,\ 9.99978098e-\/01],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01620}01620\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01621}01621\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01622}01622\ \ \ \ \ assert\_allclose(gbt.predict\_proba(X),\ pred\_result,\ rtol=1e-\/8)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01623}01623\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01624}01624\ \ \ \ \ train\_score\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01625}01625\ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01626}01626\ \ \ \ \ \ \ \ \ \ \ \ \ 1.07742210e-\/04,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01627}01627\ \ \ \ \ \ \ \ \ \ \ \ \ 9.74889078e-\/05,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01628}01628\ \ \ \ \ \ \ \ \ \ \ \ \ 8.82113863e-\/05,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01629}01629\ \ \ \ \ \ \ \ \ \ \ \ \ 7.98167784e-\/05,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01630}01630\ \ \ \ \ \ \ \ \ \ \ \ \ 7.22210566e-\/05,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01631}01631\ \ \ \ \ \ \ \ \ \ \ \ \ 6.53481907e-\/05,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01632}01632\ \ \ \ \ \ \ \ \ \ \ \ \ 5.91293869e-\/05,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01633}01633\ \ \ \ \ \ \ \ \ \ \ \ \ 5.35023988e-\/05,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01634}01634\ \ \ \ \ \ \ \ \ \ \ \ \ 4.84109045e-\/05,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01635}01635\ \ \ \ \ \ \ \ \ \ \ \ \ 4.38039423e-\/05,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01636}01636\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01637}01637\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01638}01638\ \ \ \ \ assert\_allclose(gbt.train\_score\_[-\/10:],\ train\_score,\ rtol=1e-\/8)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01639}01639\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01640}01640\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01641}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a3ce4daef7035980d3c39a832bb6d782b}{01641}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a3ce4daef7035980d3c39a832bb6d782b}{test\_multinomial\_error\_exact\_backward\_compat}}():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01642}01642\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ multiclass\ log\_loss\ GBT\ backward\ compat\ on\ a\ simple\ dataset.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01643}01643\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01644}01644\ \textcolor{stringliteral}{\ \ \ \ The\ results\ to\ compare\ against\ are\ taken\ from\ scikit-\/learn\ v1.2.0.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01645}01645\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01646}01646\ \ \ \ \ n\_samples\ =\ 10}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01647}01647\ \ \ \ \ y\ =\ np.arange(n\_samples)\ \%\ 4}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01648}01648\ \ \ \ \ x1\ =\ np.minimum(y,\ n\_samples\ /\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01649}01649\ \ \ \ \ x2\ =\ np.minimum(-\/y,\ -\/n\_samples\ /\ 2)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01650}01650\ \ \ \ \ X\ =\ np.c\_[x1,\ x2]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01651}01651\ \ \ \ \ gbt\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(loss=\textcolor{stringliteral}{"{}log\_loss"{}},\ n\_estimators=100).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01652}01652\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01653}01653\ \ \ \ \ pred\_result\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01654}01654\ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01655}01655\ \ \ \ \ \ \ \ \ \ \ \ \ [9.99999727e-\/01,\ 1.11956255e-\/07,\ 8.04921671e-\/08,\ 8.04921668e-\/08],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01656}01656\ \ \ \ \ \ \ \ \ \ \ \ \ [1.11956254e-\/07,\ 9.99999727e-\/01,\ 8.04921671e-\/08,\ 8.04921668e-\/08],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01657}01657\ \ \ \ \ \ \ \ \ \ \ \ \ [1.19417637e-\/07,\ 1.19417637e-\/07,\ 9.99999675e-\/01,\ 8.60526098e-\/08],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01658}01658\ \ \ \ \ \ \ \ \ \ \ \ \ [1.19417637e-\/07,\ 1.19417637e-\/07,\ 8.60526088e-\/08,\ 9.99999675e-\/01],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01659}01659\ \ \ \ \ \ \ \ \ \ \ \ \ [9.99999727e-\/01,\ 1.11956255e-\/07,\ 8.04921671e-\/08,\ 8.04921668e-\/08],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01660}01660\ \ \ \ \ \ \ \ \ \ \ \ \ [1.11956254e-\/07,\ 9.99999727e-\/01,\ 8.04921671e-\/08,\ 8.04921668e-\/08],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01661}01661\ \ \ \ \ \ \ \ \ \ \ \ \ [1.19417637e-\/07,\ 1.19417637e-\/07,\ 9.99999675e-\/01,\ 8.60526098e-\/08],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01662}01662\ \ \ \ \ \ \ \ \ \ \ \ \ [1.19417637e-\/07,\ 1.19417637e-\/07,\ 8.60526088e-\/08,\ 9.99999675e-\/01],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01663}01663\ \ \ \ \ \ \ \ \ \ \ \ \ [9.99999727e-\/01,\ 1.11956255e-\/07,\ 8.04921671e-\/08,\ 8.04921668e-\/08],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01664}01664\ \ \ \ \ \ \ \ \ \ \ \ \ [1.11956254e-\/07,\ 9.99999727e-\/01,\ 8.04921671e-\/08,\ 8.04921668e-\/08],}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01665}01665\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01666}01666\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01667}01667\ \ \ \ \ assert\_allclose(gbt.predict\_proba(X),\ pred\_result,\ rtol=1e-\/8)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01668}01668\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01669}01669\ \ \ \ \ train\_score\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01670}01670\ \ \ \ \ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01671}01671\ \ \ \ \ \ \ \ \ \ \ \ \ 1.13300150e-\/06,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01672}01672\ \ \ \ \ \ \ \ \ \ \ \ \ 9.75183397e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01673}01673\ \ \ \ \ \ \ \ \ \ \ \ \ 8.39348103e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01674}01674\ \ \ \ \ \ \ \ \ \ \ \ \ 7.22433588e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01675}01675\ \ \ \ \ \ \ \ \ \ \ \ \ 6.21804338e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01676}01676\ \ \ \ \ \ \ \ \ \ \ \ \ 5.35191943e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01677}01677\ \ \ \ \ \ \ \ \ \ \ \ \ 4.60643966e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01678}01678\ \ \ \ \ \ \ \ \ \ \ \ \ 3.96479930e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01679}01679\ \ \ \ \ \ \ \ \ \ \ \ \ 3.41253434e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01680}01680\ \ \ \ \ \ \ \ \ \ \ \ \ 2.93719550e-\/07,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01681}01681\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01682}01682\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01683}01683\ \ \ \ \ assert\_allclose(gbt.train\_score\_[-\/10:],\ train\_score,\ rtol=1e-\/8)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01684}01684\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01685}01685\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01686}\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a6259b225203f49f54f52ef378dc10659}{01686}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1ensemble_1_1tests_1_1test__gradient__boosting_a6259b225203f49f54f52ef378dc10659}{test\_gb\_denominator\_zero}}(global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01687}01687\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ \_update\_terminal\_regions\ denominator\ is\ not\ zero.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01688}01688\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01689}01689\ \textcolor{stringliteral}{\ \ \ \ For\ instance\ for\ log\ loss\ based\ binary\ classification,\ the\ line\ search\ step\ might}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01690}01690\ \textcolor{stringliteral}{\ \ \ \ become\ nan/inf\ as\ denominator\ =\ hessian\ =\ prob\ *\ (1\ -\/\ prob)\ and\ prob\ =\ 0\ or\ 1\ can}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01691}01691\ \textcolor{stringliteral}{\ \ \ \ happen.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01692}01692\ \textcolor{stringliteral}{\ \ \ \ Here,\ we\ create\ a\ situation\ were\ this\ happens\ (at\ least\ with\ roughly\ 80\%)\ based}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01693}01693\ \textcolor{stringliteral}{\ \ \ \ on\ the\ random\ seed.}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01694}01694\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01695}01695\ \ \ \ \ X,\ y\ =\ datasets.make\_hastie\_10\_2(n\_samples=100,\ random\_state=20)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01696}01696\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01697}01697\ \ \ \ \ params\ =\ \{}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01698}01698\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}learning\_rate"{}}:\ 1.0,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01699}01699\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}subsample"{}}:\ 0.5,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01700}01700\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}n\_estimators"{}}:\ 100,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01701}01701\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_leaf\_nodes"{}}:\ 4,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01702}01702\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}max\_depth"{}}:\ \textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01703}01703\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}random\_state"{}}:\ global\_random\_seed,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01704}01704\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}min\_samples\_leaf"{}}:\ 2,}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01705}01705\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01706}01706\ }
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01707}01707\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1ensemble_1_1__gb_1_1GradientBoostingClassifier}{GradientBoostingClassifier}}(**params)}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01708}01708\ \ \ \ \ \textcolor{comment}{\#\ \_safe\_devide\ would\ raise\ a\ RuntimeWarning}}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01709}01709\ \ \ \ \ \textcolor{keyword}{with}\ warnings.catch\_warnings():}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01710}01710\ \ \ \ \ \ \ \ \ warnings.simplefilter(\textcolor{stringliteral}{"{}error"{}})}
\DoxyCodeLine{\Hypertarget{tests_2test__gradient__boosting_8py_source_l01711}01711\ \ \ \ \ \ \ \ \ clf.fit(X,\ y)}

\end{DoxyCode}
