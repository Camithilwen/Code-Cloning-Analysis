\doxysection{pandas.\+io.\+parquet Namespace Reference}
\hypertarget{namespacepandas_1_1io_1_1parquet}{}\label{namespacepandas_1_1io_1_1parquet}\index{pandas.io.parquet@{pandas.io.parquet}}
\doxysubsubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{classpandas_1_1io_1_1parquet_1_1BaseImpl}{Base\+Impl}}
\item 
class \mbox{\hyperlink{classpandas_1_1io_1_1parquet_1_1FastParquetImpl}{Fast\+Parquet\+Impl}}
\item 
class \mbox{\hyperlink{classpandas_1_1io_1_1parquet_1_1PyArrowImpl}{Py\+Arrow\+Impl}}
\end{DoxyCompactItemize}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classpandas_1_1io_1_1parquet_1_1BaseImpl}{Base\+Impl}} \mbox{\hyperlink{namespacepandas_1_1io_1_1parquet_adc1392a3fb2d187d2c24e4701a44dccb}{get\+\_\+engine}} (str engine)
\item 
tuple\mbox{[} File\+Path\texorpdfstring{$\vert$}{|}\mbox{\hyperlink{classpandas_1_1__typing_1_1ReadBuffer}{Read\+Buffer}}\mbox{[}bytes\mbox{]}\texorpdfstring{$\vert$}{|}\mbox{\hyperlink{classpandas_1_1__typing_1_1WriteBuffer}{Write\+Buffer}}\mbox{[}bytes\mbox{]}, \mbox{\hyperlink{classpandas_1_1io_1_1common_1_1IOHandles}{IOHandles}}\mbox{[}bytes\mbox{]}\texorpdfstring{$\vert$}{|}None, Any\mbox{]} \mbox{\hyperlink{namespacepandas_1_1io_1_1parquet_a7d58c3c77e286e5ef9406f09dc191037}{\+\_\+get\+\_\+path\+\_\+or\+\_\+handle}} (File\+Path\texorpdfstring{$\vert$}{|}\mbox{\hyperlink{classpandas_1_1__typing_1_1ReadBuffer}{Read\+Buffer}}\mbox{[}bytes\mbox{]}\texorpdfstring{$\vert$}{|}\mbox{\hyperlink{classpandas_1_1__typing_1_1WriteBuffer}{Write\+Buffer}}\mbox{[}bytes\mbox{]} path, Any fs, Storage\+Options\texorpdfstring{$\vert$}{|}None storage\+\_\+options=None, str mode="{}rb"{}, bool is\+\_\+dir=False)
\item 
bytes\texorpdfstring{$\vert$}{|}None \mbox{\hyperlink{namespacepandas_1_1io_1_1parquet_a75e45db1dca53a76f90e741e7b9380b8}{to\+\_\+parquet}} (Data\+Frame df, File\+Path\texorpdfstring{$\vert$}{|}\mbox{\hyperlink{classpandas_1_1__typing_1_1WriteBuffer}{Write\+Buffer}}\mbox{[}bytes\mbox{]}\texorpdfstring{$\vert$}{|}None path=None, str engine="{}auto"{}, str\texorpdfstring{$\vert$}{|}None compression="{}snappy"{}, bool\texorpdfstring{$\vert$}{|}None index=None, Storage\+Options\texorpdfstring{$\vert$}{|}None storage\+\_\+options=None, list\mbox{[}str\mbox{]}\texorpdfstring{$\vert$}{|}None partition\+\_\+cols=None, Any filesystem=None, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\item 
Data\+Frame \mbox{\hyperlink{namespacepandas_1_1io_1_1parquet_a4cd913323e224abd56500d0d5571be09}{read\+\_\+parquet}} (File\+Path\texorpdfstring{$\vert$}{|}\mbox{\hyperlink{classpandas_1_1__typing_1_1ReadBuffer}{Read\+Buffer}}\mbox{[}bytes\mbox{]} path, str engine="{}auto"{}, list\mbox{[}str\mbox{]}\texorpdfstring{$\vert$}{|}None columns=None, Storage\+Options\texorpdfstring{$\vert$}{|}None storage\+\_\+options=None, bool\texorpdfstring{$\vert$}{|}lib.\+No\+Default use\+\_\+nullable\+\_\+dtypes=lib.\+no\+\_\+default, Dtype\+Backend\texorpdfstring{$\vert$}{|}lib.\+No\+Default dtype\+\_\+backend=lib.\+no\+\_\+default, Any filesystem=None, list\mbox{[}tuple\mbox{]}\texorpdfstring{$\vert$}{|}list\mbox{[}list\mbox{[}tuple\mbox{]}\mbox{]}\texorpdfstring{$\vert$}{|}None filters=None, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb} parquet compat \end{DoxyVerb}
 

\doxysubsection{Function Documentation}
\Hypertarget{namespacepandas_1_1io_1_1parquet_a7d58c3c77e286e5ef9406f09dc191037}\index{pandas.io.parquet@{pandas.io.parquet}!\_get\_path\_or\_handle@{\_get\_path\_or\_handle}}
\index{\_get\_path\_or\_handle@{\_get\_path\_or\_handle}!pandas.io.parquet@{pandas.io.parquet}}
\doxysubsubsection{\texorpdfstring{\_get\_path\_or\_handle()}{\_get\_path\_or\_handle()}}
{\footnotesize\ttfamily \label{namespacepandas_1_1io_1_1parquet_a7d58c3c77e286e5ef9406f09dc191037} 
 tuple\mbox{[}     File\+Path \texorpdfstring{$\vert$}{|} \mbox{\hyperlink{classpandas_1_1__typing_1_1ReadBuffer}{Read\+Buffer}}\mbox{[}bytes\mbox{]} \texorpdfstring{$\vert$}{|} \mbox{\hyperlink{classpandas_1_1__typing_1_1WriteBuffer}{Write\+Buffer}}\mbox{[}bytes\mbox{]}, \mbox{\hyperlink{classpandas_1_1io_1_1common_1_1IOHandles}{IOHandles}}\mbox{[}bytes\mbox{]} \texorpdfstring{$\vert$}{|} None, Any \mbox{]} pandas.\+io.\+parquet.\+\_\+get\+\_\+path\+\_\+or\+\_\+handle (\begin{DoxyParamCaption}\item[{File\+Path \texorpdfstring{$\vert$}{|} \mbox{\hyperlink{classpandas_1_1__typing_1_1ReadBuffer}{Read\+Buffer}}\mbox{[}bytes\mbox{]} \texorpdfstring{$\vert$}{|} \mbox{\hyperlink{classpandas_1_1__typing_1_1WriteBuffer}{Write\+Buffer}}\mbox{[}bytes\mbox{]}}]{path}{, }\item[{Any}]{fs}{, }\item[{Storage\+Options \texorpdfstring{$\vert$}{|} None }]{storage\+\_\+options}{ = {\ttfamily None}, }\item[{str }]{mode}{ = {\ttfamily "{}rb"{}}, }\item[{bool }]{is\+\_\+dir}{ = {\ttfamily False}}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}

\begin{DoxyVerb}File handling for PyArrow.\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{parquet_8py_source_l00086}{86}} of file \mbox{\hyperlink{parquet_8py_source}{parquet.\+py}}.

\Hypertarget{namespacepandas_1_1io_1_1parquet_adc1392a3fb2d187d2c24e4701a44dccb}\index{pandas.io.parquet@{pandas.io.parquet}!get\_engine@{get\_engine}}
\index{get\_engine@{get\_engine}!pandas.io.parquet@{pandas.io.parquet}}
\doxysubsubsection{\texorpdfstring{get\_engine()}{get\_engine()}}
{\footnotesize\ttfamily \label{namespacepandas_1_1io_1_1parquet_adc1392a3fb2d187d2c24e4701a44dccb} 
 \mbox{\hyperlink{classpandas_1_1io_1_1parquet_1_1BaseImpl}{Base\+Impl}} pandas.\+io.\+parquet.\+get\+\_\+engine (\begin{DoxyParamCaption}\item[{str}]{engine}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}return our implementation\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{parquet_8py_source_l00052}{52}} of file \mbox{\hyperlink{parquet_8py_source}{parquet.\+py}}.



Referenced by \mbox{\hyperlink{parquet_8py_source_l00511}{read\+\_\+parquet()}}, and \mbox{\hyperlink{parquet_8py_source_l00422}{to\+\_\+parquet()}}.

\Hypertarget{namespacepandas_1_1io_1_1parquet_a4cd913323e224abd56500d0d5571be09}\index{pandas.io.parquet@{pandas.io.parquet}!read\_parquet@{read\_parquet}}
\index{read\_parquet@{read\_parquet}!pandas.io.parquet@{pandas.io.parquet}}
\doxysubsubsection{\texorpdfstring{read\_parquet()}{read\_parquet()}}
{\footnotesize\ttfamily \label{namespacepandas_1_1io_1_1parquet_a4cd913323e224abd56500d0d5571be09} 
 Data\+Frame pandas.\+io.\+parquet.\+read\+\_\+parquet (\begin{DoxyParamCaption}\item[{File\+Path \texorpdfstring{$\vert$}{|} \mbox{\hyperlink{classpandas_1_1__typing_1_1ReadBuffer}{Read\+Buffer}}\mbox{[}bytes\mbox{]}}]{path}{, }\item[{str }]{engine}{ = {\ttfamily "{}auto"{}}, }\item[{list\mbox{[}str\mbox{]} \texorpdfstring{$\vert$}{|} None }]{columns}{ = {\ttfamily None}, }\item[{Storage\+Options \texorpdfstring{$\vert$}{|} None }]{storage\+\_\+options}{ = {\ttfamily None}, }\item[{bool \texorpdfstring{$\vert$}{|} lib.\+No\+Default }]{use\+\_\+nullable\+\_\+dtypes}{ = {\ttfamily lib.no\+\_\+default}, }\item[{Dtype\+Backend \texorpdfstring{$\vert$}{|} lib.\+No\+Default }]{dtype\+\_\+backend}{ = {\ttfamily lib.no\+\_\+default}, }\item[{Any }]{filesystem}{ = {\ttfamily None}, }\item[{list\mbox{[}tuple\mbox{]} \texorpdfstring{$\vert$}{|} list\mbox{[}list\mbox{[}tuple\mbox{]}\mbox{]} \texorpdfstring{$\vert$}{|} None }]{filters}{ = {\ttfamily None}, }\item[{\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}}]{kwargs}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Load a parquet object from the file path, returning a DataFrame.

Parameters
----------
path : str, path object or file-like object
    String, path object (implementing ``os.PathLike[str]``), or file-like
    object implementing a binary ``read()`` function.
    The string could be a URL. Valid URL schemes include http, ftp, s3,
    gs, and file. For file URLs, a host is expected. A local file could be:
    ``file://localhost/path/to/table.parquet``.
    A file URL can also be a path to a directory that contains multiple
    partitioned parquet files. Both pyarrow and fastparquet support
    paths to directories as well as file URLs. A directory path could be:
    ``file://localhost/path/to/tables`` or ``s3://bucket/partition_dir``.
engine : {{'auto', 'pyarrow', 'fastparquet'}}, default 'auto'
    Parquet library to use. If 'auto', then the option
    ``io.parquet.engine`` is used. The default ``io.parquet.engine``
    behavior is to try 'pyarrow', falling back to 'fastparquet' if
    'pyarrow' is unavailable.

    When using the ``'pyarrow'`` engine and no storage options are provided
    and a filesystem is implemented by both ``pyarrow.fs`` and ``fsspec``
    (e.g. "s3://"), then the ``pyarrow.fs`` filesystem is attempted first.
    Use the filesystem keyword with an instantiated fsspec filesystem
    if you wish to use its implementation.
columns : list, default=None
    If not None, only these columns will be read from the file.
{storage_options}

    .. versionadded:: 1.3.0

use_nullable_dtypes : bool, default False
    If True, use dtypes that use ``pd.NA`` as missing value indicator
    for the resulting DataFrame. (only applicable for the ``pyarrow``
    engine)
    As new dtypes are added that support ``pd.NA`` in the future, the
    output with this option will change to use those dtypes.
    Note: this is an experimental option, and behaviour (e.g. additional
    support dtypes) may change without notice.

    .. deprecated:: 2.0

dtype_backend : {{'numpy_nullable', 'pyarrow'}}, default 'numpy_nullable'
    Back-end data type applied to the resultant :class:`DataFrame`
    (still experimental). Behaviour is as follows:

    * ``"numpy_nullable"``: returns nullable-dtype-backed :class:`DataFrame`
      (default).
    * ``"pyarrow"``: returns pyarrow-backed nullable :class:`ArrowDtype`
      DataFrame.

    .. versionadded:: 2.0

filesystem : fsspec or pyarrow filesystem, default None
    Filesystem object to use when reading the parquet file. Only implemented
    for ``engine="pyarrow"``.

    .. versionadded:: 2.1.0

filters : List[Tuple] or List[List[Tuple]], default None
    To filter out data.
    Filter syntax: [[(column, op, val), ...],...]
    where op is [==, =, >, >=, <, <=, !=, in, not in]
    The innermost tuples are transposed into a set of filters applied
    through an `AND` operation.
    The outer list combines these sets of filters through an `OR`
    operation.
    A single list of tuples can also be used, meaning that no `OR`
    operation between set of filters is to be conducted.

    Using this argument will NOT result in row-wise filtering of the final
    partitions unless ``engine="pyarrow"`` is also specified.  For
    other engines, filtering is only performed at the partition level, that is,
    to prevent the loading of some row-groups and/or files.

    .. versionadded:: 2.1.0

**kwargs
    Any additional kwargs are passed to the engine.

Returns
-------
DataFrame

See Also
--------
DataFrame.to_parquet : Create a parquet object that serializes a DataFrame.

Examples
--------
>>> original_df = pd.DataFrame(
...     {{"foo": range(5), "bar": range(5, 10)}}
...    )
>>> original_df
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> df_parquet_bytes = original_df.to_parquet()
>>> from io import BytesIO
>>> restored_df = pd.read_parquet(BytesIO(df_parquet_bytes))
>>> restored_df
   foo  bar
0    0    5
1    1    6
2    2    7
3    3    8
4    4    9
>>> restored_df.equals(original_df)
True
>>> restored_bar = pd.read_parquet(BytesIO(df_parquet_bytes), columns=["bar"])
>>> restored_bar
    bar
0    5
1    6
2    7
3    8
4    9
>>> restored_bar.equals(original_df[['bar']])
True

The function uses `kwargs` that are passed directly to the engine.
In the following example, we use the `filters` argument of the pyarrow
engine to filter the rows of the DataFrame.

Since `pyarrow` is the default engine, we can omit the `engine` argument.
Note that the `filters` argument is implemented by the `pyarrow` engine,
which can benefit from multithreading and also potentially be more
economical in terms of memory.

>>> sel = [("foo", ">", 2)]
>>> restored_part = pd.read_parquet(BytesIO(df_parquet_bytes), filters=sel)
>>> restored_part
    foo  bar
0    3    8
1    4    9
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{parquet_8py_source_l00501}{501}} of file \mbox{\hyperlink{parquet_8py_source}{parquet.\+py}}.



References \mbox{\hyperlink{parquet_8py_source_l00052}{get\+\_\+engine()}}.

\Hypertarget{namespacepandas_1_1io_1_1parquet_a75e45db1dca53a76f90e741e7b9380b8}\index{pandas.io.parquet@{pandas.io.parquet}!to\_parquet@{to\_parquet}}
\index{to\_parquet@{to\_parquet}!pandas.io.parquet@{pandas.io.parquet}}
\doxysubsubsection{\texorpdfstring{to\_parquet()}{to\_parquet()}}
{\footnotesize\ttfamily \label{namespacepandas_1_1io_1_1parquet_a75e45db1dca53a76f90e741e7b9380b8} 
 bytes \texorpdfstring{$\vert$}{|} None pandas.\+io.\+parquet.\+to\+\_\+parquet (\begin{DoxyParamCaption}\item[{Data\+Frame}]{df}{, }\item[{File\+Path \texorpdfstring{$\vert$}{|} \mbox{\hyperlink{classpandas_1_1__typing_1_1WriteBuffer}{Write\+Buffer}}\mbox{[}bytes\mbox{]} \texorpdfstring{$\vert$}{|} None }]{path}{ = {\ttfamily None}, }\item[{str }]{engine}{ = {\ttfamily "{}auto"{}}, }\item[{str \texorpdfstring{$\vert$}{|} None }]{compression}{ = {\ttfamily "{}snappy"{}}, }\item[{bool \texorpdfstring{$\vert$}{|} None }]{index}{ = {\ttfamily None}, }\item[{Storage\+Options \texorpdfstring{$\vert$}{|} None }]{storage\+\_\+options}{ = {\ttfamily None}, }\item[{list\mbox{[}str\mbox{]} \texorpdfstring{$\vert$}{|} None }]{partition\+\_\+cols}{ = {\ttfamily None}, }\item[{Any }]{filesystem}{ = {\ttfamily None}, }\item[{\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}}]{kwargs}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Write a DataFrame to the parquet format.

Parameters
----------
df : DataFrame
path : str, path object, file-like object, or None, default None
    String, path object (implementing ``os.PathLike[str]``), or file-like
    object implementing a binary ``write()`` function. If None, the result is
    returned as bytes. If a string, it will be used as Root Directory path
    when writing a partitioned dataset. The engine fastparquet does not
    accept file-like objects.
engine : {{'auto', 'pyarrow', 'fastparquet'}}, default 'auto'
    Parquet library to use. If 'auto', then the option
    ``io.parquet.engine`` is used. The default ``io.parquet.engine``
    behavior is to try 'pyarrow', falling back to 'fastparquet' if
    'pyarrow' is unavailable.

    When using the ``'pyarrow'`` engine and no storage options are provided
    and a filesystem is implemented by both ``pyarrow.fs`` and ``fsspec``
    (e.g. "s3://"), then the ``pyarrow.fs`` filesystem is attempted first.
    Use the filesystem keyword with an instantiated fsspec filesystem
    if you wish to use its implementation.
compression : {{'snappy', 'gzip', 'brotli', 'lz4', 'zstd', None}},
    default 'snappy'. Name of the compression to use. Use ``None``
    for no compression.
index : bool, default None
    If ``True``, include the dataframe's index(es) in the file output. If
    ``False``, they will not be written to the file.
    If ``None``, similar to ``True`` the dataframe's index(es)
    will be saved. However, instead of being saved as values,
    the RangeIndex will be stored as a range in the metadata so it
    doesn't require much space and is faster. Other indexes will
    be included as columns in the file output.
partition_cols : str or list, optional, default None
    Column names by which to partition the dataset.
    Columns are partitioned in the order they are given.
    Must be None if path is not a string.
{storage_options}

filesystem : fsspec or pyarrow filesystem, default None
    Filesystem object to use when reading the parquet file. Only implemented
    for ``engine="pyarrow"``.

    .. versionadded:: 2.1.0

kwargs
    Additional keyword arguments passed to the engine

Returns
-------
bytes if no path argument is provided else None
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{parquet_8py_source_l00412}{412}} of file \mbox{\hyperlink{parquet_8py_source}{parquet.\+py}}.



References \mbox{\hyperlink{parquet_8py_source_l00052}{get\+\_\+engine()}}.

