\doxysection{sklearn.\+datasets.\+\_\+svmlight\+\_\+format\+\_\+io Namespace Reference}
\hypertarget{namespacesklearn_1_1datasets_1_1__svmlight__format__io}{}\label{namespacesklearn_1_1datasets_1_1__svmlight__format__io}\index{sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a40e01303f6c8476f5c59f1a6a2cc3b08}{load\+\_\+svmlight\+\_\+file}} (f, \texorpdfstring{$\ast$}{*}, n\+\_\+features=None, dtype=np.\+float64, multilabel=False, zero\+\_\+based="{}auto"{}, query\+\_\+id=False, offset=0, length=-\/1)
\item 
\mbox{\hyperlink{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a767d9b9bcb2c6ae557bc38e25f9e433f}{\+\_\+gen\+\_\+open}} (f)
\item 
\mbox{\hyperlink{namespacesklearn_1_1datasets_1_1__svmlight__format__io_ad4e6af19d3b8237af17dd1dbf2bc7372}{\+\_\+open\+\_\+and\+\_\+load}} (f, dtype, multilabel, zero\+\_\+based, query\+\_\+id, offset=0, length=-\/1)
\item 
\mbox{\hyperlink{namespacesklearn_1_1datasets_1_1__svmlight__format__io_aa5955114dc5a8f7c2bbeace906945845}{load\+\_\+svmlight\+\_\+files}} (files, \texorpdfstring{$\ast$}{*}, n\+\_\+features=None, dtype=np.\+float64, multilabel=False, zero\+\_\+based="{}auto"{}, query\+\_\+id=False, offset=0, length=-\/1)
\item 
\mbox{\hyperlink{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a6a334a480a2865f58f4251f3e6696722}{\+\_\+dump\+\_\+svmlight}} (X, y, f, multilabel, one\+\_\+based, comment, query\+\_\+id)
\item 
\mbox{\hyperlink{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a36c5689042a881d2c6846a8fbf8845ae}{dump\+\_\+svmlight\+\_\+file}} (X, y, f, \texorpdfstring{$\ast$}{*}, zero\+\_\+based=\mbox{\hyperlink{classTrue}{True}}, comment=None, query\+\_\+id=None, multilabel=False)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}This module implements a loader and dumper for the svmlight format

This format is a text-based format, with one sample per line. It does
not store zero valued features hence is suitable for sparse dataset.

The first element of each line can be used to store a target variable to
predict.

This format is used as the default format for both svmlight and the
libsvm command line programs.
\end{DoxyVerb}
 

\doxysubsection{Function Documentation}
\Hypertarget{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a6a334a480a2865f58f4251f3e6696722}\index{sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}!\_dump\_svmlight@{\_dump\_svmlight}}
\index{\_dump\_svmlight@{\_dump\_svmlight}!sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}}
\doxysubsubsection{\texorpdfstring{\_dump\_svmlight()}{\_dump\_svmlight()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a6a334a480a2865f58f4251f3e6696722} 
sklearn.\+datasets.\+\_\+svmlight\+\_\+format\+\_\+io.\+\_\+dump\+\_\+svmlight (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{}]{y}{, }\item[{}]{f}{, }\item[{}]{multilabel}{, }\item[{}]{one\+\_\+based}{, }\item[{}]{comment}{, }\item[{}]{query\+\_\+id}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Definition at line \mbox{\hyperlink{__svmlight__format__io_8py_source_l00416}{416}} of file \mbox{\hyperlink{__svmlight__format__io_8py_source}{\+\_\+svmlight\+\_\+format\+\_\+io.\+py}}.

\Hypertarget{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a767d9b9bcb2c6ae557bc38e25f9e433f}\index{sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}!\_gen\_open@{\_gen\_open}}
\index{\_gen\_open@{\_gen\_open}!sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}}
\doxysubsubsection{\texorpdfstring{\_gen\_open()}{\_gen\_open()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a767d9b9bcb2c6ae557bc38e25f9e433f} 
sklearn.\+datasets.\+\_\+svmlight\+\_\+format\+\_\+io.\+\_\+gen\+\_\+open (\begin{DoxyParamCaption}\item[{}]{f}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Definition at line \mbox{\hyperlink{__svmlight__format__io_8py_source_l00189}{189}} of file \mbox{\hyperlink{__svmlight__format__io_8py_source}{\+\_\+svmlight\+\_\+format\+\_\+io.\+py}}.

\Hypertarget{namespacesklearn_1_1datasets_1_1__svmlight__format__io_ad4e6af19d3b8237af17dd1dbf2bc7372}\index{sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}!\_open\_and\_load@{\_open\_and\_load}}
\index{\_open\_and\_load@{\_open\_and\_load}!sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}}
\doxysubsubsection{\texorpdfstring{\_open\_and\_load()}{\_open\_and\_load()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1datasets_1_1__svmlight__format__io_ad4e6af19d3b8237af17dd1dbf2bc7372} 
sklearn.\+datasets.\+\_\+svmlight\+\_\+format\+\_\+io.\+\_\+open\+\_\+and\+\_\+load (\begin{DoxyParamCaption}\item[{}]{f}{, }\item[{}]{dtype}{, }\item[{}]{multilabel}{, }\item[{}]{zero\+\_\+based}{, }\item[{}]{query\+\_\+id}{, }\item[{}]{offset}{ = {\ttfamily 0}, }\item[{}]{length}{ = {\ttfamily -\/1}}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Definition at line \mbox{\hyperlink{__svmlight__format__io_8py_source_l00210}{210}} of file \mbox{\hyperlink{__svmlight__format__io_8py_source}{\+\_\+svmlight\+\_\+format\+\_\+io.\+py}}.

\Hypertarget{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a36c5689042a881d2c6846a8fbf8845ae}\index{sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}!dump\_svmlight\_file@{dump\_svmlight\_file}}
\index{dump\_svmlight\_file@{dump\_svmlight\_file}!sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}}
\doxysubsubsection{\texorpdfstring{dump\_svmlight\_file()}{dump\_svmlight\_file()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a36c5689042a881d2c6846a8fbf8845ae} 
sklearn.\+datasets.\+\_\+svmlight\+\_\+format\+\_\+io.\+dump\+\_\+svmlight\+\_\+file (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{}]{y}{, }\item[{}]{f}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{zero\+\_\+based}{ = {\ttfamily \mbox{\hyperlink{classTrue}{True}}}, }\item[{}]{comment}{ = {\ttfamily None}, }\item[{}]{query\+\_\+id}{ = {\ttfamily None}, }\item[{}]{multilabel}{ = {\ttfamily False}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Dump the dataset in svmlight / libsvm file format.

This format is a text-based format, with one sample per line. It does
not store zero valued features hence is suitable for sparse dataset.

The first element of each line can be used to store a target variable
to predict.

Parameters
----------
X : {array-like, sparse matrix} of shape (n_samples, n_features)
    Training vectors, where `n_samples` is the number of samples and
    `n_features` is the number of features.

y : {array-like, sparse matrix}, shape = (n_samples,) or (n_samples, n_labels)
    Target values. Class labels must be an
    integer or float, or array-like objects of integer or float for
    multilabel classifications.

f : str or file-like in binary mode
    If string, specifies the path that will contain the data.
    If file-like, data will be written to f. f should be opened in binary
    mode.

zero_based : bool, default=True
    Whether column indices should be written zero-based (True) or one-based
    (False).

comment : str or bytes, default=None
    Comment to insert at the top of the file. This should be either a
    Unicode string, which will be encoded as UTF-8, or an ASCII byte
    string.
    If a comment is given, then it will be preceded by one that identifies
    the file as having been dumped by scikit-learn. Note that not all
    tools grok comments in SVMlight files.

query_id : array-like of shape (n_samples,), default=None
    Array containing pairwise preference constraints (qid in svmlight
    format).

multilabel : bool, default=False
    Samples may have several labels each (see
    https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html).

    .. versionadded:: 0.17
       parameter `multilabel` to support multilabel datasets.

Examples
--------
>>> from sklearn.datasets import dump_svmlight_file, make_classification
>>> X, y = make_classification(random_state=0)
>>> output_file = "my_dataset.svmlight"
>>> dump_svmlight_file(X, y, output_file)  # doctest: +SKIP
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__svmlight__format__io_8py_source_l00457}{457}} of file \mbox{\hyperlink{__svmlight__format__io_8py_source}{\+\_\+svmlight\+\_\+format\+\_\+io.\+py}}.

\Hypertarget{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a40e01303f6c8476f5c59f1a6a2cc3b08}\index{sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}!load\_svmlight\_file@{load\_svmlight\_file}}
\index{load\_svmlight\_file@{load\_svmlight\_file}!sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}}
\doxysubsubsection{\texorpdfstring{load\_svmlight\_file()}{load\_svmlight\_file()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1datasets_1_1__svmlight__format__io_a40e01303f6c8476f5c59f1a6a2cc3b08} 
sklearn.\+datasets.\+\_\+svmlight\+\_\+format\+\_\+io.\+load\+\_\+svmlight\+\_\+file (\begin{DoxyParamCaption}\item[{}]{f}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{n\+\_\+features}{ = {\ttfamily None}, }\item[{}]{dtype}{ = {\ttfamily np.float64}, }\item[{}]{multilabel}{ = {\ttfamily False}, }\item[{}]{zero\+\_\+based}{ = {\ttfamily "{}auto"{}}, }\item[{}]{query\+\_\+id}{ = {\ttfamily False}, }\item[{}]{offset}{ = {\ttfamily 0}, }\item[{}]{length}{ = {\ttfamily -\/1}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Load datasets in the svmlight / libsvm format into sparse CSR matrix.

This format is a text-based format, with one sample per line. It does
not store zero valued features hence is suitable for sparse dataset.

The first element of each line can be used to store a target variable
to predict.

This format is used as the default format for both svmlight and the
libsvm command line programs.

Parsing a text based source can be expensive. When repeatedly
working on the same dataset, it is recommended to wrap this
loader with joblib.Memory.cache to store a memmapped backup of the
CSR results of the first call and benefit from the near instantaneous
loading of memmapped structures for the subsequent calls.

In case the file contains a pairwise preference constraint (known
as "qid" in the svmlight format) these are ignored unless the
query_id parameter is set to True. These pairwise preference
constraints can be used to constraint the combination of samples
when using pairwise loss functions (as is the case in some
learning to rank problems) so that only pairs with the same
query_id value are considered.

This implementation is written in Cython and is reasonably fast.
However, a faster API-compatible loader is also available at:
https://github.com/mblondel/svmlight-loader

Parameters
----------
f : str, path-like, file-like or int
    (Path to) a file to load. If a path ends in ".gz" or ".bz2", it will
    be uncompressed on the fly. If an integer is passed, it is assumed to
    be a file descriptor. A file-like or file descriptor will not be closed
    by this function. A file-like object must be opened in binary mode.

    .. versionchanged:: 1.2
       Path-like objects are now accepted.

n_features : int, default=None
    The number of features to use. If None, it will be inferred. This
    argument is useful to load several files that are subsets of a
    bigger sliced dataset: each subset might not have examples of
    every feature, hence the inferred shape might vary from one
    slice to another.
    n_features is only required if ``offset`` or ``length`` are passed a
    non-default value.

dtype : numpy data type, default=np.float64
    Data type of dataset to be loaded. This will be the data type of the
    output numpy arrays ``X`` and ``y``.

multilabel : bool, default=False
    Samples may have several labels each (see
    https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html).

zero_based : bool or "auto", default="auto"
    Whether column indices in f are zero-based (True) or one-based
    (False). If column indices are one-based, they are transformed to
    zero-based to match Python/NumPy conventions.
    If set to "auto", a heuristic check is applied to determine this from
    the file contents. Both kinds of files occur "in the wild", but they
    are unfortunately not self-identifying. Using "auto" or True should
    always be safe when no ``offset`` or ``length`` is passed.
    If ``offset`` or ``length`` are passed, the "auto" mode falls back
    to ``zero_based=True`` to avoid having the heuristic check yield
    inconsistent results on different segments of the file.

query_id : bool, default=False
    If True, will return the query_id array for each file.

offset : int, default=0
    Ignore the offset first bytes by seeking forward, then
    discarding the following bytes up until the next new line
    character.

length : int, default=-1
    If strictly positive, stop reading any new line of data once the
    position in the file has reached the (offset + length) bytes threshold.

Returns
-------
X : scipy.sparse matrix of shape (n_samples, n_features)
    The data matrix.

y : ndarray of shape (n_samples,), or a list of tuples of length n_samples
    The target. It is a list of tuples when ``multilabel=True``, else a
    ndarray.

query_id : array of shape (n_samples,)
   The query_id for each sample. Only returned when query_id is set to
   True.

See Also
--------
load_svmlight_files : Similar function for loading multiple files in this
    format, enforcing the same number of features/columns on all of them.

Examples
--------
To use joblib.Memory to cache the svmlight file::

    from joblib import Memory
    from sklearn.datasets import load_svmlight_file
    mem = Memory("./mycache")

    @mem.cache
    def get_data():
        data = load_svmlight_file("mysvmlightfile")
        return data[0], data[1]

    X, y = get_data()
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__svmlight__format__io_8py_source_l00050}{50}} of file \mbox{\hyperlink{__svmlight__format__io_8py_source}{\+\_\+svmlight\+\_\+format\+\_\+io.\+py}}.



References \mbox{\hyperlink{__svmlight__format__io_8py_source_l00262}{load\+\_\+svmlight\+\_\+files()}}.

\Hypertarget{namespacesklearn_1_1datasets_1_1__svmlight__format__io_aa5955114dc5a8f7c2bbeace906945845}\index{sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}!load\_svmlight\_files@{load\_svmlight\_files}}
\index{load\_svmlight\_files@{load\_svmlight\_files}!sklearn.datasets.\_svmlight\_format\_io@{sklearn.datasets.\_svmlight\_format\_io}}
\doxysubsubsection{\texorpdfstring{load\_svmlight\_files()}{load\_svmlight\_files()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1datasets_1_1__svmlight__format__io_aa5955114dc5a8f7c2bbeace906945845} 
sklearn.\+datasets.\+\_\+svmlight\+\_\+format\+\_\+io.\+load\+\_\+svmlight\+\_\+files (\begin{DoxyParamCaption}\item[{}]{files}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{n\+\_\+features}{ = {\ttfamily None}, }\item[{}]{dtype}{ = {\ttfamily np.float64}, }\item[{}]{multilabel}{ = {\ttfamily False}, }\item[{}]{zero\+\_\+based}{ = {\ttfamily "{}auto"{}}, }\item[{}]{query\+\_\+id}{ = {\ttfamily False}, }\item[{}]{offset}{ = {\ttfamily 0}, }\item[{}]{length}{ = {\ttfamily -\/1}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Load dataset from multiple files in SVMlight format.

This function is equivalent to mapping load_svmlight_file over a list of
files, except that the results are concatenated into a single, flat list
and the samples vectors are constrained to all have the same number of
features.

In case the file contains a pairwise preference constraint (known
as "qid" in the svmlight format) these are ignored unless the
query_id parameter is set to True. These pairwise preference
constraints can be used to constraint the combination of samples
when using pairwise loss functions (as is the case in some
learning to rank problems) so that only pairs with the same
query_id value are considered.

Parameters
----------
files : array-like, dtype=str, path-like, file-like or int
    (Paths of) files to load. If a path ends in ".gz" or ".bz2", it will
    be uncompressed on the fly. If an integer is passed, it is assumed to
    be a file descriptor. File-likes and file descriptors will not be
    closed by this function. File-like objects must be opened in binary
    mode.

    .. versionchanged:: 1.2
       Path-like objects are now accepted.

n_features : int, default=None
    The number of features to use. If None, it will be inferred from the
    maximum column index occurring in any of the files.

    This can be set to a higher value than the actual number of features
    in any of the input files, but setting it to a lower value will cause
    an exception to be raised.

dtype : numpy data type, default=np.float64
    Data type of dataset to be loaded. This will be the data type of the
    output numpy arrays ``X`` and ``y``.

multilabel : bool, default=False
    Samples may have several labels each (see
    https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html).

zero_based : bool or "auto", default="auto"
    Whether column indices in f are zero-based (True) or one-based
    (False). If column indices are one-based, they are transformed to
    zero-based to match Python/NumPy conventions.
    If set to "auto", a heuristic check is applied to determine this from
    the file contents. Both kinds of files occur "in the wild", but they
    are unfortunately not self-identifying. Using "auto" or True should
    always be safe when no offset or length is passed.
    If offset or length are passed, the "auto" mode falls back
    to zero_based=True to avoid having the heuristic check yield
    inconsistent results on different segments of the file.

query_id : bool, default=False
    If True, will return the query_id array for each file.

offset : int, default=0
    Ignore the offset first bytes by seeking forward, then
    discarding the following bytes up until the next new line
    character.

length : int, default=-1
    If strictly positive, stop reading any new line of data once the
    position in the file has reached the (offset + length) bytes threshold.

Returns
-------
[X1, y1, ..., Xn, yn] or [X1, y1, q1, ..., Xn, yn, qn]: list of arrays
    Each (Xi, yi) pair is the result from load_svmlight_file(files[i]).
    If query_id is set to True, this will return instead (Xi, yi, qi)
    triplets.

See Also
--------
load_svmlight_file: Similar function for loading a single file in this
    format.

Notes
-----
When fitting a model to a matrix X_train and evaluating it against a
matrix X_test, it is essential that X_train and X_test have the same
number of features (X_train.shape[1] == X_test.shape[1]). This may not
be the case if you load the files individually with load_svmlight_file.

Examples
--------
To use joblib.Memory to cache the svmlight file::

    from joblib import Memory
    from sklearn.datasets import load_svmlight_file
    mem = Memory("./mycache")

    @mem.cache
    def get_data():
        data_train, target_train, data_test, target_test = load_svmlight_files(
            ["svmlight_file_train", "svmlight_file_test"]
        )
        return data_train, target_train, data_test, target_test

    X_train, y_train, X_test, y_test = get_data()
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__svmlight__format__io_8py_source_l00252}{252}} of file \mbox{\hyperlink{__svmlight__format__io_8py_source}{\+\_\+svmlight\+\_\+format\+\_\+io.\+py}}.



Referenced by \mbox{\hyperlink{__svmlight__format__io_8py_source_l00060}{load\+\_\+svmlight\+\_\+file()}}.

