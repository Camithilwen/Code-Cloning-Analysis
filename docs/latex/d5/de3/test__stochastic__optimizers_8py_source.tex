\doxysection{test\+\_\+stochastic\+\_\+optimizers.\+py}
\hypertarget{test__stochastic__optimizers_8py_source}{}\label{test__stochastic__optimizers_8py_source}\index{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/neural\_network/tests/test\_stochastic\_optimizers.py@{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/neural\_network/tests/test\_stochastic\_optimizers.py}}

\begin{DoxyCode}{0}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00001}\mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1tests_1_1test__stochastic__optimizers}{00001}}\ \textcolor{keyword}{import}\ numpy\ \textcolor{keyword}{as}\ np}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00002}00002\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00003}00003\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1neural__network_1_1__stochastic__optimizers}{sklearn.neural\_network.\_stochastic\_optimizers}}\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00004}00004\ \ \ \ \ AdamOptimizer,}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00005}00005\ \ \ \ \ BaseOptimizer,}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00006}00006\ \ \ \ \ SGDOptimizer,}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00007}00007\ )}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00008}00008\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils_1_1__testing}{sklearn.utils.\_testing}}\ \textcolor{keyword}{import}\ assert\_array\_equal}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00009}00009\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00010}00010\ shapes\ =\ [(4,\ 6),\ (6,\ 8),\ (7,\ 8,\ 9)]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00011}00011\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00012}00012\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00013}00013\ \textcolor{keyword}{def\ }test\_base\_optimizer():}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00014}00014\ \ \ \ \ \textcolor{keywordflow}{for}\ lr\ \textcolor{keywordflow}{in}\ [10**i\ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(-\/3,\ 4)]:}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00015}00015\ \ \ \ \ \ \ \ \ optimizer\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer}{BaseOptimizer}}(lr)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00016}00016\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ optimizer.trigger\_stopping(\textcolor{stringliteral}{"{}"{}},\ \textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00017}00017\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00018}00018\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00019}00019\ \textcolor{keyword}{def\ }test\_sgd\_optimizer\_no\_momentum():}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00020}00020\ \ \ \ \ params\ =\ [np.zeros(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00021}00021\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00022}00022\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00023}00023\ \ \ \ \ \textcolor{keywordflow}{for}\ lr\ \textcolor{keywordflow}{in}\ [10**i\ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(-\/3,\ 4)]:}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00024}00024\ \ \ \ \ \ \ \ \ optimizer\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer}{SGDOptimizer}}(params,\ lr,\ momentum=0,\ nesterov=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00025}00025\ \ \ \ \ \ \ \ \ grads\ =\ [rng.random\_sample(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00026}00026\ \ \ \ \ \ \ \ \ expected\ =\ [param\ -\/\ lr\ *\ grad\ \textcolor{keywordflow}{for}\ param,\ grad\ \textcolor{keywordflow}{in}\ zip(params,\ grads)]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00027}00027\ \ \ \ \ \ \ \ \ optimizer.update\_params(params,\ grads)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00028}00028\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00029}00029\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ exp,\ param\ \textcolor{keywordflow}{in}\ zip(expected,\ params):}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00030}00030\ \ \ \ \ \ \ \ \ \ \ \ \ assert\_array\_equal(exp,\ param)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00031}00031\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00032}00032\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00033}00033\ \textcolor{keyword}{def\ }test\_sgd\_optimizer\_momentum():}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00034}00034\ \ \ \ \ params\ =\ [np.zeros(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00035}00035\ \ \ \ \ lr\ =\ 0.1}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00036}00036\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00037}00037\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00038}00038\ \ \ \ \ \textcolor{keywordflow}{for}\ momentum\ \textcolor{keywordflow}{in}\ np.arange(0.5,\ 0.9,\ 0.1):}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00039}00039\ \ \ \ \ \ \ \ \ optimizer\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer}{SGDOptimizer}}(params,\ lr,\ momentum=momentum,\ nesterov=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00040}00040\ \ \ \ \ \ \ \ \ velocities\ =\ [rng.random\_sample(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00041}00041\ \ \ \ \ \ \ \ \ optimizer.velocities\ =\ velocities}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00042}00042\ \ \ \ \ \ \ \ \ grads\ =\ [rng.random\_sample(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00043}00043\ \ \ \ \ \ \ \ \ updates\ =\ [}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00044}00044\ \ \ \ \ \ \ \ \ \ \ \ \ momentum\ *\ velocity\ -\/\ lr\ *\ grad\ \textcolor{keywordflow}{for}\ velocity,\ grad\ \textcolor{keywordflow}{in}\ zip(velocities,\ grads)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00045}00045\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00046}00046\ \ \ \ \ \ \ \ \ expected\ =\ [param\ +\ update\ \textcolor{keywordflow}{for}\ param,\ update\ \textcolor{keywordflow}{in}\ zip(params,\ updates)]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00047}00047\ \ \ \ \ \ \ \ \ optimizer.update\_params(params,\ grads)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00048}00048\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00049}00049\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ exp,\ param\ \textcolor{keywordflow}{in}\ zip(expected,\ params):}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00050}00050\ \ \ \ \ \ \ \ \ \ \ \ \ assert\_array\_equal(exp,\ param)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00051}00051\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00052}00052\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00053}00053\ \textcolor{keyword}{def\ }test\_sgd\_optimizer\_trigger\_stopping():}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00054}00054\ \ \ \ \ params\ =\ [np.zeros(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00055}00055\ \ \ \ \ lr\ =\ 2e-\/6}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00056}00056\ \ \ \ \ optimizer\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer}{SGDOptimizer}}(params,\ lr,\ lr\_schedule=\textcolor{stringliteral}{"{}adaptive"{}})}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00057}00057\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ optimizer.trigger\_stopping(\textcolor{stringliteral}{"{}"{}},\ \textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00058}00058\ \ \ \ \ \textcolor{keyword}{assert}\ lr\ /\ 5\ ==\ optimizer.learning\_rate}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00059}00059\ \ \ \ \ \textcolor{keyword}{assert}\ optimizer.trigger\_stopping(\textcolor{stringliteral}{"{}"{}},\ \textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00060}00060\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00061}00061\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00062}00062\ \textcolor{keyword}{def\ }test\_sgd\_optimizer\_nesterovs\_momentum():}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00063}00063\ \ \ \ \ params\ =\ [np.zeros(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00064}00064\ \ \ \ \ lr\ =\ 0.1}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00065}00065\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00066}00066\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00067}00067\ \ \ \ \ \textcolor{keywordflow}{for}\ momentum\ \textcolor{keywordflow}{in}\ np.arange(0.5,\ 0.9,\ 0.1):}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00068}00068\ \ \ \ \ \ \ \ \ optimizer\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer}{SGDOptimizer}}(params,\ lr,\ momentum=momentum,\ nesterov=\textcolor{keyword}{True})}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00069}00069\ \ \ \ \ \ \ \ \ velocities\ =\ [rng.random\_sample(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00070}00070\ \ \ \ \ \ \ \ \ optimizer.velocities\ =\ velocities}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00071}00071\ \ \ \ \ \ \ \ \ grads\ =\ [rng.random\_sample(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00072}00072\ \ \ \ \ \ \ \ \ updates\ =\ [}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00073}00073\ \ \ \ \ \ \ \ \ \ \ \ \ momentum\ *\ velocity\ -\/\ lr\ *\ grad\ \textcolor{keywordflow}{for}\ velocity,\ grad\ \textcolor{keywordflow}{in}\ zip(velocities,\ grads)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00074}00074\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00075}00075\ \ \ \ \ \ \ \ \ updates\ =\ [}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00076}00076\ \ \ \ \ \ \ \ \ \ \ \ \ momentum\ *\ update\ -\/\ lr\ *\ grad\ \textcolor{keywordflow}{for}\ update,\ grad\ \textcolor{keywordflow}{in}\ zip(updates,\ grads)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00077}00077\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00078}00078\ \ \ \ \ \ \ \ \ expected\ =\ [param\ +\ update\ \textcolor{keywordflow}{for}\ param,\ update\ \textcolor{keywordflow}{in}\ zip(params,\ updates)]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00079}00079\ \ \ \ \ \ \ \ \ optimizer.update\_params(params,\ grads)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00080}00080\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00081}00081\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ exp,\ param\ \textcolor{keywordflow}{in}\ zip(expected,\ params):}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00082}00082\ \ \ \ \ \ \ \ \ \ \ \ \ assert\_array\_equal(exp,\ param)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00083}00083\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00084}00084\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00085}00085\ \textcolor{keyword}{def\ }test\_adam\_optimizer():}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00086}00086\ \ \ \ \ params\ =\ [np.zeros(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00087}00087\ \ \ \ \ lr\ =\ 0.001}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00088}00088\ \ \ \ \ epsilon\ =\ 1e-\/8}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00089}00089\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00090}00090\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00091}00091\ \ \ \ \ \textcolor{keywordflow}{for}\ beta\_1\ \textcolor{keywordflow}{in}\ np.arange(0.9,\ 1.0,\ 0.05):}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00092}00092\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ beta\_2\ \textcolor{keywordflow}{in}\ np.arange(0.995,\ 1.0,\ 0.001):}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00093}00093\ \ \ \ \ \ \ \ \ \ \ \ \ optimizer\ =\ \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1AdamOptimizer}{AdamOptimizer}}(params,\ lr,\ beta\_1,\ beta\_2,\ epsilon)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00094}00094\ \ \ \ \ \ \ \ \ \ \ \ \ ms\ =\ [rng.random\_sample(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00095}00095\ \ \ \ \ \ \ \ \ \ \ \ \ vs\ =\ [rng.random\_sample(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00096}00096\ \ \ \ \ \ \ \ \ \ \ \ \ t\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00097}00097\ \ \ \ \ \ \ \ \ \ \ \ \ optimizer.ms\ =\ ms}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00098}00098\ \ \ \ \ \ \ \ \ \ \ \ \ optimizer.vs\ =\ vs}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00099}00099\ \ \ \ \ \ \ \ \ \ \ \ \ optimizer.t\ =\ t\ -\/\ 1}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00100}00100\ \ \ \ \ \ \ \ \ \ \ \ \ grads\ =\ [rng.random\_sample(shape)\ \textcolor{keywordflow}{for}\ shape\ \textcolor{keywordflow}{in}\ shapes]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00101}00101\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00102}00102\ \ \ \ \ \ \ \ \ \ \ \ \ ms\ =\ [beta\_1\ *\ m\ +\ (1\ -\/\ beta\_1)\ *\ grad\ \textcolor{keywordflow}{for}\ m,\ grad\ \textcolor{keywordflow}{in}\ zip(ms,\ grads)]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00103}00103\ \ \ \ \ \ \ \ \ \ \ \ \ vs\ =\ [beta\_2\ *\ v\ +\ (1\ -\/\ beta\_2)\ *\ (grad**2)\ \textcolor{keywordflow}{for}\ v,\ grad\ \textcolor{keywordflow}{in}\ zip(vs,\ grads)]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00104}00104\ \ \ \ \ \ \ \ \ \ \ \ \ learning\_rate\ =\ lr\ *\ np.sqrt(1\ -\/\ beta\_2**t)\ /\ (1\ -\/\ beta\_1**t)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00105}00105\ \ \ \ \ \ \ \ \ \ \ \ \ updates\ =\ [}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00106}00106\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ -\/learning\_rate\ *\ m\ /\ (np.sqrt(v)\ +\ epsilon)\ \textcolor{keywordflow}{for}\ m,\ v\ \textcolor{keywordflow}{in}\ zip(ms,\ vs)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00107}00107\ \ \ \ \ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00108}00108\ \ \ \ \ \ \ \ \ \ \ \ \ expected\ =\ [param\ +\ update\ \textcolor{keywordflow}{for}\ param,\ update\ \textcolor{keywordflow}{in}\ zip(params,\ updates)]}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00109}00109\ }
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00110}00110\ \ \ \ \ \ \ \ \ \ \ \ \ optimizer.update\_params(params,\ grads)}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00111}00111\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ exp,\ param\ \textcolor{keywordflow}{in}\ zip(expected,\ params):}
\DoxyCodeLine{\Hypertarget{test__stochastic__optimizers_8py_source_l00112}00112\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ assert\_array\_equal(exp,\ param)}

\end{DoxyCode}
