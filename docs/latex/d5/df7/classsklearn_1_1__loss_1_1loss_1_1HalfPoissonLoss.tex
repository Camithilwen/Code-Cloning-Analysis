\doxysection{sklearn.\+\_\+loss.\+loss.\+Half\+Poisson\+Loss Class Reference}
\hypertarget{classsklearn_1_1__loss_1_1loss_1_1HalfPoissonLoss}{}\label{classsklearn_1_1__loss_1_1loss_1_1HalfPoissonLoss}\index{sklearn.\_loss.loss.HalfPoissonLoss@{sklearn.\_loss.loss.HalfPoissonLoss}}


Inheritance diagram for sklearn.\+\_\+loss.\+loss.\+Half\+Poisson\+Loss\+:
% FIG 0


Collaboration diagram for sklearn.\+\_\+loss.\+loss.\+Half\+Poisson\+Loss\+:
% FIG 1
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfPoissonLoss_ac9c453ea6c0d2fc67690b53efb537bf1}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, sample\+\_\+weight=None)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1HalfPoissonLoss_a0452b3e4776ba0622ff016553c9f0606}{constant\+\_\+to\+\_\+optimal\+\_\+zero}} (self, y\+\_\+true, sample\+\_\+weight=None)
\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions inherited from \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss}{sklearn.\+\_\+loss.\+loss.\+Base\+Loss}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a050f99cd8950283f434ace55115a40f7}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, closs, link, n\+\_\+classes=None)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_acf48e9151cdfbf2a35fda2f78fff42ae}{in\+\_\+y\+\_\+true\+\_\+range}} (self, y)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_af11ab89ac55cbdc1fc3b64dc68e8e75d}{in\+\_\+y\+\_\+pred\+\_\+range}} (self, y)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_ae355aae4c96c62732fb026e5241d9321}{loss}} (self, y\+\_\+true, raw\+\_\+prediction, sample\+\_\+weight=None, loss\+\_\+out=None, n\+\_\+threads=1)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a8c71136140d8c86d2d5bd5ace8bbd41d}{loss\+\_\+gradient}} (self, y\+\_\+true, raw\+\_\+prediction, sample\+\_\+weight=None, loss\+\_\+out=None, gradient\+\_\+out=None, n\+\_\+threads=1)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_aff7a3496ececc5dd431f51815620a4b9}{gradient}} (self, y\+\_\+true, raw\+\_\+prediction, sample\+\_\+weight=None, gradient\+\_\+out=None, n\+\_\+threads=1)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_ae7b33139cdecec21fd2044c9a618c94d}{gradient\+\_\+hessian}} (self, y\+\_\+true, raw\+\_\+prediction, sample\+\_\+weight=None, gradient\+\_\+out=None, hessian\+\_\+out=None, n\+\_\+threads=1)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a294afc783ab728aa3bfd859988493b35}{\+\_\+\+\_\+call\+\_\+\+\_\+}} (self, y\+\_\+true, raw\+\_\+prediction, sample\+\_\+weight=None, n\+\_\+threads=1)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a40afc87a56422158efbb681e18868a08}{fit\+\_\+intercept\+\_\+only}} (self, y\+\_\+true, sample\+\_\+weight=None)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a481e142c26f1a4db2dfaf2f7648fa725}{init\+\_\+gradient\+\_\+and\+\_\+hessian}} (self, n\+\_\+samples, dtype=np.\+float64, order="{}F"{})
\end{DoxyCompactItemize}
\doxysubsubsection*{Additional Inherited Members}
\doxysubsection*{Public Attributes inherited from \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss}{sklearn.\+\_\+loss.\+loss.\+Base\+Loss}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a2ac0fa5ee5b2367424987b8615b68504}{closs}} = closs
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a8b3ad72e068f068732da4e6b9232e456}{link}} = link
\item 
bool \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a66e10895d9cad969bea14b0adf257c40}{approx\+\_\+hessian}} = False
\item 
bool \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_af2916d8bf8ecb4f1b0f4de036546ea2f}{constant\+\_\+hessian}} = False
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_af23ae122eda60d60851e8bc38c5c85ce}{n\+\_\+classes}} = n\+\_\+classes
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a87a5c64b956653d473dfdc03b166b2fe}{interval\+\_\+y\+\_\+true}} = \mbox{\hyperlink{classsklearn_1_1__loss_1_1link_1_1Interval}{Interval}}(-\/np.\+inf, np.\+inf, False, False)
\item 
\mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a4aa175acb7ee145417f199c73f131707}{interval\+\_\+y\+\_\+pred}} = self.\+link.\+interval\+\_\+y\+\_\+pred
\end{DoxyCompactItemize}
\doxysubsection*{Static Public Attributes inherited from \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss}{sklearn.\+\_\+loss.\+loss.\+Base\+Loss}}}
\begin{DoxyCompactItemize}
\item 
bool \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_a1d8526c6ce3454df71ea3328d46cb75b}{differentiable}} = \mbox{\hyperlink{classTrue}{True}}
\item 
bool \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_ad38d68671d8b0604ac278813a5139959}{need\+\_\+update\+\_\+leaves\+\_\+values}} = False
\item 
bool \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_aba86d98f29852fcffb6c2a244a1da10d}{is\+\_\+multiclass}} = False
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Half Poisson deviance loss with log-link, for regression.

Domain:
y_true in non-negative real numbers
y_pred in positive real numbers

Link:
y_pred = exp(raw_prediction)

For a given sample x_i, half the Poisson deviance is defined as::

    loss(x_i) = y_true_i * log(y_true_i/exp(raw_prediction_i))
                - y_true_i + exp(raw_prediction_i)

Half the Poisson deviance is actually the negative log-likelihood up to
constant terms (not involving raw_prediction) and simplifies the
computation of the gradients.
We also skip the constant term `y_true_i * log(y_true_i) - y_true_i`.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{loss_8py_source_l00716}{716}} of file \mbox{\hyperlink{loss_8py_source}{loss.\+py}}.



\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{classsklearn_1_1__loss_1_1loss_1_1HalfPoissonLoss_ac9c453ea6c0d2fc67690b53efb537bf1}\index{sklearn.\_loss.loss.HalfPoissonLoss@{sklearn.\_loss.loss.HalfPoissonLoss}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!sklearn.\_loss.loss.HalfPoissonLoss@{sklearn.\_loss.loss.HalfPoissonLoss}}
\doxysubsubsection{\texorpdfstring{\_\_init\_\_()}{\_\_init\_\_()}}
{\footnotesize\ttfamily \label{classsklearn_1_1__loss_1_1loss_1_1HalfPoissonLoss_ac9c453ea6c0d2fc67690b53efb537bf1} 
sklearn.\+\_\+loss.\+loss.\+Half\+Poisson\+Loss.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{sample\+\_\+weight}{ = {\ttfamily None}}\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{loss_8py_source_l00737}{737}} of file \mbox{\hyperlink{loss_8py_source}{loss.\+py}}.



Referenced by \mbox{\hyperlink{kernels_8py_source_l00178}{sklearn.\+gaussian\+\_\+process.\+kernels.\+Kernel.\+get\+\_\+params()}}.



\doxysubsection{Member Function Documentation}
\Hypertarget{classsklearn_1_1__loss_1_1loss_1_1HalfPoissonLoss_a0452b3e4776ba0622ff016553c9f0606}\index{sklearn.\_loss.loss.HalfPoissonLoss@{sklearn.\_loss.loss.HalfPoissonLoss}!constant\_to\_optimal\_zero@{constant\_to\_optimal\_zero}}
\index{constant\_to\_optimal\_zero@{constant\_to\_optimal\_zero}!sklearn.\_loss.loss.HalfPoissonLoss@{sklearn.\_loss.loss.HalfPoissonLoss}}
\doxysubsubsection{\texorpdfstring{constant\_to\_optimal\_zero()}{constant\_to\_optimal\_zero()}}
{\footnotesize\ttfamily \label{classsklearn_1_1__loss_1_1loss_1_1HalfPoissonLoss_a0452b3e4776ba0622ff016553c9f0606} 
sklearn.\+\_\+loss.\+loss.\+Half\+Poisson\+Loss.\+constant\+\_\+to\+\_\+optimal\+\_\+zero (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{y\+\_\+true}{, }\item[{}]{sample\+\_\+weight}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Calculate term dropped in loss.

With this term added, the loss of perfect predictions is zero.
\end{DoxyVerb}
 

Reimplemented from \mbox{\hyperlink{classsklearn_1_1__loss_1_1loss_1_1BaseLoss_afc7a673025ec0b05993a924d54d6a6c5}{sklearn.\+\_\+loss.\+loss.\+Base\+Loss}}.



Definition at line \mbox{\hyperlink{loss_8py_source_l00741}{741}} of file \mbox{\hyperlink{loss_8py_source}{loss.\+py}}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/jam/\+Research/\+IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.\+12/site-\/packages/sklearn/\+\_\+loss/loss.\+py\end{DoxyCompactItemize}
