\doxysection{sklearn.\+svm.\+\_\+bounds Namespace Reference}
\hypertarget{namespacesklearn_1_1svm_1_1__bounds}{}\label{namespacesklearn_1_1svm_1_1__bounds}\index{sklearn.svm.\_bounds@{sklearn.svm.\_bounds}}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacesklearn_1_1svm_1_1__bounds_ab40ac3b202ed2a2b837c077063fc4e3a}{l1\+\_\+min\+\_\+c}} (X, y, \texorpdfstring{$\ast$}{*}, loss="{}squared\+\_\+hinge"{}, fit\+\_\+intercept=\mbox{\hyperlink{classTrue}{True}}, intercept\+\_\+scaling=1.\+0)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Determination of parameter bounds\end{DoxyVerb}
 

\doxysubsection{Function Documentation}
\Hypertarget{namespacesklearn_1_1svm_1_1__bounds_ab40ac3b202ed2a2b837c077063fc4e3a}\index{sklearn.svm.\_bounds@{sklearn.svm.\_bounds}!l1\_min\_c@{l1\_min\_c}}
\index{l1\_min\_c@{l1\_min\_c}!sklearn.svm.\_bounds@{sklearn.svm.\_bounds}}
\doxysubsubsection{\texorpdfstring{l1\_min\_c()}{l1\_min\_c()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1svm_1_1__bounds_ab40ac3b202ed2a2b837c077063fc4e3a} 
sklearn.\+svm.\+\_\+bounds.\+l1\+\_\+min\+\_\+c (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{}]{y}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{loss}{ = {\ttfamily "{}squared\+\_\+hinge"{}}, }\item[{}]{fit\+\_\+intercept}{ = {\ttfamily \mbox{\hyperlink{classTrue}{True}}}, }\item[{}]{intercept\+\_\+scaling}{ = {\ttfamily 1.0}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Return the lowest bound for `C`.

The lower bound for `C` is computed such that for `C` in `(l1_min_C, infinity)`
the model is guaranteed not to be empty. This applies to l1 penalized
classifiers, such as :class:`sklearn.svm.LinearSVC` with penalty='l1' and
:class:`sklearn.linear_model.LogisticRegression` with penalty='l1'.

This value is valid if `class_weight` parameter in `fit()` is not set.

For an example of how to use this function, see
:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.

Parameters
----------
X : {array-like, sparse matrix} of shape (n_samples, n_features)
    Training vector, where `n_samples` is the number of samples and
    `n_features` is the number of features.

y : array-like of shape (n_samples,)
    Target vector relative to X.

loss : {'squared_hinge', 'log'}, default='squared_hinge'
    Specifies the loss function.
    With 'squared_hinge' it is the squared hinge loss (a.k.a. L2 loss).
    With 'log' it is the loss of logistic regression models.

fit_intercept : bool, default=True
    Specifies if the intercept should be fitted by the model.
    It must match the fit() method parameter.

intercept_scaling : float, default=1.0
    When fit_intercept is True, instance vector x becomes
    [x, intercept_scaling],
    i.e. a "synthetic" feature with constant value equals to
    intercept_scaling is appended to the instance vector.
    It must match the fit() method parameter.

Returns
-------
l1_min_c : float
    Minimum value for C.

Examples
--------
>>> from sklearn.svm import l1_min_c
>>> from sklearn.datasets import make_classification
>>> X, y = make_classification(n_samples=100, n_features=20, random_state=42)
>>> print(f"{l1_min_c(X, y, loss='squared_hinge', fit_intercept=True):.4f}")
0.0044
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__bounds_8py_source_l00026}{26}} of file \mbox{\hyperlink{__bounds_8py_source}{\+\_\+bounds.\+py}}.

