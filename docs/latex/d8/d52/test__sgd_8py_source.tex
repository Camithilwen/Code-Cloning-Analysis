\doxysection{test\+\_\+sgd.\+py}
\hypertarget{test__sgd_8py_source}{}\label{test__sgd_8py_source}\index{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/linear\_model/tests/test\_sgd.py@{/home/jam/Research/IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.12/site-\/packages/sklearn/linear\_model/tests/test\_sgd.py}}

\begin{DoxyCode}{0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00001}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd}{00001}}\ \textcolor{keyword}{import}\ pickle}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00002}00002\ \textcolor{keyword}{from}\ unittest.mock\ \textcolor{keyword}{import}\ Mock}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00003}00003\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00004}00004\ \textcolor{keyword}{import}\ joblib}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00005}00005\ \textcolor{keyword}{import}\ numpy\ \textcolor{keyword}{as}\ np}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00006}00006\ \textcolor{keyword}{import}\ pytest}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00007}00007\ \textcolor{keyword}{import}\ \mbox{\hyperlink{namespacescipy_1_1sparse}{scipy.sparse}}\ \textcolor{keyword}{as}\ sp}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00008}00008\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00009}00009\ \textcolor{keyword}{from}\ sklearn\ \textcolor{keyword}{import}\ datasets,\ linear\_model,\ metrics}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00010}00010\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1base}{sklearn.base}}\ \textcolor{keyword}{import}\ clone,\ is\_classifier}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00011}00011\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1exceptions}{sklearn.exceptions}}\ \textcolor{keyword}{import}\ ConvergenceWarning}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00012}00012\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1kernel__approximation}{sklearn.kernel\_approximation}}\ \textcolor{keyword}{import}\ Nystroem}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00013}00013\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1linear__model}{sklearn.linear\_model}}\ \textcolor{keyword}{import}\ \_sgd\_fast\ \textcolor{keyword}{as}\ sgd\_fast}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00014}00014\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1linear__model}{sklearn.linear\_model}}\ \textcolor{keyword}{import}\ \_stochastic\_gradient}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00015}00015\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1model__selection}{sklearn.model\_selection}}\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00016}00016\ \ \ \ \ RandomizedSearchCV,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00017}00017\ \ \ \ \ ShuffleSplit,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00018}00018\ \ \ \ \ StratifiedShuffleSplit,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00019}00019\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00020}00020\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1pipeline}{sklearn.pipeline}}\ \textcolor{keyword}{import}\ make\_pipeline}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00021}00021\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1preprocessing}{sklearn.preprocessing}}\ \textcolor{keyword}{import}\ LabelEncoder,\ MinMaxScaler,\ StandardScaler,\ scale}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00022}00022\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1svm}{sklearn.svm}}\ \textcolor{keyword}{import}\ OneClassSVM}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00023}00023\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils}{sklearn.utils}}\ \textcolor{keyword}{import}\ get\_tags}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00024}00024\ \textcolor{keyword}{from}\ \mbox{\hyperlink{namespacesklearn_1_1utils_1_1__testing}{sklearn.utils.\_testing}}\ \textcolor{keyword}{import}\ (}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00025}00025\ \ \ \ \ assert\_allclose,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00026}00026\ \ \ \ \ assert\_almost\_equal,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00027}00027\ \ \ \ \ assert\_array\_almost\_equal,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00028}00028\ \ \ \ \ assert\_array\_equal,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00029}00029\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00030}00030\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00031}00031\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00032}00032\ \textcolor{keyword}{def\ }\_update\_kwargs(kwargs):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00033}00033\ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{stringliteral}{"{}random\_state"{}}\ \textcolor{keywordflow}{not}\ \textcolor{keywordflow}{in}\ kwargs:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00034}00034\ \ \ \ \ \ \ \ \ kwargs[\textcolor{stringliteral}{"{}random\_state"{}}]\ =\ 42}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00035}00035\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00036}00036\ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{stringliteral}{"{}tol"{}}\ \textcolor{keywordflow}{not}\ \textcolor{keywordflow}{in}\ kwargs:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00037}00037\ \ \ \ \ \ \ \ \ kwargs[\textcolor{stringliteral}{"{}tol"{}}]\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00038}00038\ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{stringliteral}{"{}max\_iter"{}}\ \textcolor{keywordflow}{not}\ \textcolor{keywordflow}{in}\ kwargs:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00039}00039\ \ \ \ \ \ \ \ \ kwargs[\textcolor{stringliteral}{"{}max\_iter"{}}]\ =\ 5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00040}00040\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00041}00041\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00042}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier}{00042}}\ \textcolor{keyword}{class\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier}{\_SparseSGDClassifier}}(\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{linear\_model.SGDClassifier}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00043}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_a6f3d445a30be4537c079ab56af4ba09f}{00043}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_a6f3d445a30be4537c079ab56af4ba09f}{fit}}(self,\ X,\ y,\ *args,\ **kw):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00044}00044\ \ \ \ \ \ \ \ \ X\ =\ sp.csr\_matrix(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00045}00045\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ super().\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_a6f3d445a30be4537c079ab56af4ba09f}{fit}}(X,\ y,\ *args,\ **kw)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00046}00046\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00047}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_a30f3a1b873f099f9b1d4c8be6814acec}{00047}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_a30f3a1b873f099f9b1d4c8be6814acec}{partial\_fit}}(self,\ X,\ y,\ *args,\ **kw):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00048}00048\ \ \ \ \ \ \ \ \ X\ =\ sp.csr\_matrix(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00049}00049\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ super().\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_a30f3a1b873f099f9b1d4c8be6814acec}{partial\_fit}}(X,\ y,\ *args,\ **kw)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00050}00050\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00051}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_a17128175c5c02b2ff3a8832d06480d11}{00051}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_a17128175c5c02b2ff3a8832d06480d11}{decision\_function}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00052}00052\ \ \ \ \ \ \ \ \ X\ =\ sp.csr\_matrix(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00053}00053\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ super().\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_a17128175c5c02b2ff3a8832d06480d11}{decision\_function}}(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00054}00054\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00055}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_aeb2eb3abb3118e01e66ce6168c931747}{00055}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_aeb2eb3abb3118e01e66ce6168c931747}{predict\_proba}}(self,\ X):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00056}00056\ \ \ \ \ \ \ \ \ X\ =\ sp.csr\_matrix(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00057}00057\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ super().\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier_aeb2eb3abb3118e01e66ce6168c931747}{predict\_proba}}(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00058}00058\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00059}00059\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00060}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDRegressor}{00060}}\ \textcolor{keyword}{class\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDRegressor}{\_SparseSGDRegressor}}(\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDRegressor}{linear\_model.SGDRegressor}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00061}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDRegressor_abc523188719921232df6810def1cfd6f}{00061}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDRegressor_abc523188719921232df6810def1cfd6f}{fit}}(self,\ X,\ y,\ *args,\ **kw):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00062}00062\ \ \ \ \ \ \ \ \ X\ =\ sp.csr\_matrix(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00063}00063\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ linear\_model.SGDRegressor.fit(self,\ X,\ y,\ *args,\ **kw)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00064}00064\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00065}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDRegressor_a034a3d05f9684c3fe4332d58c64ae852}{00065}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDRegressor_a034a3d05f9684c3fe4332d58c64ae852}{partial\_fit}}(self,\ X,\ y,\ *args,\ **kw):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00066}00066\ \ \ \ \ \ \ \ \ X\ =\ sp.csr\_matrix(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00067}00067\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ linear\_model.SGDRegressor.partial\_fit(self,\ X,\ y,\ *args,\ **kw)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00068}00068\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00069}00069\ \ \ \ \ \textcolor{keyword}{def\ }decision\_function(self,\ X,\ *args,\ **kw):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00070}00070\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ XXX\ untested\ as\ of\ v0.22}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00071}00071\ \ \ \ \ \ \ \ \ X\ =\ sp.csr\_matrix(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00072}00072\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ linear\_model.SGDRegressor.decision\_function(self,\ X,\ *args,\ **kw)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00073}00073\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00074}00074\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00075}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDOneClassSVM}{00075}}\ \textcolor{keyword}{class\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDOneClassSVM}{\_SparseSGDOneClassSVM}}(\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDOneClassSVM}{linear\_model.SGDOneClassSVM}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00076}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDOneClassSVM_a70f03f464192476c5fbe46e1a7c022f2}{00076}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDOneClassSVM_a70f03f464192476c5fbe46e1a7c022f2}{fit}}(self,\ X,\ *args,\ **kw):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00077}00077\ \ \ \ \ \ \ \ \ X\ =\ sp.csr\_matrix(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00078}00078\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ linear\_model.SGDOneClassSVM.fit(self,\ X,\ *args,\ **kw)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00079}00079\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00080}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDOneClassSVM_afd60108bb2ddf257b9aad5c54a5432ca}{00080}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDOneClassSVM_afd60108bb2ddf257b9aad5c54a5432ca}{partial\_fit}}(self,\ X,\ *args,\ **kw):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00081}00081\ \ \ \ \ \ \ \ \ X\ =\ sp.csr\_matrix(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00082}00082\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ linear\_model.SGDOneClassSVM.partial\_fit(self,\ X,\ *args,\ **kw)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00083}00083\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00084}\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDOneClassSVM_a661fee7b1cadd4fbc39a738a854d3d35}{00084}}\ \ \ \ \ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDOneClassSVM_a661fee7b1cadd4fbc39a738a854d3d35}{decision\_function}}(self,\ X,\ *args,\ **kw):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00085}00085\ \ \ \ \ \ \ \ \ X\ =\ sp.csr\_matrix(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00086}00086\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ linear\_model.SGDOneClassSVM.decision\_function(self,\ X,\ *args,\ **kw)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00087}00087\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00088}00088\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00089}00089\ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(**kwargs):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00090}00090\ \ \ \ \ \_update\_kwargs(kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00091}00091\ \ \ \ \ \textcolor{keywordflow}{return}\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{linear\_model.SGDClassifier}}(**kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00092}00092\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00093}00093\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00094}00094\ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDRegressor}{SGDRegressor}}(**kwargs):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00095}00095\ \ \ \ \ \_update\_kwargs(kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00096}00096\ \ \ \ \ \textcolor{keywordflow}{return}\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDRegressor}{linear\_model.SGDRegressor}}(**kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00097}00097\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00098}00098\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00099}00099\ \textcolor{keyword}{def\ }\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDOneClassSVM}{SGDOneClassSVM}}(**kwargs):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00100}00100\ \ \ \ \ \_update\_kwargs(kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00101}00101\ \ \ \ \ \textcolor{keywordflow}{return}\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDOneClassSVM}{linear\_model.SGDOneClassSVM}}(**kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00102}00102\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00103}00103\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00104}00104\ \textcolor{keyword}{def\ }SparseSGDClassifier(**kwargs):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00105}00105\ \ \ \ \ \_update\_kwargs(kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00106}00106\ \ \ \ \ \textcolor{keywordflow}{return}\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDClassifier}{\_SparseSGDClassifier}}(**kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00107}00107\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00108}00108\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00109}00109\ \textcolor{keyword}{def\ }SparseSGDRegressor(**kwargs):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00110}00110\ \ \ \ \ \_update\_kwargs(kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00111}00111\ \ \ \ \ \textcolor{keywordflow}{return}\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDRegressor}{\_SparseSGDRegressor}}(**kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00112}00112\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00113}00113\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00114}00114\ \textcolor{keyword}{def\ }SparseSGDOneClassSVM(**kwargs):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00115}00115\ \ \ \ \ \_update\_kwargs(kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00116}00116\ \ \ \ \ \textcolor{keywordflow}{return}\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1tests_1_1test__sgd_1_1__SparseSGDOneClassSVM}{\_SparseSGDOneClassSVM}}(**kwargs)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00117}00117\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00118}00118\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00119}00119\ \textcolor{comment}{\#\ Test\ Data}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00120}00120\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00121}00121\ \textcolor{comment}{\#\ test\ sample\ 1}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00122}00122\ X\ =\ np.array([[-\/2,\ -\/1],\ [-\/1,\ -\/1],\ [-\/1,\ -\/2],\ [1,\ 1],\ [1,\ 2],\ [2,\ 1]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00123}00123\ Y\ =\ [1,\ 1,\ 1,\ 2,\ 2,\ 2]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00124}00124\ T\ =\ np.array([[-\/1,\ -\/1],\ [2,\ 2],\ [3,\ 2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00125}00125\ true\_result\ =\ [1,\ 2,\ 2]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00126}00126\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00127}00127\ \textcolor{comment}{\#\ test\ sample\ 2;\ string\ class\ labels}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00128}00128\ X2\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00129}00129\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00130}00130\ \ \ \ \ \ \ \ \ [-\/1,\ 1],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00131}00131\ \ \ \ \ \ \ \ \ [-\/0.75,\ 0.5],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00132}00132\ \ \ \ \ \ \ \ \ [-\/1.5,\ 1.5],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00133}00133\ \ \ \ \ \ \ \ \ [1,\ 1],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00134}00134\ \ \ \ \ \ \ \ \ [0.75,\ 0.5],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00135}00135\ \ \ \ \ \ \ \ \ [1.5,\ 1.5],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00136}00136\ \ \ \ \ \ \ \ \ [-\/1,\ -\/1],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00137}00137\ \ \ \ \ \ \ \ \ [0,\ -\/0.5],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00138}00138\ \ \ \ \ \ \ \ \ [1,\ -\/1],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00139}00139\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00140}00140\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00141}00141\ Y2\ =\ [\textcolor{stringliteral}{"{}one"{}}]\ *\ 3\ +\ [\textcolor{stringliteral}{"{}two"{}}]\ *\ 3\ +\ [\textcolor{stringliteral}{"{}three"{}}]\ *\ 3}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00142}00142\ T2\ =\ np.array([[-\/1.5,\ 0.5],\ [1,\ 2],\ [0,\ -\/2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00143}00143\ true\_result2\ =\ [\textcolor{stringliteral}{"{}one"{}},\ \textcolor{stringliteral}{"{}two"{}},\ \textcolor{stringliteral}{"{}three"{}}]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00144}00144\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00145}00145\ \textcolor{comment}{\#\ test\ sample\ 3}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00146}00146\ X3\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00147}00147\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00148}00148\ \ \ \ \ \ \ \ \ [1,\ 1,\ 0,\ 0,\ 0,\ 0],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00149}00149\ \ \ \ \ \ \ \ \ [1,\ 1,\ 0,\ 0,\ 0,\ 0],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00150}00150\ \ \ \ \ \ \ \ \ [0,\ 0,\ 1,\ 0,\ 0,\ 0],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00151}00151\ \ \ \ \ \ \ \ \ [0,\ 0,\ 1,\ 0,\ 0,\ 0],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00152}00152\ \ \ \ \ \ \ \ \ [0,\ 0,\ 0,\ 0,\ 1,\ 1],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00153}00153\ \ \ \ \ \ \ \ \ [0,\ 0,\ 0,\ 0,\ 1,\ 1],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00154}00154\ \ \ \ \ \ \ \ \ [0,\ 0,\ 0,\ 1,\ 0,\ 0],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00155}00155\ \ \ \ \ \ \ \ \ [0,\ 0,\ 0,\ 1,\ 0,\ 0],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00156}00156\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00157}00157\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00158}00158\ Y3\ =\ np.array([1,\ 1,\ 1,\ 1,\ 2,\ 2,\ 2,\ 2])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00159}00159\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00160}00160\ \textcolor{comment}{\#\ test\ sample\ 4\ -\/\ two\ more\ or\ less\ redundant\ feature\ groups}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00161}00161\ X4\ =\ np.array(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00162}00162\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00163}00163\ \ \ \ \ \ \ \ \ [1,\ 0.9,\ 0.8,\ 0,\ 0,\ 0],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00164}00164\ \ \ \ \ \ \ \ \ [1,\ 0.84,\ 0.98,\ 0,\ 0,\ 0],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00165}00165\ \ \ \ \ \ \ \ \ [1,\ 0.96,\ 0.88,\ 0,\ 0,\ 0],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00166}00166\ \ \ \ \ \ \ \ \ [1,\ 0.91,\ 0.99,\ 0,\ 0,\ 0],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00167}00167\ \ \ \ \ \ \ \ \ [0,\ 0,\ 0,\ 0.89,\ 0.91,\ 1],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00168}00168\ \ \ \ \ \ \ \ \ [0,\ 0,\ 0,\ 0.79,\ 0.84,\ 1],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00169}00169\ \ \ \ \ \ \ \ \ [0,\ 0,\ 0,\ 0.91,\ 0.95,\ 1],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00170}00170\ \ \ \ \ \ \ \ \ [0,\ 0,\ 0,\ 0.93,\ 1,\ 1],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00171}00171\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00172}00172\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00173}00173\ Y4\ =\ np.array([1,\ 1,\ 1,\ 1,\ 2,\ 2,\ 2,\ 2])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00174}00174\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00175}00175\ iris\ =\ datasets.load\_iris()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00176}00176\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00177}00177\ \textcolor{comment}{\#\ test\ sample\ 5\ -\/\ test\ sample\ 1\ as\ binary\ classification\ problem}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00178}00178\ X5\ =\ np.array([[-\/2,\ -\/1],\ [-\/1,\ -\/1],\ [-\/1,\ -\/2],\ [1,\ 1],\ [1,\ 2],\ [2,\ 1]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00179}00179\ Y5\ =\ [1,\ 1,\ 1,\ 2,\ 2,\ 2]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00180}00180\ true\_result5\ =\ [0,\ 1,\ 1]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00181}00181\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00182}00182\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00183}00183\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00185}00185\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00186}00186\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00187}00187\ \textcolor{comment}{\#\ a\ simple\ implementation\ of\ ASGD\ to\ use\ for\ testing}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00188}00188\ \textcolor{comment}{\#\ uses\ squared\ loss\ to\ find\ the\ gradient}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00189}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_ab20ec7534385a6c109edac521ab20fb4}{00189}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_ab20ec7534385a6c109edac521ab20fb4}{asgd}}(klass,\ X,\ y,\ eta,\ alpha,\ weight\_init=None,\ intercept\_init=0.0):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00190}00190\ \ \ \ \ \textcolor{keywordflow}{if}\ weight\_init\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00191}00191\ \ \ \ \ \ \ \ \ weights\ =\ np.zeros(X.shape[1])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00192}00192\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00193}00193\ \ \ \ \ \ \ \ \ weights\ =\ weight\_init}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00194}00194\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00195}00195\ \ \ \ \ average\_weights\ =\ np.zeros(X.shape[1])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00196}00196\ \ \ \ \ intercept\ =\ intercept\_init}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00197}00197\ \ \ \ \ average\_intercept\ =\ 0.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00198}00198\ \ \ \ \ decay\ =\ 1.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00199}00199\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00200}00200\ \ \ \ \ \textcolor{comment}{\#\ sparse\ data\ has\ a\ fixed\ decay\ of\ .01}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00201}00201\ \ \ \ \ \textcolor{keywordflow}{if}\ klass\ \textcolor{keywordflow}{in}\ (SparseSGDClassifier,\ SparseSGDRegressor):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00202}00202\ \ \ \ \ \ \ \ \ decay\ =\ 0.01}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00203}00203\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00204}00204\ \ \ \ \ \textcolor{keywordflow}{for}\ i,\ entry\ \textcolor{keywordflow}{in}\ enumerate(X):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00205}00205\ \ \ \ \ \ \ \ \ p\ =\ np.dot(entry,\ weights)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00206}00206\ \ \ \ \ \ \ \ \ p\ +=\ intercept}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00207}00207\ \ \ \ \ \ \ \ \ gradient\ =\ p\ -\/\ y[i]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00208}00208\ \ \ \ \ \ \ \ \ weights\ *=\ 1.0\ -\/\ (eta\ *\ alpha)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00209}00209\ \ \ \ \ \ \ \ \ weights\ +=\ -\/(eta\ *\ gradient\ *\ entry)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00210}00210\ \ \ \ \ \ \ \ \ intercept\ +=\ -\/(eta\ *\ gradient)\ *\ decay}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00211}00211\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00212}00212\ \ \ \ \ \ \ \ \ average\_weights\ *=\ i}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00213}00213\ \ \ \ \ \ \ \ \ average\_weights\ +=\ weights}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00214}00214\ \ \ \ \ \ \ \ \ average\_weights\ /=\ i\ +\ 1.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00215}00215\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00216}00216\ \ \ \ \ \ \ \ \ average\_intercept\ *=\ i}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00217}00217\ \ \ \ \ \ \ \ \ average\_intercept\ +=\ intercept}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00218}00218\ \ \ \ \ \ \ \ \ average\_intercept\ /=\ i\ +\ 1.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00219}00219\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00220}00220\ \ \ \ \ \textcolor{keywordflow}{return}\ average\_weights,\ average\_intercept}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00221}00221\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00222}00222\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00223}00223\ \textcolor{keyword}{def\ }\_test\_warm\_start(klass,\ X,\ Y,\ lr):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00224}00224\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ explicit\ warm\ restart...}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00225}00225\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ eta0=0.01,\ shuffle=\textcolor{keyword}{False},\ learning\_rate=lr)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00226}00226\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00227}00227\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00228}00228\ \ \ \ \ clf2\ =\ klass(alpha=0.001,\ eta0=0.01,\ shuffle=\textcolor{keyword}{False},\ learning\_rate=lr)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00229}00229\ \ \ \ \ clf2.fit(X,\ Y,\ coef\_init=clf.coef\_.copy(),\ intercept\_init=clf.intercept\_.copy())}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00230}00230\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00231}00231\ \ \ \ \ \textcolor{comment}{\#\ ...\ and\ implicit\ warm\ restart\ are\ equivalent.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00232}00232\ \ \ \ \ clf3\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00233}00233\ \ \ \ \ \ \ \ \ alpha=0.01,\ eta0=0.01,\ shuffle=\textcolor{keyword}{False},\ warm\_start=\textcolor{keyword}{True},\ learning\_rate=lr}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00234}00234\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00235}00235\ \ \ \ \ clf3.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00236}00236\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00237}00237\ \ \ \ \ \textcolor{keyword}{assert}\ clf3.t\_\ ==\ clf.t\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00238}00238\ \ \ \ \ assert\_array\_almost\_equal(clf3.coef\_,\ clf.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00239}00239\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00240}00240\ \ \ \ \ clf3.set\_params(alpha=0.001)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00241}00241\ \ \ \ \ clf3.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00242}00242\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00243}00243\ \ \ \ \ \textcolor{keyword}{assert}\ clf3.t\_\ ==\ clf2.t\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00244}00244\ \ \ \ \ assert\_array\_almost\_equal(clf3.coef\_,\ clf2.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00245}00245\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00246}00246\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00247}00247\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00248}00248\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00249}00249\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00250}00250\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}lr"{},\ ["{}constant"{},\ "{}optimal"{},\ "{}invscaling"{},\ "{}adaptive"{}])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00251}00251\ \textcolor{keyword}{def\ }test\_warm\_start(klass,\ lr):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00252}00252\ \ \ \ \ \_test\_warm\_start(klass,\ X,\ Y,\ lr)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00253}00253\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00254}00254\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00255}00255\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00256}00256\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00257}00257\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00258}00258\ \textcolor{keyword}{def\ }test\_input\_format(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00259}00259\ \ \ \ \ \textcolor{comment}{\#\ Input\ format\ tests.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00260}00260\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ shuffle=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00261}00261\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00262}00262\ \ \ \ \ Y\_\ =\ np.array(Y)[:,\ np.newaxis]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00263}00263\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00264}00264\ \ \ \ \ Y\_\ =\ np.c\_[Y\_,\ Y\_]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00265}00265\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00266}00266\ \ \ \ \ \ \ \ \ clf.fit(X,\ Y\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00267}00267\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00268}00268\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00269}00269\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00270}00270\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00271}00271\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00272}00272\ \textcolor{keyword}{def\ }test\_clone(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00273}00273\ \ \ \ \ \textcolor{comment}{\#\ Test\ whether\ clone\ works\ ok.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00274}00274\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ penalty=\textcolor{stringliteral}{"{}l1"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00275}00275\ \ \ \ \ clf\ =\ clone(clf)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00276}00276\ \ \ \ \ clf.set\_params(penalty=\textcolor{stringliteral}{"{}l2"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00277}00277\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00278}00278\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00279}00279\ \ \ \ \ clf2\ =\ klass(alpha=0.01,\ penalty=\textcolor{stringliteral}{"{}l2"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00280}00280\ \ \ \ \ clf2.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00281}00281\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00282}00282\ \ \ \ \ assert\_array\_equal(clf.coef\_,\ clf2.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00283}00283\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00284}00284\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00285}00285\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00286}00286\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00287}00287\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00288}00288\ \ \ \ \ \ \ \ \ SGDClassifier,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00289}00289\ \ \ \ \ \ \ \ \ SparseSGDClassifier,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00290}00290\ \ \ \ \ \ \ \ \ SGDRegressor,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00291}00291\ \ \ \ \ \ \ \ \ SparseSGDRegressor,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00292}00292\ \ \ \ \ \ \ \ \ SGDOneClassSVM,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00293}00293\ \ \ \ \ \ \ \ \ SparseSGDOneClassSVM,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00294}00294\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00295}00295\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00296}00296\ \textcolor{keyword}{def\ }test\_plain\_has\_no\_average\_attr(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00297}00297\ \ \ \ \ clf\ =\ klass(average=\textcolor{keyword}{True},\ eta0=0.01)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00298}00298\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00299}00299\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00300}00300\ \ \ \ \ \textcolor{keyword}{assert}\ hasattr(clf,\ \textcolor{stringliteral}{"{}\_average\_coef"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00301}00301\ \ \ \ \ \textcolor{keyword}{assert}\ hasattr(clf,\ \textcolor{stringliteral}{"{}\_average\_intercept"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00302}00302\ \ \ \ \ \textcolor{keyword}{assert}\ hasattr(clf,\ \textcolor{stringliteral}{"{}\_standard\_intercept"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00303}00303\ \ \ \ \ \textcolor{keyword}{assert}\ hasattr(clf,\ \textcolor{stringliteral}{"{}\_standard\_coef"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00304}00304\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00305}00305\ \ \ \ \ clf\ =\ klass()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00306}00306\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00307}00307\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00308}00308\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ hasattr(clf,\ \textcolor{stringliteral}{"{}\_average\_coef"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00309}00309\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ hasattr(clf,\ \textcolor{stringliteral}{"{}\_average\_intercept"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00310}00310\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ hasattr(clf,\ \textcolor{stringliteral}{"{}\_standard\_intercept"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00311}00311\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ hasattr(clf,\ \textcolor{stringliteral}{"{}\_standard\_coef"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00312}00312\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00313}00313\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00314}00314\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00315}00315\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00316}00316\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00317}00317\ \ \ \ \ \ \ \ \ SGDClassifier,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00318}00318\ \ \ \ \ \ \ \ \ SparseSGDClassifier,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00319}00319\ \ \ \ \ \ \ \ \ SGDRegressor,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00320}00320\ \ \ \ \ \ \ \ \ SparseSGDRegressor,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00321}00321\ \ \ \ \ \ \ \ \ SGDOneClassSVM,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00322}00322\ \ \ \ \ \ \ \ \ SparseSGDOneClassSVM,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00323}00323\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00324}00324\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00325}00325\ \textcolor{keyword}{def\ }test\_late\_onset\_averaging\_not\_reached(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00326}00326\ \ \ \ \ clf1\ =\ klass(average=600)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00327}00327\ \ \ \ \ clf2\ =\ klass()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00328}00328\ \ \ \ \ \textcolor{keywordflow}{for}\ \_\ \textcolor{keywordflow}{in}\ range(100):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00329}00329\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ is\_classifier(clf1):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00330}00330\ \ \ \ \ \ \ \ \ \ \ \ \ clf1.partial\_fit(X,\ Y,\ classes=np.unique(Y))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00331}00331\ \ \ \ \ \ \ \ \ \ \ \ \ clf2.partial\_fit(X,\ Y,\ classes=np.unique(Y))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00332}00332\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00333}00333\ \ \ \ \ \ \ \ \ \ \ \ \ clf1.partial\_fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00334}00334\ \ \ \ \ \ \ \ \ \ \ \ \ clf2.partial\_fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00335}00335\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00336}00336\ \ \ \ \ assert\_array\_almost\_equal(clf1.coef\_,\ clf2.coef\_,\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00337}00337\ \ \ \ \ \textcolor{keywordflow}{if}\ klass\ \textcolor{keywordflow}{in}\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00338}00338\ \ \ \ \ \ \ \ \ assert\_almost\_equal(clf1.intercept\_,\ clf2.intercept\_,\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00339}00339\ \ \ \ \ \textcolor{keywordflow}{elif}\ klass\ \textcolor{keywordflow}{in}\ [SGDOneClassSVM,\ SparseSGDOneClassSVM]:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00340}00340\ \ \ \ \ \ \ \ \ assert\_allclose(clf1.offset\_,\ clf2.offset\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00341}00341\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00342}00342\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00343}00343\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00344}00344\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00345}00345\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00346}00346\ \textcolor{keyword}{def\ }test\_late\_onset\_averaging\_reached(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00347}00347\ \ \ \ \ eta0\ =\ 0.001}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00348}00348\ \ \ \ \ alpha\ =\ 0.0001}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00349}00349\ \ \ \ \ Y\_encode\ =\ np.array(Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00350}00350\ \ \ \ \ Y\_encode[Y\_encode\ ==\ 1]\ =\ -\/1.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00351}00351\ \ \ \ \ Y\_encode[Y\_encode\ ==\ 2]\ =\ 1.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00352}00352\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00353}00353\ \ \ \ \ clf1\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00354}00354\ \ \ \ \ \ \ \ \ average=7,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00355}00355\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00356}00356\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00357}00357\ \ \ \ \ \ \ \ \ eta0=eta0,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00358}00358\ \ \ \ \ \ \ \ \ alpha=alpha,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00359}00359\ \ \ \ \ \ \ \ \ max\_iter=2,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00360}00360\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00361}00361\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00362}00362\ \ \ \ \ clf2\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00363}00363\ \ \ \ \ \ \ \ \ average=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00364}00364\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00365}00365\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00366}00366\ \ \ \ \ \ \ \ \ eta0=eta0,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00367}00367\ \ \ \ \ \ \ \ \ alpha=alpha,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00368}00368\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00369}00369\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00370}00370\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00371}00371\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00372}00372\ \ \ \ \ clf1.fit(X,\ Y\_encode)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00373}00373\ \ \ \ \ clf2.fit(X,\ Y\_encode)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00374}00374\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00375}00375\ \ \ \ \ average\_weights,\ average\_intercept\ =\ \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_ab20ec7534385a6c109edac521ab20fb4}{asgd}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00376}00376\ \ \ \ \ \ \ \ \ klass,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00377}00377\ \ \ \ \ \ \ \ \ X,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00378}00378\ \ \ \ \ \ \ \ \ Y\_encode,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00379}00379\ \ \ \ \ \ \ \ \ eta0,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00380}00380\ \ \ \ \ \ \ \ \ alpha,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00381}00381\ \ \ \ \ \ \ \ \ weight\_init=clf2.coef\_.ravel(),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00382}00382\ \ \ \ \ \ \ \ \ intercept\_init=clf2.intercept\_,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00383}00383\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00384}00384\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00385}00385\ \ \ \ \ assert\_array\_almost\_equal(clf1.coef\_.ravel(),\ average\_weights.ravel(),\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00386}00386\ \ \ \ \ assert\_almost\_equal(clf1.intercept\_,\ average\_intercept,\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00387}00387\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00388}00388\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00389}00389\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00390}00390\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00391}00391\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00392}00392\ \textcolor{keyword}{def\ }test\_early\_stopping(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00393}00393\ \ \ \ \ X\ =\ iris.data[iris.target\ >\ 0]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00394}00394\ \ \ \ \ Y\ =\ iris.target[iris.target\ >\ 0]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00395}00395\ \ \ \ \ \textcolor{keywordflow}{for}\ early\_stopping\ \textcolor{keywordflow}{in}\ [\textcolor{keyword}{True},\ \textcolor{keyword}{False}]:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00396}00396\ \ \ \ \ \ \ \ \ max\_iter\ =\ 1000}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00397}00397\ \ \ \ \ \ \ \ \ clf\ =\ klass(early\_stopping=early\_stopping,\ tol=1e-\/3,\ max\_iter=max\_iter).fit(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00398}00398\ \ \ \ \ \ \ \ \ \ \ \ \ X,\ Y}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00399}00399\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00400}00400\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ clf.n\_iter\_\ <\ max\_iter}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00401}00401\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00402}00402\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00403}00403\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00404}00404\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00405}00405\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00406}00406\ \textcolor{keyword}{def\ }test\_adaptive\_longer\_than\_constant(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00407}00407\ \ \ \ \ clf1\ =\ klass(learning\_rate=\textcolor{stringliteral}{"{}adaptive"{}},\ eta0=0.01,\ tol=1e-\/3,\ max\_iter=100)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00408}00408\ \ \ \ \ clf1.fit(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00409}00409\ \ \ \ \ clf2\ =\ klass(learning\_rate=\textcolor{stringliteral}{"{}constant"{}},\ eta0=0.01,\ tol=1e-\/3,\ max\_iter=100)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00410}00410\ \ \ \ \ clf2.fit(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00411}00411\ \ \ \ \ \textcolor{keyword}{assert}\ clf1.n\_iter\_\ >\ clf2.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00412}00412\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00413}00413\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00414}00414\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00415}00415\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00416}00416\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00417}00417\ \textcolor{keyword}{def\ }test\_validation\_set\_not\_used\_for\_training(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00418}00418\ \ \ \ \ X,\ Y\ =\ iris.data,\ iris.target}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00419}00419\ \ \ \ \ validation\_fraction\ =\ 0.4}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00420}00420\ \ \ \ \ seed\ =\ 42}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00421}00421\ \ \ \ \ shuffle\ =\ \textcolor{keyword}{False}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00422}00422\ \ \ \ \ max\_iter\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00423}00423\ \ \ \ \ clf1\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00424}00424\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00425}00425\ \ \ \ \ \ \ \ \ random\_state=np.random.RandomState(seed),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00426}00426\ \ \ \ \ \ \ \ \ validation\_fraction=validation\_fraction,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00427}00427\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00428}00428\ \ \ \ \ \ \ \ \ eta0=0.01,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00429}00429\ \ \ \ \ \ \ \ \ tol=\textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00430}00430\ \ \ \ \ \ \ \ \ max\_iter=max\_iter,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00431}00431\ \ \ \ \ \ \ \ \ shuffle=shuffle,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00432}00432\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00433}00433\ \ \ \ \ clf1.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00434}00434\ \ \ \ \ \textcolor{keyword}{assert}\ clf1.n\_iter\_\ ==\ max\_iter}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00435}00435\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00436}00436\ \ \ \ \ clf2\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00437}00437\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00438}00438\ \ \ \ \ \ \ \ \ random\_state=np.random.RandomState(seed),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00439}00439\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00440}00440\ \ \ \ \ \ \ \ \ eta0=0.01,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00441}00441\ \ \ \ \ \ \ \ \ tol=\textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00442}00442\ \ \ \ \ \ \ \ \ max\_iter=max\_iter,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00443}00443\ \ \ \ \ \ \ \ \ shuffle=shuffle,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00444}00444\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00445}00445\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00446}00446\ \ \ \ \ \textcolor{keywordflow}{if}\ is\_classifier(clf2):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00447}00447\ \ \ \ \ \ \ \ \ cv\ =\ \mbox{\hyperlink{classsklearn_1_1model__selection_1_1__split_1_1StratifiedShuffleSplit}{StratifiedShuffleSplit}}(test\_size=validation\_fraction,\ random\_state=seed)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00448}00448\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00449}00449\ \ \ \ \ \ \ \ \ cv\ =\ \mbox{\hyperlink{classsklearn_1_1model__selection_1_1__split_1_1ShuffleSplit}{ShuffleSplit}}(test\_size=validation\_fraction,\ random\_state=seed)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00450}00450\ \ \ \ \ idx\_train,\ idx\_val\ =\ next(cv.split(X,\ Y))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00451}00451\ \ \ \ \ idx\_train\ =\ np.sort(idx\_train)\ \ \textcolor{comment}{\#\ remove\ shuffling}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00452}00452\ \ \ \ \ clf2.fit(X[idx\_train],\ Y[idx\_train])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00453}00453\ \ \ \ \ \textcolor{keyword}{assert}\ clf2.n\_iter\_\ ==\ max\_iter}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00454}00454\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00455}00455\ \ \ \ \ assert\_array\_equal(clf1.coef\_,\ clf2.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00456}00456\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00457}00457\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00458}00458\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00459}00459\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00460}00460\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00461}00461\ \textcolor{keyword}{def\ }test\_n\_iter\_no\_change(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00462}00462\ \ \ \ \ X,\ Y\ =\ iris.data,\ iris.target}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00463}00463\ \ \ \ \ \textcolor{comment}{\#\ test\ that\ n\_iter\_\ increases\ monotonically\ with\ n\_iter\_no\_change}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00464}00464\ \ \ \ \ \textcolor{keywordflow}{for}\ early\_stopping\ \textcolor{keywordflow}{in}\ [\textcolor{keyword}{True},\ \textcolor{keyword}{False}]:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00465}00465\ \ \ \ \ \ \ \ \ n\_iter\_list\ =\ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00466}00466\ \ \ \ \ \ \ \ \ \ \ \ \ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00467}00467\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ early\_stopping=early\_stopping,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00468}00468\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n\_iter\_no\_change=n\_iter\_no\_change,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00469}00469\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ tol=1e-\/4,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00470}00470\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=1000,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00471}00471\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00472}00472\ \ \ \ \ \ \ \ \ \ \ \ \ .fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00473}00473\ \ \ \ \ \ \ \ \ \ \ \ \ .n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00474}00474\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ n\_iter\_no\_change\ \textcolor{keywordflow}{in}\ [2,\ 3,\ 10]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00475}00475\ \ \ \ \ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00476}00476\ \ \ \ \ \ \ \ \ assert\_array\_equal(n\_iter\_list,\ sorted(n\_iter\_list))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00477}00477\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00478}00478\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00479}00479\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00480}00480\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00481}00481\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00482}00482\ \textcolor{keyword}{def\ }test\_not\_enough\_sample\_for\_early\_stopping(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00483}00483\ \ \ \ \ \textcolor{comment}{\#\ test\ an\ error\ is\ raised\ if\ the\ training\ or\ validation\ set\ is\ empty}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00484}00484\ \ \ \ \ clf\ =\ klass(early\_stopping=\textcolor{keyword}{True},\ validation\_fraction=0.99)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00485}00485\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00486}00486\ \ \ \ \ \ \ \ \ clf.fit(X3,\ Y3)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00487}00487\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00488}00488\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00489}00489\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Estimator"{},\ [SGDClassifier,\ SGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00490}00490\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}l1\_ratio"{},\ [0,\ 0.7,\ 1])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00491}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a6e067e66d2136efcea2a549a5552b449}{00491}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a6e067e66d2136efcea2a549a5552b449}{test\_sgd\_l1\_ratio\_not\_used}}(Estimator,\ l1\_ratio):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00492}00492\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ l1\_ratio\ is\ not\ used\ when\ penalty\ is\ not\ 'elasticnet'"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00493}00493\ \ \ \ \ clf1\ =\ Estimator(penalty=\textcolor{stringliteral}{"{}l1"{}},\ l1\_ratio=\textcolor{keywordtype}{None},\ random\_state=0).fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00494}00494\ \ \ \ \ clf2\ =\ Estimator(penalty=\textcolor{stringliteral}{"{}l1"{}},\ l1\_ratio=l1\_ratio,\ random\_state=0).fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00495}00495\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00496}00496\ \ \ \ \ assert\_allclose(clf1.coef\_,\ clf2.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00497}00497\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00498}00498\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00499}00499\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00500}00500\ \ \ \ \ \textcolor{stringliteral}{"{}Estimator"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00501}00501\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00502}00502\ \textcolor{keyword}{def\ }test\_sgd\_failing\_penalty\_validation(Estimator):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00503}00503\ \ \ \ \ clf\ =\ Estimator(penalty=\textcolor{stringliteral}{"{}elasticnet"{}},\ l1\_ratio=\textcolor{keywordtype}{None})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00504}00504\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00505}00505\ \ \ \ \ \ \ \ \ ValueError,\ match=\textcolor{stringliteral}{"{}l1\_ratio\ must\ be\ set\ when\ penalty\ is\ 'elasticnet'"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00506}00506\ \ \ \ \ ):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00507}00507\ \ \ \ \ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00508}00508\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00509}00509\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00510}00510\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00512}00512\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00513}00513\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00514}00514\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00515}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_aeaa8fd93db051060abd0f6c270b08ed3}{00515}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_aeaa8fd93db051060abd0f6c270b08ed3}{test\_sgd\_clf}}(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00516}00516\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ SGD\ gives\ any\ results\ :-\/)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00517}00517\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00518}00518\ \ \ \ \ \textcolor{keywordflow}{for}\ loss\ \textcolor{keywordflow}{in}\ (\textcolor{stringliteral}{"{}hinge"{}},\ \textcolor{stringliteral}{"{}squared\_hinge"{}},\ \textcolor{stringliteral}{"{}log\_loss"{}},\ \textcolor{stringliteral}{"{}modified\_huber"{}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00519}00519\ \ \ \ \ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00520}00520\ \ \ \ \ \ \ \ \ \ \ \ \ penalty=\textcolor{stringliteral}{"{}l2"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00521}00521\ \ \ \ \ \ \ \ \ \ \ \ \ alpha=0.01,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00522}00522\ \ \ \ \ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00523}00523\ \ \ \ \ \ \ \ \ \ \ \ \ loss=loss,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00524}00524\ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=10,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00525}00525\ \ \ \ \ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00526}00526\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00527}00527\ \ \ \ \ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00528}00528\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ assert\_almost\_equal(clf.coef\_[0],\ clf.coef\_[1],\ decimal=7)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00529}00529\ \ \ \ \ \ \ \ \ assert\_array\_equal(clf.predict(T),\ true\_result)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00530}00530\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00531}00531\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00532}00532\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00533}00533\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDOneClassSVM,\ SparseSGDOneClassSVM]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00534}00534\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00535}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a7a21ff87b3ebaa0820f1b07a27bd2634}{00535}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a7a21ff87b3ebaa0820f1b07a27bd2634}{test\_provide\_coef}}(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00536}00536\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ the\ shape\ of\ \`{}coef\_init\`{}\ is\ validated."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00537}00537\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=\textcolor{stringliteral}{"{}Provided\ coef\_init\ does\ not\ match\ dataset"{}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00538}00538\ \ \ \ \ \ \ \ \ klass().fit(X,\ Y,\ coef\_init=np.zeros((3,)))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00539}00539\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00540}00540\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00541}00541\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00542}00542\ \ \ \ \ \textcolor{stringliteral}{"{}klass,\ fit\_params"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00543}00543\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00544}00544\ \ \ \ \ \ \ \ \ (SGDClassifier,\ \{\textcolor{stringliteral}{"{}intercept\_init"{}}:\ np.zeros((3,))\}),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00545}00545\ \ \ \ \ \ \ \ \ (SparseSGDClassifier,\ \{\textcolor{stringliteral}{"{}intercept\_init"{}}:\ np.zeros((3,))\}),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00546}00546\ \ \ \ \ \ \ \ \ (SGDOneClassSVM,\ \{\textcolor{stringliteral}{"{}offset\_init"{}}:\ np.zeros((3,))\}),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00547}00547\ \ \ \ \ \ \ \ \ (SparseSGDOneClassSVM,\ \{\textcolor{stringliteral}{"{}offset\_init"{}}:\ np.zeros((3,))\}),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00548}00548\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00549}00549\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00550}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a76bb64bebf3f2d0f909ca16d81735b6c}{00550}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a76bb64bebf3f2d0f909ca16d81735b6c}{test\_set\_intercept\_offset}}(klass,\ fit\_params):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00551}00551\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ \`{}intercept\_init\`{}\ or\ \`{}offset\_init\`{}\ is\ validated."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00552}00552\ \ \ \ \ sgd\_estimator\ =\ klass()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00553}00553\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=\textcolor{stringliteral}{"{}does\ not\ match\ dataset"{}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00554}00554\ \ \ \ \ \ \ \ \ sgd\_estimator.fit(X,\ Y,\ **fit\_params)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00555}00555\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00556}00556\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00557}00557\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00558}00558\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDRegressor,\ SparseSGDRegressor]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00559}00559\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00560}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a591851071d4826962b6d554303b53870}{00560}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a591851071d4826962b6d554303b53870}{test\_sgd\_early\_stopping\_with\_partial\_fit}}(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00561}00561\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ we\ raise\ an\ error\ for\ \`{}early\_stopping\`{}\ used\ with}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00562}00562\ \textcolor{stringliteral}{\ \ \ \ \`{}partial\_fit\`{}.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00563}00563\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00564}00564\ \ \ \ \ err\_msg\ =\ \textcolor{stringliteral}{"{}early\_stopping\ should\ be\ False\ with\ partial\_fit"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00565}00565\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=err\_msg):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00566}00566\ \ \ \ \ \ \ \ \ klass(early\_stopping=\textcolor{keyword}{True}).partial\_fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00567}00567\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00568}00568\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00569}00569\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00570}00570\ \ \ \ \ \textcolor{stringliteral}{"{}klass,\ fit\_params"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00571}00571\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00572}00572\ \ \ \ \ \ \ \ \ (SGDClassifier,\ \{\textcolor{stringliteral}{"{}intercept\_init"{}}:\ 0\}),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00573}00573\ \ \ \ \ \ \ \ \ (SparseSGDClassifier,\ \{\textcolor{stringliteral}{"{}intercept\_init"{}}:\ 0\}),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00574}00574\ \ \ \ \ \ \ \ \ (SGDOneClassSVM,\ \{\textcolor{stringliteral}{"{}offset\_init"{}}:\ 0\}),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00575}00575\ \ \ \ \ \ \ \ \ (SparseSGDOneClassSVM,\ \{\textcolor{stringliteral}{"{}offset\_init"{}}:\ 0\}),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00576}00576\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00577}00577\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00578}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a2a5110c3c96df109ef8bfc3dc735a644}{00578}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a2a5110c3c96df109ef8bfc3dc735a644}{test\_set\_intercept\_offset\_binary}}(klass,\ fit\_params):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00579}00579\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ we\ can\ pass\ a\ scaler\ with\ binary\ classification\ to}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00580}00580\ \textcolor{stringliteral}{\ \ \ \ \`{}intercept\_init\`{}\ or\ \`{}offset\_init\`{}."{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00581}00581\ \ \ \ \ klass().fit(X5,\ Y5,\ **fit\_params)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00582}00582\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00583}00583\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00584}00584\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00585}00585\ \textcolor{keyword}{def\ }test\_average\_binary\_computed\_correctly(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00586}00586\ \ \ \ \ \textcolor{comment}{\#\ Checks\ the\ SGDClassifier\ correctly\ computes\ the\ average\ weights}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00587}00587\ \ \ \ \ eta\ =\ 0.1}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00588}00588\ \ \ \ \ alpha\ =\ 2.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00589}00589\ \ \ \ \ n\_samples\ =\ 20}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00590}00590\ \ \ \ \ n\_features\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00591}00591\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00592}00592\ \ \ \ \ X\ =\ rng.normal(size=(n\_samples,\ n\_features))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00593}00593\ \ \ \ \ w\ =\ rng.normal(size=n\_features)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00594}00594\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00595}00595\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00596}00596\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00597}00597\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00598}00598\ \ \ \ \ \ \ \ \ eta0=eta,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00599}00599\ \ \ \ \ \ \ \ \ alpha=alpha,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00600}00600\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00601}00601\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00602}00602\ \ \ \ \ \ \ \ \ average=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00603}00603\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00604}00604\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00605}00605\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00606}00606\ \ \ \ \ \textcolor{comment}{\#\ simple\ linear\ function\ without\ noise}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00607}00607\ \ \ \ \ y\ =\ np.dot(X,\ w)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00608}00608\ \ \ \ \ y\ =\ np.sign(y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00609}00609\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00610}00610\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00611}00611\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00612}00612\ \ \ \ \ average\_weights,\ average\_intercept\ =\ \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_ab20ec7534385a6c109edac521ab20fb4}{asgd}}(klass,\ X,\ y,\ eta,\ alpha)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00613}00613\ \ \ \ \ average\_weights\ =\ average\_weights.reshape(1,\ -\/1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00614}00614\ \ \ \ \ assert\_array\_almost\_equal(clf.coef\_,\ average\_weights,\ decimal=14)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00615}00615\ \ \ \ \ assert\_almost\_equal(clf.intercept\_,\ average\_intercept,\ decimal=14)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00616}00616\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00617}00617\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00618}00618\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00619}00619\ \textcolor{keyword}{def\ }test\_set\_intercept\_to\_intercept(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00620}00620\ \ \ \ \ \textcolor{comment}{\#\ Checks\ intercept\_\ shape\ consistency\ for\ the\ warm\ starts}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00621}00621\ \ \ \ \ \textcolor{comment}{\#\ Inconsistent\ intercept\_\ shape.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00622}00622\ \ \ \ \ clf\ =\ klass().fit(X5,\ Y5)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00623}00623\ \ \ \ \ klass().fit(X5,\ Y5,\ intercept\_init=clf.intercept\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00624}00624\ \ \ \ \ clf\ =\ klass().fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00625}00625\ \ \ \ \ klass().fit(X,\ Y,\ intercept\_init=clf.intercept\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00626}00626\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00627}00627\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00628}00628\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00629}00629\ \textcolor{keyword}{def\ }test\_sgd\_at\_least\_two\_labels(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00630}00630\ \ \ \ \ \textcolor{comment}{\#\ Target\ must\ have\ at\ least\ two\ labels}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00631}00631\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ max\_iter=20)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00632}00632\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00633}00633\ \ \ \ \ \ \ \ \ clf.fit(X2,\ np.ones(9))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00634}00634\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00635}00635\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00636}00636\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00637}00637\ \textcolor{keyword}{def\ }test\_partial\_fit\_weight\_class\_balanced(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00638}00638\ \ \ \ \ \textcolor{comment}{\#\ partial\_fit\ with\ class\_weight='balanced'\ not\ supported"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00639}00639\ \ \ \ \ regex\ =\ (}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00640}00640\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}class\_weight\ 'balanced'\ is\ not\ supported\ for\ "{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00641}00641\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}partial\_fit\(\backslash\).\ In\ order\ to\ use\ 'balanced'\ weights,\ "{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00642}00642\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}use\ compute\_class\_weight\(\backslash\)('balanced',\ classes=classes,\ y=y\(\backslash\)).\ "{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00643}00643\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}In\ place\ of\ y\ you\ can\ use\ a\ large\ enough\ sample\ "{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00644}00644\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}of\ the\ full\ training\ set\ target\ to\ properly\ "{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00645}00645\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}estimate\ the\ class\ frequency\ distributions\(\backslash\).\ "{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00646}00646\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}Pass\ the\ resulting\ weights\ as\ the\ class\_weight\ "{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00647}00647\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}parameter\(\backslash\)."{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00648}00648\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00649}00649\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=regex):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00650}00650\ \ \ \ \ \ \ \ \ klass(class\_weight=\textcolor{stringliteral}{"{}balanced"{}}).partial\_fit(X,\ Y,\ classes=np.unique(Y))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00651}00651\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00652}00652\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00653}00653\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00654}00654\ \textcolor{keyword}{def\ }test\_sgd\_multiclass(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00655}00655\ \ \ \ \ \textcolor{comment}{\#\ Multi-\/class\ test\ case}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00656}00656\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ max\_iter=20).fit(X2,\ Y2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00657}00657\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_.shape\ ==\ (3,\ 2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00658}00658\ \ \ \ \ \textcolor{keyword}{assert}\ clf.intercept\_.shape\ ==\ (3,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00659}00659\ \ \ \ \ \textcolor{keyword}{assert}\ clf.decision\_function([[0,\ 0]]).shape\ ==\ (1,\ 3)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00660}00660\ \ \ \ \ pred\ =\ clf.predict(T2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00661}00661\ \ \ \ \ assert\_array\_equal(pred,\ true\_result2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00662}00662\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00663}00663\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00664}00664\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00665}00665\ \textcolor{keyword}{def\ }test\_sgd\_multiclass\_average(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00666}00666\ \ \ \ \ eta\ =\ 0.001}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00667}00667\ \ \ \ \ alpha\ =\ 0.01}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00668}00668\ \ \ \ \ \textcolor{comment}{\#\ Multi-\/class\ average\ test\ case}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00669}00669\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00670}00670\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00671}00671\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00672}00672\ \ \ \ \ \ \ \ \ eta0=eta,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00673}00673\ \ \ \ \ \ \ \ \ alpha=alpha,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00674}00674\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00675}00675\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00676}00676\ \ \ \ \ \ \ \ \ average=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00677}00677\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00678}00678\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00679}00679\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00680}00680\ \ \ \ \ np\_Y2\ =\ np.array(Y2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00681}00681\ \ \ \ \ clf.fit(X2,\ np\_Y2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00682}00682\ \ \ \ \ classes\ =\ np.unique(np\_Y2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00683}00683\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00684}00684\ \ \ \ \ \textcolor{keywordflow}{for}\ i,\ cl\ \textcolor{keywordflow}{in}\ enumerate(classes):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00685}00685\ \ \ \ \ \ \ \ \ y\_i\ =\ np.ones(np\_Y2.shape[0])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00686}00686\ \ \ \ \ \ \ \ \ y\_i[np\_Y2\ !=\ cl]\ =\ -\/1}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00687}00687\ \ \ \ \ \ \ \ \ average\_coef,\ average\_intercept\ =\ \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_ab20ec7534385a6c109edac521ab20fb4}{asgd}}(klass,\ X2,\ y\_i,\ eta,\ alpha)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00688}00688\ \ \ \ \ \ \ \ \ assert\_array\_almost\_equal(average\_coef,\ clf.coef\_[i],\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00689}00689\ \ \ \ \ \ \ \ \ assert\_almost\_equal(average\_intercept,\ clf.intercept\_[i],\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00690}00690\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00691}00691\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00692}00692\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00693}00693\ \textcolor{keyword}{def\ }test\_sgd\_multiclass\_with\_init\_coef(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00694}00694\ \ \ \ \ \textcolor{comment}{\#\ Multi-\/class\ test\ case}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00695}00695\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ max\_iter=20)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00696}00696\ \ \ \ \ clf.fit(X2,\ Y2,\ coef\_init=np.zeros((3,\ 2)),\ intercept\_init=np.zeros(3))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00697}00697\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_.shape\ ==\ (3,\ 2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00698}00698\ \ \ \ \ \textcolor{keyword}{assert}\ clf.intercept\_.shape,\ (3,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00699}00699\ \ \ \ \ pred\ =\ clf.predict(T2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00700}00700\ \ \ \ \ assert\_array\_equal(pred,\ true\_result2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00701}00701\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00702}00702\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00703}00703\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00704}00704\ \textcolor{keyword}{def\ }test\_sgd\_multiclass\_njobs(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00705}00705\ \ \ \ \ \textcolor{comment}{\#\ Multi-\/class\ test\ case\ with\ multi-\/core\ support}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00706}00706\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ max\_iter=20,\ n\_jobs=2).fit(X2,\ Y2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00707}00707\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_.shape\ ==\ (3,\ 2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00708}00708\ \ \ \ \ \textcolor{keyword}{assert}\ clf.intercept\_.shape\ ==\ (3,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00709}00709\ \ \ \ \ \textcolor{keyword}{assert}\ clf.decision\_function([[0,\ 0]]).shape\ ==\ (1,\ 3)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00710}00710\ \ \ \ \ pred\ =\ clf.predict(T2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00711}00711\ \ \ \ \ assert\_array\_equal(pred,\ true\_result2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00712}00712\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00713}00713\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00714}00714\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00715}00715\ \textcolor{keyword}{def\ }test\_set\_coef\_multiclass(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00716}00716\ \ \ \ \ \textcolor{comment}{\#\ Checks\ coef\_init\ and\ intercept\_init\ shape\ for\ multi-\/class}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00717}00717\ \ \ \ \ \textcolor{comment}{\#\ problems}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00718}00718\ \ \ \ \ \textcolor{comment}{\#\ Provided\ coef\_\ does\ not\ match\ dataset}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00719}00719\ \ \ \ \ clf\ =\ klass()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00720}00720\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00721}00721\ \ \ \ \ \ \ \ \ clf.fit(X2,\ Y2,\ coef\_init=np.zeros((2,\ 2)))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00722}00722\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00723}00723\ \ \ \ \ \textcolor{comment}{\#\ Provided\ coef\_\ does\ match\ dataset}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00724}00724\ \ \ \ \ clf\ =\ klass().fit(X2,\ Y2,\ coef\_init=np.zeros((3,\ 2)))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00725}00725\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00726}00726\ \ \ \ \ \textcolor{comment}{\#\ Provided\ intercept\_\ does\ not\ match\ dataset}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00727}00727\ \ \ \ \ clf\ =\ klass()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00728}00728\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00729}00729\ \ \ \ \ \ \ \ \ clf.fit(X2,\ Y2,\ intercept\_init=np.zeros((1,)))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00730}00730\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00731}00731\ \ \ \ \ \textcolor{comment}{\#\ Provided\ intercept\_\ does\ match\ dataset.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00732}00732\ \ \ \ \ clf\ =\ klass().fit(X2,\ Y2,\ intercept\_init=np.zeros((3,)))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00733}00733\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00734}00734\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00735}00735\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00736}00736\ \textcolor{keyword}{def\ }test\_sgd\_predict\_proba\_method\_access(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00737}00737\ \ \ \ \ \textcolor{comment}{\#\ Checks\ that\ SGDClassifier\ predict\_proba\ and\ predict\_log\_proba\ methods}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00738}00738\ \ \ \ \ \textcolor{comment}{\#\ can\ either\ be\ accessed\ or\ raise\ an\ appropriate\ error\ message}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00739}00739\ \ \ \ \ \textcolor{comment}{\#\ otherwise.\ See}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00740}00740\ \ \ \ \ \textcolor{comment}{\#\ https://github.com/scikit-\/learn/scikit-\/learn/issues/10938\ for\ more}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00741}00741\ \ \ \ \ \textcolor{comment}{\#\ details.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00742}00742\ \ \ \ \ \textcolor{keywordflow}{for}\ loss\ \textcolor{keywordflow}{in}\ linear\_model.SGDClassifier.loss\_functions:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00743}00743\ \ \ \ \ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(loss=loss)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00744}00744\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ loss\ \textcolor{keywordflow}{in}\ (\textcolor{stringliteral}{"{}log\_loss"{}},\ \textcolor{stringliteral}{"{}modified\_huber"{}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00745}00745\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ hasattr(clf,\ \textcolor{stringliteral}{"{}predict\_proba"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00746}00746\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ hasattr(clf,\ \textcolor{stringliteral}{"{}predict\_log\_proba"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00747}00747\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00748}00748\ \ \ \ \ \ \ \ \ \ \ \ \ inner\_msg\ =\ \textcolor{stringliteral}{"{}probability\ estimates\ are\ not\ available\ for\ loss=\{!r\}"{}}.format(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00749}00749\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ loss}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00750}00750\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00751}00751\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ hasattr(clf,\ \textcolor{stringliteral}{"{}predict\_proba"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00752}00752\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ hasattr(clf,\ \textcolor{stringliteral}{"{}predict\_log\_proba"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00753}00753\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00754}00754\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ AttributeError,\ match=\textcolor{stringliteral}{"{}has\ no\ attribute\ 'predict\_proba'"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00755}00755\ \ \ \ \ \ \ \ \ \ \ \ \ )\ \textcolor{keyword}{as}\ exec\_info:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00756}00756\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ clf.predict\_proba}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00757}00757\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00758}00758\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ isinstance(exec\_info.value.\_\_cause\_\_,\ AttributeError)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00759}00759\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ inner\_msg\ \textcolor{keywordflow}{in}\ str(exec\_info.value.\_\_cause\_\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00760}00760\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00761}00761\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00762}00762\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ AttributeError,\ match=\textcolor{stringliteral}{"{}has\ no\ attribute\ 'predict\_log\_proba'"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00763}00763\ \ \ \ \ \ \ \ \ \ \ \ \ )\ \textcolor{keyword}{as}\ exec\_info:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00764}00764\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ clf.predict\_log\_proba}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00765}00765\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ isinstance(exec\_info.value.\_\_cause\_\_,\ AttributeError)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00766}00766\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ inner\_msg\ \textcolor{keywordflow}{in}\ str(exec\_info.value.\_\_cause\_\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00767}00767\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00768}00768\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00769}00769\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00770}00770\ \textcolor{keyword}{def\ }test\_sgd\_proba(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00771}00771\ \ \ \ \ \textcolor{comment}{\#\ Check\ SGD.predict\_proba}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00772}00772\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00773}00773\ \ \ \ \ \textcolor{comment}{\#\ Hinge\ loss\ does\ not\ allow\ for\ conditional\ prob\ estimate.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00774}00774\ \ \ \ \ \textcolor{comment}{\#\ We\ cannot\ use\ the\ factory\ here,\ because\ it\ defines\ predict\_proba}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00775}00775\ \ \ \ \ \textcolor{comment}{\#\ anyway.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00776}00776\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(loss=\textcolor{stringliteral}{"{}hinge"{}},\ alpha=0.01,\ max\_iter=10,\ tol=\textcolor{keywordtype}{None}).fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00777}00777\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ hasattr(clf,\ \textcolor{stringliteral}{"{}predict\_proba"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00778}00778\ \ \ \ \ \textcolor{keyword}{assert}\ \textcolor{keywordflow}{not}\ hasattr(clf,\ \textcolor{stringliteral}{"{}predict\_log\_proba"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00779}00779\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00780}00780\ \ \ \ \ \textcolor{comment}{\#\ log\ and\ modified\_huber\ losses\ can\ output\ probability\ estimates}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00781}00781\ \ \ \ \ \textcolor{comment}{\#\ binary\ case}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00782}00782\ \ \ \ \ \textcolor{keywordflow}{for}\ loss\ \textcolor{keywordflow}{in}\ [\textcolor{stringliteral}{"{}log\_loss"{}},\ \textcolor{stringliteral}{"{}modified\_huber"{}}]:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00783}00783\ \ \ \ \ \ \ \ \ clf\ =\ klass(loss=loss,\ alpha=0.01,\ max\_iter=10)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00784}00784\ \ \ \ \ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00785}00785\ \ \ \ \ \ \ \ \ p\ =\ clf.predict\_proba([[3,\ 2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00786}00786\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ p[0,\ 1]\ >\ 0.5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00787}00787\ \ \ \ \ \ \ \ \ p\ =\ clf.predict\_proba([[-\/1,\ -\/1]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00788}00788\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ p[0,\ 1]\ <\ 0.5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00789}00789\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00790}00790\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ If\ predict\_proba\ is\ 0,\ we\ get\ "{}RuntimeWarning:\ divide\ by\ zero\ encountered}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00791}00791\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ in\ log"{}.\ We\ avoid\ it\ here.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00792}00792\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ np.errstate(divide=\textcolor{stringliteral}{"{}ignore"{}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00793}00793\ \ \ \ \ \ \ \ \ \ \ \ \ p\ =\ clf.predict\_log\_proba([[3,\ 2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00794}00794\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ p[0,\ 1]\ >\ p[0,\ 0]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00795}00795\ \ \ \ \ \ \ \ \ \ \ \ \ p\ =\ clf.predict\_log\_proba([[-\/1,\ -\/1]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00796}00796\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ p[0,\ 1]\ <\ p[0,\ 0]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00797}00797\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00798}00798\ \ \ \ \ \textcolor{comment}{\#\ log\ loss\ multiclass\ probability\ estimates}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00799}00799\ \ \ \ \ clf\ =\ klass(loss=\textcolor{stringliteral}{"{}log\_loss"{}},\ alpha=0.01,\ max\_iter=10).fit(X2,\ Y2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00800}00800\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00801}00801\ \ \ \ \ d\ =\ clf.decision\_function([[0.1,\ -\/0.1],\ [0.3,\ 0.2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00802}00802\ \ \ \ \ p\ =\ clf.predict\_proba([[0.1,\ -\/0.1],\ [0.3,\ 0.2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00803}00803\ \ \ \ \ assert\_array\_equal(np.argmax(p,\ axis=1),\ np.argmax(d,\ axis=1))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00804}00804\ \ \ \ \ assert\_almost\_equal(p[0].sum(),\ 1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00805}00805\ \ \ \ \ \textcolor{keyword}{assert}\ np.all(p[0]\ >=\ 0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00806}00806\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00807}00807\ \ \ \ \ p\ =\ clf.predict\_proba([[-\/1,\ -\/1]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00808}00808\ \ \ \ \ d\ =\ clf.decision\_function([[-\/1,\ -\/1]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00809}00809\ \ \ \ \ assert\_array\_equal(np.argsort(p[0]),\ np.argsort(d[0]))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00810}00810\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00811}00811\ \ \ \ \ lp\ =\ clf.predict\_log\_proba([[3,\ 2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00812}00812\ \ \ \ \ p\ =\ clf.predict\_proba([[3,\ 2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00813}00813\ \ \ \ \ assert\_array\_almost\_equal(np.log(p),\ lp)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00814}00814\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00815}00815\ \ \ \ \ lp\ =\ clf.predict\_log\_proba([[-\/1,\ -\/1]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00816}00816\ \ \ \ \ p\ =\ clf.predict\_proba([[-\/1,\ -\/1]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00817}00817\ \ \ \ \ assert\_array\_almost\_equal(np.log(p),\ lp)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00818}00818\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00819}00819\ \ \ \ \ \textcolor{comment}{\#\ Modified\ Huber\ multiclass\ probability\ estimates;\ requires\ a\ separate}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00820}00820\ \ \ \ \ \textcolor{comment}{\#\ test\ because\ the\ hard\ zero/one\ probabilities\ may\ destroy\ the}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00821}00821\ \ \ \ \ \textcolor{comment}{\#\ ordering\ present\ in\ decision\_function\ output.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00822}00822\ \ \ \ \ clf\ =\ klass(loss=\textcolor{stringliteral}{"{}modified\_huber"{}},\ alpha=0.01,\ max\_iter=10)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00823}00823\ \ \ \ \ clf.fit(X2,\ Y2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00824}00824\ \ \ \ \ d\ =\ clf.decision\_function([[3,\ 2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00825}00825\ \ \ \ \ p\ =\ clf.predict\_proba([[3,\ 2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00826}00826\ \ \ \ \ \textcolor{keywordflow}{if}\ klass\ !=\ SparseSGDClassifier:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00827}00827\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ np.argmax(d,\ axis=1)\ ==\ np.argmax(p,\ axis=1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00828}00828\ \ \ \ \ \textcolor{keywordflow}{else}:\ \ \textcolor{comment}{\#\ XXX\ the\ sparse\ test\ gets\ a\ different\ X2\ (?)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00829}00829\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ np.argmin(d,\ axis=1)\ ==\ np.argmin(p,\ axis=1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00830}00830\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00831}00831\ \ \ \ \ \textcolor{comment}{\#\ the\ following\ sample\ produces\ decision\_function\ values\ <\ -\/1,}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00832}00832\ \ \ \ \ \textcolor{comment}{\#\ which\ would\ cause\ naive\ normalization\ to\ fail\ (see\ comment}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00833}00833\ \ \ \ \ \textcolor{comment}{\#\ in\ SGDClassifier.predict\_proba)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00834}00834\ \ \ \ \ x\ =\ X.mean(axis=0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00835}00835\ \ \ \ \ d\ =\ clf.decision\_function([x])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00836}00836\ \ \ \ \ \textcolor{keywordflow}{if}\ np.all(d\ <\ -\/1):\ \ \textcolor{comment}{\#\ XXX\ not\ true\ in\ sparse\ test\ case\ (why?)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00837}00837\ \ \ \ \ \ \ \ \ p\ =\ clf.predict\_proba([x])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00838}00838\ \ \ \ \ \ \ \ \ assert\_array\_almost\_equal(p[0],\ [1\ /\ 3.0]\ *\ 3)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00839}00839\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00840}00840\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00841}00841\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00842}00842\ \textcolor{keyword}{def\ }test\_sgd\_l1(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00843}00843\ \ \ \ \ \textcolor{comment}{\#\ Test\ L1\ regularization}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00844}00844\ \ \ \ \ n\ =\ len(X4)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00845}00845\ \ \ \ \ rng\ =\ np.random.RandomState(13)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00846}00846\ \ \ \ \ idx\ =\ np.arange(n)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00847}00847\ \ \ \ \ rng.shuffle(idx)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00848}00848\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00849}00849\ \ \ \ \ X\ =\ X4[idx,\ :]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00850}00850\ \ \ \ \ Y\ =\ Y4[idx]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00851}00851\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00852}00852\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00853}00853\ \ \ \ \ \ \ \ \ penalty=\textcolor{stringliteral}{"{}l1"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00854}00854\ \ \ \ \ \ \ \ \ alpha=0.2,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00855}00855\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00856}00856\ \ \ \ \ \ \ \ \ max\_iter=2000,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00857}00857\ \ \ \ \ \ \ \ \ tol=\textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00858}00858\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00859}00859\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00860}00860\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00861}00861\ \ \ \ \ assert\_array\_equal(clf.coef\_[0,\ 1:-\/1],\ np.zeros((4,)))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00862}00862\ \ \ \ \ pred\ =\ clf.predict(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00863}00863\ \ \ \ \ assert\_array\_equal(pred,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00864}00864\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00865}00865\ \ \ \ \ \textcolor{comment}{\#\ test\ sparsify\ with\ dense\ inputs}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00866}00866\ \ \ \ \ clf.sparsify()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00867}00867\ \ \ \ \ \textcolor{keyword}{assert}\ sp.issparse(clf.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00868}00868\ \ \ \ \ pred\ =\ clf.predict(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00869}00869\ \ \ \ \ assert\_array\_equal(pred,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00870}00870\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00871}00871\ \ \ \ \ \textcolor{comment}{\#\ pickle\ and\ unpickle\ with\ sparse\ coef\_}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00872}00872\ \ \ \ \ clf\ =\ pickle.loads(pickle.dumps(clf))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00873}00873\ \ \ \ \ \textcolor{keyword}{assert}\ sp.issparse(clf.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00874}00874\ \ \ \ \ pred\ =\ clf.predict(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00875}00875\ \ \ \ \ assert\_array\_equal(pred,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00876}00876\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00877}00877\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00878}00878\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00879}00879\ \textcolor{keyword}{def\ }test\_class\_weights(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00880}00880\ \ \ \ \ \textcolor{comment}{\#\ Test\ class\ weights.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00881}00881\ \ \ \ \ X\ =\ np.array([[-\/1.0,\ -\/1.0],\ [-\/1.0,\ 0],\ [-\/0.8,\ -\/1.0],\ [1.0,\ 1.0],\ [1.0,\ 0.0]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00882}00882\ \ \ \ \ y\ =\ [1,\ 1,\ 1,\ -\/1,\ -\/1]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00883}00883\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00884}00884\ \ \ \ \ clf\ =\ klass(alpha=0.1,\ max\_iter=1000,\ fit\_intercept=\textcolor{keyword}{False},\ class\_weight=\textcolor{keywordtype}{None})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00885}00885\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00886}00886\ \ \ \ \ assert\_array\_equal(clf.predict([[0.2,\ -\/1.0]]),\ np.array([1]))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00887}00887\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00888}00888\ \ \ \ \ \textcolor{comment}{\#\ we\ give\ a\ small\ weights\ to\ class\ 1}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00889}00889\ \ \ \ \ clf\ =\ klass(alpha=0.1,\ max\_iter=1000,\ fit\_intercept=\textcolor{keyword}{False},\ class\_weight=\{1:\ 0.001\})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00890}00890\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00891}00891\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00892}00892\ \ \ \ \ \textcolor{comment}{\#\ now\ the\ hyperplane\ should\ rotate\ clock-\/wise\ and}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00893}00893\ \ \ \ \ \textcolor{comment}{\#\ the\ prediction\ on\ this\ point\ should\ shift}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00894}00894\ \ \ \ \ assert\_array\_equal(clf.predict([[0.2,\ -\/1.0]]),\ np.array([-\/1]))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00895}00895\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00896}00896\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00897}00897\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00898}00898\ \textcolor{keyword}{def\ }test\_equal\_class\_weight(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00899}00899\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ equal\ class\ weights\ approx.\ equals\ no\ class\ weights.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00900}00900\ \ \ \ \ X\ =\ [[1,\ 0],\ [1,\ 0],\ [0,\ 1],\ [0,\ 1]]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00901}00901\ \ \ \ \ y\ =\ [0,\ 0,\ 1,\ 1]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00902}00902\ \ \ \ \ clf\ =\ klass(alpha=0.1,\ max\_iter=1000,\ class\_weight=\textcolor{keywordtype}{None})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00903}00903\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00904}00904\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00905}00905\ \ \ \ \ X\ =\ [[1,\ 0],\ [0,\ 1]]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00906}00906\ \ \ \ \ y\ =\ [0,\ 1]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00907}00907\ \ \ \ \ clf\_weighted\ =\ klass(alpha=0.1,\ max\_iter=1000,\ class\_weight=\{0:\ 0.5,\ 1:\ 0.5\})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00908}00908\ \ \ \ \ clf\_weighted.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00909}00909\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00910}00910\ \ \ \ \ \textcolor{comment}{\#\ should\ be\ similar\ up\ to\ some\ epsilon\ due\ to\ learning\ rate\ schedule}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00911}00911\ \ \ \ \ assert\_almost\_equal(clf.coef\_,\ clf\_weighted.coef\_,\ decimal=2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00912}00912\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00913}00913\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00914}00914\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00915}00915\ \textcolor{keyword}{def\ }test\_wrong\_class\_weight\_label(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00916}00916\ \ \ \ \ \textcolor{comment}{\#\ ValueError\ due\ to\ not\ existing\ class\ label.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00917}00917\ \ \ \ \ clf\ =\ klass(alpha=0.1,\ max\_iter=1000,\ class\_weight=\{0:\ 0.5\})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00918}00918\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00919}00919\ \ \ \ \ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00920}00920\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00921}00921\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00922}00922\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00923}00923\ \textcolor{keyword}{def\ }test\_weights\_multiplied(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00924}00924\ \ \ \ \ \textcolor{comment}{\#\ Tests\ that\ class\_weight\ and\ sample\_weight\ are\ multiplicative}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00925}00925\ \ \ \ \ class\_weights\ =\ \{1:\ 0.6,\ 2:\ 0.3\}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00926}00926\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00927}00927\ \ \ \ \ sample\_weights\ =\ rng.random\_sample(Y4.shape[0])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00928}00928\ \ \ \ \ multiplied\_together\ =\ np.copy(sample\_weights)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00929}00929\ \ \ \ \ multiplied\_together[Y4\ ==\ 1]\ *=\ class\_weights[1]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00930}00930\ \ \ \ \ multiplied\_together[Y4\ ==\ 2]\ *=\ class\_weights[2]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00931}00931\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00932}00932\ \ \ \ \ clf1\ =\ klass(alpha=0.1,\ max\_iter=20,\ class\_weight=class\_weights)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00933}00933\ \ \ \ \ clf2\ =\ klass(alpha=0.1,\ max\_iter=20)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00934}00934\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00935}00935\ \ \ \ \ clf1.fit(X4,\ Y4,\ sample\_weight=sample\_weights)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00936}00936\ \ \ \ \ clf2.fit(X4,\ Y4,\ sample\_weight=multiplied\_together)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00937}00937\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00938}00938\ \ \ \ \ assert\_almost\_equal(clf1.coef\_,\ clf2.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00939}00939\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00940}00940\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00941}00941\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00942}00942\ \textcolor{keyword}{def\ }test\_balanced\_weight(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00943}00943\ \ \ \ \ \textcolor{comment}{\#\ Test\ class\ weights\ for\ imbalanced\ data"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00944}00944\ \ \ \ \ \textcolor{comment}{\#\ compute\ reference\ metrics\ on\ iris\ dataset\ that\ is\ quite\ balanced\ by}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00945}00945\ \ \ \ \ \textcolor{comment}{\#\ default}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00946}00946\ \ \ \ \ X,\ y\ =\ iris.data,\ iris.target}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00947}00947\ \ \ \ \ X\ =\ scale(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00948}00948\ \ \ \ \ idx\ =\ np.arange(X.shape[0])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00949}00949\ \ \ \ \ rng\ =\ np.random.RandomState(6)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00950}00950\ \ \ \ \ rng.shuffle(idx)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00951}00951\ \ \ \ \ X\ =\ X[idx]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00952}00952\ \ \ \ \ y\ =\ y[idx]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00953}00953\ \ \ \ \ clf\ =\ klass(alpha=0.0001,\ max\_iter=1000,\ class\_weight=\textcolor{keywordtype}{None},\ shuffle=\textcolor{keyword}{False}).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00954}00954\ \ \ \ \ f1\ =\ metrics.f1\_score(y,\ clf.predict(X),\ average=\textcolor{stringliteral}{"{}weighted"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00955}00955\ \ \ \ \ assert\_almost\_equal(f1,\ 0.96,\ decimal=1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00956}00956\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00957}00957\ \ \ \ \ \textcolor{comment}{\#\ make\ the\ same\ prediction\ using\ balanced\ class\_weight}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00958}00958\ \ \ \ \ clf\_balanced\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00959}00959\ \ \ \ \ \ \ \ \ alpha=0.0001,\ max\_iter=1000,\ class\_weight=\textcolor{stringliteral}{"{}balanced"{}},\ shuffle=\textcolor{keyword}{False}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00960}00960\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00961}00961\ \ \ \ \ f1\ =\ metrics.f1\_score(y,\ clf\_balanced.predict(X),\ average=\textcolor{stringliteral}{"{}weighted"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00962}00962\ \ \ \ \ assert\_almost\_equal(f1,\ 0.96,\ decimal=1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00963}00963\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00964}00964\ \ \ \ \ \textcolor{comment}{\#\ Make\ sure\ that\ in\ the\ balanced\ case\ it\ does\ not\ change\ anything}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00965}00965\ \ \ \ \ \textcolor{comment}{\#\ to\ use\ "{}balanced"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00966}00966\ \ \ \ \ assert\_array\_almost\_equal(clf.coef\_,\ clf\_balanced.coef\_,\ 6)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00967}00967\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00968}00968\ \ \ \ \ \textcolor{comment}{\#\ build\ an\ very\ very\ imbalanced\ dataset\ out\ of\ iris\ data}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00969}00969\ \ \ \ \ X\_0\ =\ X[y\ ==\ 0,\ :]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00970}00970\ \ \ \ \ y\_0\ =\ y[y\ ==\ 0]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00971}00971\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00972}00972\ \ \ \ \ X\_imbalanced\ =\ np.vstack([X]\ +\ [X\_0]\ *\ 10)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00973}00973\ \ \ \ \ y\_imbalanced\ =\ np.concatenate([y]\ +\ [y\_0]\ *\ 10)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00974}00974\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00975}00975\ \ \ \ \ \textcolor{comment}{\#\ fit\ a\ model\ on\ the\ imbalanced\ data\ without\ class\ weight\ info}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00976}00976\ \ \ \ \ clf\ =\ klass(max\_iter=1000,\ class\_weight=\textcolor{keywordtype}{None},\ shuffle=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00977}00977\ \ \ \ \ clf.fit(X\_imbalanced,\ y\_imbalanced)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00978}00978\ \ \ \ \ y\_pred\ =\ clf.predict(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00979}00979\ \ \ \ \ \textcolor{keyword}{assert}\ metrics.f1\_score(y,\ y\_pred,\ average=\textcolor{stringliteral}{"{}weighted"{}})\ <\ 0.96}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00980}00980\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00981}00981\ \ \ \ \ \textcolor{comment}{\#\ fit\ a\ model\ with\ balanced\ class\_weight\ enabled}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00982}00982\ \ \ \ \ clf\ =\ klass(max\_iter=1000,\ class\_weight=\textcolor{stringliteral}{"{}balanced"{}},\ shuffle=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00983}00983\ \ \ \ \ clf.fit(X\_imbalanced,\ y\_imbalanced)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00984}00984\ \ \ \ \ y\_pred\ =\ clf.predict(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00985}00985\ \ \ \ \ \textcolor{keyword}{assert}\ metrics.f1\_score(y,\ y\_pred,\ average=\textcolor{stringliteral}{"{}weighted"{}})\ >\ 0.96}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00986}00986\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00987}00987\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00988}00988\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00989}00989\ \textcolor{keyword}{def\ }test\_sample\_weights(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00990}00990\ \ \ \ \ \textcolor{comment}{\#\ Test\ weights\ on\ individual\ samples}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00991}00991\ \ \ \ \ X\ =\ np.array([[-\/1.0,\ -\/1.0],\ [-\/1.0,\ 0],\ [-\/0.8,\ -\/1.0],\ [1.0,\ 1.0],\ [1.0,\ 0.0]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00992}00992\ \ \ \ \ y\ =\ [1,\ 1,\ 1,\ -\/1,\ -\/1]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00993}00993\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00994}00994\ \ \ \ \ clf\ =\ klass(alpha=0.1,\ max\_iter=1000,\ fit\_intercept=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00995}00995\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00996}00996\ \ \ \ \ assert\_array\_equal(clf.predict([[0.2,\ -\/1.0]]),\ np.array([1]))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00997}00997\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00998}00998\ \ \ \ \ \textcolor{comment}{\#\ we\ give\ a\ small\ weights\ to\ class\ 1}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l00999}00999\ \ \ \ \ clf.fit(X,\ y,\ sample\_weight=[0.001]\ *\ 3\ +\ [1]\ *\ 2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01000}01000\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01001}01001\ \ \ \ \ \textcolor{comment}{\#\ now\ the\ hyperplane\ should\ rotate\ clock-\/wise\ and}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01002}01002\ \ \ \ \ \textcolor{comment}{\#\ the\ prediction\ on\ this\ point\ should\ shift}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01003}01003\ \ \ \ \ assert\_array\_equal(clf.predict([[0.2,\ -\/1.0]]),\ np.array([-\/1]))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01004}01004\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01005}01005\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01006}01006\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01007}01007\ \ \ \ \ \textcolor{stringliteral}{"{}klass"{}},\ [SGDClassifier,\ SparseSGDClassifier,\ SGDOneClassSVM,\ SparseSGDOneClassSVM]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01008}01008\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01009}01009\ \textcolor{keyword}{def\ }test\_wrong\_sample\_weights(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01010}01010\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ ValueError\ is\ raised\ if\ sample\_weight\ has\ wrong\ shape}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01011}01011\ \ \ \ \ \textcolor{keywordflow}{if}\ klass\ \textcolor{keywordflow}{in}\ [SGDClassifier,\ SparseSGDClassifier]:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01012}01012\ \ \ \ \ \ \ \ \ clf\ =\ klass(alpha=0.1,\ max\_iter=1000,\ fit\_intercept=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01013}01013\ \ \ \ \ \textcolor{keywordflow}{elif}\ klass\ \textcolor{keywordflow}{in}\ [SGDOneClassSVM,\ SparseSGDOneClassSVM]:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01014}01014\ \ \ \ \ \ \ \ \ clf\ =\ klass(nu=0.1,\ max\_iter=1000,\ fit\_intercept=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01015}01015\ \ \ \ \ \textcolor{comment}{\#\ provided\ sample\_weight\ too\ long}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01016}01016\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01017}01017\ \ \ \ \ \ \ \ \ clf.fit(X,\ Y,\ sample\_weight=np.arange(7))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01018}01018\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01019}01019\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01020}01020\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01021}01021\ \textcolor{keyword}{def\ }test\_partial\_fit\_exception(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01022}01022\ \ \ \ \ clf\ =\ klass(alpha=0.01)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01023}01023\ \ \ \ \ \textcolor{comment}{\#\ classes\ was\ not\ specified}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01024}01024\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01025}01025\ \ \ \ \ \ \ \ \ clf.partial\_fit(X3,\ Y3)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01026}01026\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01027}01027\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01028}01028\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01029}01029\ \textcolor{keyword}{def\ }test\_partial\_fit\_binary(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01030}01030\ \ \ \ \ third\ =\ X.shape[0]\ //\ 3}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01031}01031\ \ \ \ \ clf\ =\ klass(alpha=0.01)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01032}01032\ \ \ \ \ classes\ =\ np.unique(Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01033}01033\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01034}01034\ \ \ \ \ clf.partial\_fit(X[:third],\ Y[:third],\ classes=classes)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01035}01035\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_.shape\ ==\ (1,\ X.shape[1])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01036}01036\ \ \ \ \ \textcolor{keyword}{assert}\ clf.intercept\_.shape\ ==\ (1,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01037}01037\ \ \ \ \ \textcolor{keyword}{assert}\ clf.decision\_function([[0,\ 0]]).shape\ ==\ (1,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01038}01038\ \ \ \ \ id1\ =\ id(clf.coef\_.data)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01039}01039\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01040}01040\ \ \ \ \ clf.partial\_fit(X[third:],\ Y[third:])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01041}01041\ \ \ \ \ id2\ =\ id(clf.coef\_.data)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01042}01042\ \ \ \ \ \textcolor{comment}{\#\ check\ that\ coef\_\ haven't\ been\ re-\/allocated}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01043}01043\ \ \ \ \ \textcolor{keyword}{assert}\ id1,\ id2}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01044}01044\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01045}01045\ \ \ \ \ y\_pred\ =\ clf.predict(T)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01046}01046\ \ \ \ \ assert\_array\_equal(y\_pred,\ true\_result)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01047}01047\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01048}01048\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01049}01049\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01050}01050\ \textcolor{keyword}{def\ }test\_partial\_fit\_multiclass(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01051}01051\ \ \ \ \ third\ =\ X2.shape[0]\ //\ 3}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01052}01052\ \ \ \ \ clf\ =\ klass(alpha=0.01)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01053}01053\ \ \ \ \ classes\ =\ np.unique(Y2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01054}01054\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01055}01055\ \ \ \ \ clf.partial\_fit(X2[:third],\ Y2[:third],\ classes=classes)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01056}01056\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_.shape\ ==\ (3,\ X2.shape[1])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01057}01057\ \ \ \ \ \textcolor{keyword}{assert}\ clf.intercept\_.shape\ ==\ (3,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01058}01058\ \ \ \ \ \textcolor{keyword}{assert}\ clf.decision\_function([[0,\ 0]]).shape\ ==\ (1,\ 3)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01059}01059\ \ \ \ \ id1\ =\ id(clf.coef\_.data)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01060}01060\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01061}01061\ \ \ \ \ clf.partial\_fit(X2[third:],\ Y2[third:])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01062}01062\ \ \ \ \ id2\ =\ id(clf.coef\_.data)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01063}01063\ \ \ \ \ \textcolor{comment}{\#\ check\ that\ coef\_\ haven't\ been\ re-\/allocated}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01064}01064\ \ \ \ \ \textcolor{keyword}{assert}\ id1,\ id2}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01065}01065\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01066}01066\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01067}01067\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01068}01068\ \textcolor{keyword}{def\ }test\_partial\_fit\_multiclass\_average(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01069}01069\ \ \ \ \ third\ =\ X2.shape[0]\ //\ 3}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01070}01070\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ average=X2.shape[0])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01071}01071\ \ \ \ \ classes\ =\ np.unique(Y2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01072}01072\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01073}01073\ \ \ \ \ clf.partial\_fit(X2[:third],\ Y2[:third],\ classes=classes)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01074}01074\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_.shape\ ==\ (3,\ X2.shape[1])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01075}01075\ \ \ \ \ \textcolor{keyword}{assert}\ clf.intercept\_.shape\ ==\ (3,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01076}01076\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01077}01077\ \ \ \ \ clf.partial\_fit(X2[third:],\ Y2[third:])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01078}01078\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_.shape\ ==\ (3,\ X2.shape[1])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01079}01079\ \ \ \ \ \textcolor{keyword}{assert}\ clf.intercept\_.shape\ ==\ (3,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01080}01080\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01081}01081\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01082}01082\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01083}01083\ \textcolor{keyword}{def\ }test\_fit\_then\_partial\_fit(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01084}01084\ \ \ \ \ \textcolor{comment}{\#\ Partial\_fit\ should\ work\ after\ initial\ fit\ in\ the\ multiclass\ case.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01085}01085\ \ \ \ \ \textcolor{comment}{\#\ Non-\/regression\ test\ for\ \#2496;\ fit\ would\ previously\ produce\ a}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01086}01086\ \ \ \ \ \textcolor{comment}{\#\ Fortran-\/ordered\ coef\_\ that\ subsequent\ partial\_fit\ couldn't\ handle.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01087}01087\ \ \ \ \ clf\ =\ klass()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01088}01088\ \ \ \ \ clf.fit(X2,\ Y2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01089}01089\ \ \ \ \ clf.partial\_fit(X2,\ Y2)\ \ \textcolor{comment}{\#\ no\ exception\ here}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01090}01090\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01091}01091\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01092}01092\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01093}01093\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}lr"{},\ ["{}constant"{},\ "{}optimal"{},\ "{}invscaling"{},\ "{}adaptive"{}])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01094}01094\ \textcolor{keyword}{def\ }test\_partial\_fit\_equal\_fit\_classif(klass,\ lr):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01095}01095\ \ \ \ \ \textcolor{keywordflow}{for}\ X\_,\ Y\_,\ T\_\ \textcolor{keywordflow}{in}\ ((X,\ Y,\ T),\ (X2,\ Y2,\ T2)):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01096}01096\ \ \ \ \ \ \ \ \ clf\ =\ klass(alpha=0.01,\ eta0=0.01,\ max\_iter=2,\ learning\_rate=lr,\ shuffle=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01097}01097\ \ \ \ \ \ \ \ \ clf.fit(X\_,\ Y\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01098}01098\ \ \ \ \ \ \ \ \ y\_pred\ =\ clf.decision\_function(T\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01099}01099\ \ \ \ \ \ \ \ \ t\ =\ clf.t\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01100}01100\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01101}01101\ \ \ \ \ \ \ \ \ classes\ =\ np.unique(Y\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01102}01102\ \ \ \ \ \ \ \ \ clf\ =\ klass(alpha=0.01,\ eta0=0.01,\ learning\_rate=lr,\ shuffle=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01103}01103\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(2):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01104}01104\ \ \ \ \ \ \ \ \ \ \ \ \ clf.partial\_fit(X\_,\ Y\_,\ classes=classes)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01105}01105\ \ \ \ \ \ \ \ \ y\_pred2\ =\ clf.decision\_function(T\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01106}01106\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01107}01107\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ clf.t\_\ ==\ t}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01108}01108\ \ \ \ \ \ \ \ \ assert\_array\_almost\_equal(y\_pred,\ y\_pred2,\ decimal=2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01109}01109\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01110}01110\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01111}01111\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01112}01112\ \textcolor{keyword}{def\ }test\_regression\_losses(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01113}01113\ \ \ \ \ random\_state\ =\ np.random.RandomState(1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01114}01114\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01115}01115\ \ \ \ \ \ \ \ \ alpha=0.01,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01116}01116\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01117}01117\ \ \ \ \ \ \ \ \ eta0=0.1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01118}01118\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}epsilon\_insensitive"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01119}01119\ \ \ \ \ \ \ \ \ random\_state=random\_state,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01120}01120\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01121}01121\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01122}01122\ \ \ \ \ \textcolor{keyword}{assert}\ 1.0\ ==\ np.mean(clf.predict(X)\ ==\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01123}01123\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01124}01124\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01125}01125\ \ \ \ \ \ \ \ \ alpha=0.01,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01126}01126\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01127}01127\ \ \ \ \ \ \ \ \ eta0=0.1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01128}01128\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_epsilon\_insensitive"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01129}01129\ \ \ \ \ \ \ \ \ random\_state=random\_state,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01130}01130\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01131}01131\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01132}01132\ \ \ \ \ \textcolor{keyword}{assert}\ 1.0\ ==\ np.mean(clf.predict(X)\ ==\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01133}01133\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01134}01134\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ loss=\textcolor{stringliteral}{"{}huber"{}},\ random\_state=random\_state)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01135}01135\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01136}01136\ \ \ \ \ \textcolor{keyword}{assert}\ 1.0\ ==\ np.mean(clf.predict(X)\ ==\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01137}01137\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01138}01138\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01139}01139\ \ \ \ \ \ \ \ \ alpha=0.01,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01140}01140\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01141}01141\ \ \ \ \ \ \ \ \ eta0=0.01,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01142}01142\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01143}01143\ \ \ \ \ \ \ \ \ random\_state=random\_state,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01144}01144\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01145}01145\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01146}01146\ \ \ \ \ \textcolor{keyword}{assert}\ 1.0\ ==\ np.mean(clf.predict(X)\ ==\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01147}01147\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01148}01148\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01149}01149\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01150}01150\ \textcolor{keyword}{def\ }test\_warm\_start\_multiclass(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01151}01151\ \ \ \ \ \_test\_warm\_start(klass,\ X2,\ Y2,\ \textcolor{stringliteral}{"{}optimal"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01152}01152\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01153}01153\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01154}01154\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDClassifier,\ SparseSGDClassifier])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01155}01155\ \textcolor{keyword}{def\ }test\_multiple\_fit(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01156}01156\ \ \ \ \ \textcolor{comment}{\#\ Test\ multiple\ calls\ of\ fit\ w/\ different\ shaped\ inputs.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01157}01157\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ shuffle=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01158}01158\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01159}01159\ \ \ \ \ \textcolor{keyword}{assert}\ hasattr(clf,\ \textcolor{stringliteral}{"{}coef\_"{}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01160}01160\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01161}01161\ \ \ \ \ \textcolor{comment}{\#\ Non-\/regression\ test:\ try\ fitting\ with\ a\ different\ label\ set.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01162}01162\ \ \ \ \ y\ =\ [[\textcolor{stringliteral}{"{}ham"{}},\ \textcolor{stringliteral}{"{}spam"{}}][i]\ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__label_1_1LabelEncoder}{LabelEncoder}}().fit\_transform(Y)]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01163}01163\ \ \ \ \ clf.fit(X[:,\ :-\/1],\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01164}01164\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01165}01165\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01166}01166\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01168}01168\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01169}01169\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01170}01170\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01171}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a168fa84cb56b6cc23a3177b4f9772eae}{01171}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a168fa84cb56b6cc23a3177b4f9772eae}{test\_sgd\_reg}}(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01172}01172\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ SGD\ gives\ any\ results.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01173}01173\ \ \ \ \ clf\ =\ klass(alpha=0.1,\ max\_iter=2,\ fit\_intercept=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01174}01174\ \ \ \ \ clf.fit([[0,\ 0],\ [1,\ 1],\ [2,\ 2]],\ [0,\ 1,\ 2])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01175}01175\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_[0]\ ==\ clf.coef\_[1]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01176}01176\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01177}01177\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01178}01178\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01179}01179\ \textcolor{keyword}{def\ }test\_sgd\_averaged\_computed\_correctly(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01180}01180\ \ \ \ \ \textcolor{comment}{\#\ Tests\ the\ average\ regressor\ matches\ the\ naive\ implementation}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01181}01181\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01182}01182\ \ \ \ \ eta\ =\ 0.001}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01183}01183\ \ \ \ \ alpha\ =\ 0.01}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01184}01184\ \ \ \ \ n\_samples\ =\ 20}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01185}01185\ \ \ \ \ n\_features\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01186}01186\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01187}01187\ \ \ \ \ X\ =\ rng.normal(size=(n\_samples,\ n\_features))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01188}01188\ \ \ \ \ w\ =\ rng.normal(size=n\_features)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01189}01189\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01190}01190\ \ \ \ \ \textcolor{comment}{\#\ simple\ linear\ function\ without\ noise}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01191}01191\ \ \ \ \ y\ =\ np.dot(X,\ w)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01192}01192\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01193}01193\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01194}01194\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01195}01195\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01196}01196\ \ \ \ \ \ \ \ \ eta0=eta,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01197}01197\ \ \ \ \ \ \ \ \ alpha=alpha,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01198}01198\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01199}01199\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01200}01200\ \ \ \ \ \ \ \ \ average=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01201}01201\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01202}01202\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01203}01203\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01204}01204\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01205}01205\ \ \ \ \ average\_weights,\ average\_intercept\ =\ \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_ab20ec7534385a6c109edac521ab20fb4}{asgd}}(klass,\ X,\ y,\ eta,\ alpha)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01206}01206\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01207}01207\ \ \ \ \ assert\_array\_almost\_equal(clf.coef\_,\ average\_weights,\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01208}01208\ \ \ \ \ assert\_almost\_equal(clf.intercept\_,\ average\_intercept,\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01209}01209\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01210}01210\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01211}01211\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01212}01212\ \textcolor{keyword}{def\ }test\_sgd\_averaged\_partial\_fit(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01213}01213\ \ \ \ \ \textcolor{comment}{\#\ Tests\ whether\ the\ partial\ fit\ yields\ the\ same\ average\ as\ the\ fit}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01214}01214\ \ \ \ \ eta\ =\ 0.001}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01215}01215\ \ \ \ \ alpha\ =\ 0.01}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01216}01216\ \ \ \ \ n\_samples\ =\ 20}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01217}01217\ \ \ \ \ n\_features\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01218}01218\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01219}01219\ \ \ \ \ X\ =\ rng.normal(size=(n\_samples,\ n\_features))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01220}01220\ \ \ \ \ w\ =\ rng.normal(size=n\_features)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01221}01221\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01222}01222\ \ \ \ \ \textcolor{comment}{\#\ simple\ linear\ function\ without\ noise}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01223}01223\ \ \ \ \ y\ =\ np.dot(X,\ w)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01224}01224\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01225}01225\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01226}01226\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01227}01227\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01228}01228\ \ \ \ \ \ \ \ \ eta0=eta,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01229}01229\ \ \ \ \ \ \ \ \ alpha=alpha,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01230}01230\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01231}01231\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01232}01232\ \ \ \ \ \ \ \ \ average=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01233}01233\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01234}01234\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01235}01235\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01236}01236\ \ \ \ \ clf.partial\_fit(X[:\ int(n\_samples\ /\ 2)][:],\ y[:\ int(n\_samples\ /\ 2)])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01237}01237\ \ \ \ \ clf.partial\_fit(X[int(n\_samples\ /\ 2)\ :][:],\ y[int(n\_samples\ /\ 2)\ :])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01238}01238\ \ \ \ \ average\_weights,\ average\_intercept\ =\ \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_ab20ec7534385a6c109edac521ab20fb4}{asgd}}(klass,\ X,\ y,\ eta,\ alpha)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01239}01239\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01240}01240\ \ \ \ \ assert\_array\_almost\_equal(clf.coef\_,\ average\_weights,\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01241}01241\ \ \ \ \ assert\_almost\_equal(clf.intercept\_[0],\ average\_intercept,\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01242}01242\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01243}01243\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01244}01244\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01245}01245\ \textcolor{keyword}{def\ }test\_average\_sparse(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01246}01246\ \ \ \ \ \textcolor{comment}{\#\ Checks\ the\ average\ weights\ on\ data\ with\ 0s}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01247}01247\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01248}01248\ \ \ \ \ eta\ =\ 0.001}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01249}01249\ \ \ \ \ alpha\ =\ 0.01}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01250}01250\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01251}01251\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_error"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01252}01252\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01253}01253\ \ \ \ \ \ \ \ \ eta0=eta,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01254}01254\ \ \ \ \ \ \ \ \ alpha=alpha,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01255}01255\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01256}01256\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01257}01257\ \ \ \ \ \ \ \ \ average=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01258}01258\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01259}01259\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01260}01260\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01261}01261\ \ \ \ \ n\_samples\ =\ Y3.shape[0]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01262}01262\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01263}01263\ \ \ \ \ clf.partial\_fit(X3[:\ int(n\_samples\ /\ 2)][:],\ Y3[:\ int(n\_samples\ /\ 2)])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01264}01264\ \ \ \ \ clf.partial\_fit(X3[int(n\_samples\ /\ 2)\ :][:],\ Y3[int(n\_samples\ /\ 2)\ :])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01265}01265\ \ \ \ \ average\_weights,\ average\_intercept\ =\ \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_ab20ec7534385a6c109edac521ab20fb4}{asgd}}(klass,\ X3,\ Y3,\ eta,\ alpha)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01266}01266\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01267}01267\ \ \ \ \ assert\_array\_almost\_equal(clf.coef\_,\ average\_weights,\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01268}01268\ \ \ \ \ assert\_almost\_equal(clf.intercept\_,\ average\_intercept,\ decimal=16)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01269}01269\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01270}01270\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01271}01271\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01272}01272\ \textcolor{keyword}{def\ }test\_sgd\_least\_squares\_fit(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01273}01273\ \ \ \ \ xmin,\ xmax\ =\ -\/5,\ 5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01274}01274\ \ \ \ \ n\_samples\ =\ 100}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01275}01275\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01276}01276\ \ \ \ \ X\ =\ np.linspace(xmin,\ xmax,\ n\_samples).reshape(n\_samples,\ 1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01277}01277\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01278}01278\ \ \ \ \ \textcolor{comment}{\#\ simple\ linear\ function\ without\ noise}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01279}01279\ \ \ \ \ y\ =\ 0.5\ *\ X.ravel()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01280}01280\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01281}01281\ \ \ \ \ clf\ =\ klass(loss=\textcolor{stringliteral}{"{}squared\_error"{}},\ alpha=0.1,\ max\_iter=20,\ fit\_intercept=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01282}01282\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01283}01283\ \ \ \ \ score\ =\ clf.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01284}01284\ \ \ \ \ \textcolor{keyword}{assert}\ score\ >\ 0.99}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01285}01285\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01286}01286\ \ \ \ \ \textcolor{comment}{\#\ simple\ linear\ function\ with\ noise}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01287}01287\ \ \ \ \ y\ =\ 0.5\ *\ X.ravel()\ +\ rng.randn(n\_samples,\ 1).ravel()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01288}01288\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01289}01289\ \ \ \ \ clf\ =\ klass(loss=\textcolor{stringliteral}{"{}squared\_error"{}},\ alpha=0.1,\ max\_iter=20,\ fit\_intercept=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01290}01290\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01291}01291\ \ \ \ \ score\ =\ clf.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01292}01292\ \ \ \ \ \textcolor{keyword}{assert}\ score\ >\ 0.5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01293}01293\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01294}01294\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01295}01295\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01296}01296\ \textcolor{keyword}{def\ }test\_sgd\_epsilon\_insensitive(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01297}01297\ \ \ \ \ xmin,\ xmax\ =\ -\/5,\ 5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01298}01298\ \ \ \ \ n\_samples\ =\ 100}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01299}01299\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01300}01300\ \ \ \ \ X\ =\ np.linspace(xmin,\ xmax,\ n\_samples).reshape(n\_samples,\ 1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01301}01301\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01302}01302\ \ \ \ \ \textcolor{comment}{\#\ simple\ linear\ function\ without\ noise}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01303}01303\ \ \ \ \ y\ =\ 0.5\ *\ X.ravel()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01304}01304\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01305}01305\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01306}01306\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}epsilon\_insensitive"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01307}01307\ \ \ \ \ \ \ \ \ epsilon=0.01,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01308}01308\ \ \ \ \ \ \ \ \ alpha=0.1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01309}01309\ \ \ \ \ \ \ \ \ max\_iter=20,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01310}01310\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01311}01311\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01312}01312\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01313}01313\ \ \ \ \ score\ =\ clf.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01314}01314\ \ \ \ \ \textcolor{keyword}{assert}\ score\ >\ 0.99}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01315}01315\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01316}01316\ \ \ \ \ \textcolor{comment}{\#\ simple\ linear\ function\ with\ noise}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01317}01317\ \ \ \ \ y\ =\ 0.5\ *\ X.ravel()\ +\ rng.randn(n\_samples,\ 1).ravel()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01318}01318\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01319}01319\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01320}01320\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}epsilon\_insensitive"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01321}01321\ \ \ \ \ \ \ \ \ epsilon=0.01,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01322}01322\ \ \ \ \ \ \ \ \ alpha=0.1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01323}01323\ \ \ \ \ \ \ \ \ max\_iter=20,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01324}01324\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01325}01325\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01326}01326\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01327}01327\ \ \ \ \ score\ =\ clf.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01328}01328\ \ \ \ \ \textcolor{keyword}{assert}\ score\ >\ 0.5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01329}01329\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01330}01330\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01331}01331\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01332}01332\ \textcolor{keyword}{def\ }test\_sgd\_huber\_fit(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01333}01333\ \ \ \ \ xmin,\ xmax\ =\ -\/5,\ 5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01334}01334\ \ \ \ \ n\_samples\ =\ 100}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01335}01335\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01336}01336\ \ \ \ \ X\ =\ np.linspace(xmin,\ xmax,\ n\_samples).reshape(n\_samples,\ 1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01337}01337\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01338}01338\ \ \ \ \ \textcolor{comment}{\#\ simple\ linear\ function\ without\ noise}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01339}01339\ \ \ \ \ y\ =\ 0.5\ *\ X.ravel()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01340}01340\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01341}01341\ \ \ \ \ clf\ =\ klass(loss=\textcolor{stringliteral}{"{}huber"{}},\ epsilon=0.1,\ alpha=0.1,\ max\_iter=20,\ fit\_intercept=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01342}01342\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01343}01343\ \ \ \ \ score\ =\ clf.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01344}01344\ \ \ \ \ \textcolor{keyword}{assert}\ score\ >\ 0.99}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01345}01345\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01346}01346\ \ \ \ \ \textcolor{comment}{\#\ simple\ linear\ function\ with\ noise}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01347}01347\ \ \ \ \ y\ =\ 0.5\ *\ X.ravel()\ +\ rng.randn(n\_samples,\ 1).ravel()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01348}01348\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01349}01349\ \ \ \ \ clf\ =\ klass(loss=\textcolor{stringliteral}{"{}huber"{}},\ epsilon=0.1,\ alpha=0.1,\ max\_iter=20,\ fit\_intercept=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01350}01350\ \ \ \ \ clf.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01351}01351\ \ \ \ \ score\ =\ clf.score(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01352}01352\ \ \ \ \ \textcolor{keyword}{assert}\ score\ >\ 0.5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01353}01353\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01354}01354\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01355}01355\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01356}01356\ \textcolor{keyword}{def\ }test\_elasticnet\_convergence(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01357}01357\ \ \ \ \ \textcolor{comment}{\#\ Check\ that\ the\ SGD\ output\ is\ consistent\ with\ coordinate\ descent}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01358}01358\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01359}01359\ \ \ \ \ n\_samples,\ n\_features\ =\ 1000,\ 5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01360}01360\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01361}01361\ \ \ \ \ X\ =\ rng.randn(n\_samples,\ n\_features)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01362}01362\ \ \ \ \ \textcolor{comment}{\#\ ground\_truth\ linear\ model\ that\ generate\ y\ from\ X\ and\ to\ which\ the}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01363}01363\ \ \ \ \ \textcolor{comment}{\#\ models\ should\ converge\ if\ the\ regularizer\ would\ be\ set\ to\ 0.0}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01364}01364\ \ \ \ \ ground\_truth\_coef\ =\ rng.randn(n\_features)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01365}01365\ \ \ \ \ y\ =\ np.dot(X,\ ground\_truth\_coef)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01366}01366\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01367}01367\ \ \ \ \ \textcolor{comment}{\#\ XXX:\ alpha\ =\ 0.1\ seems\ to\ cause\ convergence\ problems}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01368}01368\ \ \ \ \ \textcolor{keywordflow}{for}\ alpha\ \textcolor{keywordflow}{in}\ [0.01,\ 0.001]:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01369}01369\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ l1\_ratio\ \textcolor{keywordflow}{in}\ [0.5,\ 0.8,\ 1.0]:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01370}01370\ \ \ \ \ \ \ \ \ \ \ \ \ cd\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__coordinate__descent_1_1ElasticNet}{linear\_model.ElasticNet}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01371}01371\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ alpha=alpha,\ l1\_ratio=l1\_ratio,\ fit\_intercept=\textcolor{keyword}{False}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01372}01372\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01373}01373\ \ \ \ \ \ \ \ \ \ \ \ \ cd.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01374}01374\ \ \ \ \ \ \ \ \ \ \ \ \ sgd\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01375}01375\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ penalty=\textcolor{stringliteral}{"{}elasticnet"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01376}01376\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ max\_iter=50,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01377}01377\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ alpha=alpha,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01378}01378\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ l1\_ratio=l1\_ratio,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01379}01379\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01380}01380\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01381}01381\ \ \ \ \ \ \ \ \ \ \ \ \ sgd.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01382}01382\ \ \ \ \ \ \ \ \ \ \ \ \ err\_msg\ =\ (}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01383}01383\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}cd\ and\ sgd\ did\ not\ converge\ to\ comparable\ "{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01384}01384\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}results\ for\ alpha=\%f\ and\ l1\_ratio=\%f"{}}\ \%\ (alpha,\ l1\_ratio)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01385}01385\ \ \ \ \ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01386}01386\ \ \ \ \ \ \ \ \ \ \ \ \ assert\_almost\_equal(cd.coef\_,\ sgd.coef\_,\ decimal=2,\ err\_msg=err\_msg)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01387}01387\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01388}01388\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01389}01389\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01390}01390\ \textcolor{keyword}{def\ }test\_partial\_fit(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01391}01391\ \ \ \ \ third\ =\ X.shape[0]\ //\ 3}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01392}01392\ \ \ \ \ clf\ =\ klass(alpha=0.01)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01393}01393\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01394}01394\ \ \ \ \ clf.partial\_fit(X[:third],\ Y[:third])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01395}01395\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_.shape\ ==\ (X.shape[1],)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01396}01396\ \ \ \ \ \textcolor{keyword}{assert}\ clf.intercept\_.shape\ ==\ (1,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01397}01397\ \ \ \ \ \textcolor{keyword}{assert}\ clf.predict([[0,\ 0]]).shape\ ==\ (1,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01398}01398\ \ \ \ \ id1\ =\ id(clf.coef\_.data)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01399}01399\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01400}01400\ \ \ \ \ clf.partial\_fit(X[third:],\ Y[third:])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01401}01401\ \ \ \ \ id2\ =\ id(clf.coef\_.data)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01402}01402\ \ \ \ \ \textcolor{comment}{\#\ check\ that\ coef\_\ haven't\ been\ re-\/allocated}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01403}01403\ \ \ \ \ \textcolor{keyword}{assert}\ id1,\ id2}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01404}01404\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01405}01405\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01406}01406\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01407}01407\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}lr"{},\ ["{}constant"{},\ "{}optimal"{},\ "{}invscaling"{},\ "{}adaptive"{}])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01408}01408\ \textcolor{keyword}{def\ }test\_partial\_fit\_equal\_fit(klass,\ lr):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01409}01409\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ max\_iter=2,\ eta0=0.01,\ learning\_rate=lr,\ shuffle=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01410}01410\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01411}01411\ \ \ \ \ y\_pred\ =\ clf.predict(T)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01412}01412\ \ \ \ \ t\ =\ clf.t\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01413}01413\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01414}01414\ \ \ \ \ clf\ =\ klass(alpha=0.01,\ eta0=0.01,\ learning\_rate=lr,\ shuffle=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01415}01415\ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(2):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01416}01416\ \ \ \ \ \ \ \ \ clf.partial\_fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01417}01417\ \ \ \ \ y\_pred2\ =\ clf.predict(T)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01418}01418\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01419}01419\ \ \ \ \ \textcolor{keyword}{assert}\ clf.t\_\ ==\ t}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01420}01420\ \ \ \ \ assert\_array\_almost\_equal(y\_pred,\ y\_pred2,\ decimal=2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01421}01421\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01422}01422\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01423}01423\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDRegressor,\ SparseSGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01424}01424\ \textcolor{keyword}{def\ }test\_loss\_function\_epsilon(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01425}01425\ \ \ \ \ clf\ =\ klass(epsilon=0.9)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01426}01426\ \ \ \ \ clf.set\_params(epsilon=0.1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01427}01427\ \ \ \ \ \textcolor{keyword}{assert}\ clf.loss\_functions[\textcolor{stringliteral}{"{}huber"{}}][1]\ ==\ 0.1}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01428}01428\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01429}01429\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01430}01430\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01432}01432\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01433}01433\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01434}01434\ \textcolor{comment}{\#\ a\ simple\ implementation\ of\ ASGD\ to\ use\ for\ testing\ SGDOneClassSVM}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01435}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a02af4d01757846fc3af4b55bde99efee}{01435}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a02af4d01757846fc3af4b55bde99efee}{asgd\_oneclass}}(klass,\ X,\ eta,\ nu,\ coef\_init=None,\ offset\_init=0.0):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01436}01436\ \ \ \ \ \textcolor{keywordflow}{if}\ coef\_init\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01437}01437\ \ \ \ \ \ \ \ \ coef\ =\ np.zeros(X.shape[1])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01438}01438\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01439}01439\ \ \ \ \ \ \ \ \ coef\ =\ coef\_init}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01440}01440\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01441}01441\ \ \ \ \ average\_coef\ =\ np.zeros(X.shape[1])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01442}01442\ \ \ \ \ offset\ =\ offset\_init}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01443}01443\ \ \ \ \ intercept\ =\ 1\ -\/\ offset}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01444}01444\ \ \ \ \ average\_intercept\ =\ 0.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01445}01445\ \ \ \ \ decay\ =\ 1.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01446}01446\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01447}01447\ \ \ \ \ \textcolor{comment}{\#\ sparse\ data\ has\ a\ fixed\ decay\ of\ .01}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01448}01448\ \ \ \ \ \textcolor{keywordflow}{if}\ klass\ ==\ SparseSGDOneClassSVM:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01449}01449\ \ \ \ \ \ \ \ \ decay\ =\ 0.01}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01450}01450\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01451}01451\ \ \ \ \ \textcolor{keywordflow}{for}\ i,\ entry\ \textcolor{keywordflow}{in}\ enumerate(X):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01452}01452\ \ \ \ \ \ \ \ \ p\ =\ np.dot(entry,\ coef)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01453}01453\ \ \ \ \ \ \ \ \ p\ +=\ intercept}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01454}01454\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ p\ <=\ 1.0:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01455}01455\ \ \ \ \ \ \ \ \ \ \ \ \ gradient\ =\ -\/1}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01456}01456\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01457}01457\ \ \ \ \ \ \ \ \ \ \ \ \ gradient\ =\ 0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01458}01458\ \ \ \ \ \ \ \ \ coef\ *=\ max(0,\ 1.0\ -\/\ (eta\ *\ nu\ /\ 2))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01459}01459\ \ \ \ \ \ \ \ \ coef\ +=\ -\/(eta\ *\ gradient\ *\ entry)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01460}01460\ \ \ \ \ \ \ \ \ intercept\ +=\ -\/(eta\ *\ (nu\ +\ gradient))\ *\ decay}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01461}01461\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01462}01462\ \ \ \ \ \ \ \ \ average\_coef\ *=\ i}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01463}01463\ \ \ \ \ \ \ \ \ average\_coef\ +=\ coef}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01464}01464\ \ \ \ \ \ \ \ \ average\_coef\ /=\ i\ +\ 1.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01465}01465\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01466}01466\ \ \ \ \ \ \ \ \ average\_intercept\ *=\ i}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01467}01467\ \ \ \ \ \ \ \ \ average\_intercept\ +=\ intercept}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01468}01468\ \ \ \ \ \ \ \ \ average\_intercept\ /=\ i\ +\ 1.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01469}01469\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01470}01470\ \ \ \ \ \textcolor{keywordflow}{return}\ average\_coef,\ 1\ -\/\ average\_intercept}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01471}01471\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01472}01472\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01473}01473\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDOneClassSVM,\ SparseSGDOneClassSVM])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01474}01474\ \textcolor{keyword}{def\ }\_test\_warm\_start\_oneclass(klass,\ X,\ lr):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01475}01475\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ explicit\ warm\ restart...}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01476}01476\ \ \ \ \ clf\ =\ klass(nu=0.5,\ eta0=0.01,\ shuffle=\textcolor{keyword}{False},\ learning\_rate=lr)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01477}01477\ \ \ \ \ clf.fit(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01478}01478\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01479}01479\ \ \ \ \ clf2\ =\ klass(nu=0.1,\ eta0=0.01,\ shuffle=\textcolor{keyword}{False},\ learning\_rate=lr)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01480}01480\ \ \ \ \ clf2.fit(X,\ coef\_init=clf.coef\_.copy(),\ offset\_init=clf.offset\_.copy())}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01481}01481\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01482}01482\ \ \ \ \ \textcolor{comment}{\#\ ...\ and\ implicit\ warm\ restart\ are\ equivalent.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01483}01483\ \ \ \ \ clf3\ =\ klass(nu=0.5,\ eta0=0.01,\ shuffle=\textcolor{keyword}{False},\ warm\_start=\textcolor{keyword}{True},\ learning\_rate=lr)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01484}01484\ \ \ \ \ clf3.fit(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01485}01485\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01486}01486\ \ \ \ \ \textcolor{keyword}{assert}\ clf3.t\_\ ==\ clf.t\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01487}01487\ \ \ \ \ assert\_allclose(clf3.coef\_,\ clf.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01488}01488\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01489}01489\ \ \ \ \ clf3.set\_params(nu=0.1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01490}01490\ \ \ \ \ clf3.fit(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01491}01491\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01492}01492\ \ \ \ \ \textcolor{keyword}{assert}\ clf3.t\_\ ==\ clf2.t\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01493}01493\ \ \ \ \ assert\_allclose(clf3.coef\_,\ clf2.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01494}01494\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01495}01495\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01496}01496\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDOneClassSVM,\ SparseSGDOneClassSVM])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01497}01497\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}lr"{},\ ["{}constant"{},\ "{}optimal"{},\ "{}invscaling"{},\ "{}adaptive"{}])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01498}01498\ \textcolor{keyword}{def\ }test\_warm\_start\_oneclass(klass,\ lr):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01499}01499\ \ \ \ \ \_test\_warm\_start\_oneclass(klass,\ X,\ lr)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01500}01500\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01501}01501\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01502}01502\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDOneClassSVM,\ SparseSGDOneClassSVM])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01503}01503\ \textcolor{keyword}{def\ }test\_clone\_oneclass(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01504}01504\ \ \ \ \ \textcolor{comment}{\#\ Test\ whether\ clone\ works\ ok.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01505}01505\ \ \ \ \ clf\ =\ klass(nu=0.5)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01506}01506\ \ \ \ \ clf\ =\ clone(clf)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01507}01507\ \ \ \ \ clf.set\_params(nu=0.1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01508}01508\ \ \ \ \ clf.fit(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01509}01509\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01510}01510\ \ \ \ \ clf2\ =\ klass(nu=0.1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01511}01511\ \ \ \ \ clf2.fit(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01512}01512\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01513}01513\ \ \ \ \ assert\_array\_equal(clf.coef\_,\ clf2.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01514}01514\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01515}01515\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01516}01516\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDOneClassSVM,\ SparseSGDOneClassSVM])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01517}01517\ \textcolor{keyword}{def\ }test\_partial\_fit\_oneclass(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01518}01518\ \ \ \ \ third\ =\ X.shape[0]\ //\ 3}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01519}01519\ \ \ \ \ clf\ =\ klass(nu=0.1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01520}01520\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01521}01521\ \ \ \ \ clf.partial\_fit(X[:third])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01522}01522\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_.shape\ ==\ (X.shape[1],)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01523}01523\ \ \ \ \ \textcolor{keyword}{assert}\ clf.offset\_.shape\ ==\ (1,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01524}01524\ \ \ \ \ \textcolor{keyword}{assert}\ clf.predict([[0,\ 0]]).shape\ ==\ (1,)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01525}01525\ \ \ \ \ previous\_coefs\ =\ clf.coef\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01526}01526\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01527}01527\ \ \ \ \ clf.partial\_fit(X[third:])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01528}01528\ \ \ \ \ \textcolor{comment}{\#\ check\ that\ coef\_\ haven't\ been\ re-\/allocated}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01529}01529\ \ \ \ \ \textcolor{keyword}{assert}\ clf.coef\_\ \textcolor{keywordflow}{is}\ previous\_coefs}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01530}01530\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01531}01531\ \ \ \ \ \textcolor{comment}{\#\ raises\ ValueError\ if\ number\ of\ features\ does\ not\ match\ previous\ data}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01532}01532\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01533}01533\ \ \ \ \ \ \ \ \ clf.partial\_fit(X[:,\ 1])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01534}01534\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01535}01535\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01536}01536\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDOneClassSVM,\ SparseSGDOneClassSVM])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01537}01537\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}lr"{},\ ["{}constant"{},\ "{}optimal"{},\ "{}invscaling"{},\ "{}adaptive"{}])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01538}01538\ \textcolor{keyword}{def\ }test\_partial\_fit\_equal\_fit\_oneclass(klass,\ lr):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01539}01539\ \ \ \ \ clf\ =\ klass(nu=0.05,\ max\_iter=2,\ eta0=0.01,\ learning\_rate=lr,\ shuffle=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01540}01540\ \ \ \ \ clf.fit(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01541}01541\ \ \ \ \ y\_scores\ =\ clf.decision\_function(T)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01542}01542\ \ \ \ \ t\ =\ clf.t\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01543}01543\ \ \ \ \ coef\ =\ clf.coef\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01544}01544\ \ \ \ \ offset\ =\ clf.offset\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01545}01545\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01546}01546\ \ \ \ \ clf\ =\ klass(nu=0.05,\ eta0=0.01,\ max\_iter=1,\ learning\_rate=lr,\ shuffle=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01547}01547\ \ \ \ \ \textcolor{keywordflow}{for}\ \_\ \textcolor{keywordflow}{in}\ range(2):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01548}01548\ \ \ \ \ \ \ \ \ clf.partial\_fit(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01549}01549\ \ \ \ \ y\_scores2\ =\ clf.decision\_function(T)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01550}01550\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01551}01551\ \ \ \ \ \textcolor{keyword}{assert}\ clf.t\_\ ==\ t}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01552}01552\ \ \ \ \ assert\_allclose(y\_scores,\ y\_scores2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01553}01553\ \ \ \ \ assert\_allclose(clf.coef\_,\ coef)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01554}01554\ \ \ \ \ assert\_allclose(clf.offset\_,\ offset)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01555}01555\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01556}01556\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01557}01557\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDOneClassSVM,\ SparseSGDOneClassSVM])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01558}01558\ \textcolor{keyword}{def\ }test\_late\_onset\_averaging\_reached\_oneclass(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01559}01559\ \ \ \ \ \textcolor{comment}{\#\ Test\ average}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01560}01560\ \ \ \ \ eta0\ =\ 0.001}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01561}01561\ \ \ \ \ nu\ =\ 0.05}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01562}01562\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01563}01563\ \ \ \ \ \textcolor{comment}{\#\ 2\ passes\ over\ the\ training\ set\ but\ average\ only\ at\ second\ pass}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01564}01564\ \ \ \ \ clf1\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01565}01565\ \ \ \ \ \ \ \ \ average=7,\ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},\ eta0=eta0,\ nu=nu,\ max\_iter=2,\ shuffle=\textcolor{keyword}{False}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01566}01566\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01567}01567\ \ \ \ \ \textcolor{comment}{\#\ 1\ pass\ over\ the\ training\ set\ with\ no\ averaging}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01568}01568\ \ \ \ \ clf2\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01569}01569\ \ \ \ \ \ \ \ \ average=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01570}01570\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01571}01571\ \ \ \ \ \ \ \ \ eta0=eta0,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01572}01572\ \ \ \ \ \ \ \ \ nu=nu,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01573}01573\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01574}01574\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01575}01575\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01576}01576\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01577}01577\ \ \ \ \ clf1.fit(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01578}01578\ \ \ \ \ clf2.fit(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01579}01579\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01580}01580\ \ \ \ \ \textcolor{comment}{\#\ Start\ from\ clf2\ solution,\ compute\ averaging\ using\ asgd\ function\ and}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01581}01581\ \ \ \ \ \textcolor{comment}{\#\ compare\ with\ clf1\ solution}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01582}01582\ \ \ \ \ average\_coef,\ average\_offset\ =\ \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a02af4d01757846fc3af4b55bde99efee}{asgd\_oneclass}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01583}01583\ \ \ \ \ \ \ \ \ klass,\ X,\ eta0,\ nu,\ coef\_init=clf2.coef\_.ravel(),\ offset\_init=clf2.offset\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01584}01584\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01585}01585\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01586}01586\ \ \ \ \ assert\_allclose(clf1.coef\_.ravel(),\ average\_coef.ravel())}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01587}01587\ \ \ \ \ assert\_allclose(clf1.offset\_,\ average\_offset)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01588}01588\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01589}01589\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01590}01590\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDOneClassSVM,\ SparseSGDOneClassSVM])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01591}01591\ \textcolor{keyword}{def\ }test\_sgd\_averaged\_computed\_correctly\_oneclass(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01592}01592\ \ \ \ \ \textcolor{comment}{\#\ Tests\ the\ average\ SGD\ One-\/Class\ SVM\ matches\ the\ naive\ implementation}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01593}01593\ \ \ \ \ eta\ =\ 0.001}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01594}01594\ \ \ \ \ nu\ =\ 0.05}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01595}01595\ \ \ \ \ n\_samples\ =\ 20}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01596}01596\ \ \ \ \ n\_features\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01597}01597\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01598}01598\ \ \ \ \ X\ =\ rng.normal(size=(n\_samples,\ n\_features))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01599}01599\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01600}01600\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01601}01601\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01602}01602\ \ \ \ \ \ \ \ \ eta0=eta,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01603}01603\ \ \ \ \ \ \ \ \ nu=nu,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01604}01604\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01605}01605\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01606}01606\ \ \ \ \ \ \ \ \ average=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01607}01607\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01608}01608\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01609}01609\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01610}01610\ \ \ \ \ clf.fit(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01611}01611\ \ \ \ \ average\_coef,\ average\_offset\ =\ \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a02af4d01757846fc3af4b55bde99efee}{asgd\_oneclass}}(klass,\ X,\ eta,\ nu)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01612}01612\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01613}01613\ \ \ \ \ assert\_allclose(clf.coef\_,\ average\_coef)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01614}01614\ \ \ \ \ assert\_allclose(clf.offset\_,\ average\_offset)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01615}01615\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01616}01616\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01617}01617\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDOneClassSVM,\ SparseSGDOneClassSVM])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01618}01618\ \textcolor{keyword}{def\ }test\_sgd\_averaged\_partial\_fit\_oneclass(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01619}01619\ \ \ \ \ \textcolor{comment}{\#\ Tests\ whether\ the\ partial\ fit\ yields\ the\ same\ average\ as\ the\ fit}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01620}01620\ \ \ \ \ eta\ =\ 0.001}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01621}01621\ \ \ \ \ nu\ =\ 0.05}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01622}01622\ \ \ \ \ n\_samples\ =\ 20}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01623}01623\ \ \ \ \ n\_features\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01624}01624\ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01625}01625\ \ \ \ \ X\ =\ rng.normal(size=(n\_samples,\ n\_features))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01626}01626\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01627}01627\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01628}01628\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01629}01629\ \ \ \ \ \ \ \ \ eta0=eta,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01630}01630\ \ \ \ \ \ \ \ \ nu=nu,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01631}01631\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01632}01632\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01633}01633\ \ \ \ \ \ \ \ \ average=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01634}01634\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01635}01635\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01636}01636\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01637}01637\ \ \ \ \ clf.partial\_fit(X[:\ int(n\_samples\ /\ 2)][:])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01638}01638\ \ \ \ \ clf.partial\_fit(X[int(n\_samples\ /\ 2)\ :][:])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01639}01639\ \ \ \ \ average\_coef,\ average\_offset\ =\ \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a02af4d01757846fc3af4b55bde99efee}{asgd\_oneclass}}(klass,\ X,\ eta,\ nu)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01640}01640\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01641}01641\ \ \ \ \ assert\_allclose(clf.coef\_,\ average\_coef)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01642}01642\ \ \ \ \ assert\_allclose(clf.offset\_,\ average\_offset)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01643}01643\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01644}01644\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01645}01645\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}klass"{},\ [SGDOneClassSVM,\ SparseSGDOneClassSVM])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01646}01646\ \textcolor{keyword}{def\ }test\_average\_sparse\_oneclass(klass):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01647}01647\ \ \ \ \ \textcolor{comment}{\#\ Checks\ the\ average\ coef\ on\ data\ with\ 0s}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01648}01648\ \ \ \ \ eta\ =\ 0.001}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01649}01649\ \ \ \ \ nu\ =\ 0.01}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01650}01650\ \ \ \ \ clf\ =\ klass(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01651}01651\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01652}01652\ \ \ \ \ \ \ \ \ eta0=eta,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01653}01653\ \ \ \ \ \ \ \ \ nu=nu,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01654}01654\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01655}01655\ \ \ \ \ \ \ \ \ max\_iter=1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01656}01656\ \ \ \ \ \ \ \ \ average=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01657}01657\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01658}01658\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01659}01659\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01660}01660\ \ \ \ \ n\_samples\ =\ X3.shape[0]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01661}01661\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01662}01662\ \ \ \ \ clf.partial\_fit(X3[:\ int(n\_samples\ /\ 2)])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01663}01663\ \ \ \ \ clf.partial\_fit(X3[int(n\_samples\ /\ 2)\ :])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01664}01664\ \ \ \ \ average\_coef,\ average\_offset\ =\ \mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a02af4d01757846fc3af4b55bde99efee}{asgd\_oneclass}}(klass,\ X3,\ eta,\ nu)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01665}01665\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01666}01666\ \ \ \ \ assert\_allclose(clf.coef\_,\ average\_coef)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01667}01667\ \ \ \ \ assert\_allclose(clf.offset\_,\ average\_offset)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01668}01668\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01669}01669\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01670}01670\ \textcolor{keyword}{def\ }test\_sgd\_oneclass():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01671}01671\ \ \ \ \ \textcolor{comment}{\#\ Test\ fit,\ decision\_function,\ predict\ and\ score\_samples\ on\ a\ toy}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01672}01672\ \ \ \ \ \textcolor{comment}{\#\ dataset}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01673}01673\ \ \ \ \ X\_train\ =\ np.array([[-\/2,\ -\/1],\ [-\/1,\ -\/1],\ [1,\ 1]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01674}01674\ \ \ \ \ X\_test\ =\ np.array([[0.5,\ -\/2],\ [2,\ 2]])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01675}01675\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDOneClassSVM}{SGDOneClassSVM}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01676}01676\ \ \ \ \ \ \ \ \ nu=0.5,\ eta0=1,\ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},\ shuffle=\textcolor{keyword}{False},\ max\_iter=1}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01677}01677\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01678}01678\ \ \ \ \ clf.fit(X\_train)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01679}01679\ \ \ \ \ assert\_allclose(clf.coef\_,\ np.array([-\/0.125,\ 0.4375]))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01680}01680\ \ \ \ \ \textcolor{keyword}{assert}\ clf.offset\_[0]\ ==\ -\/0.5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01681}01681\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01682}01682\ \ \ \ \ scores\ =\ clf.score\_samples(X\_test)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01683}01683\ \ \ \ \ assert\_allclose(scores,\ np.array([-\/0.9375,\ 0.625]))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01684}01684\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01685}01685\ \ \ \ \ dec\ =\ clf.score\_samples(X\_test)\ -\/\ clf.offset\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01686}01686\ \ \ \ \ assert\_allclose(clf.decision\_function(X\_test),\ dec)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01687}01687\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01688}01688\ \ \ \ \ pred\ =\ clf.predict(X\_test)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01689}01689\ \ \ \ \ assert\_array\_equal(pred,\ np.array([-\/1,\ 1]))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01690}01690\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01691}01691\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01692}01692\ \textcolor{keyword}{def\ }test\_ocsvm\_vs\_sgdocsvm():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01693}01693\ \ \ \ \ \textcolor{comment}{\#\ Checks\ SGDOneClass\ SVM\ gives\ a\ good\ approximation\ of\ kernelized}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01694}01694\ \ \ \ \ \textcolor{comment}{\#\ One-\/Class\ SVM}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01695}01695\ \ \ \ \ nu\ =\ 0.05}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01696}01696\ \ \ \ \ gamma\ =\ 2.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01697}01697\ \ \ \ \ random\_state\ =\ 42}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01698}01698\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01699}01699\ \ \ \ \ \textcolor{comment}{\#\ Generate\ train\ and\ test\ data}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01700}01700\ \ \ \ \ rng\ =\ np.random.RandomState(random\_state)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01701}01701\ \ \ \ \ X\ =\ 0.3\ *\ rng.randn(500,\ 2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01702}01702\ \ \ \ \ X\_train\ =\ np.r\_[X\ +\ 2,\ X\ -\/\ 2]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01703}01703\ \ \ \ \ X\ =\ 0.3\ *\ rng.randn(100,\ 2)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01704}01704\ \ \ \ \ X\_test\ =\ np.r\_[X\ +\ 2,\ X\ -\/\ 2]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01705}01705\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01706}01706\ \ \ \ \ \textcolor{comment}{\#\ One-\/Class\ SVM}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01707}01707\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1svm_1_1__classes_1_1OneClassSVM}{OneClassSVM}}(gamma=gamma,\ kernel=\textcolor{stringliteral}{"{}rbf"{}},\ nu=nu)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01708}01708\ \ \ \ \ clf.fit(X\_train)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01709}01709\ \ \ \ \ y\_pred\_ocsvm\ =\ clf.predict(X\_test)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01710}01710\ \ \ \ \ dec\_ocsvm\ =\ clf.decision\_function(X\_test).reshape(1,\ -\/1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01711}01711\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01712}01712\ \ \ \ \ \textcolor{comment}{\#\ SGDOneClassSVM\ using\ kernel\ approximation}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01713}01713\ \ \ \ \ max\_iter\ =\ 15}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01714}01714\ \ \ \ \ transform\ =\ \mbox{\hyperlink{classsklearn_1_1kernel__approximation_1_1Nystroem}{Nystroem}}(gamma=gamma,\ random\_state=random\_state)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01715}01715\ \ \ \ \ clf\_sgd\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDOneClassSVM}{SGDOneClassSVM}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01716}01716\ \ \ \ \ \ \ \ \ nu=nu,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01717}01717\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01718}01718\ \ \ \ \ \ \ \ \ fit\_intercept=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01719}01719\ \ \ \ \ \ \ \ \ max\_iter=max\_iter,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01720}01720\ \ \ \ \ \ \ \ \ random\_state=random\_state,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01721}01721\ \ \ \ \ \ \ \ \ tol=\textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01722}01722\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01723}01723\ \ \ \ \ pipe\_sgd\ =\ make\_pipeline(transform,\ clf\_sgd)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01724}01724\ \ \ \ \ pipe\_sgd.fit(X\_train)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01725}01725\ \ \ \ \ y\_pred\_sgdocsvm\ =\ pipe\_sgd.predict(X\_test)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01726}01726\ \ \ \ \ dec\_sgdocsvm\ =\ pipe\_sgd.decision\_function(X\_test).reshape(1,\ -\/1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01727}01727\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01728}01728\ \ \ \ \ \textcolor{keyword}{assert}\ np.mean(y\_pred\_sgdocsvm\ ==\ y\_pred\_ocsvm)\ >=\ 0.99}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01729}01729\ \ \ \ \ corrcoef\ =\ np.corrcoef(np.concatenate((dec\_ocsvm,\ dec\_sgdocsvm)))[0,\ 1]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01730}01730\ \ \ \ \ \textcolor{keyword}{assert}\ corrcoef\ >=\ 0.9}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01731}01731\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01732}01732\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01733}01733\ \textcolor{keyword}{def\ }test\_l1\_ratio():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01734}01734\ \ \ \ \ \textcolor{comment}{\#\ Test\ if\ l1\ ratio\ extremes\ match\ L1\ and\ L2\ penalty\ settings.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01735}01735\ \ \ \ \ X,\ y\ =\ datasets.make\_classification(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01736}01736\ \ \ \ \ \ \ \ \ n\_samples=1000,\ n\_features=100,\ n\_informative=20,\ random\_state=1234}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01737}01737\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01738}01738\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01739}01739\ \ \ \ \ \textcolor{comment}{\#\ test\ if\ elasticnet\ with\ l1\_ratio\ near\ 1\ gives\ same\ result\ as\ pure\ l1}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01740}01740\ \ \ \ \ est\_en\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01741}01741\ \ \ \ \ \ \ \ \ alpha=0.001,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01742}01742\ \ \ \ \ \ \ \ \ penalty=\textcolor{stringliteral}{"{}elasticnet"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01743}01743\ \ \ \ \ \ \ \ \ tol=\textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01744}01744\ \ \ \ \ \ \ \ \ max\_iter=6,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01745}01745\ \ \ \ \ \ \ \ \ l1\_ratio=0.9999999999,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01746}01746\ \ \ \ \ \ \ \ \ random\_state=42,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01747}01747\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01748}01748\ \ \ \ \ est\_l1\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01749}01749\ \ \ \ \ \ \ \ \ alpha=0.001,\ penalty=\textcolor{stringliteral}{"{}l1"{}},\ max\_iter=6,\ random\_state=42,\ tol=\textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01750}01750\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01751}01751\ \ \ \ \ assert\_array\_almost\_equal(est\_en.coef\_,\ est\_l1.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01752}01752\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01753}01753\ \ \ \ \ \textcolor{comment}{\#\ test\ if\ elasticnet\ with\ l1\_ratio\ near\ 0\ gives\ same\ result\ as\ pure\ l2}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01754}01754\ \ \ \ \ est\_en\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01755}01755\ \ \ \ \ \ \ \ \ alpha=0.001,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01756}01756\ \ \ \ \ \ \ \ \ penalty=\textcolor{stringliteral}{"{}elasticnet"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01757}01757\ \ \ \ \ \ \ \ \ tol=\textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01758}01758\ \ \ \ \ \ \ \ \ max\_iter=6,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01759}01759\ \ \ \ \ \ \ \ \ l1\_ratio=0.0000000001,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01760}01760\ \ \ \ \ \ \ \ \ random\_state=42,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01761}01761\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01762}01762\ \ \ \ \ est\_l2\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01763}01763\ \ \ \ \ \ \ \ \ alpha=0.001,\ penalty=\textcolor{stringliteral}{"{}l2"{}},\ max\_iter=6,\ random\_state=42,\ tol=\textcolor{keywordtype}{None}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01764}01764\ \ \ \ \ ).fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01765}01765\ \ \ \ \ assert\_array\_almost\_equal(est\_en.coef\_,\ est\_l2.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01766}01766\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01767}01767\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01768}01768\ \textcolor{keyword}{def\ }test\_underflow\_or\_overlow():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01769}01769\ \ \ \ \ \textcolor{keyword}{with}\ np.errstate(all=\textcolor{stringliteral}{"{}raise"{}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01770}01770\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Generate\ some\ weird\ data\ with\ hugely\ unscaled\ features}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01771}01771\ \ \ \ \ \ \ \ \ rng\ =\ np.random.RandomState(0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01772}01772\ \ \ \ \ \ \ \ \ n\_samples\ =\ 100}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01773}01773\ \ \ \ \ \ \ \ \ n\_features\ =\ 10}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01774}01774\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01775}01775\ \ \ \ \ \ \ \ \ X\ =\ rng.normal(size=(n\_samples,\ n\_features))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01776}01776\ \ \ \ \ \ \ \ \ X[:,\ :2]\ *=\ 1e300}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01777}01777\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ np.isfinite(X).all()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01778}01778\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01779}01779\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Use\ MinMaxScaler\ to\ scale\ the\ data\ without\ introducing\ a\ numerical}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01780}01780\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ instability\ (computing\ the\ standard\ deviation\ naively\ is\ not\ possible}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01781}01781\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ on\ this\ data)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01782}01782\ \ \ \ \ \ \ \ \ X\_scaled\ =\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__data_1_1MinMaxScaler}{MinMaxScaler}}().fit\_transform(X)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01783}01783\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ np.isfinite(X\_scaled).all()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01784}01784\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01785}01785\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Define\ a\ ground\ truth\ on\ the\ scaled\ data}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01786}01786\ \ \ \ \ \ \ \ \ ground\_truth\ =\ rng.normal(size=n\_features)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01787}01787\ \ \ \ \ \ \ \ \ y\ =\ (np.dot(X\_scaled,\ ground\_truth)\ >\ 0.0).astype(np.int32)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01788}01788\ \ \ \ \ \ \ \ \ assert\_array\_equal(np.unique(y),\ [0,\ 1])}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01789}01789\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01790}01790\ \ \ \ \ \ \ \ \ model\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(alpha=0.1,\ loss=\textcolor{stringliteral}{"{}squared\_hinge"{}},\ max\_iter=500)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01791}01791\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01792}01792\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ smoke\ test:\ model\ is\ stable\ on\ scaled\ data}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01793}01793\ \ \ \ \ \ \ \ \ model.fit(X\_scaled,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01794}01794\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ np.isfinite(model.coef\_).all()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01795}01795\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01796}01796\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ model\ is\ numerically\ unstable\ on\ unscaled\ data}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01797}01797\ \ \ \ \ \ \ \ \ msg\_regxp\ =\ (}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01798}01798\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{r"{}Floating-\/point\ under-\//overflow\ occurred\ at\ epoch\ \#.*"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01799}01799\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\ Scaling\ input\ data\ with\ StandardScaler\ or\ MinMaxScaler"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01800}01800\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\ might\ help."{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01801}01801\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01802}01802\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=msg\_regxp):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01803}01803\ \ \ \ \ \ \ \ \ \ \ \ \ model.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01804}01804\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01805}01805\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01806}01806\ \textcolor{keyword}{def\ }test\_numerical\_stability\_large\_gradient():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01807}01807\ \ \ \ \ \textcolor{comment}{\#\ Non\ regression\ test\ case\ for\ numerical\ stability\ on\ scaled\ problems}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01808}01808\ \ \ \ \ \textcolor{comment}{\#\ where\ the\ gradient\ can\ still\ explode\ with\ some\ losses}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01809}01809\ \ \ \ \ model\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01810}01810\ \ \ \ \ \ \ \ \ loss=\textcolor{stringliteral}{"{}squared\_hinge"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01811}01811\ \ \ \ \ \ \ \ \ max\_iter=10,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01812}01812\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01813}01813\ \ \ \ \ \ \ \ \ penalty=\textcolor{stringliteral}{"{}elasticnet"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01814}01814\ \ \ \ \ \ \ \ \ l1\_ratio=0.3,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01815}01815\ \ \ \ \ \ \ \ \ alpha=0.01,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01816}01816\ \ \ \ \ \ \ \ \ eta0=0.001,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01817}01817\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01818}01818\ \ \ \ \ \ \ \ \ tol=\textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01819}01819\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01820}01820\ \ \ \ \ \textcolor{keyword}{with}\ np.errstate(all=\textcolor{stringliteral}{"{}raise"{}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01821}01821\ \ \ \ \ \ \ \ \ model.fit(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01822}01822\ \ \ \ \ \textcolor{keyword}{assert}\ np.isfinite(model.coef\_).all()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01823}01823\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01824}01824\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01825}01825\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}penalty"{},\ ["{}l2"{},\ "{}l1"{},\ "{}elasticnet"{}])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01826}01826\ \textcolor{keyword}{def\ }test\_large\_regularization(penalty):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01827}01827\ \ \ \ \ \textcolor{comment}{\#\ Non\ regression\ tests\ for\ numerical\ stability\ issues\ caused\ by\ large}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01828}01828\ \ \ \ \ \textcolor{comment}{\#\ regularization\ parameters}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01829}01829\ \ \ \ \ model\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01830}01830\ \ \ \ \ \ \ \ \ alpha=1e5,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01831}01831\ \ \ \ \ \ \ \ \ learning\_rate=\textcolor{stringliteral}{"{}constant"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01832}01832\ \ \ \ \ \ \ \ \ eta0=0.1,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01833}01833\ \ \ \ \ \ \ \ \ penalty=penalty,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01834}01834\ \ \ \ \ \ \ \ \ shuffle=\textcolor{keyword}{False},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01835}01835\ \ \ \ \ \ \ \ \ tol=\textcolor{keywordtype}{None},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01836}01836\ \ \ \ \ \ \ \ \ max\_iter=6,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01837}01837\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01838}01838\ \ \ \ \ \textcolor{keyword}{with}\ np.errstate(all=\textcolor{stringliteral}{"{}raise"{}}):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01839}01839\ \ \ \ \ \ \ \ \ model.fit(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01840}01840\ \ \ \ \ assert\_array\_almost\_equal(model.coef\_,\ np.zeros\_like(model.coef\_))}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01841}01841\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01842}01842\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01843}01843\ \textcolor{keyword}{def\ }test\_tol\_parameter():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01844}01844\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ the\ tol\ parameter\ behaves\ as\ expected}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01845}01845\ \ \ \ \ X\ =\ \mbox{\hyperlink{classsklearn_1_1preprocessing_1_1__data_1_1StandardScaler}{StandardScaler}}().fit\_transform(iris.data)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01846}01846\ \ \ \ \ y\ =\ iris.target\ ==\ 1}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01847}01847\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01848}01848\ \ \ \ \ \textcolor{comment}{\#\ With\ tol\ is\ None,\ the\ number\ of\ iteration\ should\ be\ equal\ to\ max\_iter}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01849}01849\ \ \ \ \ max\_iter\ =\ 42}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01850}01850\ \ \ \ \ model\_0\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(tol=\textcolor{keywordtype}{None},\ random\_state=0,\ max\_iter=max\_iter)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01851}01851\ \ \ \ \ model\_0.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01852}01852\ \ \ \ \ \textcolor{keyword}{assert}\ max\_iter\ ==\ model\_0.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01853}01853\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01854}01854\ \ \ \ \ \textcolor{comment}{\#\ If\ tol\ is\ not\ None,\ the\ number\ of\ iteration\ should\ be\ less\ than\ max\_iter}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01855}01855\ \ \ \ \ max\_iter\ =\ 2000}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01856}01856\ \ \ \ \ model\_1\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(tol=0,\ random\_state=0,\ max\_iter=max\_iter)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01857}01857\ \ \ \ \ model\_1.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01858}01858\ \ \ \ \ \textcolor{keyword}{assert}\ max\_iter\ >\ model\_1.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01859}01859\ \ \ \ \ \textcolor{keyword}{assert}\ model\_1.n\_iter\_\ >\ 5}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01860}01860\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01861}01861\ \ \ \ \ \textcolor{comment}{\#\ A\ larger\ tol\ should\ yield\ a\ smaller\ number\ of\ iteration}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01862}01862\ \ \ \ \ model\_2\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(tol=0.1,\ random\_state=0,\ max\_iter=max\_iter)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01863}01863\ \ \ \ \ model\_2.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01864}01864\ \ \ \ \ \textcolor{keyword}{assert}\ model\_1.n\_iter\_\ >\ model\_2.n\_iter\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01865}01865\ \ \ \ \ \textcolor{keyword}{assert}\ model\_2.n\_iter\_\ >\ 3}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01866}01866\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01867}01867\ \ \ \ \ \textcolor{comment}{\#\ Strict\ tolerance\ and\ small\ max\_iter\ should\ trigger\ a\ warning}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01868}01868\ \ \ \ \ model\_3\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(max\_iter=3,\ tol=1e-\/3,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01869}01869\ \ \ \ \ warning\_message\ =\ (}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01870}01870\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}Maximum\ number\ of\ iteration\ reached\ before\ "{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01871}01871\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}convergence.\ Consider\ increasing\ max\_iter\ to\ "{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01872}01872\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}improve\ the\ fit."{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01873}01873\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01874}01874\ \ \ \ \ \textcolor{keyword}{with}\ pytest.warns(ConvergenceWarning,\ match=warning\_message):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01875}01875\ \ \ \ \ \ \ \ \ model\_3.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01876}01876\ \ \ \ \ \textcolor{keyword}{assert}\ model\_3.n\_iter\_\ ==\ 3}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01877}01877\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01878}01878\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01879}01879\ \textcolor{keyword}{def\ }\_test\_loss\_common(loss\_function,\ cases):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01880}01880\ \ \ \ \ \textcolor{comment}{\#\ Test\ the\ different\ loss\ functions}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01881}01881\ \ \ \ \ \textcolor{comment}{\#\ cases\ is\ a\ list\ of\ (p,\ y,\ expected)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01882}01882\ \ \ \ \ \textcolor{keywordflow}{for}\ p,\ y,\ expected\_loss,\ expected\_dloss\ \textcolor{keywordflow}{in}\ cases:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01883}01883\ \ \ \ \ \ \ \ \ assert\_almost\_equal(loss\_function.py\_loss(p,\ y),\ expected\_loss)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01884}01884\ \ \ \ \ \ \ \ \ assert\_almost\_equal(loss\_function.py\_dloss(p,\ y),\ expected\_dloss)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01885}01885\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01886}01886\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01887}01887\ \textcolor{keyword}{def\ }test\_loss\_hinge():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01888}01888\ \ \ \ \ \textcolor{comment}{\#\ Test\ Hinge\ (hinge\ /\ perceptron)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01889}01889\ \ \ \ \ \textcolor{comment}{\#\ hinge}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01890}01890\ \ \ \ \ loss\ =\ sgd\_fast.Hinge(1.0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01891}01891\ \ \ \ \ cases\ =\ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01892}01892\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ (p,\ y,\ expected\_loss,\ expected\_dloss)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01893}01893\ \ \ \ \ \ \ \ \ (1.1,\ 1.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01894}01894\ \ \ \ \ \ \ \ \ (-\/2.0,\ -\/1.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01895}01895\ \ \ \ \ \ \ \ \ (1.0,\ 1.0,\ 0.0,\ -\/1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01896}01896\ \ \ \ \ \ \ \ \ (-\/1.0,\ -\/1.0,\ 0.0,\ 1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01897}01897\ \ \ \ \ \ \ \ \ (0.5,\ 1.0,\ 0.5,\ -\/1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01898}01898\ \ \ \ \ \ \ \ \ (2.0,\ -\/1.0,\ 3.0,\ 1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01899}01899\ \ \ \ \ \ \ \ \ (-\/0.5,\ -\/1.0,\ 0.5,\ 1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01900}01900\ \ \ \ \ \ \ \ \ (0.0,\ 1.0,\ 1,\ -\/1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01901}01901\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01902}01902\ \ \ \ \ \_test\_loss\_common(loss,\ cases)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01903}01903\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01904}01904\ \ \ \ \ \textcolor{comment}{\#\ perceptron}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01905}01905\ \ \ \ \ loss\ =\ sgd\_fast.Hinge(0.0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01906}01906\ \ \ \ \ cases\ =\ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01907}01907\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ (p,\ y,\ expected\_loss,\ expected\_dloss)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01908}01908\ \ \ \ \ \ \ \ \ (1.0,\ 1.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01909}01909\ \ \ \ \ \ \ \ \ (-\/0.1,\ -\/1.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01910}01910\ \ \ \ \ \ \ \ \ (0.0,\ 1.0,\ 0.0,\ -\/1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01911}01911\ \ \ \ \ \ \ \ \ (0.0,\ -\/1.0,\ 0.0,\ 1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01912}01912\ \ \ \ \ \ \ \ \ (0.5,\ -\/1.0,\ 0.5,\ 1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01913}01913\ \ \ \ \ \ \ \ \ (2.0,\ -\/1.0,\ 2.0,\ 1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01914}01914\ \ \ \ \ \ \ \ \ (-\/0.5,\ 1.0,\ 0.5,\ -\/1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01915}01915\ \ \ \ \ \ \ \ \ (-\/1.0,\ 1.0,\ 1.0,\ -\/1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01916}01916\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01917}01917\ \ \ \ \ \_test\_loss\_common(loss,\ cases)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01918}01918\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01919}01919\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01920}01920\ \textcolor{keyword}{def\ }test\_gradient\_squared\_hinge():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01921}01921\ \ \ \ \ \textcolor{comment}{\#\ Test\ SquaredHinge}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01922}01922\ \ \ \ \ loss\ =\ sgd\_fast.SquaredHinge(1.0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01923}01923\ \ \ \ \ cases\ =\ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01924}01924\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ (p,\ y,\ expected\_loss,\ expected\_dloss)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01925}01925\ \ \ \ \ \ \ \ \ (1.0,\ 1.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01926}01926\ \ \ \ \ \ \ \ \ (-\/2.0,\ -\/1.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01927}01927\ \ \ \ \ \ \ \ \ (1.0,\ -\/1.0,\ 4.0,\ 4.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01928}01928\ \ \ \ \ \ \ \ \ (-\/1.0,\ 1.0,\ 4.0,\ -\/4.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01929}01929\ \ \ \ \ \ \ \ \ (0.5,\ 1.0,\ 0.25,\ -\/1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01930}01930\ \ \ \ \ \ \ \ \ (0.5,\ -\/1.0,\ 2.25,\ 3.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01931}01931\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01932}01932\ \ \ \ \ \_test\_loss\_common(loss,\ cases)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01933}01933\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01934}01934\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01935}01935\ \textcolor{keyword}{def\ }test\_loss\_modified\_huber():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01936}01936\ \ \ \ \ \textcolor{comment}{\#\ (p,\ y,\ expected\_loss,\ expected\_dloss)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01937}01937\ \ \ \ \ loss\ =\ sgd\_fast.ModifiedHuber()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01938}01938\ \ \ \ \ cases\ =\ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01939}01939\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ (p,\ y,\ expected\_loss,\ expected\_dloss)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01940}01940\ \ \ \ \ \ \ \ \ (1.0,\ 1.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01941}01941\ \ \ \ \ \ \ \ \ (-\/1.0,\ -\/1.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01942}01942\ \ \ \ \ \ \ \ \ (2.0,\ 1.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01943}01943\ \ \ \ \ \ \ \ \ (0.0,\ 1.0,\ 1.0,\ -\/2.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01944}01944\ \ \ \ \ \ \ \ \ (-\/1.0,\ 1.0,\ 4.0,\ -\/4.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01945}01945\ \ \ \ \ \ \ \ \ (0.5,\ -\/1.0,\ 2.25,\ 3.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01946}01946\ \ \ \ \ \ \ \ \ (-\/2.0,\ 1.0,\ 8,\ -\/4.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01947}01947\ \ \ \ \ \ \ \ \ (-\/3.0,\ 1.0,\ 12,\ -\/4.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01948}01948\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01949}01949\ \ \ \ \ \_test\_loss\_common(loss,\ cases)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01950}01950\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01951}01951\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01952}01952\ \textcolor{keyword}{def\ }test\_loss\_epsilon\_insensitive():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01953}01953\ \ \ \ \ \textcolor{comment}{\#\ Test\ EpsilonInsensitive}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01954}01954\ \ \ \ \ loss\ =\ sgd\_fast.EpsilonInsensitive(0.1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01955}01955\ \ \ \ \ cases\ =\ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01956}01956\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ (p,\ y,\ expected\_loss,\ expected\_dloss)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01957}01957\ \ \ \ \ \ \ \ \ (0.0,\ 0.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01958}01958\ \ \ \ \ \ \ \ \ (0.1,\ 0.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01959}01959\ \ \ \ \ \ \ \ \ (-\/2.05,\ -\/2.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01960}01960\ \ \ \ \ \ \ \ \ (3.05,\ 3.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01961}01961\ \ \ \ \ \ \ \ \ (2.2,\ 2.0,\ 0.1,\ 1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01962}01962\ \ \ \ \ \ \ \ \ (2.0,\ -\/1.0,\ 2.9,\ 1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01963}01963\ \ \ \ \ \ \ \ \ (2.0,\ 2.2,\ 0.1,\ -\/1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01964}01964\ \ \ \ \ \ \ \ \ (-\/2.0,\ 1.0,\ 2.9,\ -\/1.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01965}01965\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01966}01966\ \ \ \ \ \_test\_loss\_common(loss,\ cases)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01967}01967\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01968}01968\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01969}01969\ \textcolor{keyword}{def\ }test\_loss\_squared\_epsilon\_insensitive():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01970}01970\ \ \ \ \ \textcolor{comment}{\#\ Test\ SquaredEpsilonInsensitive}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01971}01971\ \ \ \ \ loss\ =\ sgd\_fast.SquaredEpsilonInsensitive(0.1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01972}01972\ \ \ \ \ cases\ =\ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01973}01973\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ (p,\ y,\ expected\_loss,\ expected\_dloss)}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01974}01974\ \ \ \ \ \ \ \ \ (0.0,\ 0.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01975}01975\ \ \ \ \ \ \ \ \ (0.1,\ 0.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01976}01976\ \ \ \ \ \ \ \ \ (-\/2.05,\ -\/2.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01977}01977\ \ \ \ \ \ \ \ \ (3.05,\ 3.0,\ 0.0,\ 0.0),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01978}01978\ \ \ \ \ \ \ \ \ (2.2,\ 2.0,\ 0.01,\ 0.2),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01979}01979\ \ \ \ \ \ \ \ \ (2.0,\ -\/1.0,\ 8.41,\ 5.8),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01980}01980\ \ \ \ \ \ \ \ \ (2.0,\ 2.2,\ 0.01,\ -\/0.2),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01981}01981\ \ \ \ \ \ \ \ \ (-\/2.0,\ 1.0,\ 8.41,\ -\/5.8),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01982}01982\ \ \ \ \ ]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01983}01983\ \ \ \ \ \_test\_loss\_common(loss,\ cases)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01984}01984\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01985}01985\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01986}01986\ \textcolor{keyword}{def\ }test\_multi\_thread\_multi\_class\_and\_early\_stopping():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01987}01987\ \ \ \ \ \textcolor{comment}{\#\ This\ is\ a\ non-\/regression\ test\ for\ a\ bad\ interaction\ between}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01988}01988\ \ \ \ \ \textcolor{comment}{\#\ early\ stopping\ internal\ attribute\ and\ thread-\/based\ parallelism.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01989}01989\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01990}01990\ \ \ \ \ \ \ \ \ alpha=1e-\/3,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01991}01991\ \ \ \ \ \ \ \ \ tol=1e-\/3,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01992}01992\ \ \ \ \ \ \ \ \ max\_iter=1000,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01993}01993\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01994}01994\ \ \ \ \ \ \ \ \ n\_iter\_no\_change=100,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01995}01995\ \ \ \ \ \ \ \ \ random\_state=0,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01996}01996\ \ \ \ \ \ \ \ \ n\_jobs=2,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01997}01997\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01998}01998\ \ \ \ \ clf.fit(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l01999}01999\ \ \ \ \ \textcolor{keyword}{assert}\ clf.n\_iter\_\ >\ clf.n\_iter\_no\_change}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02000}02000\ \ \ \ \ \textcolor{keyword}{assert}\ clf.n\_iter\_\ <\ clf.n\_iter\_no\_change\ +\ 20}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02001}02001\ \ \ \ \ \textcolor{keyword}{assert}\ clf.score(iris.data,\ iris.target)\ >\ 0.8}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02002}02002\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02003}02003\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02004}02004\ \textcolor{keyword}{def\ }test\_multi\_core\_gridsearch\_and\_early\_stopping():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02005}02005\ \ \ \ \ \textcolor{comment}{\#\ This\ is\ a\ non-\/regression\ test\ for\ a\ bad\ interaction\ between}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02006}02006\ \ \ \ \ \textcolor{comment}{\#\ early\ stopping\ internal\ attribute\ and\ process-\/based\ multi-\/core}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02007}02007\ \ \ \ \ \textcolor{comment}{\#\ parallelism.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02008}02008\ \ \ \ \ param\_grid\ =\ \{}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02009}02009\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}alpha"{}}:\ np.logspace(-\/4,\ 4,\ 9),}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02010}02010\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}n\_iter\_no\_change"{}}:\ [5,\ 10,\ 50],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02011}02011\ \ \ \ \ \}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02012}02012\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02013}02013\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(tol=1e-\/2,\ max\_iter=1000,\ early\_stopping=\textcolor{keyword}{True},\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02014}02014\ \ \ \ \ search\ =\ \mbox{\hyperlink{classsklearn_1_1model__selection_1_1__search_1_1RandomizedSearchCV}{RandomizedSearchCV}}(clf,\ param\_grid,\ n\_iter=5,\ n\_jobs=2,\ random\_state=0)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02015}02015\ \ \ \ \ search.fit(iris.data,\ iris.target)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02016}02016\ \ \ \ \ \textcolor{keyword}{assert}\ search.best\_score\_\ >\ 0.8}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02017}02017\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02018}02018\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02019}02019\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}backend"{},\ ["{}loky"{},\ "{}multiprocessing"{},\ "{}threading"{}])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02020}02020\ \textcolor{keyword}{def\ }test\_SGDClassifier\_fit\_for\_all\_backends(backend):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02021}02021\ \ \ \ \ \textcolor{comment}{\#\ This\ is\ a\ non-\/regression\ smoke\ test.\ In\ the\ multi-\/class\ case,}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02022}02022\ \ \ \ \ \textcolor{comment}{\#\ SGDClassifier.fit\ fits\ each\ class\ in\ a\ one-\/versus-\/all\ fashion\ using}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02023}02023\ \ \ \ \ \textcolor{comment}{\#\ joblib.Parallel.\ \ However,\ each\ OvA\ step\ updates\ the\ coef\_\ attribute\ of}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02024}02024\ \ \ \ \ \textcolor{comment}{\#\ the\ estimator\ in-\/place.\ Internally,\ SGDClassifier\ calls\ Parallel\ using}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02025}02025\ \ \ \ \ \textcolor{comment}{\#\ require='sharedmem'.\ This\ test\ makes\ sure\ SGDClassifier.fit\ works}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02026}02026\ \ \ \ \ \textcolor{comment}{\#\ consistently\ even\ when\ the\ user\ asks\ for\ a\ backend\ that\ does\ not\ provide}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02027}02027\ \ \ \ \ \textcolor{comment}{\#\ sharedmem\ semantics.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02028}02028\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02029}02029\ \ \ \ \ \textcolor{comment}{\#\ We\ further\ test\ a\ case\ where\ memmapping\ would\ have\ been\ used\ if}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02030}02030\ \ \ \ \ \textcolor{comment}{\#\ SGDClassifier.fit\ was\ called\ from\ a\ loky\ or\ multiprocessing\ backend.\ In}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02031}02031\ \ \ \ \ \textcolor{comment}{\#\ this\ specific\ case,\ in-\/place\ modification\ of\ clf.coef\_\ would\ have\ caused}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02032}02032\ \ \ \ \ \textcolor{comment}{\#\ a\ segmentation\ fault\ when\ trying\ to\ write\ in\ a\ readonly\ memory\ mapped}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02033}02033\ \ \ \ \ \textcolor{comment}{\#\ buffer.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02034}02034\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02035}02035\ \ \ \ \ random\_state\ =\ np.random.RandomState(42)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02036}02036\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02037}02037\ \ \ \ \ \textcolor{comment}{\#\ Create\ a\ classification\ problem\ with\ 50000\ features\ and\ 20\ classes.\ Using}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02038}02038\ \ \ \ \ \textcolor{comment}{\#\ loky\ or\ multiprocessing\ this\ make\ the\ clf.coef\_\ exceed\ the\ threshold}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02039}02039\ \ \ \ \ \textcolor{comment}{\#\ above\ which\ memmaping\ is\ used\ in\ joblib\ and\ loky\ (1MB\ as\ of\ 2018/11/1).}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02040}02040\ \ \ \ \ X\ =\ sp.random(500,\ 2000,\ density=0.02,\ format=\textcolor{stringliteral}{"{}csr"{}},\ random\_state=random\_state)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02041}02041\ \ \ \ \ y\ =\ random\_state.choice(20,\ 500)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02042}02042\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02043}02043\ \ \ \ \ \textcolor{comment}{\#\ Begin\ by\ fitting\ a\ SGD\ classifier\ sequentially}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02044}02044\ \ \ \ \ clf\_sequential\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(max\_iter=1000,\ n\_jobs=1,\ random\_state=42)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02045}02045\ \ \ \ \ clf\_sequential.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02046}02046\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02047}02047\ \ \ \ \ \textcolor{comment}{\#\ Fit\ a\ SGDClassifier\ using\ the\ specified\ backend,\ and\ make\ sure\ the}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02048}02048\ \ \ \ \ \textcolor{comment}{\#\ coefficients\ are\ equal\ to\ those\ obtained\ using\ a\ sequential\ fit}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02049}02049\ \ \ \ \ clf\_parallel\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{SGDClassifier}}(max\_iter=1000,\ n\_jobs=4,\ random\_state=42)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02050}02050\ \ \ \ \ \textcolor{keyword}{with}\ \mbox{\hyperlink{classjoblib_1_1parallel_1_1parallel__backend}{joblib.parallel\_backend}}(backend=backend):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02051}02051\ \ \ \ \ \ \ \ \ clf\_parallel.fit(X,\ y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02052}02052\ \ \ \ \ assert\_array\_almost\_equal(clf\_sequential.coef\_,\ clf\_parallel.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02053}02053\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02054}02054\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02055}02055\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02056}02056\ \ \ \ \ \textcolor{stringliteral}{"{}Estimator"{}},\ [\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{linear\_model.SGDClassifier}},\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDRegressor}{linear\_model.SGDRegressor}}]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02057}02057\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02058}02058\ \textcolor{keyword}{def\ }test\_sgd\_random\_state(Estimator,\ global\_random\_seed):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02059}02059\ \ \ \ \ \textcolor{comment}{\#\ Train\ the\ same\ model\ on\ the\ same\ data\ without\ converging\ and\ check\ that\ we}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02060}02060\ \ \ \ \ \textcolor{comment}{\#\ get\ reproducible\ results\ by\ fixing\ the\ random\ seed.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02061}02061\ \ \ \ \ \textcolor{keywordflow}{if}\ Estimator\ ==\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDRegressor}{linear\_model.SGDRegressor}}:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02062}02062\ \ \ \ \ \ \ \ \ X,\ y\ =\ datasets.make\_regression(random\_state=global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02063}02063\ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02064}02064\ \ \ \ \ \ \ \ \ X,\ y\ =\ datasets.make\_classification(random\_state=global\_random\_seed)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02065}02065\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02066}02066\ \ \ \ \ \textcolor{comment}{\#\ Fitting\ twice\ a\ model\ with\ the\ same\ hyper-\/parameters\ on\ the\ same\ training}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02067}02067\ \ \ \ \ \textcolor{comment}{\#\ set\ with\ the\ same\ seed\ leads\ to\ the\ same\ results\ deterministically.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02068}02068\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02069}02069\ \ \ \ \ est\ =\ Estimator(random\_state=global\_random\_seed,\ max\_iter=1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02070}02070\ \ \ \ \ \textcolor{keyword}{with}\ pytest.warns(ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02071}02071\ \ \ \ \ \ \ \ \ coef\_same\_seed\_a\ =\ est.fit(X,\ y).coef\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02072}02072\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ est.n\_iter\_\ ==\ 1}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02073}02073\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02074}02074\ \ \ \ \ est\ =\ Estimator(random\_state=global\_random\_seed,\ max\_iter=1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02075}02075\ \ \ \ \ \textcolor{keyword}{with}\ pytest.warns(ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02076}02076\ \ \ \ \ \ \ \ \ coef\_same\_seed\_b\ =\ est.fit(X,\ y).coef\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02077}02077\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ est.n\_iter\_\ ==\ 1}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02078}02078\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02079}02079\ \ \ \ \ assert\_allclose(coef\_same\_seed\_a,\ coef\_same\_seed\_b)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02080}02080\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02081}02081\ \ \ \ \ \textcolor{comment}{\#\ Fitting\ twice\ a\ model\ with\ the\ same\ hyper-\/parameters\ on\ the\ same\ training}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02082}02082\ \ \ \ \ \textcolor{comment}{\#\ set\ but\ with\ different\ random\ seed\ leads\ to\ different\ results\ after\ one}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02083}02083\ \ \ \ \ \textcolor{comment}{\#\ epoch\ because\ of\ the\ random\ shuffling\ of\ the\ dataset.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02084}02084\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02085}02085\ \ \ \ \ est\ =\ Estimator(random\_state=global\_random\_seed\ +\ 1,\ max\_iter=1)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02086}02086\ \ \ \ \ \textcolor{keyword}{with}\ pytest.warns(ConvergenceWarning):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02087}02087\ \ \ \ \ \ \ \ \ coef\_other\_seed\ =\ est.fit(X,\ y).coef\_}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02088}02088\ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ est.n\_iter\_\ ==\ 1}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02089}02089\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02090}02090\ \ \ \ \ \textcolor{keyword}{assert}\ np.abs(coef\_same\_seed\_a\ -\/\ coef\_other\_seed).max()\ >\ 1.0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02091}02091\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02092}02092\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02093}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a9acc61010c48c2065b9dae2657f20ab0}{02093}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a9acc61010c48c2065b9dae2657f20ab0}{test\_validation\_mask\_correctly\_subsets}}(monkeypatch):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02094}02094\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Test\ that\ data\ passed\ to\ validation\ callback\ correctly\ subsets.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02095}02095\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02096}02096\ \textcolor{stringliteral}{\ \ \ \ Non-\/regression\ test\ for\ \#23255.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02097}02097\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02098}02098\ \ \ \ \ X,\ Y\ =\ iris.data,\ iris.target}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02099}02099\ \ \ \ \ n\_samples\ =\ X.shape[0]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02100}02100\ \ \ \ \ validation\_fraction\ =\ 0.2}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02101}02101\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{linear\_model.SGDClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02102}02102\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02103}02103\ \ \ \ \ \ \ \ \ tol=1e-\/3,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02104}02104\ \ \ \ \ \ \ \ \ max\_iter=1000,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02105}02105\ \ \ \ \ \ \ \ \ validation\_fraction=validation\_fraction,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02106}02106\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02107}02107\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02108}02108\ \ \ \ \ mock\ =\ Mock(side\_effect=\mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1__ValidationScoreCallback}{\_stochastic\_gradient.\_ValidationScoreCallback}})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02109}02109\ \ \ \ \ monkeypatch.setattr(\_stochastic\_gradient,\ \textcolor{stringliteral}{"{}\_ValidationScoreCallback"{}},\ mock)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02110}02110\ \ \ \ \ clf.fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02111}02111\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02112}02112\ \ \ \ \ X\_val,\ y\_val\ =\ mock.call\_args[0][1:3]}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02113}02113\ \ \ \ \ \textcolor{keyword}{assert}\ X\_val.shape[0]\ ==\ int(n\_samples\ *\ validation\_fraction)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02114}02114\ \ \ \ \ \textcolor{keyword}{assert}\ y\_val.shape[0]\ ==\ int(n\_samples\ *\ validation\_fraction)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02115}02115\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02116}02116\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02117}02117\ \textcolor{keyword}{def\ }test\_sgd\_error\_on\_zero\_validation\_weight():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02118}02118\ \ \ \ \ \textcolor{comment}{\#\ Test\ that\ SGDClassifier\ raises\ error\ when\ all\ the\ validation\ samples}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02119}02119\ \ \ \ \ \textcolor{comment}{\#\ have\ zero\ sample\_weight.\ Non-\/regression\ test\ for\ \#17229.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02120}02120\ \ \ \ \ X,\ Y\ =\ iris.data,\ iris.target}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02121}02121\ \ \ \ \ sample\_weight\ =\ np.zeros\_like(Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02122}02122\ \ \ \ \ validation\_fraction\ =\ 0.4}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02123}02123\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02124}02124\ \ \ \ \ clf\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDClassifier}{linear\_model.SGDClassifier}}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02125}02125\ \ \ \ \ \ \ \ \ early\_stopping=\textcolor{keyword}{True},\ validation\_fraction=validation\_fraction,\ random\_state=0}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02126}02126\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02127}02127\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02128}02128\ \ \ \ \ error\_message\ =\ (}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02129}02129\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}The\ sample\ weights\ for\ validation\ set\ are\ all\ zero,\ consider\ using\ a"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02130}02130\ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{"{}\ different\ random\ state."{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02131}02131\ \ \ \ \ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02132}02132\ \ \ \ \ \textcolor{keyword}{with}\ pytest.raises(ValueError,\ match=error\_message):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02133}02133\ \ \ \ \ \ \ \ \ clf.fit(X,\ Y,\ sample\_weight=sample\_weight)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02134}02134\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02135}02135\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02136}02136\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}Estimator"{},\ [SGDClassifier,\ SGDRegressor])}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02137}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_ad202300b771877872f944388c9f6e6a5}{02137}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_ad202300b771877872f944388c9f6e6a5}{test\_sgd\_verbose}}(Estimator):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02138}02138\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}non-\/regression\ test\ for\ gh\ \#25249"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02139}02139\ \ \ \ \ Estimator(verbose=1).fit(X,\ Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02140}02140\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02141}02141\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02142}02142\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02143}02143\ \ \ \ \ \textcolor{stringliteral}{"{}SGDEstimator"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02144}02144\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02145}02145\ \ \ \ \ \ \ \ \ SGDClassifier,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02146}02146\ \ \ \ \ \ \ \ \ SparseSGDClassifier,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02147}02147\ \ \ \ \ \ \ \ \ SGDRegressor,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02148}02148\ \ \ \ \ \ \ \ \ SparseSGDRegressor,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02149}02149\ \ \ \ \ \ \ \ \ SGDOneClassSVM,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02150}02150\ \ \ \ \ \ \ \ \ SparseSGDOneClassSVM,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02151}02151\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02152}02152\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02153}02153\ \textcolor{preprocessor}{@pytest.mark.parametrize("{}data\_type"{},\ (np.float32,\ np.float64)})}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02154}02154\ \textcolor{keyword}{def\ }test\_sgd\_dtype\_match(SGDEstimator,\ data\_type):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02155}02155\ \ \ \ \ \_X\ =\ X.astype(data\_type)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02156}02156\ \ \ \ \ \_Y\ =\ np.array(Y,\ dtype=data\_type)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02157}02157\ \ \ \ \ sgd\_model\ =\ SGDEstimator()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02158}02158\ \ \ \ \ sgd\_model.fit(\_X,\ \_Y)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02159}02159\ \ \ \ \ \textcolor{keyword}{assert}\ sgd\_model.coef\_.dtype\ ==\ data\_type}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02160}02160\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02161}02161\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02162}02162\ \textcolor{preprocessor}{@pytest.mark.parametrize}(}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02163}02163\ \ \ \ \ \textcolor{stringliteral}{"{}SGDEstimator"{}},}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02164}02164\ \ \ \ \ [}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02165}02165\ \ \ \ \ \ \ \ \ SGDClassifier,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02166}02166\ \ \ \ \ \ \ \ \ SparseSGDClassifier,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02167}02167\ \ \ \ \ \ \ \ \ SGDRegressor,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02168}02168\ \ \ \ \ \ \ \ \ SparseSGDRegressor,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02169}02169\ \ \ \ \ \ \ \ \ SGDOneClassSVM,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02170}02170\ \ \ \ \ \ \ \ \ SparseSGDOneClassSVM,}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02171}02171\ \ \ \ \ ],}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02172}02172\ )}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02173}02173\ \textcolor{keyword}{def\ }test\_sgd\_numerical\_consistency(SGDEstimator):}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02174}02174\ \ \ \ \ X\_64\ =\ X.astype(dtype=np.float64)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02175}02175\ \ \ \ \ Y\_64\ =\ np.array(Y,\ dtype=np.float64)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02176}02176\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02177}02177\ \ \ \ \ X\_32\ =\ X.astype(dtype=np.float32)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02178}02178\ \ \ \ \ Y\_32\ =\ np.array(Y,\ dtype=np.float32)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02179}02179\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02180}02180\ \ \ \ \ sgd\_64\ =\ SGDEstimator(max\_iter=20)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02181}02181\ \ \ \ \ sgd\_64.fit(X\_64,\ Y\_64)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02182}02182\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02183}02183\ \ \ \ \ sgd\_32\ =\ SGDEstimator(max\_iter=20)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02184}02184\ \ \ \ \ sgd\_32.fit(X\_32,\ Y\_32)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02185}02185\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02186}02186\ \ \ \ \ assert\_allclose(sgd\_64.coef\_,\ sgd\_32.coef\_)}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02187}02187\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02188}02188\ }
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02189}\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a9f97312eeeb0e215cca1063077b624d0}{02189}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesklearn_1_1linear__model_1_1tests_1_1test__sgd_a9f97312eeeb0e215cca1063077b624d0}{test\_sgd\_one\_class\_svm\_estimator\_type}}():}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02190}02190\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}Check\ that\ SGDOneClassSVM\ has\ the\ correct\ estimator\ type.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02191}02191\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02192}02192\ \textcolor{stringliteral}{\ \ \ \ Non-\/regression\ test\ for\ if\ the\ mixin\ was\ not\ on\ the\ left.}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02193}02193\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02194}02194\ \ \ \ \ sgd\_ocsvm\ =\ \mbox{\hyperlink{classsklearn_1_1linear__model_1_1__stochastic__gradient_1_1SGDOneClassSVM}{SGDOneClassSVM}}()}
\DoxyCodeLine{\Hypertarget{test__sgd_8py_source_l02195}02195\ \ \ \ \ \textcolor{keyword}{assert}\ get\_tags(sgd\_ocsvm).estimator\_type\ ==\ \textcolor{stringliteral}{"{}outlier\_detector"{}}}

\end{DoxyCode}
