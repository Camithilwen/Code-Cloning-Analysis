\doxysection{sklearn.\+manifold.\+\_\+locally\+\_\+linear Namespace Reference}
\hypertarget{namespacesklearn_1_1manifold_1_1__locally__linear}{}\label{namespacesklearn_1_1manifold_1_1__locally__linear}\index{sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}}
\doxysubsubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{classsklearn_1_1manifold_1_1__locally__linear_1_1LocallyLinearEmbedding}{Locally\+Linear\+Embedding}}
\end{DoxyCompactItemize}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacesklearn_1_1manifold_1_1__locally__linear_a54d10d8b2cb41cf4a6bb1ce465336f70}{barycenter\+\_\+weights}} (X, Y, indices, reg=1e-\/3)
\item 
\mbox{\hyperlink{namespacesklearn_1_1manifold_1_1__locally__linear_a28d74ad2b04cf9efd21547a612bcdc0a}{barycenter\+\_\+kneighbors\+\_\+graph}} (X, n\+\_\+neighbors, reg=1e-\/3, n\+\_\+jobs=None)
\item 
\mbox{\hyperlink{namespacesklearn_1_1manifold_1_1__locally__linear_ae9628b4f26e82cee77c287a7fc60516b}{null\+\_\+space}} (M, k, k\+\_\+skip=1, eigen\+\_\+solver="{}arpack"{}, tol=1e-\/6, max\+\_\+iter=100, random\+\_\+state=None)
\item 
\mbox{\hyperlink{namespacesklearn_1_1manifold_1_1__locally__linear_a117303b996f164ad3939e4f3b9fb4a21}{\+\_\+locally\+\_\+linear\+\_\+embedding}} (X, \texorpdfstring{$\ast$}{*}, n\+\_\+neighbors, n\+\_\+components, reg=1e-\/3, eigen\+\_\+solver="{}auto"{}, tol=1e-\/6, max\+\_\+iter=100, method="{}standard"{}, hessian\+\_\+tol=1e-\/4, modified\+\_\+tol=1e-\/12, random\+\_\+state=None, n\+\_\+jobs=None)
\item 
\mbox{\hyperlink{namespacesklearn_1_1manifold_1_1__locally__linear_a3975e88970c93d695cdd76716336f05e}{locally\+\_\+linear\+\_\+embedding}} (X, \texorpdfstring{$\ast$}{*}, n\+\_\+neighbors, n\+\_\+components, reg=1e-\/3, eigen\+\_\+solver="{}auto"{}, tol=1e-\/6, max\+\_\+iter=100, method="{}standard"{}, hessian\+\_\+tol=1e-\/4, modified\+\_\+tol=1e-\/12, random\+\_\+state=None, n\+\_\+jobs=None)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Locally Linear Embedding\end{DoxyVerb}
 

\doxysubsection{Function Documentation}
\Hypertarget{namespacesklearn_1_1manifold_1_1__locally__linear_a117303b996f164ad3939e4f3b9fb4a21}\index{sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}!\_locally\_linear\_embedding@{\_locally\_linear\_embedding}}
\index{\_locally\_linear\_embedding@{\_locally\_linear\_embedding}!sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}}
\doxysubsubsection{\texorpdfstring{\_locally\_linear\_embedding()}{\_locally\_linear\_embedding()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1manifold_1_1__locally__linear_a117303b996f164ad3939e4f3b9fb4a21} 
sklearn.\+manifold.\+\_\+locally\+\_\+linear.\+\_\+locally\+\_\+linear\+\_\+embedding (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{n\+\_\+neighbors}{, }\item[{}]{n\+\_\+components}{, }\item[{}]{reg}{ = {\ttfamily 1e-\/3}, }\item[{}]{eigen\+\_\+solver}{ = {\ttfamily "{}auto"{}}, }\item[{}]{tol}{ = {\ttfamily 1e-\/6}, }\item[{}]{max\+\_\+iter}{ = {\ttfamily 100}, }\item[{}]{method}{ = {\ttfamily "{}standard"{}}, }\item[{}]{hessian\+\_\+tol}{ = {\ttfamily 1e-\/4}, }\item[{}]{modified\+\_\+tol}{ = {\ttfamily 1e-\/12}, }\item[{}]{random\+\_\+state}{ = {\ttfamily None}, }\item[{}]{n\+\_\+jobs}{ = {\ttfamily None}}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Definition at line \mbox{\hyperlink{__locally__linear_8py_source_l00200}{200}} of file \mbox{\hyperlink{__locally__linear_8py_source}{\+\_\+locally\+\_\+linear.\+py}}.

\Hypertarget{namespacesklearn_1_1manifold_1_1__locally__linear_a28d74ad2b04cf9efd21547a612bcdc0a}\index{sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}!barycenter\_kneighbors\_graph@{barycenter\_kneighbors\_graph}}
\index{barycenter\_kneighbors\_graph@{barycenter\_kneighbors\_graph}!sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}}
\doxysubsubsection{\texorpdfstring{barycenter\_kneighbors\_graph()}{barycenter\_kneighbors\_graph()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1manifold_1_1__locally__linear_a28d74ad2b04cf9efd21547a612bcdc0a} 
sklearn.\+manifold.\+\_\+locally\+\_\+linear.\+barycenter\+\_\+kneighbors\+\_\+graph (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{}]{n\+\_\+neighbors}{, }\item[{}]{reg}{ = {\ttfamily 1e-\/3}, }\item[{}]{n\+\_\+jobs}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Computes the barycenter weighted graph of k-Neighbors for points in X

Parameters
----------
X : {array-like, NearestNeighbors}
    Sample data, shape = (n_samples, n_features), in the form of a
    numpy array or a NearestNeighbors object.

n_neighbors : int
    Number of neighbors for each sample.

reg : float, default=1e-3
    Amount of regularization when solving the least-squares
    problem. Only relevant if mode='barycenter'. If None, use the
    default.

n_jobs : int or None, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
    for more details.

Returns
-------
A : sparse matrix in CSR format, shape = [n_samples, n_samples]
    A[i, j] is assigned the weight of edge that connects i to j.

See Also
--------
sklearn.neighbors.kneighbors_graph
sklearn.neighbors.radius_neighbors_graph
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__locally__linear_8py_source_l00082}{82}} of file \mbox{\hyperlink{__locally__linear_8py_source}{\+\_\+locally\+\_\+linear.\+py}}.



References \mbox{\hyperlink{__locally__linear_8py_source_l00028}{barycenter\+\_\+weights()}}.



Referenced by \mbox{\hyperlink{__locally__linear_8py_source_l00126}{null\+\_\+space()}}.

\Hypertarget{namespacesklearn_1_1manifold_1_1__locally__linear_a54d10d8b2cb41cf4a6bb1ce465336f70}\index{sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}!barycenter\_weights@{barycenter\_weights}}
\index{barycenter\_weights@{barycenter\_weights}!sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}}
\doxysubsubsection{\texorpdfstring{barycenter\_weights()}{barycenter\_weights()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1manifold_1_1__locally__linear_a54d10d8b2cb41cf4a6bb1ce465336f70} 
sklearn.\+manifold.\+\_\+locally\+\_\+linear.\+barycenter\+\_\+weights (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{}]{Y}{, }\item[{}]{indices}{, }\item[{}]{reg}{ = {\ttfamily 1e-\/3}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute barycenter weights of X from Y along the first axis

We estimate the weights to assign to each point in Y[indices] to recover
the point X[i]. The barycenter weights sum to 1.

Parameters
----------
X : array-like, shape (n_samples, n_dim)

Y : array-like, shape (n_samples, n_dim)

indices : array-like, shape (n_samples, n_dim)
        Indices of the points in Y used to compute the barycenter

reg : float, default=1e-3
    Amount of regularization to add for the problem to be
    well-posed in the case of n_neighbors > n_dim

Returns
-------
B : array-like, shape (n_samples, n_neighbors)

Notes
-----
See developers note for more information.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__locally__linear_8py_source_l00028}{28}} of file \mbox{\hyperlink{__locally__linear_8py_source}{\+\_\+locally\+\_\+linear.\+py}}.



Referenced by \mbox{\hyperlink{__locally__linear_8py_source_l00082}{barycenter\+\_\+kneighbors\+\_\+graph()}}, and \mbox{\hyperlink{__locally__linear_8py_source_l00850}{sklearn.\+manifold.\+\_\+locally\+\_\+linear.\+Locally\+Linear\+Embedding.\+transform()}}.

\Hypertarget{namespacesklearn_1_1manifold_1_1__locally__linear_a3975e88970c93d695cdd76716336f05e}\index{sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}!locally\_linear\_embedding@{locally\_linear\_embedding}}
\index{locally\_linear\_embedding@{locally\_linear\_embedding}!sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}}
\doxysubsubsection{\texorpdfstring{locally\_linear\_embedding()}{locally\_linear\_embedding()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1manifold_1_1__locally__linear_a3975e88970c93d695cdd76716336f05e} 
sklearn.\+manifold.\+\_\+locally\+\_\+linear.\+locally\+\_\+linear\+\_\+embedding (\begin{DoxyParamCaption}\item[{}]{X}{, }\item[{\texorpdfstring{$\ast$}{*}}]{}{, }\item[{}]{n\+\_\+neighbors}{, }\item[{}]{n\+\_\+components}{, }\item[{}]{reg}{ = {\ttfamily 1e-\/3}, }\item[{}]{eigen\+\_\+solver}{ = {\ttfamily "{}auto"{}}, }\item[{}]{tol}{ = {\ttfamily 1e-\/6}, }\item[{}]{max\+\_\+iter}{ = {\ttfamily 100}, }\item[{}]{method}{ = {\ttfamily "{}standard"{}}, }\item[{}]{hessian\+\_\+tol}{ = {\ttfamily 1e-\/4}, }\item[{}]{modified\+\_\+tol}{ = {\ttfamily 1e-\/12}, }\item[{}]{random\+\_\+state}{ = {\ttfamily None}, }\item[{}]{n\+\_\+jobs}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Perform a Locally Linear Embedding analysis on the data.

Read more in the :ref:`User Guide <locally_linear_embedding>`.

Parameters
----------
X : {array-like, NearestNeighbors}
    Sample data, shape = (n_samples, n_features), in the form of a
    numpy array or a NearestNeighbors object.

n_neighbors : int
    Number of neighbors to consider for each point.

n_components : int
    Number of coordinates for the manifold.

reg : float, default=1e-3
    Regularization constant, multiplies the trace of the local covariance
    matrix of the distances.

eigen_solver : {'auto', 'arpack', 'dense'}, default='auto'
    auto : algorithm will attempt to choose the best method for input data

    arpack : use arnoldi iteration in shift-invert mode.
                For this method, M may be a dense matrix, sparse matrix,
                or general linear operator.
                Warning: ARPACK can be unstable for some problems.  It is
                best to try several random seeds in order to check results.

    dense  : use standard dense matrix operations for the eigenvalue
                decomposition.  For this method, M must be an array
                or matrix type.  This method should be avoided for
                large problems.

tol : float, default=1e-6
    Tolerance for 'arpack' method
    Not used if eigen_solver=='dense'.

max_iter : int, default=100
    Maximum number of iterations for the arpack solver.

method : {'standard', 'hessian', 'modified', 'ltsa'}, default='standard'
    standard : use the standard locally linear embedding algorithm.
               see reference [1]_
    hessian  : use the Hessian eigenmap method.  This method requires
               n_neighbors > n_components * (1 + (n_components + 1) / 2.
               see reference [2]_
    modified : use the modified locally linear embedding algorithm.
               see reference [3]_
    ltsa     : use local tangent space alignment algorithm
               see reference [4]_

hessian_tol : float, default=1e-4
    Tolerance for Hessian eigenmapping method.
    Only used if method == 'hessian'.

modified_tol : float, default=1e-12
    Tolerance for modified LLE method.
    Only used if method == 'modified'.

random_state : int, RandomState instance, default=None
    Determines the random number generator when ``solver`` == 'arpack'.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary <random_state>`.

n_jobs : int or None, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
    for more details.

Returns
-------
Y : ndarray of shape (n_samples, n_components)
    Embedding vectors.

squared_error : float
    Reconstruction error for the embedding vectors. Equivalent to
    ``norm(Y - W Y, 'fro')**2``, where W are the reconstruction weights.

References
----------

.. [1] Roweis, S. & Saul, L. Nonlinear dimensionality reduction
    by locally linear embedding.  Science 290:2323 (2000).
.. [2] Donoho, D. & Grimes, C. Hessian eigenmaps: Locally
    linear embedding techniques for high-dimensional data.
    Proc Natl Acad Sci U S A.  100:5591 (2003).
.. [3] `Zhang, Z. & Wang, J. MLLE: Modified Locally Linear
    Embedding Using Multiple Weights.
    <https://citeseerx.ist.psu.edu/doc_view/pid/0b060fdbd92cbcc66b383bcaa9ba5e5e624d7ee3>`_
.. [4] Zhang, Z. & Zha, H. Principal manifolds and nonlinear
    dimensionality reduction via tangent space alignment.
    Journal of Shanghai Univ.  8:406 (2004)

Examples
--------
>>> from sklearn.datasets import load_digits
>>> from sklearn.manifold import locally_linear_embedding
>>> X, _ = load_digits(return_X_y=True)
>>> X.shape
(1797, 64)
>>> embedding, _ = locally_linear_embedding(X[:100],n_neighbors=5, n_components=2)
>>> embedding.shape
(100, 2)
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__locally__linear_8py_source_l00465}{465}} of file \mbox{\hyperlink{__locally__linear_8py_source}{\+\_\+locally\+\_\+linear.\+py}}.

\Hypertarget{namespacesklearn_1_1manifold_1_1__locally__linear_ae9628b4f26e82cee77c287a7fc60516b}\index{sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}!null\_space@{null\_space}}
\index{null\_space@{null\_space}!sklearn.manifold.\_locally\_linear@{sklearn.manifold.\_locally\_linear}}
\doxysubsubsection{\texorpdfstring{null\_space()}{null\_space()}}
{\footnotesize\ttfamily \label{namespacesklearn_1_1manifold_1_1__locally__linear_ae9628b4f26e82cee77c287a7fc60516b} 
sklearn.\+manifold.\+\_\+locally\+\_\+linear.\+null\+\_\+space (\begin{DoxyParamCaption}\item[{}]{M}{, }\item[{}]{k}{, }\item[{}]{k\+\_\+skip}{ = {\ttfamily 1}, }\item[{}]{eigen\+\_\+solver}{ = {\ttfamily "{}arpack"{}}, }\item[{}]{tol}{ = {\ttfamily 1e-\/6}, }\item[{}]{max\+\_\+iter}{ = {\ttfamily 100}, }\item[{}]{random\+\_\+state}{ = {\ttfamily None}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Find the null space of a matrix M.

Parameters
----------
M : {array, matrix, sparse matrix, LinearOperator}
    Input covariance matrix: should be symmetric positive semi-definite

k : int
    Number of eigenvalues/vectors to return

k_skip : int, default=1
    Number of low eigenvalues to skip.

eigen_solver : {'auto', 'arpack', 'dense'}, default='arpack'
    auto : algorithm will attempt to choose the best method for input data
    arpack : use arnoldi iteration in shift-invert mode.
                For this method, M may be a dense matrix, sparse matrix,
                or general linear operator.
                Warning: ARPACK can be unstable for some problems.  It is
                best to try several random seeds in order to check results.
    dense  : use standard dense matrix operations for the eigenvalue
                decomposition.  For this method, M must be an array
                or matrix type.  This method should be avoided for
                large problems.

tol : float, default=1e-6
    Tolerance for 'arpack' method.
    Not used if eigen_solver=='dense'.

max_iter : int, default=100
    Maximum number of iterations for 'arpack' method.
    Not used if eigen_solver=='dense'

random_state : int, RandomState instance, default=None
    Determines the random number generator when ``solver`` == 'arpack'.
    Pass an int for reproducible results across multiple function calls.
    See :term:`Glossary <random_state>`.
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__locally__linear_8py_source_l00124}{124}} of file \mbox{\hyperlink{__locally__linear_8py_source}{\+\_\+locally\+\_\+linear.\+py}}.



References \mbox{\hyperlink{__locally__linear_8py_source_l00082}{barycenter\+\_\+kneighbors\+\_\+graph()}}, and \mbox{\hyperlink{__locally__linear_8py_source_l00126}{null\+\_\+space()}}.



Referenced by \mbox{\hyperlink{__locally__linear_8py_source_l00126}{null\+\_\+space()}}.

