\doxysection{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer Class Reference}
\hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer}{}\label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer}\index{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}}


Inheritance diagram for sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer\+:
% FIG 0
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a5695074d302d0ce580863d1cba1731aa}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, learning\+\_\+rate\+\_\+init=0.\+1)
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a840bd3275bac4a6db219ca7370977baf}{update\+\_\+params}} (self, params, grads)
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a23867e22d6b166756b2cf4faebc12c9d}{iteration\+\_\+ends}} (self, time\+\_\+step)
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_aeeb3ca05e9540cba44a543cd9a39cc87}{trigger\+\_\+stopping}} (self, msg, verbose)
\end{DoxyCompactItemize}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_ab5689b36eec135b26ea1378a0c1e0ac2}{learning\+\_\+rate\+\_\+init}} = learning\+\_\+rate\+\_\+init
\item 
\mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a909a1524f14f1c374998e353818c5830}{learning\+\_\+rate}} = float(learning\+\_\+rate\+\_\+init)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Base (Stochastic) gradient descent optimizer

Parameters
----------
learning_rate_init : float, default=0.1
    The initial learning rate used. It controls the step-size in updating
    the weights

Attributes
----------
learning_rate : float
    the current learning rate
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00009}{9}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a5695074d302d0ce580863d1cba1731aa}\index{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}}
\doxysubsubsection{\texorpdfstring{\_\_init\_\_()}{\_\_init\_\_()}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a5695074d302d0ce580863d1cba1731aa} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{learning\+\_\+rate\+\_\+init}{ = {\ttfamily 0.1}}\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00024}{24}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



Referenced by \mbox{\hyperlink{kernels_8py_source_l00178}{sklearn.\+gaussian\+\_\+process.\+kernels.\+Kernel.\+get\+\_\+params()}}.



\doxysubsection{Member Function Documentation}
\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a23867e22d6b166756b2cf4faebc12c9d}\index{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}!iteration\_ends@{iteration\_ends}}
\index{iteration\_ends@{iteration\_ends}!sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}}
\doxysubsubsection{\texorpdfstring{iteration\_ends()}{iteration\_ends()}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a23867e22d6b166756b2cf4faebc12c9d} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+iteration\+\_\+ends (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{time\+\_\+step}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Perform update to learning rate and potentially other states at the
end of an iteration
\end{DoxyVerb}
 

Reimplemented in \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a94cef6294a4a466a5954ae16135d2a59}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer}}.



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00045}{45}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.

\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_aeeb3ca05e9540cba44a543cd9a39cc87}\index{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}!trigger\_stopping@{trigger\_stopping}}
\index{trigger\_stopping@{trigger\_stopping}!sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}}
\doxysubsubsection{\texorpdfstring{trigger\_stopping()}{trigger\_stopping()}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_aeeb3ca05e9540cba44a543cd9a39cc87} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+trigger\+\_\+stopping (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{msg}{, }\item[{}]{verbose}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Decides whether it is time to stop training

Parameters
----------
msg : str
    Message passed in for verbose output

verbose : bool
    Print message to stdin if True

Returns
-------
is_stopping : bool
    True if training needs to stop
\end{DoxyVerb}
 

Reimplemented in \mbox{\hyperlink{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1SGDOptimizer_a89122ecbecd6649d51b412b3e3886f81}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer}}.



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00051}{51}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.

\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a840bd3275bac4a6db219ca7370977baf}\index{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}!update\_params@{update\_params}}
\index{update\_params@{update\_params}!sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}}
\doxysubsubsection{\texorpdfstring{update\_params()}{update\_params()}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a840bd3275bac4a6db219ca7370977baf} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+update\+\_\+params (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{params}{, }\item[{}]{grads}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Update parameters with given gradients

Parameters
----------
params : list of length = len(coefs_) + len(intercepts_)
    The concatenated list containing coefs_ and intercepts_ in MLP
    model. Used for initializing velocities and updating params

grads : list of length = len(params)
    Containing gradients with respect to coefs_ and intercepts_ in MLP
    model. So length should be aligned with params
\end{DoxyVerb}
 

Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00028}{28}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



References \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00255}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Adam\+Optimizer.\+\_\+get\+\_\+updates()}}, and \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00168}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+\_\+get\+\_\+updates()}}.



\doxysubsection{Member Data Documentation}
\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a909a1524f14f1c374998e353818c5830}\index{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}!learning\_rate@{learning\_rate}}
\index{learning\_rate@{learning\_rate}!sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}}
\doxysubsubsection{\texorpdfstring{learning\_rate}{learning\_rate}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_a909a1524f14f1c374998e353818c5830} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+learning\+\_\+rate = float(learning\+\_\+rate\+\_\+init)}



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00026}{26}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



Referenced by \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00255}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Adam\+Optimizer.\+\_\+get\+\_\+updates()}}, \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00168}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+\_\+get\+\_\+updates()}}, \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00137}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+iteration\+\_\+ends()}}, and \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00152}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+trigger\+\_\+stopping()}}.

\Hypertarget{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_ab5689b36eec135b26ea1378a0c1e0ac2}\index{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}!learning\_rate\_init@{learning\_rate\_init}}
\index{learning\_rate\_init@{learning\_rate\_init}!sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer@{sklearn.neural\_network.\_stochastic\_optimizers.BaseOptimizer}}
\doxysubsubsection{\texorpdfstring{learning\_rate\_init}{learning\_rate\_init}}
{\footnotesize\ttfamily \label{classsklearn_1_1neural__network_1_1__stochastic__optimizers_1_1BaseOptimizer_ab5689b36eec135b26ea1378a0c1e0ac2} 
sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Base\+Optimizer.\+learning\+\_\+rate\+\_\+init = learning\+\_\+rate\+\_\+init}



Definition at line \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00025}{25}} of file \mbox{\hyperlink{__stochastic__optimizers_8py_source}{\+\_\+stochastic\+\_\+optimizers.\+py}}.



Referenced by \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00255}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+Adam\+Optimizer.\+\_\+get\+\_\+updates()}}, and \mbox{\hyperlink{__stochastic__optimizers_8py_source_l00137}{sklearn.\+neural\+\_\+network.\+\_\+stochastic\+\_\+optimizers.\+SGDOptimizer.\+iteration\+\_\+ends()}}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/jam/\+Research/\+IRES-\/2025/dev/src/llm-\/scripts/testing/hypothesis-\/testing/hyp-\/env/lib/python3.\+12/site-\/packages/sklearn/neural\+\_\+network/\+\_\+stochastic\+\_\+optimizers.\+py\end{DoxyCompactItemize}
