name: embed_check


on:

  push:
    branches: [ embed ]

jobs:
  kaggle-embedding:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'


      - name: Install dependencies
        run: |
          pip install kaggle requests


      - name: Setup Kaggle credentials
        run: |
          mkdir -p ~/.kaggle
          echo '{"username":"${{ secrets.KAGGLE_USERNAME }}","key":"${{ secrets.KAGGLE_KEY }}"}' > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      - name: Create and run Kaggle kernel
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          # Create kernel script that includes the repository code
          cat > kaggle_runner.py << 'EOF'
          import os
          import subprocess
          import sys


          # Set environment variables
          os.environ['HF_TOKEN'] = '${{ secrets.HF_TOKEN }}'

          # Clone repository
          subprocess.run(['git', 'clone', '-b', 'embed', 'https://github.com/camithilwen/code-cloning-analysis'], check=True)
          os.chdir('code-cloning-analysis/src/')

          # Install UV
          subprocess.run('curl -LsSf https://astral.sh/uv/install.sh | sh', shell=True, check=True)

          # Add UV to path
          uv_path = os.path.expanduser('~/.cargo/bin')
          os.environ['PATH'] = f"{uv_path}:{os.environ['PATH']}"

          # Create .env file
          with open('.env', 'w') as f:
              f.write(f"HF_TOKEN={os.environ.get('HF_TOKEN', '')}\n")

          # Run main script
          subprocess.run(['uv', 'run', '--env-file', '.env', 'embed/main.py'], check=True)
          #add auto run of check script here
          subprocess.run(['uv', 'run', 'db_check/check.py'], check=True)

          # Check for database files
          embed_data_dir = 'embed/data'
          if os.path.exists(embed_data_dir):
              db_files = [f for f in os.listdir(embed_data_dir) if f.startswith('embeddings_pair_') and f.endswith('.db')]
              print(f"Found {len(db_files)} database files:")
              for db_file in db_files:
                  full_path = os.path.join(embed_data_dir, db_file)
                  size = os.path.getsize(full_path)
                  print(f"  - {db_file}: {size} bytes")
          else:
              print("embed/data directory not found!")
              print("Available files:", os.listdir('.'))
          EOF


          # Create kernel metadata
          cat > kernel-metadata.json << EOF
          {
            "id": "${{ secrets.KAGGLE_USERNAME }}/code-embedding-pipeline",
            "title": "Code Embedding Pipeline",
            "code_file": "kaggle_runner.py",
            "language": "python",
            "kernel_type": "script",
            "is_private": true,
            "enable_gpu": true,
            "enable_internet": true,
            "dataset_sources": [],
            "competition_sources": [],
            "kernel_sources": []
          }
          EOF


          # Push kernel and capture the version
          echo "Pushing kernel to Kaggle..."
          kaggle kernels push

      - name: Wait for Kaggle Execution
        run: |
          echo "Waiting for Kaggle kernel execution to complete..."

          # Get kernel status and wait for completion
          KERNEL_REF="code-embedding-pipeline"

          # Wait for kernel to complete (max 30 minutes)
          MAX_WAIT=1800
          WAIT_TIME=0
          SLEEP_INTERVAL=240

          while [ $WAIT_TIME -lt $MAX_WAIT ]; do
            echo "Checking kernel status... (${WAIT_TIME}s elapsed)"

            # Get kernel status
            STATUS=$(kaggle kernels status $KERNEL_REF)
            echo "Current status: $STATUS"

            if [ "${STATUS}" = 'code-embedding-pipeline has status "KernelWorkerStatus.COMPLETE"' ]; then
              echo "âœ… Kernel execution completed successfully!"
              break
            elif [ "${STATUS}" = 'code-embedding-pipeline has status "KernelWorkerStatus.ERROR"' ]; then
              echo "âŒ Kernel execution failed!"
              kaggle kernels output $KERNEL_REF --path ./kaggle_output
              exit 1
            elif [ "${STATUS}" = 'code-embedding-pipeline has status "KernelWorkerStatus.RUNNING"' ]; then
              echo "â³ Kernel is still running..."
            fi

            sleep $SLEEP_INTERVAL
            WAIT_TIME=$((WAIT_TIME + SLEEP_INTERVAL))
          done

          if [ $WAIT_TIME -ge $MAX_WAIT ]; then
            echo "â° Kernel execution timed out after 30 minutes"
            exit 1
          fi

      - name: Download Kaggle Output
        run: |
          echo "Downloading Kaggle kernel output..."

          KERNEL_REF="code-embedding-pipeline"

          # Download kernel output
          mkdir -p ./kaggle_output
          kaggle kernels output $KERNEL_REF --path ./kaggle_output

          echo "Downloaded files:"
          find ./kaggle_output -type f | head -20

          # Search for all database files in the output
          echo "Searching for embeddings_pair_*.db files in output..."
          find ./kaggle_output -name "embeddings_pair_*.db" -type f

      - name: Extract and Process Database Files
        run: |
          echo "Searching for embeddings_pair_*.db files..."

          # Search for all database files
          DB_FILES=$(find ./kaggle_output -name "embeddings_pair_*.db" -type f)
          DB_COUNT=$(echo "$DB_FILES" | grep -c "embeddings_pair_" || echo "0")

          echo "Found $DB_COUNT database files"

          if [ "$DB_COUNT" -gt 0 ]; then
            echo "âœ… Found database files:"

            # Create a clean directory for the artifacts
            mkdir -p ./database_artifacts

            # Copy each database file to the artifacts directory
            for db_file in $DB_FILES; do
              filename=$(basename "$db_file")
              echo "Processing: $filename ($(stat -c%s "$db_file") bytes)"
              cp "$db_file" "./database_artifacts/$filename"
            done

            echo "âœ… Database files prepared for artifact upload"
            echo "DATABASE_COUNT=$DB_COUNT" >> $GITHUB_ENV

            # Verify the copied files
            echo "Verifying copied files:"
            for copied_file in ./database_artifacts/embeddings_pair_*.db; do
              if [ -f "$copied_file" ]; then
                echo "âœ… Verified: $(basename "$copied_file") ($(stat -c%s "$copied_file") bytes)"
              else
                echo "âŒ Error: Failed to copy $(basename "$copied_file")"
              fi
            done

          else
            echo "âŒ No database files found in Kaggle output"
            echo "All files in kaggle_output:"
            find ./kaggle_output -type f | head -30
            echo "DATABASE_COUNT=0" >> $GITHUB_ENV
          fi

      - name: Upload Database Artifacts
        if: env.DATABASE_COUNT != '0'
        uses: actions/upload-artifact@v4
        with:
          name: embeddings-databases
          path: ./database_artifacts/
          retention-days: 30
          compression-level: 6
          if-no-files-found: error

      - name: Create Individual Database Artifacts
        if: env.DATABASE_COUNT != '0'
        run: |
          echo "Creating individual artifacts for each database file..."

          # Create individual artifacts for each database
          for db_file in ./database_artifacts/embeddings_pair_*.db; do
            if [ -f "$db_file" ]; then
              filename=$(basename "$db_file" .db)
              artifact_name="embeddings-${filename}"

              echo "Creating artifact: $artifact_name for file: $(basename "$db_file")"

              # Create individual directory
              mkdir -p "./individual_artifacts/$filename"
              cp "$db_file" "./individual_artifacts/$filename/"

              echo "ARTIFACT_${filename}=true" >> $GITHUB_ENV
            fi
          done

      - name: Upload Individual Database Artifacts
        if: env.DATABASE_COUNT != '0'
        run: |
          # Upload each database file as a separate artifact
          for db_dir in ./individual_artifacts/*/; do
            if [ -d "$db_dir" ]; then
              dirname=$(basename "$db_dir")
              artifact_name="embeddings-${dirname}"

              echo "Uploading artifact: $artifact_name"

              # Use GitHub CLI if available, otherwise use actions/upload-artifact in a loop
              # For now, we'll document the files for manual upload
              echo "Prepared individual artifact: $artifact_name in $db_dir"
            fi
          done

      - name: Summary Report
        if: always()
        run: |
          echo "ðŸ” EMBEDDING PIPELINE SUMMARY"
          echo "============================="

          if [ "${DATABASE_COUNT:-0}" -gt 0 ]; then
            echo "âœ… SUCCESS: Created $DATABASE_COUNT database files"
            echo "Database files:"
            for db_file in ./database_artifacts/embeddings_pair_*.db 2>/dev/null || true; do
              if [ -f "$db_file" ]; then
                filename=$(basename "$db_file")
                size=$(stat -c%s "$db_file")
                size_mb=$((size / 1024 / 1024))
                echo "  - $filename: ${size_mb}MB"
              fi
            done

            echo ""
            echo "Artifacts created:"
            echo "  - Main artifact: embeddings-databases (all files)"
            echo "  - Individual artifacts available in individual_artifacts/"

          else
            echo "âŒ FAILURE: No database files created"
          fi

      - name: Failure Diagnostics
        if: failure()
        run: |
          echo "ðŸ” FAILURE DIAGNOSTICS"
          echo "========================"

          echo "Environment variables:"
          echo "DATABASE_COUNT: ${DATABASE_COUNT:-'not set'}"

          echo "Current directory contents:"
          ls -la

          echo "Kaggle output directory:"
          if [ -d "./kaggle_output" ]; then
            find ./kaggle_output -type f | head -20
          else
            echo "No kaggle_output directory found"
          fi

          echo "Checking for any .db files in workspace:"
          find . -name "*.db" -type f 2>/dev/null || echo "No .db files found anywhere"

          # Try to get kernel logs
          KERNEL_REF="${{ secrets.KAGGLE_USERNAME }}/code-embedding-pipeline"
          echo "Attempting to get kernel logs..."
          kaggle kernels output $KERNEL_REF --path ./debug_output 2>/dev/null || echo "Could not retrieve kernel logs"
