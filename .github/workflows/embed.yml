name: embed_check

on:
  push:
    branches: [ embed ]

jobs:
  kaggle-embedding:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run Kaggle Script with UV Environment
        uses: KevKibe/kaggle-script-action@v1.0.5
        with:
          # Kaggle credentials
          username: ${{ secrets.KAGGLE_USERNAME }}
          key: ${{ secrets.KAGGLE_KEY }}

          # Kernel configuration
          title: "Code Embedding Pipeline"
          enable_gpu: true
          enable_internet: true

          # Script to execute (simplified for Kaggle execution)
          custom_script: |
            import os
            import subprocess
            import sys

            # Set environment variables
            os.environ['HF_TOKEN'] = '${{ secrets.HF_TOKEN }}'

            # Clone repository to get the latest code
            print("Cloning repository...")
            subprocess.run(['git', 'clone', '-b', 'embed', 'https://github.com/${{ github.repository }}', 'code-cloning-analysis'], check=True)

            # Change to the source directory
            os.chdir('code-cloning-analysis/src/')
            print(f"Changed to directory: {os.getcwd()}")

            # Install UV package manager
            print("Installing UV package manager...")
            subprocess.run('curl -LsSf https://astral.sh/uv/install.sh | sh', shell=True, check=True)

            # Add UV to path
            uv_path = os.path.expanduser('~/.cargo/bin')
            os.environ['PATH'] = f"{uv_path}:{os.environ['PATH']}"

            # Create .env file for HF token
            print("Creating .env file...")
            with open('.env', 'w') as f:
                f.write(f"HF_TOKEN={os.environ.get('HF_TOKEN', '')}\n")

            # Create embed/data directory to ensure proper path structure
            os.makedirs('embed/data', exist_ok=True)
            print("Created embed/data directory")

            # Run the main embedding script
            print("Starting embedding process...")
            result = subprocess.run(['uv', 'run', '--env-file', '.env', 'embed/main.py'],
                                  capture_output=True, text=True)
            print("STDOUT:", result.stdout)
            if result.stderr:
                print("STDERR:", result.stderr)
            if result.returncode != 0:
                print(f"Embedding script failed with return code: {result.returncode}")
                sys.exit(1)

            # Run the database check script
            print("Running database verification...")
            result = subprocess.run(['uv', 'run', 'db_check/check.py'],
                                  capture_output=True, text=True)
            print("Check script output:", result.stdout)
            if result.stderr:
                print("Check script errors:", result.stderr)

            # Verify database was created
            import os
            db_path = 'embed/data/embeddings.db'
            if os.path.exists(db_path):
                db_size = os.path.getsize(db_path)
                print(f"✅ Database file created successfully!")
                print(f"Database size: {db_size} bytes")

                # List contents of embed/data directory
                print("Contents of embed/data/:")
                for item in os.listdir('embed/data/'):
                    item_path = os.path.join('embed/data/', item)
                    if os.path.isfile(item_path):
                        print(f"  {item} ({os.path.getsize(item_path)} bytes)")
                    else:
                        print(f"  {item} (directory)")
            else:
                print("❌ Database file not found at embed/data/embeddings.db")
                print("Contents of embed/data/:")
                try:
                    for item in os.listdir('embed/data/'):
                        print(f"  {item}")
                except FileNotFoundError:
                    print("embed/data/ directory not found")

                print("Searching for .db files:")
                import glob
                db_files = glob.glob('**/*.db', recursive=True)
                for db_file in db_files:
                    print(f"  Found: {db_file}")

                sys.exit(1)

      - name: Wait for Kaggle Execution
        run: |
          echo "Waiting for Kaggle kernel execution to complete..."
          echo "The kernel will run on Kaggle's infrastructure."
          echo "Check the action logs above for execution details."
          sleep 30

      - name: Download Kaggle Output
        run: |
          echo "Attempting to download Kaggle kernel output..."

          # The action should have created output files
          # Check if any output was downloaded by the action
          if [ -d "./output" ]; then
            echo "Output directory found:"
            find ./output -type f | head -20
          else
            echo "No output directory found from Kaggle action"
          fi

          # Also check current directory for any .db files
          echo "Searching for database files in current directory:"
          find . -name "*.db" -type f 2>/dev/null || echo "No .db files found"

      - name: Extract and Upload Database
        run: |
          echo "Searching for embeddings.db..."

          # Search in multiple possible locations
          DB_FILE=""

          # Check output directory first
          if [ -d "./output" ]; then
            DB_FILE=$(find ./output -name "embeddings.db" -type f | head -1)
          fi

          # Check current directory
          if [ -z "$DB_FILE" ]; then
            DB_FILE=$(find . -name "embeddings.db" -type f | head -1)
          fi

          # Check for any .db files
          if [ -z "$DB_FILE" ]; then
            DB_FILE=$(find . -name "*.db" -type f | grep -i embed | head -1)
          fi

          if [ -n "$DB_FILE" ]; then
            echo "✅ Found database file: $DB_FILE"

            # Create staging directory and copy file
            mkdir -p ./database_artifact
            cp "$DB_FILE" ./database_artifact/embeddings.db

            echo "Database file prepared:"
            ls -la ./database_artifact/
            echo "File size: $(stat -c%s ./database_artifact/embeddings.db) bytes"

            # Upload as artifact
            echo "Database file ready for artifact upload"
          else
            echo "❌ No database file found"
            echo "All files in workspace:"
            find . -type f | head -30

            # Don't exit with error - this will be handled by conditional upload
            echo "DATABASE_FOUND=false" >> $GITHUB_ENV
          fi

      - name: Upload Database Artifact
        if: env.DATABASE_FOUND != 'false'
        uses: actions/upload-artifact@v4
        with:
          name: embeddings-database
          path: ./database_artifact/embeddings.db
          retention-days: 30
          compression-level: 6
          if-no-files-found: warn
