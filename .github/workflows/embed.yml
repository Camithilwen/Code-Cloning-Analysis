name: embed_check

on:
  push:
    branches: [ embed ]

jobs:
  kaggle-embedding:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install kaggle requests

      - name: Setup Kaggle credentials
        run: |
          mkdir -p ~/.kaggle
          echo '{"username":"${{ secrets.KAGGLE_USERNAME }}","key":"${{ secrets.KAGGLE_KEY }}"}' > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      - name: Create and run Kaggle kernel
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          # Create kernel script that includes the repository code
          cat > kaggle_runner.py << 'EOF'
          import os
          import subprocess
          import sys

          # Set environment variables
          os.environ['HF_TOKEN'] = '${{ secrets.HF_TOKEN }}'

          # Clone repository
          subprocess.run(['git', 'clone', '-b', 'embed', 'https://github.com/camithilwen/code-cloning-analysis'], check=True)
          os.chdir('code-cloning-analysis/src/')

          # Install UV
          subprocess.run('curl -LsSf https://astral.sh/uv/install.sh | sh', shell=True, check=True)

          # Add UV to path
          uv_path = os.path.expanduser('~/.cargo/bin')
          os.environ['PATH'] = f"{uv_path}:{os.environ['PATH']}"

          # Create .env file
          with open('.env', 'w') as f:
              f.write(f"HF_TOKEN={os.environ.get('HF_TOKEN', '')}\n")

          # Run main script
          subprocess.run(['uv', 'run', '--env-file', '.env', 'embed/main.py'], check=True)
          #add auto run of check script here
          #subprocess.run(['uv', 'run', 'db_check/check.py'], check=True)

          # Check for database files (now multiple files)
          embed_data_path = 'embed/data'
          if os.path.exists(embed_data_path):
              db_files = [f for f in os.listdir(embed_data_path) if f.startswith('embeddings_') and f.endswith('.db')]
              if db_files:
                  print(f"Found {len(db_files)} database files:")
                  for db_file in db_files:
                      full_path = os.path.join(embed_data_path, db_file)
                      print(f"  {db_file}: {os.path.getsize(full_path)} bytes")
              else:
                  print("No database files found!")
                  print("Available files in embed/data:", os.listdir(embed_data_path))
          else:
              print("embed/data directory not found!")
              print("Available files:", os.listdir('.'))
          EOF

          # Create kernel metadata
          cat > kernel-metadata.json << EOF
          {
            "id": "${{ secrets.KAGGLE_USERNAME }}/code-embedding-pipeline",
            "title": "Code Embedding Pipeline",
            "code_file": "kaggle_runner.py",
            "language": "python",
            "kernel_type": "script",
            "is_private": true,
            "enable_gpu": true,
            "enable_internet": true,
            "dataset_sources": [],
            "competition_sources": [],
            "kernel_sources": []
          }
          EOF

          # Push kernel and capture the version
          echo "Pushing kernel to Kaggle..."
          kaggle kernels push

      - name: Wait for Kaggle Execution
        run: |
          echo "Waiting for Kaggle kernel execution to complete..."

          # Get kernel status and wait for completion
          KERNEL_REF="code-embedding-pipeline"

          # Wait for kernel to complete (max 30 minutes)
          MAX_WAIT=43200
          WAIT_TIME=0
          SLEEP_INTERVAL=240

          while [ $WAIT_TIME -lt $MAX_WAIT ]; do
            echo "Checking kernel status... (${WAIT_TIME}s elapsed)"

            # Get kernel status
            STATUS=$(kaggle kernels status $KERNEL_REF)
            echo "Current status: $STATUS"

            if [ "${STATUS}" = 'code-embedding-pipeline has status "KernelWorkerStatus.COMPLETE"' ]; then
              echo "✅ Kernel execution completed successfully!"
              break
            elif [ "${STATUS}" = 'code-embedding-pipeline has status "KernelWorkerStatus.ERROR"' ]; then
              echo "❌ Kernel execution failed!"
              kaggle kernels output $KERNEL_REF --path ./kaggle_output
              exit 1
            elif [ "${STATUS}" = 'code-embedding-pipeline has status "KernelWorkerStatus.RUNNING"' ]; then
              echo "⏳ Kernel is still running..."
            fi

            sleep $SLEEP_INTERVAL
            WAIT_TIME=$((WAIT_TIME + SLEEP_INTERVAL))
          done

          if [ $WAIT_TIME -ge $MAX_WAIT ]; then
            echo "⏰ Kernel execution timed out after 12 hours"
            exit 1
          fi

      - name: Download Kaggle Output
        run: |
          echo "Downloading Kaggle kernel output..."

          KERNEL_REF="code-embedding-pipeline"

          # Download kernel output
          mkdir -p ./kaggle_output
          kaggle kernels output $KERNEL_REF --path ./kaggle_output

          echo "Downloaded files:"
          find ./kaggle_output -type f | head -20

          # Search for all database files in the output
          echo "Searching for database files in output..."
          find ./kaggle_output -name "embeddings_*.db" -type f

      - name: Extract and Process Database Files
        run: |
          echo "Searching for database files..."

          # Search for all database files
          DB_FILES=$(find ./kaggle_output -name "embeddings_*.db" -type f)

          if [ -n "$DB_FILES" ]; then
            echo "✅ Found database files:"
            echo "$DB_FILES"

            # Create a clean directory for the artifacts
            mkdir -p ./database_artifacts

            # Copy each database file to a predictable location
            DB_COUNT=0
            for DB_FILE in $DB_FILES; do
              BASENAME=$(basename "$DB_FILE")
              echo "Processing: $BASENAME ($(stat -c%s "$DB_FILE") bytes)"

              cp "$DB_FILE" "./database_artifacts/$BASENAME"
              DB_COUNT=$((DB_COUNT + 1))
            done

            echo "✅ $DB_COUNT database files prepared for artifact upload"
            echo "DATABASE_COUNT=$DB_COUNT" >> $GITHUB_ENV
            echo "DATABASES_FOUND=true" >> $GITHUB_ENV

            # Verify the copied files
            echo "Verifying copied files:"
            for COPIED_FILE in ./database_artifacts/embeddings_*.db; do
              if [ -f "$COPIED_FILE" ]; then
                echo "✅ $(basename "$COPIED_FILE"): $(stat -c%s "$COPIED_FILE") bytes"
              fi
            done

          else
            echo "❌ No database files found in Kaggle output"
            echo "All files in kaggle_output:"
            find ./kaggle_output -type f | head -30
            echo "DATABASES_FOUND=false" >> $GITHUB_ENV
          fi

      - name: Upload Database Artifacts
        if: env.DATABASES_FOUND == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: embeddings-databases
          path: ./database_artifacts/
          retention-days: 30
          compression-level: 6
          if-no-files-found: error

      - name: Summary
        if: env.DATABASES_FOUND == 'true'
        run: |
          echo "🎉 SUCCESS SUMMARY"
          echo "=================="
          echo "Successfully processed $DATABASE_COUNT repository pairs"
          echo "Created $DATABASE_COUNT separate Milvus database files"
          echo ""
          echo "Artifact contents:"
          ls -la ./database_artifacts/

      - name: Failure Diagnostics
        if: failure()
        run: |
          echo "🔍 FAILURE DIAGNOSTICS"
          echo "========================"

          echo "Environment variables:"
          echo "DATABASES_FOUND: $DATABASES_FOUND"
          echo "DATABASE_COUNT: $DATABASE_COUNT"

          echo "Current directory contents:"
          ls -la

          echo "Kaggle output directory:"
          if [ -d "./kaggle_output" ]; then
            find ./kaggle_output -type f | head -20
          else
            echo "No kaggle_output directory found"
          fi

          echo "Checking for any .db files in workspace:"
          find . -name "*.db" -type f 2>/dev/null || echo "No .db files found anywhere"

          # Try to get kernel logs
          KERNEL_REF="${{ secrets.KAGGLE_USERNAME }}/code-embedding-pipeline"
          echo "Attempting to get kernel logs..."
          kaggle kernels output $KERNEL_REF --path ./debug_output 2>/dev/null || echo "Could not retrieve kernel logs"
